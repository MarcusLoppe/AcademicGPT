
Machine Learning Interpretability in Malware Detection (2020) by Brigugilio, William Ryan
Abstract:
The ever increasing processing power of modern computers, as well as the increased availability of large and complex data sets, has led to an explosion in machine learning research. This has led to increasingly complex machine learning algorithms, such as Convolutional Neural Networks, with increasingly complex applications, such as malware detection. Recently, malware authors have become increasingly successful in bypassing traditional malware detection methods, partly due to advanced evasion techniques such as obfuscation and server-side polymorphism. Further, new programming paradigms such as fileless malware, that is malware that exist only in the main memory (RAM) of the infected host, add to the challenges faced with modern day malware detection. This has led security specialists to turn to machine learning to augment their malware detection systems. However, with this new technology comes new challenges. One of these challenges is the need for interpretability in machine learning. Machine learning interpretability is the process of giving explanations of a machine learning model\u27s predictions to humans. Rather than trying to understand everything that is learnt by the model, it is an attempt to find intuitive explanations which are simple enough and provide relevant information for downstream tasks. Cybersecurity analysts always prefer interpretable solutions because of the need to fine tune these solutions. If malware analysts can\u27t interpret the reason behind a misclassification, they will not accept the non-interpretable or black box detector. In this thesis, we provide an overview of machine learning and discuss its roll in cyber security, the challenges it faces, and potential improvements to current approaches in the literature. We showcase its necessity as a result of new computing paradigms by implementing a proof of concept fileless malware with JavaScript. We then present techniques for interpreting machine learning based detectors which leverage n-gram analysis and put forward a novel and fully interpretable approach for malware detection which uses convolutional neural networks. We also define a novel approach for evaluating the robustness of a machine learning based detector

FullText:
University of Windsor Scholarship at UWindsor Electronic Theses and Dissertations Theses, Dissertations, and Major Papers 5-21-2020 Machine Learning Interpretability in Malware Detection William Ryan Brigugilio University of Windsor Follow this and additional works at: https://scholar.uwindsor.ca/etd Recommended Citation Brigugilio, William Ryan, "Machine Learning Interpretability in Malware Detection" (2020). Electronic Theses and Dissertations. 8331. https://scholar.uwindsor.ca/etd/8331 This online database contains the full-text of PhD dissertations and Masters’ theses of University of Windsor students from 1954 forward. These documents are made available for personal study and research purposes only, in accordance with the Canadian Copyright Act and the Creative Commons license—CC BY-NC-ND (Attribution, Non-Commercial, No Derivative Works). Under this license, works must always be attributed to the copyright holder (original author), cannot be used for any commercial purposes, and may not be altered. Any other use would require the permission of the copyright holder. Students may inquire about withdrawing their dissertation and/or thesis from this database. For additional inquiries, please contact the repository administrator via email (scholarship@uwindsor.ca) or by telephone at 519-253-3000ext. 3208. Machine Learning Interpretability inMalware DetectionByWilliam R. BriguglioA ThesisSubmitted to the Faculty of Graduate Studiesthrough the School of Computer Sciencein Partial Fulfillment of the Requirements forthe Degree of Master of Scienceat the University of WindsorWindsor, Ontario, Canada2020c©2020 William R. BriguglioMachine Learning Interpretability in Malware DetectionbyWilliam R. BriguglioAPPROVED BY:M. MirhassaniDepartment of Electrical and Computer EngineeringA. NgomSchool of Computer ScienceS. Sherif, AdvisorSchool of Computer ScienceMarch 17, 2019DECLARATION OF CO-AUTHORSHIP AND PREVIOUS PUBLICATIONI. Co-AuthorshipI hereby declare that this thesis incorporates material that is the result of joint re-search, as follows: 



Chapter 2 of the thesis was co-authored with Dr. Saad and Dr.Elmiligi. 



Chapter 3 was co-authored with Dr. Saad and M.Sc. Farhan Mahmood andDr. Elmiligi. 



Chapter 4 was co-authored with Dr. Saad. In the case of 



Chapter 2,which was a position paper, the position was principally arrived at by Dr. Saad andDr. Elmiligi while I read and summarized relevant literature and helped formulatethe final wording in which the position was put forward. For 



Chapter 3, Dr. Saadcontributed the objectives of the paper and important guidance for achieving said ob-jectives as well as proof reading and review of the paper. The implementation of themalicious functionalities of the malware described therein, and the web applicationused to test said malware, was completed in equal parts by Farhan Mahmood andmyself. Farhan also selected various malware detection tools as well as designed andconducted the tests to evaluate the the malware’s ability to bypass said detectors. Inthe case of 



Chapter 4 the key ideas, primary contributions, experimental designs, dataanalysis, interpretation, and writing were performed by myself, and the contributionof the co-author, Dr. Saad, was primarily through valuable guidance and feedbackon refinement of ideas and editing of the paper.I am aware of the University of Windsor Senate Policy on Authorship and I certifythat I have properly acknowledged the contribution of other researchers to my thesis,and have obtained written permission from each of the co-author(s) to include theabove material(s) in my thesis.I certify that, with the above qualification, this thesis, and the research to whichit refers, is the product of my own work.iiiII. Previous PublicationThis thesis includes 3 original papers that have been previously published/submittedfor publication in peer reviewed journals, as follows:Thesis 



Chapter Publication 



Title/full citation Publication Status



Chapter 2 Saad, S.; Briguglio, W. and Elmiligi, H. (2019).The Curious Case of Machine Learning in Mal-ware Detection. In Proceedings of the 5thInternational Conference on Information Sys-tems Security and Privacy - Volume 1: ICISSP,ISBN 978-989-758-359-9, pages 528-535. DOI:10.5220/0007470705280535Published



Chapter 3 Saad, S.; Mahmood, F.; Briguglio, W. andElmiligi, H. (2019) JSLess: A Tale of a FilelessJavascript Memory-Resident Malware. In Pro-ceedings of the 15th International Conference onInformation Security Practice and Experience -Volume 1: ISBN 978-3-030-34338-5, pages 113-131. DOI: 10.1007/978-3-030-34339-2Published



Chapter 4 Briguglio, W. and Saad, S. (2019). Interpret-ing Machine Learning Malware Detectors WhichLeverage N-gram Analysis. In Proceedings ofthe 12th International Symposium on Founda-tions and Practice of SecurityIn PressI certify that I have obtained a written permission from the copyright owner(s)to include the above published material(s) in my thesis. I certify that the abovematerial describes work completed during my registration as a graduate student atthe University of WindsorIII. GeneralI declare that, to the best of my knowledge, my thesis does not infringe upon any-one’s copyright nor violate any proprietary rights and that any ideas, techniques,quotations, or any other material from the work of other people included in my the-sis, published or otherwise, are fully acknowledged in accordance with the standardivreferencing practices. Furthermore, to the extent that I have included copyrightedmaterial that surpasses the bounds of fair dealing within the meaning of the CanadaCopyright Act, I certify that I have obtained a written permission from the copyrightowner(s) to include such material(s) in my thesis.I declare that this is a true copy of my thesis, including any final revisions, asapproved by my thesis committee and the Graduate Studies office, and that this thesishas not been submitted for a higher degree to any other University or Institution.v



AbstractThe ever increasing processing power of modern computers, as well as the increasedavailability of large and complex data sets, has led to an explosion in machine learningresearch. This has led to increasingly complex machine learning algorithms, suchas Convolutional Neural Networks, with increasingly complex applications, such asmalware detection.Recently, malware authors have become increasingly successful in bypassing tra-ditional malware detection methods, partly due to advanced evasion techniques suchas obfuscation and server-side polymorphism. Further, new programming paradigmssuch as fileless malware, that is malware that exist only in the main memory (RAM)of the infected host, add to the challenges faced with modern day malware detection.This has led security specialists to turn to machine learning to augment their malwaredetection systems. However, with this new technology comes new challenges. One ofthese challenges is the need for interpretability in machine learning.Machine learning interpretability is the process of giving explanations of a machinelearning model’s predictions to humans. Rather than trying to understand everythingthat is learnt by the model, it is an attempt to find intuitive explanations which aresimple enough and provide relevant information for downstream tasks. Cybersecurityanalysts always prefer interpretable solutions because of the need to fine tune thesesolutions. If malware analysts can’t interpret the reason behind a misclassification,they will not accept the non-interpretable or “black box” detector.In this thesis, we provide an 

Overview of machine learning and discuss its roll in cy-ber security, the challenges it faces, and potential improvements to current approachesin the literature. We showcase its necessity as a result of new computing paradigmsby implementing a proof of concept fileless malware with JavaScript. We then presenttechniques for interpreting machine learning based detectors which leverage n-gramanalysis and put forward a novel and fully interpretable approach for malware detec-tion which uses convolutional neural networks. We also define a novel approach forevaluating the robustness of a machine learning based detector.vi



AcknowledgementsHere I would like to acknowledge the invaluable mentorship of my supervisor Dr.Sherif, not only during my masters but also during the last year of my undergrad,during which I would not have considered graduate school were it not for his encour-agement.vii



Table of ContentsDECLARATION OF CO-AUTHORSHIP AND PREVIOUS PUBLI-CATION iii



Abstract vi



Acknowledgements vii



List of Tables xi



List of Figures xii1 



Introduction 11.1 Machine Learning Algorithms . . . . . . . . . . . . . . . . . . . . . . 31.2 Machine Learning Interpretability . . . . . . . . . . . . . . . . . . . . 71.3 Machine Learning in Cyber Security . . . . . . . . . . . . . . . . . . . 91.4 Thesis 

Overview . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9



References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 102 The Curious Case of Machine Learning in Malware Detection 112.1 



Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 112.2 



Literature Review . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 132.3 Emerging Malware Threats . . . . . . . . . . . . . . . . . . . . . . . . 152.3.1 Unconventional Computing Paradigms . . . . . . . . . . . . . 152.3.2 Unconventional Evasion Techniques . . . . . . . . . . . . . . . 172.4 Practical Challenges . . . . . . . . . . . . . . . . . . . . . . . . . . . 202.4.1 Cost of Training Detectors . . . . . . . . . . . . . . . . . . . . 202.4.2 Malware Detector Interpretability . . . . . . . . . . . . . . . . 212.4.3 Adversarial Malware . . . . . . . . . . . . . . . . . . . . . . . 212.5 Bridging the Detection Gap . . . . . . . . . . . . . . . . . . . . . . . 222.5.1 Disposable Micro Detectors . . . . . . . . . . . . . . . . . . . 222.5.2 Analyst Friendly Interpretation . . . . . . . . . . . . . . . . . 232.5.3 Anti Adversarial Malware . . . . . . . . . . . . . . . . . . . . 242.6 

Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25



References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 253 JSLess: A Tale of Fileless JavaScript Memory-Resident Malware 313.1 



Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 313.2 



Literature Review . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 343.3 Benign Features with Malicious Potentials . . . . . . . . . . . . . . . 373.3.1 WebSockets . . . . . . . . . . . . . . . . . . . . . . . . . . . . 373.3.2 WebWorker . . . . . . . . . . . . . . . . . . . . . . . . . . . . 383.3.3 ServiceWorker . . . . . . . . . . . . . . . . . . . . . . . . . . . 393.4 JavaScript Fileless Malware . . . . . . . . . . . . . . . . . . . . . . . 40viii3.4.1 Infection 



Scenarios . . . . . . . . . . . . . . . . . . . . . . . . 403.4.2 Operational 



Scenarios . . . . . . . . . . . . . . . . . . . . . . 423.4.3 Attack Vectors . . . . . . . . . . . . . . . . . . . . . . . . . . 463.4.3.1 Data Stealing . . . . . . . . . . . . . . . . . . . . . . 463.4.3.2 DDoS . . . . . . . . . . . . . . . . . . . . . . . . . . 473.4.3.3 Resource Consumption Attack . . . . . . . . . . . . 473.5 Experiment & Evaluation . . . . . . . . . . . . . . . . . . . . . . . . 473.5.1 JS Malware Detection Tools . . . . . . . . . . . . . . . . . . . 483.5.2 Detection & Mitigation . . . . . . . . . . . . . . . . . . . . . . 483.5.3 Detection Tool Analysis 

Results . . . . . . . . . . . . . . . . . 493.6 

Conclusion & 



Future Work . . . . . . . . . . . . . . . . . . . . . . . . 51



References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 524 Interpreting Machine Learning Malware Detectors Which LeverageN-gram Analysis 564.1 



Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 564.2 



Literature Review . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 584.3 Method . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 614.4 Interpretation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 644.4.1 Logistic Regression Model Interpretation . . . . . . . . . . . . 644.4.2 Random Forest Interpretation . . . . . . . . . . . . . . . . . . 694.4.3 Neural Network Model Interpretation . . . . . . . . . . . . . . 724.5 

Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 77



References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 785 Interpreting Machine Learning Malware Detectors Which LeverageConvolutional Neural 815.1 



Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 815.2 



Literature Review . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 835.3 Method . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 875.4 

Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 915.4.1 Evaluation of Our Model . . . . . . . . . . . . . . . . . . . . . 915.4.2 Interpretation . . . . . . . . . . . . . . . . . . . . . . . . . . . 915.4.3 Comparison With Other Models . . . . . . . . . . . . . . . . . 965.5 

Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 98



References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 996 Robustness Metric 1026.1 



Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1026.2 The Robustness Metric . . . . . . . . . . . . . . . . . . . . . . . . . . 1046.3 Method . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1066.4 

Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 109



References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1097 

Conclusion 111ixVITA AUCTORIS 113x



List of Tables1.1.1 Machine Learning Further Readering . . . . . . . . . . . . . . . . . . 73.5.1 JavaScript and Web App Malware Detection Tools . . . . . . . . . . 484.3.1 Class distribution in Data Set . . . . . . . . . . . . . . . . . . . . . . 614.4.1 Max 15 Absolute Weights of the Logistic Regression Model AveragedAcross All 9 Binary Sub-classifiers . . . . . . . . . . . . . . . . . . . . 654.4.2 Max 15 Weights for Kelihos ver3 Binary Sub-classifier . . . . . . . . . 664.4.3 Max Feature 15 Importances for Random Forest . . . . . . . . . . . . 704.4.4 Max Average Absolute Relevances . . . . . . . . . . . . . . . . . . . . 734.4.5 Max Avg Relevances for Class 3 . . . . . . . . . . . . . . . . . . . . . 744.4.6 Layer 1 Nodes relevance to n240 . . . . . . . . . . . . . . . . . . . . . . 765.3.1 Class distribution in Data Set . . . . . . . . . . . . . . . . . . . . . . 885.4.1 Confusion Matrix for Our Model on the Left Out Test Set . . . . . . 965.4.2 Confusion Matrix for Model used in [3]* . . . . . . . . . . . . . . . . 965.4.3 Confusion Matrix for Model used in [6]* . . . . . . . . . . . . . . . . 975.4.4 Model Comparisons . . . . . . . . . . . . . . . . . . . . . . . . . . . . 986.3.1 Robustness Metrics For Trained Models . . . . . . . . . . . . . . . . . 107xi



List of Figures1.1.1 Neural Network with 6 nodes in the input layer, 6 in the hidden layer,and 3 in the output layer . . . . . . . . . . . . . . . . . . . . . . . . . 73.4.1 JavaScript Fileless Malware First Infection Scenario . . . . . . . . . . 413.4.2 JavaScript Fileless Malware Second Infection Scenario . . . . . . . . 423.4.3 Obfuscated JavaScript code injection . . . . . . . . . . . . . . . . . . 445.3.1 Images from two samples from each of the 6 classes. Images in columnslabeled F are the first three channels of the samples interpreted asRGBchannels while the images in columns labeled L are the last threechannels . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 905.3.2 Model Architecture . . . . . . . . . . . . . . . . . . . . . . . . . . . . 905.4.1 Test and Validation Loss History . . . . . . . . . . . . . . . . . . . . 925.4.2 Test and Validation Balanced Categorical Accuracy History . . . . . 925.4.3 0AnoOZDNbPXIr2MRBSCJ Relevance Map . . . . . . . . . . . . . . 935.4.4 Terminal output when working backwards from the relevant 6-gramsto the code snippets . . . . . . . . . . . . . . . . . . . . . . . . . . . 946.3.1 Robustness plots with balanced accuracy on the y-axis and number offeatures deactivated on the x-axis . . . . . . . . . . . . . . . . . . . . 108xii



Chapter 1



IntroductionMachine Learning has come a long way in recent years. There has been a vastamount of papers published in the last decade which offer a number of substantialimprovements on machine learning algorithms both old and new. Along side thisresearch there has also been many papers which study the various applications ofmachine learning algorithms. From perhaps the most well known, even among non-experts, such as machine vision and natural language processing, to the less wellknown but all the while pervasive and significant medical, commercial, and industrialapplications.Machine learning is the study of algorithms which allow computers to preform aspecific task without the use of explicit programming. These algorithms accomplishthis by using statistics and inference techniques to detect or “learn” patterns withindata (hence machine learning is considered a type of pattern recognition). Thesepatterns are then used in various ways to preform a certain task.The data used by the machine learning algorithm, referred to as the “data set”,is typically a table where each row is considered a single record or “sample” and eachcolumn corresponds to a “feature” whose values describe said feature for each samplein the data set. For example, a housing market data set would have a separate rowfor each house and a column for each feature, such as the number of rooms, squarefootage, and so on. In practice, a data set of n samples and m features is an n ×marray (table, matrix, etc.) of values where the ith row of the feature array gives the“feature vector” of the ith sample. Meanwhile, the jth column in the ith row gives the11. 



Introductionvalue of the jth feature for the ith sample. This value is denoted denoted xi,j howeverthe row index i is omitted when the context makes it obvious we are discussing asingle example. The processes of choosing features and determining their value foreach sample are known as feature selection and feature extraction respectively. Insome cases, such as computer vision with neural networks, feature extraction is doneby the machine learning algorithm automatically from raw data such as images (e.g.pixel RGB values).Machine learning can be broadly separated into two categories, supervised andunsupervised learning. In supervised learning, each sample is accompanied by a“label”, and the 1 × n array of labels forms a column vector where the ith element,denoted yi, is the label of the sample ith sample. The machine learning algorithmuses a subset of the data set, called the training set, in order to learn the relationshipbetween the feature values and the label. This learnt relationship is referred to as“the model” and can be used to predict the label of previously unseen samples fromtheir feature values. However, before being used as a predictor, to ensure the modelis effective at making predictions, the trained model makes predictions on a portionof the labeled data set which was left out during training, called the test set. Thepredicted labels are compared with the known labels to see if the predictions arereliable. What is considered reliable is application specific, and as we shall see later,goes far beyond simple metrics such as accuracy.Supervised learning can be further divided into two subcategories, regression andclassification. In the former case, the model predicts a real value such as a the pricea house will sell for. In the latter case, the model predicts a discrete value whichcorresponds to the class of a sample. For example, in binary classification the modelmay predict either 0 or 1 which may correspond to the rejection class or approvalclass of mortgage applicants based on features extracted from financial histories.In the case of unsupervised learning, samples in the data set are not accompaniedby labels and here the objective is to find unknown structure and relationships in thedata. Models trained using unsupervised learning can find anomalous data points oruncover potential classes to be used later in a supervised approach. We hold off on a21. 



Introduction



Discussion of unsupervised machine learning techniques as they are not the focus ofthis thesis.Next we introduce a high level 



Discussion of the machine learning models usedlater in this thesis, specifically in 



Chapter 4. This will serve as a preliminary forunderstanding what is discussed there for readers without a 

Background in machinelearning.1.1 Machine Learning AlgorithmsOne of the most basic and widely used machine learning algorithms is Linear Re-gression. Linear Regression models are used for regression by simply calculating aweighted sum of a sample’s feature values and adding a real valued “bias” whichyields it’s predicted label. The weight of the jth feature is denoted wj resulting in thefollowing equation for predicting a samples label:y =m∑j=1xjwj + β (1)A version of Linear Regression adapted for binary classification is Logistic Regres-sion in which the result of the sigmoid function applied to the weighted sum is usedto determine the label. Since the sigmoid function outputs only values between 0 and1, a sample is predicted to belong to class 0 if it produces an output less than 0.5,otherwise it is predicted to belong to class 1. In the case where there are more thentwo classes, a Logistic Regression model is trained for each class. For the kth LogisticRegression model, only the samples belong to the kth class are labeled 1 and the restare labeled 0. Thus the multi-class scenario is treated as multiple binary classification



Scenarios. During prediction, a sample is predicted as the class whose Logistic Regres-sion model produced the highest output. This is known as one-vs-rest classification.Below is the function a logistic regression model uses to make predictions.y =11 + e−zwhere z is the result of equation 1 (2)31. 



IntroductionSo far we have seen how linear regression and logistic regression models makepredictions, but as of yet we have not discussed how they are trained. Before we cando this we must introduce the idea of the “loss function”. The loss function providesa measure of the error in a models predictions given a set of labeled samples and mustbe differentiable with respect to the parameters of the model which we wish to learn.Here parameters refers to any values which we learn during training, such as featureweights and the bias. (Values which are not learnt during training and are chosenbefore hand are called hyper-parameters.) When we say “differentiable with respectto the parameters we wish to learn”, we are saying that we can determine if increasingone of the parameters by a very small amount will cause the loss function to decreaseor increase. For a more detailed 



Discussion of linear and logistic regression, we referthe reader to [2]Since the loss function is a measure of our model’s error, and we wish to minimizethe error, we also wish to minimize the loss function. Therefore, we determine for eachtrainable parameter whether increasing it or decreasing it will cause the loss functionto decrease and we add/subtract a very small amount to/from the parameter’s valuebased off this. Once we do this for all parameters, we recalculate the loss functionand repeat. Since we cannot jump directly to the values where the loss function isminimized, because the derivative only gives local information about the parameterseffect on the output of the loss function, we must take small steps each iterationand repeat. In this way, making locally optimal decisions with course correctionsalong the way, we ideally arrive at a “global minimum”. That is, the values for theparameters of the model for which the loss function is lowest given the training set.The mathematical construct which specifies the direction to move each parameterin order to minimize the loss function is called the “gradient” and since we use thisgradient to descend the loss function, we call this process gradient descent. Thereare many things to consider when preforming gradient descent, such as the size ofchanges to parameters at each iteration, but we refer the reader to [3] for a morethorough and detailed 



Discussion.Another classic machine learning algorithm is the decision tree. Decision trees41. 



Introductioncan be used for regression or classification but here we will focus on the classificationcase. Decision trees are made up of three parts; a root node, where the decisionprocess starts, leaf nodes, which are at the other end of the tree opposite of the rootnode, and internal nodes, which lay along the path from root to leaf node. Thereis only one path from the root node to any given leaf node. During prediction, thealgorithm moves from the root node, through some internal nodes to a leaf, and thevalue of said leaf node determines the predicted class of the sample. The path whichthe algorithm takes is determined by the value of the sample’s features and “splitconditions” in each of the root and internal nodes, such as xj > 13.Decision trees are trained by using a labeled training set to determine the splitcondition at each node which maximizes the “information gain” in the child nodes.Starting at the root node which is reachable by all training samples, a split is chosenwhich best separates the classes within the training set. This is repeated at the childnodes of the root node, and repeated again for their children and so on, until thechild nodes produced by a splitting condition are only reachable by training exampleswhich all belong to the same class, or some other stopping condition is met, such asmaximum depth of the tree. In the case where the leaf node is reachable by trainingsamples from more then one class, the prediction is the class which the majority ofthose training samples belong to.An extension of the decision tree algorithm is the Random Forest algorithm whichtrains a large number of decision trees on random subsets of the training set, usingrandom subsets of the feature set. At prediction time, each constituent decision treepredicts the class of the sample which counts as a vote for said class. The votesfrom all the sub trees are counted and the class with the most votes is the predictionof the Random Forest. This is known as an ensemble method, and its strength isthat misclassification occurs only if the majority of the constituent decision treesmake a misclassification. Further, since the constituent decision trees all use differentfeature sets and were trained with different training sets, a feature value which isuncommon for one class will not trick all of the constituent decision trees. The endresult is a model which is more stable when encountering unseen data, achieving51. 



Introductionbetter performance. This is known as generalizability. We say a model generalizeswell when it achieves performance which is equal or better with unseen data as withthe training data. For a deeper 



Discussion on random forests we again refer the readerto [2]The last machine learning algorithm which we’ll introduce here is the NeuralNetwork. Neural networks are much more complex then the algorithms discussed sofar but some of the ideas are the same. The standard neural network architectureis the feed forward architecture such as the one shown in figure 1.1.1. This typeof neural network makes predictions as follows. The feature values are inputtedinto their respective input neuron (or node) in the first layer, called the input layer.(i.e. feature xj is inputted to the jth neuron in the input layer.) Next, this valueis propagated along the connections (shown in 1.1.1 as lines connecting the neuron(circles) in different layers) from the input layer to the first hidden layer. Whenthe neurons in the next layer receive the values from the previous layer along theseconnections, they multiply them by the weight associated with each connection andsum the 

Results along with a bias. This weighted sum is identical to that calculatedin equation 1 for the linear regression algorithm, except that the feature values arereplaced by the outputs of neurons in the previous layer. Each neuron then appliesan “activation function”, of which there are many different types, such as the sigmoidfunction from equation 2. The output of the activation applied to the weighted sumof incoming signals from the previous layer is the output of that node, which is sentto the next layer. This process is repeated for an arbitrary number of layers until thefinal layer outputs a value which indicates the predicted class.The way neural networks are trained is also similar to the way the linear andlogistic regression models were trained. Except here there loss function is a complexcomposite function where the derivative must be taken with respect to many moreparameters, in some cases well into the tens of millions. However, the basic idea ofgradient descent still applies, incrementally make very small changes to the weightsin a direction which decreases the loss function given a training set, and repeat untilwe find some minimum. There are many intricacies to workout when implementing61. 



IntroductionFig. 1.1.1: Neural Network with 6 nodes in the input layer, 6 in the hidden layer, and3 in the output layersuch a method but we do not busy our selves with them here. For a more detailed



Discussion of neural networks, architecture and activation function choices, and lossfunctions, we refer the reader to [1].This concludes our preliminary 



Discussion of machine learning. Table 1.1.1 sum-marizes more in depth sources on the topics briefly discussed here, which the readercan make use of at their own discretion.Table 1.1.1: Machine Learning Further ReaderingLogistic Regression [2]Linear Regression [2]Gradient Descent [3]Random Forest [2]Neural Networks [1]1.2 Machine Learning InterpretabilityIn the previous 



Section we discuss the basics of machine learning and introduced someof more well known machine learning algorithms. We discuss how the machine learn-ing algorithms are trained and how they make predictions but we now introduce one71. 



Introductionof the central topics of this thesis, interpretability. Machine Learning interpretabilityis the process of giving explanations of a models predictions to humans. It is not anattempt to understand every thing that is learnt by the model, rather it an attemptto find intuitive explanations which are simple enough and give information pertinentto down stream tasks. For example, sometimes we wish to select the best feature setfor a given model, in this case we would like to determine the most significant fea-tures for feature selection. The processes which determine the feature significances,of which there are many, is a simple form of machine learning interpretation.The perfect interpretation of a machine learning model tells us only what weneed to know while leaving out details of the model itself. It leaves out the messycomplexities of the model in order to give us enough information for later tasks. Itis usually not possible to get clear, high fidelity interpretations. Most times we haveto settle for more vague interpretations such as “this input is more influential thenthe others” or “the model will still be accurate with such and such features no longerbehaving in an informative way”.In terms of varieties of interpretations, they can generally be divided into twogroups. Local interpretations are interpretations which apply only to a single sampleor a subset of the sample space. Meanwhile Global interpretations apply to theentire sample space. Interpretation techniques can also be divided into categories.Model agnostic, that is techniques which can be applied to any type of machinelearning model, and model specific which can only be applied to a single type ofmachine learning model. To be clear, global vs. local is a categorization of theinterpretations themselves, while model-agnostic vs. model-specific is a categorizationof the techniques used to arrive at interpretations.One last note, since interpretation is done for the sake of down stream tasks,and further, it is influenced by the type of model and features used, this makesmachine learning interpretation a application specific problem. Hence, the techniqueson exposition in this thesis may be applicable with varying amounts of modificationin other domains, but they are chiefly applicable in the malware detection domain.81. 



Introduction1.3 Machine Learning in Cyber SecurityMachine Learning’s application in the cyber security domain is discussed at length inthe following 



Chapter so we give only a brief 

Overview as a primer for the 



Discussionto come, as well as to elucidate the connection between the various 



Chapters in thisthesis.Recently, there has been increased ability for malware authors to bypass tradi-tional malware detection methods. Techniques such as obfuscation and server-sidepolymorphism can help authors automatically change malware to be unrecognizableenough to bypass simple detection techniques. Further, new programming paradigmssuch as fileless malware, that is malware that does not exist on the file system of theinfected machine, mean that new malware may not leave behind binaries to studyand be used with traditional detection methods. This has lead security specialists toturn to machine learning algorithms to augment malware detection systems. How-ever, with this new detection technique comes new challenges, one of which and thefocus of this thesis, is the need for interpretable machine learning methods.1.4 Thesis 

OverviewThe remainder of this thesis is laid out as follows. In 



Chapter 2, we discuss MachineLearning’s roll in cyber security, the challenges presented with its application in mal-ware detection, and some potential improvements to the current approaches in theliterature. Further we discuss the necessity for machine learning based malware de-tection as a result of new computing paradigms such as fileless malware, among otheremerging threats. In 



Chapter 3, we provide a proof of concept fileless malware whichuses benign functionality of JavaScript in order to carry out its malicious actions. Wethen test various malware detection softwares against out malware in order to showthe severity of the threat of fileless malware. In 



Chapter 4 we present techniques forinterpreting machine learning based malware detection models which leverage n-gramanalysis. In 



Chapter 5 we put forward a novel and fully interpretable approach for91. 



Introductionmalware detection which leverages convolutional neural networks. In 



Chapter 6 wedefine a novel approach for evaluating the robustness of a machine learning basedmalware detector based off the features it uses. Lastly, we end off in 



Chapter 7 withour 



Conclusions and a 



Discussion of 



Future Work.



References[1] C. C. Aggarwal. Neural Networks and Deep Learning. Springer, 2018. isbn:978-3-319-94462-3. doi: 10.1007/978-3-319-94463-0.[2] T. Hastie, R. Tibshirani, and J. Friedman. The elements of statistical learning:data mining, inference and prediction. 2nd ed. Springer, 2009. url: http://www-stat.stanford.edu/~tibs/ElemStatLearn/.[3] S. Ruder. “An 

Overview of gradient descent optimization algorithms”. In: CoRRabs/1609.04747 (2016). arXiv: 1609.04747. url: http://arxiv.org/abs/1609.04747.10



Chapter 2The Curious Case of MachineLearning in Malware DetectionSherif Saad, William Briguglio, and Haytham ElmiligiIn Proceedings of the 5th International Conference on Information Systems Securityand Privacy2.1 



IntroductionNowadays, computer networks and the Internet have become the primary tool forspreading and distributing malware by malware authors. The massive number offeature-rich programming languages and off-the-shelf software libraries enable thedevelopment of new sophisticated malware such as botnet, fileless, k-ary and ran-somware. New computing paradigms, such as cloud computing and the Internet ofThings, expand potential malware infection sites from PC’s to any electronic device.To decide if software code is malicious or benign, we could either use static anal-ysis or dynamic analysis. Static analysis techniques do not execute the code andonly examine the code structure and other binary data properties. Dynamic analysistechniques, on the other hand, execute the code to observe the execution behaviorsof the code over the network or at end-point devices. Some malware detection sys-tems apply only static or dynamic techniques, and some apply both. While dynamicmalware analysis techniques are not intended to replace static analysis techniques,recent unconventional malware attacks (botnet, ransomware, fileless, etc.) and theuse of sophisticated evasion techniques to avoid detection have shown the urgent needof dynamic analysis and the 

Limitations of static analysis. In our opinion, the use of112. THE CURIOUS CASE OF MACHINE LEARNING IN MALWARE DETECTIONdynamic and behavioral malware analysis will dominate the next-generation malwaredetection systems.There is a general belief among cybersecurity experts that antimalware tools andsystems powered by artificial intelligence and machine learning will be the solutionto modern malware attacks. The number of studies published in the last few yearson malware detection techniques that leverage machine learning is a distinct evidenceof this belief as shown in 



Section 2.2. In the literature, various malware detectiontechniques using machine learning are proposed with excellent detection accuracy.However, malware attacks in the wild continue to grow and manage to bypass malwaredetection systems powered by machine learning techniques. This is because it isdifficult to operate and deploy machine learning for malware detection in a productionenvironment or the performance in a production environment is disturbing (e.g. highfalse positives rate). In fact, there is a significant difference (a detection gap) betweenthe accuracy of malware detection techniques in the literature and their accuracy ina production environment.A perfect malware detection system will detect all types of malicious softwareand will never consider a benign software as a malicious one. Cohen provided aformal proof that creating a perfect malware detection system is not possible [7, 6].Moreover, Chess and White proved that a malware detector with zero false positivesis not possible [4]. Selcuk et al. discussed the undecidable problems in malwaredetection in more details [31]. In light of this, the high levels of accuracy claimedby commercial malware detection systems and some malware detection studies inliterature seems questionable.In this 



Chapter, we briefly review the current state of the art in malware detectionusing machine learning approaches. Then, we discuss the importance of dynamicand behavioral analysis based on emerging malware threats. Next, the shortcomingsof the current machine learning malware detectors are explained to indicate their

Limitations in the wild. Finally, we discuss the possible solutions to improve thequality of malware detection systems and point out potential research directions.122. THE CURIOUS CASE OF MACHINE LEARNING IN MALWARE DETECTION2.2 



Literature ReviewIn recent years, machine learning algorithms have been used to design both static anddynamic analysis techniques for malware detection. Hassen et al. proposed a newtechnique for malware classification using static analysis based on control statementshingling [15]. In their work, they used static analysis to classify malware instancesinto new or known malware families. They extracted features from disassembledmalicious binaries and used the random forest algorithm to classify malware usingthe extracted features. Using a dataset of 10,260 malware instances, they reportedup to 99.21% accuracy.Static analysis has been used to study malwares that infect embedded systems,mobile devices, and other IoT devices. Naeem et al. proposed a static analysistechnique to detect IoT malware [24]. The proposed technique converts a malwarefile to a grayscale image and extracts a set of visual features from the malware imageto train an SVM classifier that could distinguish between malware families usingvisual features. Using a dataset of 9342 samples that belong to 25 malware families,they reported 97.4% accuracy. Su et al. proposed a similar technique to classifyIoT malware into malware families using visual features and image recognition [34].Their approach is very similar to the one proposed in [24]. They used a one-classSVM classifier and tested their approach on IoT malwarethat infect Linux-like IoTsystems; they reported 94.0% accuracy for detecting malware and 81.8% accuracyfor detecting malware families. Raff et al. proposed a malware detection techniqueusing static analysis and deep learning [29]. The proposed technique achieved 94.0%detection accuracy.Several works have been proposed to detect Android malware apps using staticanalysis techniques. Sahin et al. proposed an Android malware detection model thatuses app permission to detect malicious apps [26]. They used the permissions requiredby the app with a weighted distance function and kNN plus Naive Bayes classifier todetect malicious apps. They reported an accuracy up to 93.27%. Su and Fung usedsensitive functions and app permissions to detect Android malware [35]. They used132. THE CURIOUS CASE OF MACHINE LEARNING IN MALWARE DETECTIONdifferent machine learning algorithms such as SVM, decision tree, and kNN to buildan android malware detector. They reported an average accuracy between 85.0% and90.0%Collecting and monitoring all malware behaviors is a complicated and time con-suming process. For that reason, several works in the literature focused on collectingpartial dynamic behaviors of the malware. Lim et al. [19] proposed a malware detec-tion technique by analyzing network traffic generated when the malware communi-cates with a malicious C&C server such as in the case of botnet or ransomware. Theproposed technique extracts a set of features from network flows to present a flowssequence. The authors used different sequence alignment algorithms to classify mal-ware traffic. They reported an accuracy above 60% when analyzing malware trafficin a real network environment.Kilgallon et al. applied machine learning and dynamic malware analysis [17]. Theproposed technique gathers register value information and API calls made by themonitored malware binaries. The collected information is stored in vector structuresand analyzed using a value set analysis method. Then, they used a linear similaritymetric to compare unseen malware to known malware binaries. Their experimentshowed that the proposed technique could detect malware with an accuracy up to98.0%Omind and Nathan proposed a behavioral-based malware detection method usinga deep belief network [9]. The proposed method collected data about malware behav-iors from a sandbox environment. The collected data is API calls, registry entries,visited websites, accessed ports, and IP addresses. Then using a deep neural networkof eight layers, it generates malware signatures. These signatures could be used totrain malware detectors. In their experiments, they reported up to 95.3% detectionaccuracy with a malware detector utilizing the SVM algorithm.Yeo et al. proposed a new malware detection method by monitoring malicious be-haviors in network traffic [38]. They designed 35 features to describe malicious trafficof malware instances. They tested several machine learning algorithms includingCNN, MLP, SVM, and random forest. The proposed method achieved an accuracy142. THE CURIOUS CASE OF MACHINE LEARNING IN MALWARE DETECTIONabove 85% when utilizing CNN or random forest. Prokofiev et al. proposed a machinelearning technique to detect C&C traffic of infected IoT devices [28]. The proposedapproach used network traffic features such as port number, IP addresses, connectionduration and frequency. They reported a detection accuracy up to 97.3%. However,the proposed approach is still relying on traditional malware analysis methods andwill not be able to work in production IoT deployment as discussed in [33]. Severalhybrid malware detection techniques that combine both static and dynamic analysishave also been proposed [21, 27]. These techniques try to improve the quality andperformance of malware detection systems by taking advantage of static and dynamicanalysis to build robust malware detection systems.2.3 Emerging Malware ThreatsWith the recent changes in malware development and the rise of commercial malware(malicious code rented or purchased), many new challenges are facing malware ana-lysts that make static analysis more difficult and impractical. These challenges willforce anti malware vendors to adapt behavioral malware analysis and detection tech-niques. In our opinion, there are two main reasons behind these challenges; the rise ofunconventional computing paradigms and unconventional evasion techniques. Thereis a new generation of malware that take advantage of unconventional computingparadigms and off-the-shelf soft-ware libraries written by feature-rich programminglanguages. The current state-of-the-art malware analysis/detection techniques andtools are not effective against this new generation of malware.2.3.1 Unconventional Computing ParadigmsNew computing paradigms and technologies such as cloud computing, the internet ofthings, big data, in-memory computing, and blockchain introduced new playgroundsfor malware authors to develop com-plex and sophisticated malwares that are almostun-detectable. Here we describe several recent examples of new malware threats thatare difficult to detect or analyze using static analysis.152. THE CURIOUS CASE OF MACHINE LEARNING IN MALWARE DETECTIONFor instance, the Internet of Things (IoT) is an appealing platform for modernand sophisticated malware such as ransomware. Zhang-Kennedy et al. discussed theransomware threat in IoT and how a self-spreading ransomware could infect an IoTecosystem [39]. The authors pointed out that the ransomware will mainly lock downIoT devices and disable the essential functions of these devices. The study focusedon identifying the attack vectors in IoT, the techniques for ransomware self-spreadingin IoT, and predicting the most likely class of IoT applications to be a target forransomware attacks. Finally, the authors identified the techniques the ransomwarecould apply to lock down IoT devices. Authors in [39] used a Raspberry Pi to developa proof of concept IoT ransomware that can infect an IoT system. One interestingaspect in [39] is the need for collaboration or swarming behavior in IoT ransomware,where the IoT ransomware will spread as much as possible and then lock down thedevices or device and then spread.Miller and Valasek developed a proof-of-concept for malicious code that infectsconnected cars and lockdowns key functions [22].For instance, the authors demon-strated the ability for the malicious code to control the steering wheel of a vehicle,disable the breaks, lock doors, and shut down the engine while in motion. Behavingas ransomware, this real example of a malware that locks and disables key featuresin IoT systems (e.g. connected cars) could have life threatening consequences if theransom is not paid. The study explained a design flow in the Controller Area Network(CAN) protocol that allows malicious and crafted CAN messages to be injected intothe vehicle CAN channel by a compromised mobile phone that is connected to thevehicle entertainment unit. It was reported that for some vehicles only the dealershipcould restore and patch the vehicle to prevent this attack. Choi et al. proposed asolution for malware attacks in connected vehicles using machine learning [5]. Thesolution uses SVM to distinguish between crafted malicious CAN messages, and be-nign CAN messages generated by actual electronic control units (ECU). The modelextracts features from the vehicle ECUs and creates fingerprints for those ECUs.The ECU fingerprint is noticeable in a benign CAN message and does not exist in amalicious message.162. THE CURIOUS CASE OF MACHINE LEARNING IN MALWARE DETECTIONAzmoodeh et al. discussed a new technique to detect ransomware attacks in IoTsystems by monitoring the energy consumption of infected devices [3]. As a proofof concept, they studied the energy consumption of infected Android devices. Thedevices were infected by a ransomware with crypto impact. They used differentmachine learning models (kNN, SVM, NN, and Random Forest) to analyze energyconsumption data and extract unique patterns to detect compromised Android de-vices. They reported a ransomware detection accuracy of 95.65%.In 2015, Karam (INTERPOL) and Kamluk (Kaspersky lab) introduced a proof ofconcept distributed malware that also takes advantage of blockchain technology [16].In 2018, Moubarak et al. provided design and implementation of a K-ary mal-ware (distributed malware) that takes advantages of the blockchain networks suchas Etherum and Hyperledger [23]. The proposed malware is stored and executed in-side blockchain networks and acts as a malicious keylogger. While detecting a K-arymalware is an NP-hard problem [10], it is also complicated to implement a K-arymalware. However, Mubarak’s works demonstrated the simplicity of K-ary malwaredevelopment by taking advantage of blockchain technology as a distributed and de-centralized network.2.3.2 Unconventional Evasion TechniquesThe new generation of malware will use advanced evasion techniques to avoid de-tection by antimalware systems and tools. New evasion techniques implemented bymalware authors use new technologies and off-the-shelf software libraries that enablethe design of sophisticated evasion methods. Antimalware vendors and malware re-searchers discussed recent examples of using new antimalware evasion techniques inthe wild.Fileless malware or memory-resident malware is the new technique used by mal-ware authors to develop and execute malicious attacks. Fileless malware resides indevice memory and does not leave any files on the infected device file system. Thismakes the detection of the fileless malware using signature-based detection or staticanalysis infeasible. In addition, the fileless malware takes advantage of the utilities172. THE CURIOUS CASE OF MACHINE LEARNING IN MALWARE DETECTIONand libraries that already exist in the platform of the infected device to completeits malicious intents. In other words, benign applications and software libraries aremanipulated by fileless malware to accomplish the attack objectives.Fileless malware attacks and incidents are already observed in the wild compromis-ing large enterprises. According to KASPERSKY lab, 140 enterprises were attackedin 2017 using fileless malwares [11]. Ponemon Institute reported that 77% of theattacks against companies use fileless techniques [36]. Moreover, there are severalsigns that ransomware attacks are going fileless, as discussed in [20]. Besides thesesigns, there are other reasons in our opinion that confirms that ransomware and othermalware attacks will be fileless. One main reason is the moving towards in-memorycomputing.In recent years, in-memory computing and in-memory data stores became the firstbackbone and storage technology for many organizations. Many bigdata platformsand data grids (Apache Spark, Redis, HazelCast, etc.) enable storing data in memoryfor performance and scalability requirements. Valuable data and information is storedin memory for a longtime before moving to a persistent data store. In-Memoryransomware that encrypts in-memory data (such as recent transactions, financialinformation, etc.) present a severe and aggressive attack. This is because any attemptto reset or reboot the machine to remove the ransomware from the device memory orshutdown the application will result in losing this valuable data permanently.The moving towards distributed and decentralized computing is another reasonfor the rise of fileless ransomware. In distributed and decentralized computing severalnodes and devices are available to store the in-memory malware, which will increasethe life expectancy of the malware since there will always be a group of active nodeswere the malware could replicate and store itself.The recent and massive development in machine learning/artificial intelligence(aka data science) and a large number of off-the-shelf machine learning libraries enablemalware authors to develop advanced evasion techniques. Rigaki and Garcia proposedthe use of deep learning techniques to create malicious malware samples that evadedetection by mimicking the behaviors of benign applications [30]. In their work, a182. THE CURIOUS CASE OF MACHINE LEARNING IN MALWARE DETECTIONproof of concept was proposed to demonstrate how malware authors could cover themalware C&C traffic. The authors use a Generative Adversarial Networks (GANs)to enable malware (e.g., botnet) to mimic the traffic of a legitimate application andavoid detection. The study showed that it is possible to modify the source codeof malware to receive parameters from a GAN to change the behaviors of its C&Ctraffic to mimic the behaviors of other legitimate network applications, such as Face-book traffic. The enhanced malware samples were tested against the StratosphereLinux IPS (slips) system, which uses machine learning to detect malicious traffic.The experiment showed that 63.42% of the malicious traffic was able to bypass thedetection.A research team from IBM demonstrated the use of artificial intelligence to en-gineering malware attacks [8]. In their study, the authors proposed DeepLocker asa proof of concept to show how next-generation malware could leverage artificial in-telligence. DeepLocker is a malware generation engine that malware authors coulduse to empower traditional malware samples such as WannaCry with artificial intelli-gence. A deep convolutional neural network (CNN) was used to customize a malwareattack by combining a benign application and a malware sample to generate a hybridmalware that bypasses detection by mimicking benign behaviors. Besides that, themalware is engineered to unlock its malicious payload when it reaches a target (end-point) with a loose predefined set of attributes. In the study, those attributes werethe biometrics feature of the target such as facial and voice features. The malwareuses CNN to detect and confirm target identity, and upon target confirmation, anencryption key is generated and used by the WannCry malware to encrypt the fileson the target endpoint device. The encryption key is only generated by matchingthe voice and the facial features of the target. This means reverse engineering themalware using static analysis is not useful to recover the encryption key.192. THE CURIOUS CASE OF MACHINE LEARNING IN MALWARE DETECTION2.4 Practical ChallengesThe new and emerging malware threats discussed in 



Section 2.3 provide strong evi-dence for the need of adopting dynamic and behavioural analysis to build malwaredetection tools. The use of machine learning is the most promising technique toimplement malware detectors and tools that apply behavioural analysis as shownin 



Section 2.2. While the use of machine learning for malware detection has shownpromising 

Results in both static and dynamic analysis, there are significant challengesthat limit the success of machine learning based malware detectors in the wild.2.4.1 Cost of Training DetectorsThe first challenge is the cost of training and updating malware detectors in pro-duction environments. Malware detection is unlike other domains where machinelearning techniques have been applied successfully such as computer vision, naturallanguage processing, and e-commerce. Malware instances evolve and change their be-haviors over a short period; some studies by antimalware vendors reported that a newmalware instance could change its behaviors in less than 24 hours since it has beenreleased [13, 2]. This means a frequently trained machine learning model will becomeout-dated. This also means we need to frequently retrain our malware detectors tobe able to detect new and mutated malware instances. Therefore, adaptability inmachine learning models for malware detection is a crucial requirement and not justan ancillary capability.Recently, the challenge of adaptability, and scalability of machine learning modelsfor malware detection in the wild has become obvious [25]. The majority of the workproposed in the literature has done very little to reduce and optimize the featurespace to design detectors ready for early malware detection in a production environ-ment [14]. For instance, it is not clear how the proposed detection methods will scalewhen the number of monitored endpoints increases. Unlike computer vision, naturallanguage processing and other areas that utilize machine learning, malware instancescontinue to evolve and change. This mostly requires retraining machine learning mod-202. THE CURIOUS CASE OF MACHINE LEARNING IN MALWARE DETECTIONels in production, which is an expensive and complicated task. Therefore, when usingmachine learning for malware detection, we need to think differently. New methodsto reduce the cost of retraining malware detectors and improve detection quality areurgent.2.4.2 Malware Detector InterpretabilityCybersecurity analysts always prefer solutions that are interpretable and understand-able, such as rule-based or signature-based detection. This is because of the need totune and optimize these solutions to mitigate and control the effect of false positivesand false negatives. Interpreting machine learning models is a new and open chal-lenge [32]. However, it is expected that an interpretable machine learning solutionwill be domain specific, for instance, interpretable solutions for machine learning mod-els in healthcare are different than solutions in malware detection [1]. Any malwaredetector will generate false positives, and unless malware analysts can understandand interpret the reason that a benign application was wrongly classified as mali-cious, they will not accept those black box malware detectors. To our knowledge, nowork in the literature investigated the interpretability of machine learning models formalware detection.One difficulty with machine learning interpretability in this domain is that manyof the features are not meaningful to humans without the context which they appearin. This means it is necessary to map back from features to raw data in order to betterunderstand the feature and its context at the time of classification. The problem ofmapping features to raw data is touched upon in 



Chapters 4 and 5 and applies tomalware detectors which use ngrams or binaries converted to images. However, thetechniques used to map features to raw data will also be application specific.2.4.3 Adversarial MalwareLast but not least, a malware detection system utilizing machine learning could bedefeated using adversarial malware samples. For instance, Kolosnjaji et al. showed212. THE CURIOUS CASE OF MACHINE LEARNING IN MALWARE DETECTIONin [18] that by using an intelligent evasion attack they can defeat the deep learningdetection system proposed in [29] by Raff et al. They simply used their knowledge ofhow the proposed deep learning detection system operates and designed a gradient-based attack as an evasion technique to overcome it. With adversarial malware, thesystem detection accuracy dropped from 94.0% to almost 50.0%. Machine learn-ing algorithms are not designed to work with adversarial examples. Grosse et al.demonstrated that using adversarial malware samples; they could reduce the detec-tion accuracy of a malware detection system that uses static analysis and machinelearning to 63.0% [12]. They also showed that adopting anti adversarial machinelearning techniques used in computer vision is not effective in malware detection.Yang et al. proposed adversarial training as a solution for adversarial malware [37].They designed a method for adversarial android malware instances generation. Theproposed method requires access to the malware binaries and source code, besides, itis mainly useful for static malware detection systems.2.5 Bridging the Detection GapTo overcome the challenges we discussed in 



Section 2.4, we propose new solutions tomitigate these challenges and reduce the gap.2.5.1 Disposable Micro DetectorsCurrent best practices in constructing and building machine learning models followa monolithic architecture. In a monolithic architecture, a single computationallyexpensive (to build and train) machine learning model is used to detect malware.While this architecture or approach for building machine learning models is successfulin other domains, we believe it is unsuitable for malware detection given the highlyevolving characteristics of malware instances. We propose a new approach inspired bythe microservices architecture. In this approach, multiple, small, inexpensive, focusedmachine learning models are built and orchestrated to detect malware instances. Eachmodel or detector is built to detect the behaviors of a specific malware instance (e.g.,222. THE CURIOUS CASE OF MACHINE LEARNING IN MALWARE DETECTIONMirai, WannaCry), or at most a single malware family (a group of similar malwareinstances). Also, each model or detector is built using features that are similar, such ashaving the same computational cost, or unique to the specific execution environment.This is because out of the super set of features designed to detect malware, it iscommon that a subset of these features could be more or less useful to detect a specificmalware instance or family. The use of micro (small) and focused detectors reduce thecost of retraining and deployment in production. This is because detectors for newmalware could be trained and added without the need to retrain existing detectors.In addition, when malware detectors become outdated as a result of a malware’sevolving behavior, the outdated detectors are disposed of and replaced by new ones.The use of micro-detectors enables adaptability by design rather than attempting tochange machine learning models and algorithms to support adaptability.2.5.2 Analyst Friendly InterpretationAdopting sophisticated machine learning techniques for malware detection in a pro-duction environment is a challenge. This is because most of the time it is not possibleto understand how the machine learning systems make their malware detection deci-sions. Therefore, tuning and maintaining these systems is a challenge in productionand new techniques for malware analysts to interpret and evaluate the performanceof malware detectors are needed. We propose the use of evolutionary computationtechniques such as genetic algorithms or clonal selection algorithms to generate aninterpretation for black-box machine learning models such as deep learning. Usingevolutionary computation, we could describe the decisions of malware detectors us-ing a set of IF-Then rules. The only information required is the input features themalware detector uses to make a decision.The IF-Then rules are useful to explain the behaviors that trigger a specific deci-sion (e.g., malicious or benign) by the malware detector. Cybersecurity and malwareanalyst are comfortable working with IF-Then rules. These rules will help in under-standing the decision made by malware detectors, explain the scope of the detection,and identify potential over generalization or overfitting that could result in false pos-232. THE CURIOUS CASE OF MACHINE LEARNING IN MALWARE DETECTIONitives or false negatives.It is essential that the IF-Then rules set interpretation of the malware detector isexpressed in raw malware behaviors and not in machine learning features. Machinelearning features are most likely understandable by machine learning engineers andexperts. The interpretation should be acceptable to a malware analyst who does notneed to be a machine learning expert.Other model specific Interpretations techniques, such as the ones discussed in



Chapters 4 and 5 of this thesis, can be utilized to improve model confidence so stake-holders are more likely to trust machine learning based malware detectors. Further,these approaches can ensure the model is not easily manipulated and thus prone toadversarial malware by over-relying on easy to change and superficial features. In thisway, interpretation can help ensure model robustness. Lastly, machine learning mod-els learn complex patterns that can be utilized making beyond making classificationdecisions. Interpretation can be used so that patterns learn by a machine learn-ing model can help malware analyst with downstream tasks such as finding importsnippets of code.2.5.3 Anti Adversarial MalwareTo improve the resilience of malware detectors against adversarial malware, we be-lieve it is essential to study the effort required by the malware authors to design anadversarial malware for specific malware detectors. For example, what technique amalware author would use to probe and study a malware detector in production todesign a malware that could bypass a detector.Measuring the effort to probe detectors and design adversarial malware undertwo main settings is essential. The first setting is black-box, where the malwareauthors have minimum knowledge about the malware detector’s internal design andthe features used by the machine learning algorithm. The second setting is white-box,where the malware authors have sufficient knowledge about the malware detector’sinternal design and the machine learning algorithm. Training and updating malwaredetectors is likely the most efficient solution against adversarial malware. Knowing242. THE CURIOUS CASE OF MACHINE LEARNING IN MALWARE DETECTIONthe effort needed to evade a malware detector will help in designing training strategiesand policies to increase the effort required to evade the detectors.As we mentioned before, Cohen provided a formal proof that creating a perfectmalware detection system is not possible [7, 6]. We believe that designing a perfectadversarial malware is not possible. Therefore we expect that using ensemble-basedhybrid machine learning approach for malware detectors will be effective against ad-versarial malware. It is expected that by creating a malware detector using an en-semble hybrid machine-learning approach, the risk of evading detection will decreaseand the effort to design adversarial malware will increase. A hybrid machine learningmodel is when two or more different machine learning algorithms are used to constructthe model. In the literature, adversarial malware samples evade malware detectorsthat use a single machine learning algorithm or technique [37, 12, 18]. In our method,a hybrid machine learning approach for building a malware detector is an approachto provide a defense-in-depth model for malware detectors.2.6 

ConclusionIn this 



Chapter, we reviewed the current state-of-the-art in malware detection usingmachine learning. We discussed the recent trends in malware development and emerg-ing malware threats. We argued that behavioral analysis would dominate the nextgeneration anti malware systems. We discussed the challenges of applying machinelearning to detect malware in the wild and proposed our thoughts on how we couldovercome these challenges. Machine learning malware detectors require inexpensivetraining methods; they need to be interpretable for the malware analysts and notonly for machine learning experts. Finally, they need to tolerate adversarial malwareby design252. THE CURIOUS CASE OF MACHINE LEARNING IN MALWARE DETECTION



References[1] M. A. Ahmad, A. Teredesai, and C. Eckert. “Interpretable Machine Learning inHealthcare”. In: 2018 IEEE International Conference on Healthcare Informatics(ICHI). June 2018, pp. 447–447. doi: 10.1109/ICHI.2018.00095.[2] K. Allix et al. “Are Your Training Datasets Yet Relevant?” In: EngineeringSecure Software and Systems. Ed. by Frank Piessens, Juan Caballero, and Na-taliia Bielova. Cham: Springer International Publishing, 2015, pp. 51–67. isbn:978-3-319-15618-7.[3] A. Azmoodeh et al. “Detecting crypto-ransomware in IoT networks based onenergy consumption footprint”. In: Journal of Ambient Intelligence and Hu-manized Computing 9.4 (Aug. 2018), pp. 1141–1152. issn: 1868-5145. doi:10.1007/s12652-017-0558-5. url: https://doi.org/10.1007/s12652-017-0558-5.[4] D. M. Chess and S. R. White. “An Undetectable Computer Virus”. In: InProceedings of Virus Bulletin Conference (2000).[5] Y. Han Choi et al. “Toward extracting malware features for classification us-ing static and dynamic analysis”. In: 2012 8th International Conference onComputing and Networking Technology (INC, ICCIS and ICMIC). Aug. 2012,pp. 126–129.[6] F. Cohen. “Computational aspects of computer viruses”. In: Computers & Se-curity 8.4 (1989), pp. 297–298.[7] F. Cohen. “Computer viruses: Theory and experiments”. In: Computers & Se-curity 6.1 (1987), pp. 22–35.[8] J. Jang D. Kirat and M. Stoecklin. DeepLocker Concealing Targeted Attackswith AI Locksmithing. Aug. 2018.[9] O. E. David and N. S. Netanyahu. “DeepSign: Deep learning for automaticmalware signature generation and classification”. In: 2015 International Joint262. THE CURIOUS CASE OF MACHINE LEARNING IN MALWARE DETECTIONConference on Neural Networks (IJCNN). July 2015, pp. 1–8. doi: 10.1109/IJCNN.2015.7280815.[10] D. de Drézigué, J.P. Fizaine, and N. Hansma. “In-depth analysis of the viralthreats with OpenOffice.org documents”. In: Journal in Computer Virology 2.3(Dec. 2006), pp. 187–210. url: https://doi.org/10.1007/s11416-006-0020-2.[11] Global Research and Analysis Team, KASPERSKY Lab. Fileless Attack AgainstEnterprise Network. White Paper. KASPERSKY Lab, 2017.[12] K. Grosse et al. “Adversarial Examples for Malware Detection”. In: ComputerSecurity – ESORICS 2017. Ed. by Simon N. Foley, Dieter Gollmann, and EinarSnekkenes. Cham: Springer International Publishing, 2017, pp. 62–79. isbn:978-3-319-66399-9.[13] A. Gupta et al. “An empirical study of malware evolution”. In: 2009 First In-ternational Communication Systems and Networks and Workshops. Jan. 2009,pp. 1–10. doi: 10.1109/COMSNETS.2009.4808876.[14] G. Hajmasan, A. Mondoc, and O. Creţ. “Dynamic behavior evaluation for mal-ware detection”. In: 2017 5th International Symposium on Digital Forensic andSecurity (ISDFS). Apr. 2017, pp. 1–6. doi: 10.1109/ISDFS.2017.7916495.[15] M. Hassen, M. M. Carvalho, and P. K. Chan. “Malware classification using staticanalysis based features”. In: 2017 IEEE Symposium Series on ComputationalIntelligence (SSCI). Nov. 2017, pp. 1–7.[16] C. Karam and V. Kamluk. “Blockchainware - Decentralized Malware on TheBlockchain”. In: Black Hat ASIA. 2015.[17] S. Kilgallon, L. De La Rosa, and J. Cavazos. “Improving the effectiveness andefficiency of dynamic malware analysis with machine learning”. In: 2017 Re-silience Week (RWS). Sept. 2017, pp. 30–36.272. THE CURIOUS CASE OF MACHINE LEARNING IN MALWARE DETECTION[18] B. Kolosnjaji et al. “Adversarial Malware Binaries: Evading Deep Learning forMalware Detection in Executables”. In: CoRR abs/1803.04173 (2018). arXiv:1803.04173. url: http://arxiv.org/abs/1803.04173.[19] H. Lim et al. “Malware classification method based on sequence of traffic flow”.In: 2015 International Conference on Information Systems Security and Privacy(ICISSP). Feb. 2015, pp. 1–8.[20] A. Magnusardottir. Fileless Ransomware: How It Works & How To Stop it?White Paper. Cyren, June 2018.[21] F. Martinelli et al. “I find your behavior disturbing: Static and dynamic appbehavioral analysis for detection of Android malware”. In: 2016 14th AnnualConference on Privacy, Security and Trust (PST). Dec. 2016, pp. 129–136.[22] C. Miller and C. Valasek. Remote Exploitation of an Unaltered Passenger Ve-hicle. White Paper. Black Hat, Oct. 2015.[23] J. Moubarak, M. Chamoun, and E. Filiol. “Developing a K-ary malware usingblockchain”. In: NOMS 2018 - 2018 IEEE/IFIP Network Operations and Man-agement Symposium. Apr. 2018, pp. 1–4. doi: 10.1109/NOMS.2018.8406331.[24] H. Naeem, B. Guo, and M. R. Naeem. “A light-weight malware static visualanalysis for IoT infrastructure”. In: 2018 International Conference on ArtificialIntelligence and Big Data (ICAIBD). May 2018, pp. 240–244.[25] A. Narayanan et al. “Adaptive and scalable Android malware detection throughonline learning”. In: 2016 International Joint Conference on Neural Networks(IJCNN). July 2016, pp. 2484–2491. doi: 10.1109/IJCNN.2016.7727508.[26] D. OSahın et al. “New 

Results on permission based static analysis for Androidmalware”. In: 2018 6th International Symposium on Digital Forensic and Secu-rity (ISDFS). Mar. 2018, pp. 1–4.[27] A. De Paola et al. “A hybrid system for malware detection on big data”.In: IEEE INFOCOM 2018 - IEEE Conference on Computer CommunicationsWorkshops (INFOCOM WKSHPS). Apr. 2018, pp. 45–50.282. THE CURIOUS CASE OF MACHINE LEARNING IN MALWARE DETECTION[28] A. O. Prokofiev, Y. S. Smirnova, and V. A. Surov. “A method to detect Internetof Things botnets”. In: 2018 IEEE Conference of Russian Young Researchersin Electrical and Electronic Engineering (EIConRus). Jan. 2018, pp. 105–108.[29] E. Raff et al. “Malware Detection by Eating a Whole EXE”. In: CoRR abs/1710.09435 (2017).[30] M. Rigaki and S. Garcia. “Bringing a GAN to a Knife-Fight: Adapting Mal-ware Communication to Avoid Detection”. In: 2018 IEEE Security and PrivacyWorkshops (SPW). May 2018, pp. 70–75.[31] A. A. Selcuk, F. Orhan, and B. Batur. “Undecidable problems in malware analy-sis”. In: 2017 12th International Conference for Internet Technology and SecuredTransactions (ICITST). 2017, pp. 494–497.[32] S. Shirataki and S. Yamaguchi. “A study on interpretability of decision of ma-chine learning”. In: 2017 IEEE International Conference on Big Data (BigData). Dec. 2017, pp. 4830–4831. doi: 10.1109/BigData.2017.8258557.[33] S. W. Soliman, M. A. Sobh, and A. M. Bahaa-Eldin. “Taxonomy of malwareanalysis in the IoT”. In: 2017 12th International Conference on Computer En-gineering and Systems (ICCES). Dec. 2017, pp. 519–529.[34] J. Su et al. “Lightweight Classification of IoT Malware Based on Image Recog-nition”. In: 2018 IEEE 42nd Annual Computer Software and Applications Con-ference (COMPSAC). Vol. 01. July 2018, pp. 664–669.[35] M. Su and K. Fung. “Detection of android malware by static analysis on per-missions and sensitive functions”. In: 2016 Eighth International Conference onUbiquitous and Future Networks (ICUFN). July 2016, pp. 873–875.[36] The 2017 State of Endpoint Security Risk. White Paper. Ponemon Institute,2017.[37] W. Yang et al. “Malware Detection in Adversarial Settings: Exploiting FeatureEvolutions and Confusions in Android Apps”. In: ACSAC. 2017.292. THE CURIOUS CASE OF MACHINE LEARNING IN MALWARE DETECTION[38] M. Yeo et al. “Flow-based malware detection using convolutional neural net-work”. In: 2018 International Conference on Information Networking (ICOIN).Jan. 2018, pp. 910–913. doi: 10.1109/ICOIN.2018.8343255.[39] L. Zhang-Kennedy et al. “The Aftermath of a Crypto-ransomware Attack at aLarge Academic Institution”. In: Proceedings of the 27th USENIX Conferenceon Security Symposium. SEC’18. Baltimore, MD, USA: USENIX Association,2018, pp. 1061–1078. isbn: 978-1-931971-46-1. url: http://dl.acm.org/citation.cfm?id=3277203.3277282.30



Chapter 3JSLess: A Tale of FilelessJavaScript Memory-ResidentMalwareSherif Saad, Farhan Mahmood, and William BriguglioIn Proceedings of the 15th International Conference on Information Security Practiceand Experience3.1 



IntroductionFileless malware is a new class of the memory-resident malware family that success-fully infects and compromises a target system without leaving a trace on the targetfilesystem or secondary memory (e.g., hard drive). Fileless malware infects the tar-get’s main-memory (RAM) and executes its malicious payload. Fileless malware isnot just another memory-resident malware. To our knowledge, Fred Cohen developedthe first memory-resident malware (Lehigh Virus) in the early 80s. This usually leadssome researchers to believe that fileless malware is not a new malware threat butonly a new name for an old threat. However, this is not true, fileless malware hassome distinguishing properties. First, malware attacks require some file infection orwriting to the hard drive, this includes traditional memory resident malware. Filelessmalware infection and propagation does not require writing any data to the targetdevice filesystem. However, it is possible that the malicious payload (e.g., the endgoal ) of the fileless malware writes data to the hard drive, for example, a filelessransomware, but again the ransomware propagation and infection are fileless. The313. JSLESS: A TALE OF FILELESS JAVASCRIPT MEMORY-RESIDENT MALWAREsecond key property of fileless malware is that it depends heavily on using benignsoftware utilities and libraries already installed on the target device to execute themalicious payload. For instance, a fileless ransomware will use cryptographic librariesand APIs already installed on the target to complete its attack rather than installingnew cryptographic libraries or implementing its own.There are other unique properties of fileless malware, but the most importantones are the fileless infection approach and the use of benign utilities and librariesof the compromised machine to execute the malicious payload. Those two propertiesof fileless malware make it an effective threat in evading and bypassing sophisticatedanti-malware detection systems. This is because most anti-malware relies on scan-ning the compromised filesystem to detect malware infections. Also, because filelessmalware use legitimate software utilities and programs to attack computer systems,it is challenging for anti-malware systems that use dynamic analysis to detect filelessmalware. Moreover, being fileless is an anti-forensics technique, since it does not leaveany trace after the attack is complete, it is tough for forensics investigator to reverseengineer the malware.Fileless malware attacks and incidents are already observed in the wild compromis-ing large enterprises. According to KASPERSKY lab, 140 enterprises were attackedin 2017 using fileless malwares [5]. Ponemon Institute reported that 77% of the attacksagainst companies use fileless techniques [18]. Also, CYREN recently reported thatduring 2017 there was over 300% increase in the use of fileless attacks. Moreover, theyexpected that the new generation of Ransomware would be fileless [7]. This expec-tation proved to be correct when TrendMicro reported the analysis of SOREBRECTRansomware, the first fileless ransomware attack in the wild [19]. However, we thinkthat it is inaccurate to describe SOREBRECT Ransomware as fileless malware, sinceit places an executable file on the compromised machine which injects the maliciouspayload into a running system process. Then, it deletes the file and any trace onthe system logs using a self-destruct routine. Because the infection and the injectionof SOREBRECT Ransomware requires placing files on the compromised host, we donot think it is a true fileless malware. Moreover, deleting the files is not enough to323. JSLESS: A TALE OF FILELESS JAVASCRIPT MEMORY-RESIDENT MALWAREhide the trace, file carving techniques could be used to recover the deleted files.Another common trend in developing fileless malware is the use of Microsoft Pow-erShell. PowerShell is a command-line shell and scripting language that allows systemadministrators to manage and automate tasks related to running processes, the op-erating system, and networks. It is preinstalled by default on new Windows versionsand it can be installed on Linux and MacOS systems. PowerShell is a good exampleof a benign and powerful system utility that could be used by fileless malware. Sev-eral reports by anti-malware vendors discuss how malware authors take advantagesof PowerShell to develop sophisticated fileless malware [10].In this 



Chapter, we summarize our research on fileless malware attacks in modernweb applications. We investigate the possibility of developing a fileless malware usingmodern JavaScript(JS) features that were introduced with HTML5. In our assessmentof the potential threats of fileless malware attacks, we explore the use of benignJavaScript and HTML5 features to develop fileless malware. Based on our analysiswe implemented JSLess as a proof-of-concept(PoC) fileless JavaScript malware thatsuccessfully infects a web browser and executes several malicious payloads.The contribution of this 



Chapter is threefold. First, identify the malicious poten-tial of new benign features in web technology and how they could be used to developfileless malware. Second, design and implement JSLess as a PoC fileless JS malwarethat uses a new dynamic injection method and advanced evasion techniques to infectmodern web apps and execute a variety of attacks. Third, demonstrate the threatsof fileless malware in modern web applications by evaluating the proposed filelessmalware with several free and commercial malware detection tools that apply bothstatic and dynamic analysis.This 



Chapter is organized as follows; 



Section 3.2 is a 



Literature Review of filelessmalware and JavaScript malware. In 



Section 3.3, we explain new benign features inmodern JavaScript and HTML5 and their security issues. Then, in 



Section 3.4 wepresent our JavaScript fileless malware design and implementation. Next, in 



Section3.5 we evaluate the evasion behaviors of the JS fileless malware against free andcommercial anti-malware tools, then we discuss possible detection and mitigation333. JSLESS: A TALE OF FILELESS JAVASCRIPT MEMORY-RESIDENT MALWAREtechniques. Finally, a 

Conclusion and possible 



Future Work is presented in 



Section 3.6.3.2 



Literature ReviewCode injection attacks have been studied from different perspectives in the literature.The research in this area tried to detect malicious behaviors in JavaScripts usingvarious methods, including signature-based analysis, utilizing machine learning algo-rithms, using honeynets, and applying several deobfuscation techniques. This 



Sectiondiscusses the main research directions in this area and 

Highlights some of the mostimportant contributions in the literature.S. Yoon et al. proposed a method to generate unique signatures for maliciousJavaScripts [23]. The authors used content-based signature generation techniquesand utilized the Term Frequency - Inverse Document Frequency (TF-IDF) and Bal-anced Iterative Reducing and Clustering using Hierarchies methods to generate theconjunction signatures for JavaScripts [23]. Although signature-based analysis canhelp detect several malicious behaviours, the work in [23] is based on the assumptionthat the attack type of the input JavaScripts is known, which is not always a practi-cal assumption in real-life environments. Moreover, obfuscation remains a challengingproblem that reduces the effectiveness of signature-based techniques.G. Blanc et al. tried to address the obfuscation problem by applying 



Abstractsyntax tree (AST) based methods to characterize obfuscating transformations foundin malicious JavaScript [2]. The authors used AST-based methods to demonstratesignificant regularities in obfuscated JavaScript programs. The work in [2] is basedon generating AST fingerprints (ASTFs) for each JS file present in their learningdataset then manually picking representative subtrees for further processing. Themanual intervention in this procedure and relying only on the training data setswithout providing a mechanism to update the training set with new samples raisemany questions about the feasibility of this solution. Moreover, the work in [2] didnot consider the different categories of obfuscation techniques in real-world maliciousJavaScript, which was analyzed by W. Xu et al. in [22]. Similar work was done by I.343. JSLESS: A TALE OF FILELESS JAVASCRIPT MEMORY-RESIDENT MALWAREAL-Taharwa1 et al. to detect obfuscation in JavaScript using semantic-based analysisbased on the variable length context-based feature extraction (VCLFE) scheme thattakes advantage of AST representation [17].One controversial issue in this area of research is the physical location where thedetection mechanism takes place. One approach is to collect and analyze HTTPtraffic via local proxy and implement the detection algorithm on the proxy side [12].Another approach is to implement the detection mechanism on the client side, such asthe work done by V. Sachin et al., who used light-weight JavaScript instrumentationthat enables static and dynamic analysis of the visited webpage to detect maliciousbehavior [13]. R. K. Kishor et al. took an extra step and developed an extension thatcan be installed on the client web browser to detect malicious web contents [6]. Similarwork was done by C. Wang et al., who focused on the browser detection mechanismintegrated with HTML5 and Cross Origin resource sharing (CORS) properties [20].In recent years, JavaScript became a very popular solution for hybrid mobile ap-plications. This recent adoption of technology in mobile applications poses a newrisk of malicious code injection attacks on mobile devices. J. Mao et al. proposeda method to detect anomalous behaviors in hybrid Android apps as anomalies infunction call behaviors [9]. The authors instrumented the JavaScript code dynami-cally in the JavaScript engine to intercept function calls of JavaScript in hybrid apps.They also extracted events from the Android WebView component to enhance theperformance of their proposed detection model [9].Since the feature engineering step is the core of any machine-learning malwaredetection solution, many researchers focused on developing a feature engineering



Methodology. H. Adas et al. proposed a method to extract inspection features fromover two million mobile URLs [1]. The authors used a MapReduce/Hadoop basedcloud computing platform to train and implement their classifier and evaluate itsperformance. Although this is a good step towards building a cloud-based classifier,more experiments need to be conducted to evaluate its efficiency with respect to real-time detection of malware. Moreover, the classification model in [1] was trained withfeatures based on the static analysis of the malicious code, which is not an efficient353. JSLESS: A TALE OF FILELESS JAVASCRIPT MEMORY-RESIDENT MALWAREapproach in detecting most fileless malwares.S. Ndichu et al. developed a neural network model that can be trained to learnthe context information of texts [11]. The main contribution of the work in [11] isdeveloping a new feature extraction method and using unsupervised learning algo-rithms that produce vectors of fixed lengths. These vectors can be used to train aneural network that classifies the JavaScript code as normal or malicious [11]. Similarwork was done earlier by Y. Wang et al. using deep learning [21]. Wang et al. useddeep features extracted by stacked denoising auto-encoders (SdA) to detect maliciousJavaScript codes [21].Neural networks were not the only machine learning framework used to detectmalicious JavaScript codes. Seshagiri et al. used Support Vector Machine (SVM) todetect malicious JavaScript codes [15]. Features were extracted using static analysisof web pages. Although ML is a promising solution, there are many challenges thatface developers during the implementation of such solutions. The main challenge iscreating a feature vector that can truly characterize the behaviour of fileless malware.Fileless malware does not leave clear traces on the victim’s machine and therefore arevery difficult to identify.Other research directions are considered in the literature. The following are fewexamples of different approaches considered by researchers in the last few years. B.Sayed et al. proposed a model that uses information flow control dynamically atrun-time to detect malicious JavaScript [14]. Y. Fange et al. used Long Short-TermMemory (LSTM) to develop a malicious JavaScript detection model [4]. V. Shenused a high-level fuzzy Petri net (HLFPN) to detect JavaScript malware [16]. D.Cosovan used hidden markov models and linear classifiers to detect JavaScript-basedmalware [3]. Last but not least, D. Maiorca et al. used discriminant and adversary-aware API analysis to detect malicious scripting code[8].Although the previous work in this research area presented promising 

Results, thereare many challenges that prevent accurate detection of fileless malwares in real webapplications. To highlight the significance of the threat posed by fileless malwares,this 



Chapter presents a practical design and implementation of a fileless malware as363. JSLESS: A TALE OF FILELESS JAVASCRIPT MEMORY-RESIDENT MALWAREa PoC to demonstrate the threats of fileless malware in web applications.3.3 Benign Features with Malicious PotentialsWith the 



Introduction of HTML5, a new generation of modern web applicationsbecome a reality. This is mainly because HTML5 introduced a rich-set of powerfulAPIs and features that can be used by JavaScript. Some of the new features and APIsin HTML focus on enabling the development of web apps with high connectivity andperformance. Further, HTML5 provides a set of APIs that allow web applicationswritten in JavaScript to access information about the host running the web appand also other peripheral devices connected to the host. For instance, a web appdeveloped with HTML5 and JavaScript could have access to the user geolocation,device orientation, mic, and camera.While these new powerful features were proposed to improve web applicationdevelopment, we found in our analysis of these features that hackers and malwareauthors could misuse them. Many of these benign features have serious maliciouspotential. In this 



Section, we will mainly focus on HTML5 features that were proposedto boost web application performance, scalability, and connectivity.3.3.1 WebSocketsWebSocket is a new communication protocol that enables a web-client and a web-server to establish a two-way (full-duplex) interactive communication channel overa single TCP connection. It provides bi-directional real-time communication whichis an urgent requirement for modern interactive web applications. With WebSocket,the communication method between the web-client and the web-server is not lim-ited to pull-communication. Instead, push-communication and even an interactivecommunication become possible. For this reason, WebSocket becomes the dominatetechnology in developing instant messaging apps, gaming applications, streaming ser-vices, or any web app which requires data exchange between the client and the serverin real-time.373. JSLESS: A TALE OF FILELESS JAVASCRIPT MEMORY-RESIDENT MALWAREWebSocket is currently supported by all major web browsers such as Chrome,Firefox, Safari, Edge, and IE. Moreover, the WebSocket protocol is supported bycommon programming languages such as Java, Python, C#, and others. This enablesthe development of desktop, mobile apps, or even microservices that communicateusing WebSocket as a modern and convenient communication protocol.It is clear that by using WebSocket the connectivity of web apps becomes muchhigher quality and much more reliable. However, WebSocket is considered by websecurity researchers a security risk. WebSocket enables a new attack vector for mali-cious actors. Common web attacks such as cross-site scripting (XSS) and man in themiddle (MitM) are possible over WebSockets. WebSocket by design does not obeythe same-origin policy; this means the web browser will allow a WebSocket scriptto connect to different web pages even if they do not share the same-origin (sameURI scheme, host and port number). Again WebSocket by design is not bound bycross-origin resource sharing (CORS). This means a web app running inside the clientweb browser could request resources that have a different origin from the web app.This flexibility could be easily abused by malicious actors as we will demonstrate inthe next 



Section.3.3.2 WebWorkerOriginally JavaScript is a single-threaded language which means in any web app thereis only a single line of code or statement that can be executed at any given time. Asa result, JavaScript cannot perform multiple tasks simultaneously. WebWorker isa new JavaScript feature that was introduced with HTML5 to improve the perfor-mance of the JavaScript applications. WebWorker enables JavaScript code to run ina 

Background thread separate from the main execution thread of a web app. In otherwords WebWorker allows web applications to execute tasks in the 

Background with-out impacting the user interface as it works completely separate from the UI thread.For this reason, WebWorkers are typically used to run long and expensive operationswithout blocking the UI. For instance, the code in listing 3.1 initializes a new webworker object and runs the code in worker.js asynchronously in a new thread.383. JSLESS: A TALE OF FILELESS JAVASCRIPT MEMORY-RESIDENT MALWAREif (typeof(worker) == "undefined") {worker = new Worker("worker.js");}Listing 3.1: WebWorker Initialization ExampleWebWorker should be used to do computationally intensive tasks to avoid block-ing the UI or any other code executed in the main thread. If a computationallyintensive task executes in the main JavaScript thread, the web app will freeze andbecome unresponsive to the user. WebWorker is currently supported by all majorweb browsers such as Chrome, Firefox, Safari, Edge, and IE.As we can see WebWorker is an essential feature for developing a modern andresponsive web application. However, the devil is in the details. While WebWorkerseems like a harmless feature, it opens the door for several malicious 



Scenarios andsecurity issues. For example, is allows DOM-based XSS. CORS does not bind it, andhence a web worker could share and access resources from different origins. But inour opinion, the most critical security issue with WebWorker is its ability to insertsilent running JavaScript code. This could enable a malicious payload to run in a

Background thread created by malicious or compromised web apps. One possibleexample is using a WebWorker with a malicious web app to preform cryptocurrencymining without the users’ consent. On the bright side, the WebWorker will terminateif the user closes the web browser or the web app that created the web worker object.However, as we will see in the next sub



Section, malware authors can work around thiswith ServiceWorkers.3.3.3 ServiceWorkerServiceWorker is another new appealing JavaScript feature. We could consider Ser-viceWorker as a special type of WebWoker. ServiceWorker allows running JavaScriptcode in a separate 

Background thread. This is very similar to WebWorker but unlikeWebWorker, the lifetime of the ServiceWorker is not tied to a specific webpage oreven the web browser. This means even if the user navigates away from the web393. JSLESS: A TALE OF FILELESS JAVASCRIPT MEMORY-RESIDENT MALWAREapp that created the ServiceWorker or closes the web browser, the ServiceWorkerwill continue to run in the 

Background. The ServiceWorker will normally terminatewhen it has complete its task (e.g., execute its script) or received a termination signalfrom the web server, or terminate abnormally as a result of a crash, system reboot orshutdown.ServiceWorker was introduced to enable a rich offline experience to users andimprove the performance of modern web apps. The code in listing 3.2 shows anexample that creates a ServiceWorker from the file sw demo.js. ServiceWorkers sharethe same security issues and risks that exist in WebWorkers but the lifetime of thesecurity risks persists longer.window.addEventListener(’load’, () => {navigator.serviceWorker.register(’/sw_demo.js’).then(( registration) => {// ServiceWorker registered successfully}, (err) => {// ServiceWorker registration failed});});Listing 3.2: ServiceWorker Registration Example3.4 JavaScript Fileless MalwareIn this 



Section, we explain how the benign JavaScript features we introduced in 



Section3.3 could be used to implement a fileless JavaScript malware. To demonstrate thisthreat, we designed and implemented JSLess as a PoC fileless malware. We designedJSLess as a fileless polymorphic malware, with a dynamic malicious payload, thatapplies both timing and event-based evasion.3.4.1 Infection 



ScenariosIn our investigation, we define two main infection 



Scenarios. The first scenario iswhen the victim (web user) visits a malicious web server or application as illustrated403. JSLESS: A TALE OF FILELESS JAVASCRIPT MEMORY-RESIDENT MALWAREFig. 3.4.1: JavaScript Fileless Malware First Infection Scenarioin figure 3.4.1. In this case, the malicious web server will not show any maliciousbehaviors until a specific event triggers the malicious behavior. In our demo, theattack posts specific text messages on a common chat room. The message act as anactivation command to the malware. When the message is received the malware isinjected dynamically into the victim’s browser and starts running as part of the scriptbelonging to the public chat room.The second infection scenario is when the malware compromises a legitimate webapplication or server to infect the web browsers of the users who are currently visitingthe compromised website as illustrated in figure 3.4.2. In this case, both the websiteand the website visitors are victims of the malware attack. The malware will opena connection with the malicious server (e.g., C&C server) that hosts the malware todownload the malicious payload or receive a command from the malware authors toexecute on the victim browser.Note that in both 



Scenarios the malicious code infection/injection happens on theclient side, not the server side.413. JSLESS: A TALE OF FILELESS JAVASCRIPT MEMORY-RESIDENT MALWAREFig. 3.4.2: JavaScript Fileless Malware Second Infection Scenario3.4.2 Operational 



ScenariosJSLess is delivered to the victim’s web browser through a WebSocket connection.When the victim visits a malicious web server, the WebSocket connection will bepart of the web app on the malicious server. However, if the malware authors preferto deliver JSLess by compromising a legitimate web app/server to increase in theinfection rate, then the WebSocket delivery code could be added into a third-partyJavaScript library (e.g. JQuery). Almost all modern web application relies on inte-grating third-party JavaScript files. The WebSocket delivery code is relatively simple(see the code in listing 3.3) and could easily be hidden in a malicious third-party scriptlibrary that is disguised as legitimate. Alternatively, the code could be inserted viaan HTML injection attack on a vulnerable site that does not correctly sanitize theuser input.423. JSLESS: A TALE OF FILELESS JAVASCRIPT MEMORY-RESIDENT MALWAREMalWS = new WebSocket(’{{ WSSurl }}/ KeyCookieLog.js’);MalWS.onmessage = function(e) {sc = document.createElement(’script ’);sc.type = ’text/JavaScript ’;sc.id = ’MalSocket ’;sc.appendChild(document.createTextNode(e.data));B = document.getElementsByTagName("

Body");B[0]. appendChild(sc);};Listing 3.3: malicious payload delivered with websocketThe WebSocket API is used to deliver the malware source code in JavaScript tothe victim browser. Once the connection is opened, it downloads the JavaScript codeand uses it to create a new script element which is appended as a child to the HTMLfile’s 

Body element. This causes the downloaded script to be executed by the client’sweb browser.Delivering the malware payload over WebSocket and dynamically injecting it intothe client’s web browser provides several advantages to malware authors. The factthat the malware code is only observable when the web browser is executing the codeand mainly as a result of a trigger event provides one important fileless behaviorfor the malware. The malicious code is never written to the victim’s file system.Using WebSocket to deliver the malware payload does not raise any red flags by anti-malware systems since it is a popular and common benign feature. Using benignAPIs is another essential characteristic of fileless malware.The fact that JSLess can send any malicious payload for many attack vectors andinject arbitrary JavaScript code with the option to obfuscate the injected maliciouscode enables the design of polymorphic malware. All of these attributes make JSLessa powerful malware threat that can easily evade detection by anti-malware systems.For instance, a pure JavaScript logger could be quickly injected in the user’s browserto captures user’s keystroke events and send them to the malware C&C server overWebSocket. Note that benign and native JavaScript keystroke capturing APIs areused which again will not raise any red flags. Figure 3.4.3 shows an example of an433. JSLESS: A TALE OF FILELESS JAVASCRIPT MEMORY-RESIDENT MALWAREFig. 3.4.3: Obfuscated JavaScript code injectioninjected obfuscated JavaScript key logger that captures keystroke events and sends itto the malware C&C server over WebSockect.To utilize the victim’s system’s computation power or run the malicious scripts ina separate thread from the main UI thread, JSless takes advantage of WebWorkers.This allows JSless to run malicious activities that are computationally intensive, suchas cryptocurrency mining. The WebWorker script is downloaded from the C&Cserver. The JavaScript code in listing 3.4 shows how the malicious WebWorker codecould be obtained as a blob object and initiated on the victim’s browser. Using theimportScripts and createObjectURL functions, we were able to load a script from adifferent domain hosted on the different server and execute it in the 

Background ofthe benign web app.blob = new Blob(["self.importScripts (’{{ HTTPSurl }}/ foo.js ’);"],{type: ’application/JavaScript ’});w = new Worker(URL.createObjectURL(blob));Listing 3.4: Breaking Same-origin Policy with ImportScripts()Until this point one limitation of JSless malware-framework is that fact that themalware will terminate as soon as the user closes his web browser or navigates away443. JSLESS: A TALE OF FILELESS JAVASCRIPT MEMORY-RESIDENT MALWAREfrom the compromised/malicious web server. This limitation is not specific to JSless,it is the common behavior of any fileless malware. In fact, many malware authorssacrifice the persistence of their malware infection by using fileless malware to avoiddetection and bypass anti-malware systems. However, that does not mean filelessmalware authors are not trying to come up with new methods and techniques tomake their fileless malware persistent. In our investigation to provide persistence forJSless even if the user navigates away from the compromised/malicious web page orcloses the web browser. We take advantage of the ServiceWorker API to implementa malware persistence technique with minimal footprint.To achieve malware persistence, we used the WebSocket API to download a scriptfrom the malicious server. After downloading the ServiceWorker registration codefrom the malicious server, as shown in listing 3.1, it registers a sync event, as shownin listing 3.5, to cause the downloaded code to execute and stay alive even if the userhas navigated away from the original page or closed the web browser. The maliciouscode will continue to run and terminate normally when it is completed or abnormallyas result of exception, crash, or if the user restarts his machine. Note that whenwe use ServiceWorker, a file is created and temporarily stored on the client machinewhile the ServiceWorker is running. This is the only case where JSless will place afile on the victim machine, and it is only needed for malware persistence.453. JSLESS: A TALE OF FILELESS JAVASCRIPT MEMORY-RESIDENT MALWAREself.addEventListener(’sync’, function (event) {if (event.tag === ’mal -service -worker ’) {event.waitUntil(malServiceWorker ().then(( response) => {// Service Worker task is done}));}});function malServiceWorker () {// Malicious activity can be performed here}Listing 3.5: ServiceWorker Implementation for malicious purposeIn our proof-of-concept implementation for the malware persistence with Service-Worker, we implemented a MapReduce system. In this malicious MapReduce system,all the current infected web browsers receive the map function and a chunk of thedata via WebSocket. The map function executes as a ServiceWorker and operatesover the data chunks sent by the malicious server. When the ServiceWorker finishesexecuting the map function, it returns the result to the malicious server via Web-Socket. When the malicious server receives the 

Results from the ServiceWorker, itperforms the reduce phase and returns the final result to the malware author.3.4.3 Attack VectorsThe ability to inject and execute arbitrary JavaScript code allows JSless to supporta wide variety of malicious attacks. Here are the most common attacks that JSlesscould execute:3.4.3.1 Data StealingOn infection JSless can easily collect keystrokes, cookie and web storage data, asdemonstrated in our PoC. Also, it could control multimedia devices and capture datafrom a connected mic or webcam using native browser WebRTC APIs.463. JSLESS: A TALE OF FILELESS JAVASCRIPT MEMORY-RESIDENT MALWARE3.4.3.2 DDoSJSless malicious C&C server could orchestrate all the currently infected web browsersto connect to a specific URL or web server to perform a DDoS attack. In this case,JSless constructs a botnet of infected browsers to execute the DDoS attack.3.4.3.3 Resource Consumption AttackIn this case, JSless could use the infected users’ browser to run computationally inten-sive tasks such as cryptocurrency mining, password cracking, etc. The MapReducesystem we implement as part of JSless is an example of managing and running compu-tationally intensive tasks. Also, beside the above attacks which we have implementedin our JSless it is possible to perform other attacks like Click Fraud, RAT-in-the-Browser (RitB) Attacks, and many other web-based attacks.3.5 Experiment & EvaluationIn order to assess the identified JavaScript/HTML5 vulnerabilities and threats, wedeveloped JSless as a proof-of-concept fileless malware that is completely writtenin JavaScript. We used the second injection scenario to test our fileless malwareimplementation. For this purpose, we also implemented a web app that JSless willcompromise to infect the web browser of any user using the web app. The web app isa shared chat board that allows users to register, post and receive messages to/froma shared chat board. The web app and the JSless C&C server are implementedin JavaScript using MEAN stack (MongoDB, ExpressJS, AngularJS, and Node.js).The source code for the fileless malware and the target web app is available on ourGitHub/bitbucket repository for interested researchers and security analysts.For the actual test, we deployed the target web app and the JSless C&C serveron Amazon Web Services (AWS). We used two AWS instances with two differentdomains, one to host the target web app and the second to host JSLess C&C server.We mainly tested two attack vectors, the data stealing attack and the resource con-sumption attack.473. JSLESS: A TALE OF FILELESS JAVASCRIPT MEMORY-RESIDENT MALWARE3.5.1 JS Malware Detection ToolsTo our surprise, few anti-malware systems try to detect JavaScript malware. Weidentified seven tools that we considered promising based on the techniques and thetechnology they use for detection. Most of the tools apply both static and dynamicanalysis. Some of those tools are commercial, but they provide a free trial periodthat includes all the commercial feature for a limited time. Table 3.5.1 shows the listof tools we used in our study.Tool Name Detection Technique License Website Detect JSLessReScan.pro static & dynamic commercial https://rescan.pro/ NOVirusTotal static & dynamic free & commerical https://www.virustotal.com/ NOSUCURI static commercial https://sucuri.net/ NOSiteGuarding static commercial https://www.siteguarding.com/ NOWeb Inspector static & dynamic free https://app.webinspector.com/ NOQuttera static & dynamic free & commercial https://quttera.com/ NOAI-Bolit static & dynamic free & commercial https://revisium.com/aibo/ NOTable 3.5.1: JavaScript and Web App Malware Detection ToolsNone of the tools were able to detect JSless malicious behaviors. To confirm our

Results we invited different teams from anti-malware service providers to inspect ourcompromised web app. Only Fortiguard Labs (https://fortiguard.com/) confirmedthe malicious behaviors of JSless through manual analysis and full access to theobfuscated source code of JSless since the automated tools raised a suspicious flag.3.5.2 Detection & MitigationBy reviewing the 

Results from the detection tools and how those tools work, it isobvious that detecting JSLess is very difficult. The use of WebSocket to inject and runobfuscated malicious code makes it almost impossible for any static analysis tool todetect JSLess, since the malicious payload does not exist at the time of static analysis.The use of benign JavaScript/HTML5 APIs and features, in addition to the dynamicinjection behaviors, also make it very difficult for the current dynamic analysis tools483. JSLESS: A TALE OF FILELESS JAVASCRIPT MEMORY-RESIDENT MALWAREto detect JSLess. Blocking or preventing new JavaScript/HTML5 APIs is not thesolution and it is not an option. In our opinion, a dynamic analysis technique thatimplements continuous monitoring and is context-aware is the only approach that wethink could detect or mitigate fileless malware similar to JSLess.3.5.3 Detection Tool Analysis 

ResultsReScan.ProReScan.Pro is a cloud-based web application scanner which takes the URL of a web-site and generates a report after scanning the website for web-based malware andother web security issues. It explores the website and checks for infections, suspi-cious content, obfuscated malware injections, hidden redirects and other web securitythreats present. Analysis by ReScan.Pro is based on three main features.1. Static Page Scanning: A combination of generic signature detection techniquesand heuristic detection. It uses signature and pattern-based analysis to identifymalicious code snippets and malware injections. It also looks for malicious andblacklisted URLs in a proprietary database.2. Behavioral Analysis: It imitates the website user’s possible behavior to evaluatethe intended action of implemented functionality.3. Dynamic Page Analysis: performs dynamic web page loading analysis whichincludes deobfuscation techniques to decode the obfuscated JavaScript in orderto identify runtime code injections and check for malware in external JavaScriptfiles.We ran the experiment with the ReScan.Pro to test if it will detect the maliciousactivities of JSless malware. It generated a well defined report after analyzing thewebsite with its static and dynamic features. The produced result indicated thewebsite is clean and no malicious activity has been found. ReScan.Pro could notdetect our JavaScript fileless malware.493. JSLESS: A TALE OF FILELESS JAVASCRIPT MEMORY-RESIDENT MALWAREWeb InspectorThis tool runs a website security scan and provides a report of a given website afterit is provided with its URL. Its security scanner is bit different from others because itperforms both malware and vulnerabilities scans together. This tool claims to providefive different detection techniques; Honeypot Engine, Antivirus Detection, BlackListChecking, SSL Checking, and Analyst Research.In our experiment our JavaScript fileless malware was able to successfully deceivethis malware detection tool as well. Web Inspector’s report indicated that no malwarewas detected.SucuriSucuri is another tool that offers a website security evaluation with a free online scan-ner. This scanning tool searches for various indicators of compromise, which includesmalware, drive-by downloads, defacement, hidden redirects, conditional malware, etc.Sucuri claim to uses static techniques with intelligent signatures which are based oncode anomalies and heuristic detection to detect malicious behaviour. Server sidemonitoring is another service provided by them which can be hosted on the compro-mised server to look for backdoors, phishing attack vulnerabilities, and other securityissues by scanning the files present on the server. Moreover, Sucuri also provides ascanning API as a paid feature.Testing Sucuri online scanner with JSLess, we found that it failed to detect outfileless malware, indicating that there is ”No Malware Found” as well as indicating amedium security risk. However, this is due to Insecure SSL certificates, not from thedetection of our fileless malware.QutteraQuttera is yet another website scanner that attempts to identify malware and sus-picious activities in web applications. Its malware detector contains non-signaturebased approaches which attempt to uncover traffic re-directs, generic malware, and503. JSLESS: A TALE OF FILELESS JAVASCRIPT MEMORY-RESIDENT MALWAREsecurity weakness exploits. It also claims to provide real-time detection of shell-codes,obfuscated JavaScript, malicious iframes, traffic re-directs and other threats. Heretoo, the website scanner failed to detect our JavaScript fileless malware.VirusTotalVirusTotal is a popular free malware inspection tool which offers a number of servicesincluding websites scanning. They aggregate different tools which cover a wide varietyof techniques, such as heuristic, signature based analysis, domain blacklisting services,and more. A detailed report is provided after completing the scan which not onlyindicates the malicious content present in a website but also exhibits the detectionlabel by each engine.We scanned our compromised web app with VirusTotal which used 66 differentmalware detection engines, and none of were able to detect that the web app iscompromised, as shown in figure.AI-BOLITAI-BOLIT is an antivirus/malware scanner for website browsing and hosting. It usesheuristic analysis and other “patented AI algorithms” to find malware. We used it toscan our JSLess malware scripts. However, it failed to detect JSLess and generateda false positive when it consider some of the core modules of NodeJS as maliciousJavaScripts.3.6 

Conclusion & 



Future WorkIn this 



Chapter, we confirmed several threat-vectors that exist in new JavaScript andHTML5 features. We demonstrated how an attacker could abuse benign featuresand APIs in JavaScript and HTML5 to implement fileless malware with advancedevasion capabilities. We showed a practical implementation of a fileless JavaScriptmalware that to our knowledge is the first of its kind. The proof-of-concept implemen-tation of the proposed JS fileless malware successfully bypasses several well-known513. JSLESS: A TALE OF FILELESS JAVASCRIPT MEMORY-RESIDENT MALWAREanti-malware systems that are designed to detect JavaScript and web malware. In ad-dition, third-party malware analyst teams confirmed our finding and proved that theproposed malware bypasses automated malware detection systems. From this par-ticular study, we conclude that the current static and dynamic analysis techniquesare limited if not useless against fileless malware attacks. Moreover, fileless malwareattacks are not limited to PowerShell and Windows environment. In our opinion,any computing environment that enables running and executing arbitrary JavaScriptcode is vulnerable to fileless attacks.Our 



Future Work could be summarized in three different directions. First, we willcontinue extending the malicious behaviors of JSLess and investigate the possibilityof more advanced attacks using other new benign features and APIs from JavaScriptand HTML5. Second, we will design a new detection technique to detect advanced JSmalware and mainly fileless JS malware like the proposed JSLess. We plan to imple-ment dynamic analysis approaches that continually monitor and analyze JavaScriptand Browser activities. Finally, our third research direction will focus on investigat-ing the fileless malware threat in unconventional computing environments, such asthe Internet of Things, in-memory computing environments (e.g., Redis, Hazelcast,Spark, etc.), and so on. We hope our research will help to raise awareness of theemerging unconventional malware threats.



References[1] H. Adas, S. Shetty, and W. Tayib. “Scalable detection of web malware onsmartphones”. In: 2015 International Conference on Information and Commu-nication Technology Research (ICTRC). May 2015, pp. 198–201. doi: 10.1109/ICTRC.2015.7156456.[2] G. Blanc et al. “Characterizing Obfuscated JavaScript Using 



Abstract Syn-tax Trees: Experimenting with Malicious Scripts”. In: 2012 26th InternationalConference on Advanced Information Networking and Applications Workshops.Mar. 2012, pp. 344–351. doi: 10.1109/WAINA.2012.140.523. JSLESS: A TALE OF FILELESS JAVASCRIPT MEMORY-RESIDENT MALWARE[3] D. Cosovan, R. Benchea, and D. Gavrilut. “A Practical Guide for Detectingthe Java Script-Based Malware Using Hidden Markov Models and Linear Clas-sifiers”. In: 2014 16th International Symposium on Symbolic and Numeric Al-gorithms for Scientific Computing. Sept. 2014, pp. 236–243. doi: 10.1109/SYNASC.2014.39.[4] Y. Fang et al. “Research on Malicious JavaScript Detection Technology Basedon LSTM”. In: IEEE Access PP (Oct. 2018), pp. 1–1. doi: 10.1109/ACCESS.2018.2874098.[5] Global Research and Analysis Team, KASPERSKY Lab. Fileless Attack AgainstEnterprise Network. White Paper. KASPERSKY Lab, 2017.[6] K. R. Kishore et al. “Browser JS Guard: Detects and defends against MaliciousJavaScript injection based drive by download attacks”. In: The Fifth Interna-tional Conference on the Applications of Digital Information and Web Tech-nologies (ICADIWT 2014). Feb. 2014, pp. 92–100. doi: 10.1109/ICADIWT.2014.6814705.[7] A. Magnusardottir. Fileless Ransomware: How It Works & How To Stop it?White Paper. Cyren, June 2018.[8] D. Maiorca et al. “Detection of Malicious Scripting Code Through Discrimi-nant and Adversary-Aware API Analysis”. In: Proceedings of the First ItalianConference on Cybersecurity (ITASEC17), Venice, Italy, January 17-20, 2017.Ed. by Alessandro Armando, Roberto Baldoni, and Riccardo Focardi. Vol. 1816.CEUR Workshop Proceedings. CEUR-WS.org, 2017, pp. 96–105. url: http://ceur-ws.org/Vol-1816/paper-10.pdf.[9] J. Mao et al. “Detecting Malicious Behaviors in JavaScript Applications”. In:IEEE Access 6 (2018), pp. 12284–12294. issn: 2169-3536. doi: 10 . 1109 /ACCESS.2018.2795383.[10] McAfee. Fileless Malware Execution with PowerShell Is Easier than You MayRealize. McAfee, Mar. 2017. url: https://www.mcafee.com/enterprise/en-us/assets/solution-briefs/sb-fileless-malware-execution.pdf.533. JSLESS: A TALE OF FILELESS JAVASCRIPT MEMORY-RESIDENT MALWARE[11] S. Ndichu et al. “A Machine Learning Approach to Malicious JavaScript Detec-tion using Fixed Length Vector Representation”. In: 2018 International JointConference on Neural Networks (IJCNN). July 2018, pp. 1–8. doi: 10.1109/IJCNN.2018.8489414.[12] S. Oh et al. “Malicious Script Blocking Detection Technology Using a LocalProxy”. In: 2016 10th International Conference on Innovative Mobile and In-ternet Services in Ubiquitous Computing (IMIS). July 2016, pp. 495–498.[13] V. Sachin and N. N. Chiplunkar. “SurfGuard JavaScript instrumentation-baseddefense against Drive-by downloads”. In: 2012 International Conference on Re-cent Advances in Computing and Software Systems. Apr. 2012, pp. 267–272.[14] B. Sayed, I. Traoré, and A. Abdelhalim. “Detection and mitigation of maliciousJavaScript using information flow control”. In: 2014 Twelfth Annual Interna-tional Conference on Privacy, Security and Trust. July 2014, pp. 264–273. doi:10.1109/PST.2014.6890948.[15] P. Seshagiri, A. Vazhayil, and P. Sriram. “AMA: Static Code Analysis of WebPage for the Detection of Malicious Scripts”. In: Procedia Computer Science93 (2016). Proceedings of the 6th International Conference on Advances inComputing and Communications, pp. 768–773. issn: 1877-0509. doi: https://doi.org/10.1016/j.procs.2016.07.291. url: http://www.sciencedirect.com/science/article/pii/S187705091631537X.[16] V. R. L. Shen, C. Wei, and T. Tong-Ying Juang. “Javascript Malware DetectionUsing A High-Level Fuzzy Petri Net”. In: July 2018, pp. 511–514. doi: 10.1109/ICMLC.2018.8527036.[17] I. A. AL-Taharwa et al. “RedJsod: A Readable JavaScript Obfuscation DetectorUsing Semantic-based Analysis”. In: 2012 IEEE 11th International Conferenceon Trust, Security and Privacy in Computing and Communications. June 2012,pp. 1370–1375.[18] The 2017 State of Endpoint Security Risk. White Paper. Ponemon Institute,2017.543. JSLESS: A TALE OF FILELESS JAVASCRIPT MEMORY-RESIDENT MALWARE[19] TrendMicro. Analyzing the Fileless, Code-injecting SOREBRECT Ransomware.TrendMicro, June 2017. url: https://blog.trendmicro.com/trendlabs-security-intelligence/analyzing-fileless-code-injecting-sorebrect-ransomware/.[20] C. Wang and Y. Zhou. “A New Cross-Site Scripting Detection Mechanism Inte-grated with HTML5 and CORS Properties by Using Browser Extensions”. In:2016 International Computer Symposium (ICS). Dec. 2016, pp. 264–269. doi:10.1109/ICS.2016.0060.[21] Y. Wang, W.g Cai, and P. Wei. “A deep learning approach for detecting ma-licious JavaScript code”. In: Security and Communication Networks 9 (2016),pp. 1520–1534.[22] W. Xu, F. Zhang, and S. Zhu. “The power of obfuscation techniques in maliciousJavaScript code: A measurement study”. In: 2012 7th International Conferenceon Malicious and Unwanted Software. Oct. 2012, pp. 9–16.[23] S. Yoon et al. “Automatic attack signature generation technology for mali-cious javascript”. In: Proceedings of 2014 International Conference on Mod-elling, Identification Control. Dec. 2014, pp. 351–354. doi: 10.1109/ICMIC.2014.7020779.55



Chapter 4Interpreting Machine LearningMalware Detectors WhichLeverage N-gram AnalysisWilliam Briguglio and Sherif SaadIn Proceedings of the 12th International Symposium on Foundations and Practice ofSecurity4.1 



IntroductionAdopting sophisticated machine learning techniques for malware detection or othercyber attack detection and prevention systems in a production environment is a chal-lenge. This is because most of the time it is not possible to understand how machinelearning systems make their detection decisions. In the malware detection domain,machine learning models can be trained to distinguish between benign binaries andmalware, or between different malware families. The advantage of using machinelearning models is that they are less sensitive to minute changes in malware binariesand can therefore detect unseen samples so long as they are designed and trained todetect characteristics common across seen and unseen samples. Furthermore, theirlearnt relationships can be used to determine relevant features for a classification,limiting the amount of data malware analyst must sift through to determine thefunctionality of a malicious binary. However, there are several drawbacks that mustbe addressed before their full potential can be realized in the malware detection do-main. Firstly, due to the quick evolving nature of malware, the models must be made564. INTERPRETING ML MALWARE DETECTORS WHICH USE N-GRAM FEATURESefficient to train and update frequently when new malware families are discovered.Secondly, it is possible to create specially crafted “adversarial samples” which takeadvantage of peculiarities in the models learnt relationships to bypass the detectorwith relatively inconsequential changes to the binary. Finally, given the high degreeof risk involved with classification errors, the models must provide a reason for theirdecisions in order to improve performance and increase trust in the model and itspredictions.The process of providing reasons for a machine learning model’s predictions isknown as interpretation. Interpretation in this setting should provide several keybenefits. Firstly, due to the high cost of classification error, a low false positive andfalse negative rate is a must, and therefore these systems must be robust. Further,robustness makes it more difficult for malware authors to create adversarial malwareto bypass the detector. A model is said to be robust if small changes in input donot cause large changes in output such as a different classification. Second, the highrisk necessitates a high degree of model confidence. Therefore, interpretation mustprovide evidence that the model has learnt something which can be corroborated withindustry knowledge. This also goes hand in hand with the first requirement as aninterpretation which can show a model is robust can improve model confidence aswell. Additionally, the interpretation should aid malware analysts in down streamtasks such as determining the functionality of a malware binary.Machine learning interpretation can be broadly separated into two categories. Oneis model agnostic techniques which are independent of the type of model which theyare interpreting and rely solely on the input and output of the model. The other,which we will be using in this 



Chapter, are model specific techniques, which use specificelements of the model such as learnt weights or decision rules in order to provide aninterpretation of a prediction. Interpretations themselves can be divided into globaland local interpretations. Global interpretations provide an interpretation that isapplicable across the entire feature space. Meanwhile local interpretations apply toonly a single example or a small subset of the feature space. Some interpretationtechniques provide only one type of interpretation while others provide both.574. INTERPRETING ML MALWARE DETECTORS WHICH USE N-GRAM FEATURESIn this 



Chapter we explore the interpretability of machine learning based malwareclassifiers in relation to the goals of model robustness, confidence in model predic-tions, and aiding the process of determining the functionality of a malware sample. Wetrain a logistic regression model, random forest, and a neural network on a Microsoftdata set containing the hexadecimal representations of malware binaries belongingto several different malware families. We then apply model specific interpretationtechniques to provide both a global and local interpretation of each of the models.The objective of this 



Chapter is to demonstrate interpretability techniques in practiceon machine learning based malware detectors. We also try to evaluate the effective-ness of existing interpretability techniques in the malware analysis domain in termsof their usefulness to malware analysts in a practical setting. To the best of ourknowledge, this is the only work which explores the application of machine learninginterpretability techniques in the malware analysis domain.4.2 



Literature ReviewIn the last decade, with the increasingly massive data sets machine learning algo-rithms are being used on, and the growing complexity of the algorithms, the predictionprocess of these algorithms has become so non-intuitive that traditional analysis tech-niques no longer suffice. Analysis being necessary for a number of practical and legalconcerns has caused research to now shift towards machine learning interpretability.Christoph Molnar [11] put together a 

Summary of machine learning interpreta-tion methods in which he outlines a basic approach for the interpretation of LinearRegression models (of course the same approach can be applied to linear SVM’s, Shi-rataki et al. [18]) where a feature’s contribution to a prediction is the product of itsvalue and weight. For logistic regression he shows that when the jth feature value isincremented by 1, then the quotient of the predicted odds of the sample belonging tothe positive class after the increase over the predicted odds of the sample belongingto the positive class before the increase is equal to eβj , where βj is the weight offeature j. Alternatively, this means that a unit increase in feature j 

Results in the584. INTERPRETING ML MALWARE DETECTORS WHICH USE N-GRAM FEATURESpredicted odds increasing by ((eβj − 1) ∗ 100)%. He goes on to discuss the seeminglytrivial interpretation of decision trees as the conjunction of the conditions describedin the nodes along a predictions path to a leaf node. Similarly, for rule list models,an “explanation” is simply restating the rule or combination of rules which lead to adecision.However, the evaluation of a model’s complexity is closely tied with its explana-tion’s comprehensibility, especially for rule set models, linear models, and tree mod-els. Given the following complexity definitions, the explanation approaches discussedabove could be too complex for highly dimensional datasets. Marco Ribeiro et al. [15]define the complexity of a linear model as the number of non-zero weights and thecomplexity of a decision tree as the depth of the tree. Meanwhile, Otero and Freitas[12] defined the complexity of a list of rules as the average number of conditions evalu-ated to classify a set of test data. They referred to this as the “prediction-explanationsize”.There has also been work done on the interpretability of neural networks(NNs)such as the Layer-wise Relevance Propagation introduced in [3] as a set of constraints.The constraints ensure that the total relevance is preserved from one layer to anotheras well as that the relevance of each node is equal to the sum of relevance contribu-tions from its input nodes which in turn is equal to the sum of relevance contributionsto its output nodes. Any decomposition function following these constraints is con-sidered a type of Layer-wise Relevance Propagation. In [19], Shrikumar et al. proposeDeepLIFT which attributes to each node a contribution to the difference in predictionfrom a reference prediction by back propagating the difference in predication scaledby the difference in intermediate and initial inputs.Moving on to model agnostic methods, Friedman in [6] used Partial DependencePlots (PDP) to show the marginal effect a feature has in a predictive model. Similarly,Goldstein et al. [8] used Individual Conditional Expectation (ICE) plots to show acurve for each sample in the data set where one or two features are free variables whilethe rest of the features remain fixed. Since ICE plots and PDPs do not work wellwith strongly correlated features, Deniel W. Apley et al. [2] proposed Accumulated594. INTERPRETING ML MALWARE DETECTORS WHICH USE N-GRAM FEATURESLocal Effects plots to display the average local effect a feature has on predictions.The H-statistic was used by Friedman and Popescu in [7] (equations 44-46) to pro-vide a statistical estimate of the interaction strength between features by measuringthe fraction of variance not captured by the effects of single variables. Feature Im-portance was measured by Breiman [4] as the increase in model error after a feature’svalues are permuted (a.k.a. permutation importance).Marco Ribeiro et al. in [15] defined a version of the surrogate method which canexplain individual predictions using an approach called Local Interpretable Model-agnostic Explanations (LIME) which trains an interpretable classifier by heavilyweighing samples nearer to a sample of interest. Tomi Peltola [13] extended this workwith KL-LIME, which generated local interpretable probabilistic models for Bayesianpredictive models (although the method can also be applied to non-Bayesian proba-bilistic models) by minimizing the Kullback-Leibler divergence of the predictive modeland the interpretable model. This has the added benefit of providing explanationsthat account for model uncertainty. Strumbelj et al. [20] detailed how to describethe contributions made by each feature to a prediction for a specific instance usingShapely Values, a concept adopted from coalitional game theory.Finally, there are Example-Based methods such as the method put forward byWachter et al. in [21] which produce interpretations by finding counter-factual ex-amples which are samples with a significant difference in prediction, whose featuresare relatively similar to the sample of interest, by minimizing a loss function. Thefound sample is then used to explain what small changes would cause the originalprediction to change meaningfully. There is also the MMD-critic algorithm by Kimet al. [9] which finds Prototypes (well represented examples) and Criticisms (poorlyrepresented examples) in the dataset. To find examples in the training data whichhave a strong effect on a trained linear regression model (i.e. influential instances)Cook [5] proposed Cook’s distance, a measure of the difference in predictions madeby a linear regression model (however the measure can be generalized to any model)trained with and without an instance of interest. Koh and Liang [10] put forwarda method for estimating the influence of a specific instance without retraining the604. INTERPRETING ML MALWARE DETECTORS WHICH USE N-GRAM FEATURESmodel as long as the model has a twice differentiable loss function.4.3 MethodTraining and classification were done on a data set of 10,896 malware files belongingto 9 different malware families.1 The data set is discussed in [16]. Each sampleconsists of the hexadecimal representation of the malware’s binary content. The classdetails are summed up in table 4.3.1.Table 4.3.1: Class distribution in Data SetClass No. Family Sample Count Type1 Ramnit 1541 Worm2 Lollipop 2478 Adware3 Kelihos ver3 2942 Backdoor4 Vundo 475 Trojan5 Simda 42 Backdoor6 Tracur 751 TrojanDownloader7 Kelihos ver1 398 Backdoor8 Obfuscator.ACY 1228 obfuscated malware9 Gatak 1013 BackdoorBased on other work on the the same data set, we decided to use n-grams asfeatures. N-grams are sequences of words of length n which occur in a 

Body of text.However, in our case the n-grams are sequences of bytes of length n which occur in abinary. The length of n-gram we settled on was 6 because they were shown to preformwell in [14], however our approach can work with n-grams of arbitrary length. Weextracted the 6-gram features from the hex representations of the malware files by1The data set was downloaded from https://www.kaggle.com/c/malware-classification/data614. INTERPRETING ML MALWARE DETECTORS WHICH USE N-GRAM FEATURESobtaining the entire list of 6-grams present in the data set, and the number of files each6-gram appeared in. This resulted in over 2,536,629,413 candidate features. Next,any 6-gram which did not appear in at least 100 files was removed from consideration,bringing the feature set size down to 817,785. This was done because [14] also showedthat selection by frequency is an effective way to reduce the initial feature set size anda computationally cheap approach was needed considering the number of features.Next, feature vectors were created for each of the malware samples so that a moresophisticated feature selection method can be preformed. This was done by searchingfor the selected 6-gram feature in a binary and setting the corresponding value in thatbinary’s feature vector to 1 if the binary did contain the 6-gram, and 0 otherwise.To select the features for the logistic regression model, Chi2 was used because it candetect if a categorical feature is independent of a predicted categorical variable (inthis case our class) and is therefore irrelevant to our classifier. For the neural networkand random forest, Mutual Information (MI) was used because it can detect the morecomplex dependencies between a feature and a sample’s classification which can betaken advantage of by a neural network or random forest. Since the feature set wasstill very large, the Chi2 and MI scores had to be calculated in batches. This was doneby splitting the data set into 20 batches, each with the same distribution of classes,and averaging out the resulting scores for each feature. Next, the features with Chi2scores above 330 or MI scores above 0.415 were selected. This brought the feature setsize down to 8867 in the case of the logistic regression model and to 9980 in the caseof the neural network and random forest. The feature set size was determined basedoff other work using n-grams to classify the same data set. We did not attempt tofind an optimal feature set size as our primary focus was model interpretation.Next, the models were trained on their respective feature sets. To find the bestparameters for the logistic regression model and train the model, grid search with5-fold cross validation was used, yielding C = 10 and tolerance = 0.0001. The valueof C inversely determines the strength of regularization, that is, smaller values of Ccause more feature weights in the classifier to be set to 0, a value of 0 correspondsto no regularization, and values above 0 encourage the classifier to use more fea-624. INTERPRETING ML MALWARE DETECTORS WHICH USE N-GRAM FEATUREStures. Tolerance determines the minimum change in error, from one iteration of theoptimization algorithm to the next, that causes the algorithm to terminate training.Similarly for random forest, finding the best parameters and training was done withgrid search with 5-fold cross validation as well. The number of trees found to preformbest was 300 and the and the minimum samples per leaf found to preform best was0.01% of the total number of samples. The grid search with cross validation, logisticregression model, and the random forest model were implemented using the scikitpython library.For the neural network the data was split into a training and a test set each withthe same class distribution. This was done because the extra parameters in a neuralnetwork require a larger data set to learn more 



Abstract patterns and splitting it upinto many folds might have stifled this process. The neural network consisted of aninput layer with one neuron per feature, an output layer with one neuron per classusing the sigmoid activation function, and a hidden layer consisting of 40 neuronsusing the tanh activation function. 40 neurons was chosen because that number wasfound to preform the best after testing with various other configurations. There werealso no bias units to aid in interpretation. The neural network was implemented usingthe Keras python library.After training and testing the three models, the logistic regression model wasinterpreted by examining the weights used by the classifier. The random forest wasinterpreted by examining the feature importance as well as using the treeInterpreterpython library [17] to obtain feature contributions to a particular prediction. Inthe case of the Neural network, the iNNvestigate python library by [1] was used topreform LRP to get the relevances of each node in the model for interpretation. Thebalanced accuracy on the left out fold was 96.19% for the logistic regression modeland 96.97% for the random forest. The balanced accuracy on the test set was 94.22%for the neural network. A 



Discussion of the model interpretations follows in the next



Section.634. INTERPRETING ML MALWARE DETECTORS WHICH USE N-GRAM FEATURES4.4 Interpretation4.4.1 Logistic Regression Model InterpretationThe logistic regression model uses a one-vs-rest classification scheme whereby for eachclass, a constituent model is trained to classify a sample as either that class, or notthat class, and therefore we are actually dealing with nine separate logistic regressionmodels each making binary classifications. For this reason we cannot preform thetypical global interpretation of the overall multi-class model by examining the weightssince the weights should be different for each of the binary models. However, we cangain insight of the importance of each feature by averaging these weights across the9 constituent binary models. For this we take the average of the absolute values ofthe weights. This is because if a feature contributes positively for one constituentbinary classifier and negatively for another, then the weights would cancel each otherout during averaging which would falsely give the impression that the feature was notimportant in the overall multi-class model. Table 4.4.1 shows the largest 15 averagesof the absolute feature weights.Looking at the table 4.4.1, we can see that three 6-grams are relatively heavilyweighted, 00E404000000, 0083C4088B4D, and C78530FDFFFF. Recall from 



Section4.2 that for logistic regression, when the jth feature value is incremented by a value of1, then the predicted odds increase by ((eβj−1)∗100)%, where βj is the learnt weightof the jth feature. In our case we are using binary feature values where a 1 indicatesthe presence of a 6-gram and 0 indicates its absence, so we interpret the weights asfollows. When the 6-gram corresponding to the jth feature is present, the predictedodds increase by ((eβj −1)∗100)%. One may be tempted to apply this to the weightsin table 4.4.1, but these are averaged absolute weights across all 9 constituent binaryclassifiers. Further, negative weights do not cause a decrease in the predicted oddsthat is proportional to a positive weight with the same absolute value due to theshape of the function f(x) = ex − 1. Therefore, it would be inaccurate to say theaverage absolute effect of some 6-gram corresponds to a (eavgj − 1)% change in thepredicted odds, where avgj is the average absolute weight of feature j. Thus a global644. INTERPRETING ML MALWARE DETECTORS WHICH USE N-GRAM FEATURESTable 4.4.1: Max 15 Absolute Weights of the Logistic Regression Model AveragedAcross All 9 Binary Sub-classifiersAvg. Abs. Weight Feature1.3151053659364556 0000000066C71.3480135328294032 008B4C240C891.4629237676020752 8BEC83EC10C71.4846778818947817 00000000EB071.5276044995023308 B800000000501.540535475655897 5001476574531.5605614219830626 0068000040001.6494330450079937 89852CFDFFFF1.685741868293823 0033C58945FC1.7235671007282005 8B91C80000001.781357432072784 034C6F61644C1.8232074423648363 8BEC6A006A002.071327588344743 00E4040000002.15007904223129 0083C4088B4D2.1561672884172056 C78530FDFFFF654. INTERPRETING ML MALWARE DETECTORS WHICH USE N-GRAM FEATURESinterpretation of a multi-class one-vs-rest logistic regression model using n-grams inconfined to vague statements about which n-grams are important based solely offtheir average absolute weights, which is not very useful in a practical setting.Next we will examine the max weights for a constituent binary model. This willallow us to make 



Conclusions on what features the model uses to detect a specificclass of malware in the data set. Furthermore, we will be able to determine exactlythe change in predicted odds that the presence of an n-gram causes. For the sake ofbrevity, we will examine just the binary model for class 3, corresponding to the Keli-hos ver3 family of malware, as all three models performed well for this class but thesame process can be followed for the other constituent binary models correspondingto other classes. Table 4.4.2 shows the max 15 weights of the classifier for class 3.Table 4.4.2: Max 15 Weights for Kelihos ver3 Binary Sub-classifierWeight Feature0.6438606978376447 0006074765740.6438606978376447 000C074765740.6438606978376447 0607476574440.6438606978376447 0747657444430.6438606978376447 0C07476574440.6438606978376447 9306446973701.3719246726968015 00000083FEFF1.5114878196031336 E8000000895D2.1067800174989904 0F85CC0100002.3123117293223405 0A0100008B452.9041700918303084 000F859D00003.174276823535364 000F847001003.5334477027408613 0083C4088B4D3.7941081330633857 034C6F61644C4.391600387291376 00008B5DE43B664. INTERPRETING ML MALWARE DETECTORS WHICH USE N-GRAM FEATURESIn table 4.4.2 we can see three 6-grams have relatively large weights. This meansthese n-grams are most strongly associated with class 3 and in this case, since we arelooking at only the weights for a single binary classifier, we can use our interpretationfrom above. That is, when the 6-gram corresponding to the jth feature is present, thepredicted odds increase by ((eβj − 1) ∗ 100)%. For example we can say the presenceof 00008B5DE43B, increases the predicted odds of a sample belonging to class 3 by((e4.3916−1)∗100)% = 7977%. At first glance this number may seem excessive but inorder to make good sense of it we must also determine what the predicted odds of asample belonging to class 3 are when this 6-grams are not present, using a 



Referencesample. For this we use a zero-vector corresponding to a sample where none of the6-grams used as features are present. Since the dot product of a zero vector andthe weight vector is zero, we only need to take the sigmoid of the intercept of thebinary model for class 3 to determine the predicted probability of the reference vectorbelonging to class 3. The intercept is -4.2843, thus the predicted probability of thereference sample belonging to class 3 is sigmoid(−4.28426) = 0.01360. Next we mustconvert this to odds with 0.01360/(1−0.01360) = 0.01378. This means a sample withno feature 6-grams present except 00008B5DE43B increases the odds from 0.01378 by7977% to 0.01378 + (0.01378 ∗ 79.77) = 1.11301 predicted odds, or a 0.5267 predictedprobability, of belonging to class 3. Thus we see that because of the intercept, thelarge weight of this feature does not necessarily guarantee a classification into class3.We can get a better idea of the robustness of the model by checking the number of6-grams which play a significant role in the classification of a sample into class 3. Thisis because robustness is a measure of how tolerant a model is to small changes in input.Therefore, if the number of 6-grams which play a significant role is large, then a largenumber of changes in input will be required for a change in classification, thus givingus confidence in the model’s robustness. However, if the number of significant featuresis low then only a small number of changes in input will be required for a change inclassification, changes that may be easy and inconsequential for malware authors tomake. Thus the robustness of the model would be called into question. In our case,674. INTERPRETING ML MALWARE DETECTORS WHICH USE N-GRAM FEATURES20 features have weights greater than or equal to about 0.59. 6-grams with weightsabove this number increase the predicted odds by ((e0.59 − 1) ∗ 100)% ≈ 80%. Sincethe predicted odds of the reference example belonging to class 3 is 0.01378, this meansabout 11 such features can cause a sample to be classified as class 3 with about 90%predicted probability. This may indicate that the model is putting too much emphasison just a few highly weighted 6-grams. To test this we can reclassify samples belong toclass 3 with the highest weighted 6-grams set to 0. In our case, we set the nine highestweighted features to 0 for all samples. This required 22863 changes to the featurearray, and the result was only 24 more misclassifications, 17 of which belonged to class3, which has 2942 samples. Here, we encounter a specification issue. Currently, thereis no formally defined metric to measure robustness quantitatively and once there is, athreshold for acceptable robustness will be application specific. We leave a definitionof a robustness metric to 



Future Work, however, given that robustness is defined interms of a model’s tolerance to changes in input, and that tolerance to changes ofinsignificant features is irrelevant, we can be confident that this approach can give usan idea of our model’s robustness. The models robustness becomes more clear whencompared with other models. For example, if setting the same number of features to 0in another model resulted in more or less misclassification, then we can say that modelis less or more robust respectively than our logistic regression model Therefore, we canconfidently say our approach gave an idea of model robustness for class 3. One canincrease the model’s robustness by further training the classifier with samples whichhave the highly weighted 6-grams removed. This would force the classifier to learn amore diverse set of features which correspond to class 3, meaning that more changeswould be required to change a prediction to or from class 3. Thus by observing theimportant features, we can improve the models robustness to small changes in theinput. A similar strategy can be followed for the most negatively weighted features.If there are features with too large negative weights, then a detector can be fooledby intentionally adding these 6-grams. Further training the classifier by adding thelarge negative weighted 6-grams to samples labeled class 3 will force the classifier tolearn not to negate positively weighted features with one or a small set of 6-grams.684. INTERPRETING ML MALWARE DETECTORS WHICH USE N-GRAM FEATURESTherefore we can conclude that examining the weights in the manner we have donehere can be useful for debugging logistic regression models leveraging n-grams. Thisinterpretation is still global in that it encompasses the entire feature space, however,it must be repeated for each class. On the upside though, the global interpretationdoubles as a local interpretation as the relationship between the presence of an n-gram and the change in the predicted odds holds across the entire data set for eachsample.Furthermore, this method for finding important n-grams features can be helpfulin a practical setting as it can be used to aid malware analysts in down stream tasks.A malware binary’s functionality can be more easily determined by implementinga method which automatically disassembles binaries and 

Highlights the code whichcorresponds to the most heavily weighted n-grams that are present in the binary.This approach can also improve confidence in the model if the highlighted code’sfunctionality is corroborated with industry knowledge. Both these advantages requireanother interpretation step of mapping feature values from the feature space to thedomain space (i.e. mapping n-grams to the corresponding code) which is not thefocus of this 



Chapter. The downside to this interpretation approach is that it isspecific to logistic regression models only, and unlike models such as neural networksor decisions tress, logistic regression models are not easily capable of learning morecomplex relationships between features and target values.4.4.2 Random Forest InterpretationIn the case of the random forest, interpretation is more difficult. It is easy in a moregeneral sense, in that we can get the feature importance scores, shown below in table4.4.3, and use these to determine what features are generally most important, butgetting a more fine grained interpretation is a challenge as the random forest is anensemble of often hundreds of different decision trees.Table 4.4.3 gives us a great idea of the model robustness. Since the total featureimportance is always equal to 1, we can be sure that the model isn’t relying on just asmall number of features to make predictions because the 15 most important features694. INTERPRETING ML MALWARE DETECTORS WHICH USE N-GRAM FEATURESTable 4.4.3: Max Feature 15 Importances for Random ForestFeature Importance Feature0.006877917709695 7265737300000.007047751117095 7450726F63410.00723117607771 6472657373000.007262894349522 558BEC83EC080.007377076296786 0064A10000000.007401045194749 727475616C410.007815881804511 A100000000500.008221953575956 75616C416C6C0.008652467124996 6341646472650.008657476622364 8A040388840D0.008840768087294 69727475616C0.008879491127129 89F5034C24040.00898170788833 7475616C416C0.008987620418762 008A840D2F060.009011931204589 060000E2EFB9704. INTERPRETING ML MALWARE DETECTORS WHICH USE N-GRAM FEATURESonly accounts for 0.9% of the total importance. Additionally, the feature importancesteadily declines without one feature or a small group of features overshadowingthe rest. Unfortunately, general statements about robustness which do not providemuch utility to the malware analyst in a practical setting are the most we can saywith a global interpretation. However considering a single example can give us moreinformation, albeit only locally.Interpretation of a Single Sample with Random ForestWith random forest, a local interpretation of a single example is difficult as a classifi-cation decision is the result of a vote amongst many different decision trees. However,here we find the tree with the highest predicted probability that a specific examplebelongs to its actual class. Then we use the tree interpreter library [17] to break downthe contributions of each 6-gram feature. In our case we followed this procedure forsample 4WM7aZDLCmlosUBiqKOx and found that the 6-gram 002500000031 andthe bias contributed 97.3% of the total feature importance. One may be tempted tothink this means the model is relying on only a single feature however this is justone tree out of many which have heavily varying structures. Thus, changing thisfeature may not cause many of the other tree’s predictions to change, such is theadvantage of using random forests over single decisions trees. The significance of theresulting feature contribution is two fold. Firstly, the model designer can find thecode corresponding to 002500000031 in the assembly code and determine weather thefunctionality of the code corroborates industry knowledge. If it does, then this can beused with other examples to improve model confidence. Secondly, by finding 6-gramsin the constituent decision trees of the random forest model which are significant toa prediction, a process can be automated to disassemble the input file and highlightthe code that corresponds to these significant 6-grams, aiding in malware analysis.The downside to this approach is that the random forest is made up of many dif-ferent decision trees, many of which should all be predicting the correct class, so anautomated process which collects significant 6-grams from these constituent trees and

Highlights the corresponding code may provide an overwhelming number of 

Results.714. INTERPRETING ML MALWARE DETECTORS WHICH USE N-GRAM FEATURESThis is because well over a hundred trees will be contributing at least a few 6-grams,meaning that potentially 100’s of snippets of code will be highlighted to the analyst.Once again we are faced with the problem of mapping the feature values to the do-main, however this should not be too tall a task and we leave this challenge to futurework.4.4.3 Neural Network Model InterpretationFor our global interpretation of the Neural Network model, we used LRP to deter-mine the most relevant input nodes for classification. LRP was preformed in thisexperiment using iNNvestigate python library by [1]. First we found the relevancesof the input nodes for each sample and then we averaged the absolute values of theserelevances for the entire data set. This was done because one input node may be pos-itively contributing to one output nodes prediction while negatively contributing toanother, causing the input nodes relevances to cancel out during averaging and givingfalse impressions about the feature set. Table 4.4.4 shows the largest 15 averages ofthe absolute relevances.In Table 4.4.4 we can see two values had significantly higher relevances than therest, 000000000400 and 0000000000FF, and are therefore important for the modelsclassification. Additionally, we can see many of the features which appear here are alsoin the top 15 most important 6-grams for the random forest. This result partiallyvalidates our technique for finding important 6-gram features in a neural networkwhich to the best of our knowledge is a novel use of LRP in this domain. This givesus a general idea of the importance of features used by the model but, just like in thecase of the other two models, we are still confined to vague general statements abouta feature’s importance. However, this time it is due to the complexity of the model.Next we will examine the max relevances for a particular class. In this case weaverage the relevances for each node across all samples which were correctly classifiedas class 3. Table 4.4.5 shows the max 15 average relevances for class 3.In Table 4.4.5 we can see five of the features which appear here are also in thetop 15 highest weighted 6-grams for the binary logistic regression classifier for class724. INTERPRETING ML MALWARE DETECTORS WHICH USE N-GRAM FEATURESTable 4.4.4: Max Average Absolute RelevancesAvg. Abs. Relevance Feature0.4204155570273673 24000000008B0.438576163384531 75616C416C6C0.4604056179848827 0004000000000.6358686047042836 00FFFFFFFFFF0.6414918343055965 008A840D2F060.6961477693970937 060000E2EFB90.7207968499760279 8A040388840D0.7391062783969391 0000010000000.7655264716760353 0400000000000.7695977668414099 89F5034C24040.8623695409436033 416C6C6F63000.8762457266039623 6C6C6F6300000.8811945910382549 69727475616C1.1011308772023591 0000000004001.129173981900078 0000000000FFBolded 6-grams also present in Table 4.4.3734. INTERPRETING ML MALWARE DETECTORS WHICH USE N-GRAM FEATURESTable 4.4.5: Max Avg Relevances for Class 3Avg Relevance Feature0.07849652902147494 0607476574440.0858714786617495 8B00000067000.08840799934653523 07497357696E0.09155762345728868 0C07476574440.09213969967088875 F104486561700.09360746295067239 00F0F02800000.09471450612061977 00F1044865610.10572475395119978 C3008BFF558B0.10603324133390207 0093064469730.11341626335133194 000C074765740.11451772113662628 C38BFF558BEC0.12097247805393918 9306446973700.14448647700726405 04546C7347650.1895982317973578 0644697370610.24520372442763907 034C6F61644CBolded 6-grams also present in Table 4.4.2744. INTERPRETING ML MALWARE DETECTORS WHICH USE N-GRAM FEATURES3. This result also partially validates our technique for finding important 6-gramfeatures in a neural network for a single class. In this case we are still confined togeneral statements about a features importance for a specific class. However, we canget an idea of the model’s robustness by setting the features with the highest averagerelevances for class 3 to 0 for all correctly classified samples in class 3. If the modelrelies heavily on only the presence of these 6-grams, then the class accuracy will dropdrastically, however if we have a similar class accuracy as before, then it is unlikelythat the features with a lesser average relevance would have a larger effect on theclass accuracy and therefore we can somewhat confidently say the model is robust forthis class. In our experiment the top 4 highest average relevance features were all setto 0 and it resulted in no further misclassifications. Therefore we can say our modelis somewhat robust for class 3. This result is somewhat helpful in a practical settingas a malware analyst can use this technique to ensure the robustness of their model,but not much else.Interpretation of a Single Sample with Neural NetworkNext we’ll further explore the neural network’s predictions for samples belonging toclass 3 by taking the test sample with the highest predicted probability of belongingto class 3, sample 4WM7aZDLCmlosUBiqKOx, and examining relevances for thissample in order to provide a local interpretation. In doing so we can see what theinternal nodes are learning. First we determine the internal node relevances for thissample. The library used for this experiment did not have a built in method todetermine the relevances of internal layer nodes so we created a second neural networkthat was a duplicate of the last two layers of the original neural network. We thenobtained the value of the second layer nodes before the activation function is appliedwhen classifying this sample. That is, if W 1 is the weight matrix for the connectionsbetween layer 1 and layer 2, and X1 is the outputs of layer 1, then we obtainedX1 ·W 1. We then inputted X1 ·W 1 into our second neural network and preformedLRP to get the relevances of the first layer of our second neural network which areequivalent to the relevances of the hidden layer in our original neural network. The754. INTERPRETING ML MALWARE DETECTORS WHICH USE N-GRAM FEATURESmost relevant node by a substantial margin was the 40th node in the hidden layerwith a relevance of 0.61 and an activation of -0.99996614. Since this node is in layer2 we will denote it with n240. Next we created a third neural network that had twolayers. The first was identical to layer 1 of our original neural network, the secondwas just the single node, n240, from the original neural network, and the weight matrixfor the connections from layer 1 to layer 2 of this new network is W 1(40) were W1(i) is the9980-dimensional weight vector for connections from layer 1 to the ith node in layer2 of the original neural network. In this way we were able to obtain the relevancesof the input layer to only the activation of n240 in the hidden layer. Table 4.4.6 showsthe max 10 node relevances for the activation of n240 in the hidden layer.Table 4.4.6: Layer 1 Nodes relevance to n240Activation Relevance Feature1.0 0.025721772 0073000000611.0 0.027428055 2300000019001.0 0.02751717 2F00000023001.0 0.029254071 2700000033001.0 0.030343212 00870000009D1.0 0.03163522 002F000000251.0 0.031697582 040000C000001.0 0.03176714 0023000000191.0 0.032007236 00C0000000D01.0 0.034308888 007701476574In table 4.4.6 we can see that many of the 6-grams have similar relevance’s whichslowly decrease. This corroborates our 

Results when examining class 3 as a wholesince the similar relevances across many input nodes indicates that many featuresare responsible for a classification which is to be expected when a model is robust764. INTERPRETING ML MALWARE DETECTORS WHICH USE N-GRAM FEATURESto changes in the input data. One can automate the process of preforming LRP onspecific examples to find relevant input nodes, both for the entire model and for aspecific internal node possibly showing what the internal node is learning. From therehighlighting the disassembled code which corresponds to the most relevant nodes canhelp malware analyst either determine the functionality of the file or show that themodel has learnt something which corresponds to industry knowledge, thus improvingconfidence in the model.4.5 

ConclusionIn this 



Chapter we demonstrated techniques for the interpretation of malware detectorswhich leverage n-grams as features. We’ve shown that it is possible to interpret aneural network, a logistic regression model, and a random forest, with the objectivesof debugging and creating robust models, improving model confidence, and aidingmalware analysts in downstream tasks. For the logistic regression model, examiningthe weights was all that was needed to meet these goals. However, although straightforward to interpret, the model was less expressive then the other two considered.The random forest required slightly more work for analysis but it was also possibleto get a meaningful local interpretation that helped with the above stated goals.The downside here was that the random forest interpretation must consider many ofthe constituent trees to be thorough, which can be time consuming and provide tooverbose 

Results. The neural network interpretation was much more intensive but byusing layer-wise relevance propagation it was possible to determine the relevance orsignificance of different n-grams across the data set, across a specific class, and for asingle example or for a single node. Thus, we were able to provide a global and localinterpretation which was somewhat useful in a practical setting since by using theserelevances it was then possible to get an idea of the robustness of the model and buildconfidence or aid in downstream analysis of samples.Over all it was possible to satisfy our interpretation objectives for each modelbut the ubiquitous trade off between the interpretability and the expressivity of the774. INTERPRETING ML MALWARE DETECTORS WHICH USE N-GRAM FEATURESmodel was still present. Additionally, n-grams in and of themselves seem slightlyproblematic as it is not easy to determine what a n-gram corresponds to on its own,without considering a single example for context. So providing a global interpretationof a n-gram in order to show what the model has learnt is difficult. To this end itwould be advantageous to include human readable features as well or other featureswhich can be easily interpreted in a manner that doesn’t require examining a specificreal example.For 



Future Work the interpretation of other models using other feature sets is amust. Additionally, a metric to quantify the robustness of a malware detector isneeded for more direct comparison.



References[1] M. Alber et al. iNNvestigate neural networks! 2018. arXiv: 1808.04260 [cs.LG].[2] A. W. Apley and J. Zhu. Visualizing the Effects of Predictor Variables in BlackBox Supervised Learning Models. 2016. arXiv: 1612.08468 [stat.ME].[3] S. Bach et al. “On Pixel-Wise Explanations for Non-Linear Classifier Decisionsby Layer-Wise Relevance Propagation”. In: PloS one. 2015.[4] L. Breiman. “Random Forests”. In: Machine Learning 45.1 (Oct. 2001), pp. 5–32. issn: 1573-0565. doi: 10.1023/A:1010933404324. url: https://doi.org/10.1023/A:1010933404324.[5] R. Dennis Cook. “Detection of Influential Observation in Linear Regression”.In: Technometrics 19.1 (1977), pp. 15–18. doi: 10.1080/00401706.1977.10489493. eprint: https://doi.org/10.1080/00401706.1977.10489493.url: https://doi.org/10.1080/00401706.1977.10489493.[6] J. H. Friedman. “Greedy function approximation: A gradient boosting ma-chine.” In: Ann. Statist. 29.5 (Oct. 2001), pp. 1189–1232. doi: 10.1214/aos/1013203451. url: https://doi.org/10.1214/aos/1013203451.784. INTERPRETING ML MALWARE DETECTORS WHICH USE N-GRAM FEATURES[7] J. H. Friedman and B. E. Popescu. “Predictive learning via rule ensembles”.In: Ann. Appl. Stat. 2.3 (Sept. 2008), pp. 916–954. doi: 10.1214/07-AOAS148.url: https://doi.org/10.1214/07-AOAS148.[8] A. Goldstein et al. Peeking Inside the Black Box: Visualizing Statistical Learn-ing with Plots of Individual Conditional Expectation. 2013. arXiv: 1309.6392[stat.AP].[9] B. Kim, R. Khanna, and O. O. Koyejo. “Examples are not enough, learn tocriticize! Criticism for Interpretability”. In: Advances in Neural InformationProcessing Systems 29. Ed. by D. D. Lee et al. Curran Associates, Inc., 2016,pp. 2280–2288. url: http://papers.nips.cc/paper/6300-examples-are-not-enough-learn-to-criticize-criticism-for-interpretability.pdf.[10] P. W. Koh and P. Liang. “Understanding Black-box Predictions via InfluenceFunctions”. In: Proceedings of the 34th International Conference on MachineLearning - Volume 70. ICML’17. Sydney, NSW, Australia: JMLR.org, 2017,pp. 1885–1894. url: http://dl.acm.org/citation.cfm?id=3305381.3305576.[11] C. Molnar. Interpretable Machine Learning. A Guide for Making Black BoxModels Explainable. https://christophm.github.io/interpretable-ml-book/. GitHub, 2019.[12] F. E. B. Otero and A. A. Freitas. “Improving the Interpretability of Classifi-cation Rules Discovered by an Ant Colony Algorithm”. In: Proceedings of the15th Annual Conference on Genetic and Evolutionary Computation. GECCO’13. Amsterdam, The Netherlands: ACM, 2013, pp. 73–80. isbn: 978-1-4503-1963-8. doi: 10.1145/2463372.2463382. url: http://doi.acm.org/10.1145/2463372.2463382.[13] T. Peltola. “Local Interpretable Model-agnostic Explanations of Bayesian Pre-dictive Models via Kullback-Leibler Projections”. In: ArXiv abs/1810.02678(2018).794. INTERPRETING ML MALWARE DETECTORS WHICH USE N-GRAM FEATURES[14] E. Raff et al. “An investigation of byte n-gram features for malware classifi-cation”. In: Journal of Computer Virology and Hacking Techniques 14 (2016),pp. 1–20.[15] M. T. Ribeiro, S. Singh, and C. Guestrin. ”Why Should I Trust You?”: Explain-ing the Predictions of Any Classifier. 2016. arXiv: 1602.04938 [cs.LG].[16] R. Ronen et al. Microsoft Malware Classification Challenge. 2018. arXiv: 1802.10135 [cs.CR].[17] A. Saabas. TreeInterpreter. 2015. url: https://github.com/andosa/tree-interpreter.[18] S. Shirataki and S. Yamaguchi. “A study on interpretability of decision of ma-chine learning”. In: 2017 IEEE International Conference on Big Data (BigData). Dec. 2017, pp. 4830–4831. doi: 10.1109/BigData.2017.8258557.[19] A. Shrikumar, P. Greenside, and A. Kundaje. “Learning Important FeaturesThrough Propagating Activation Differences”. In: (2017). arXiv: 1704.02685[cs.CV].[20] E. Strumbelj and I. Kononenko. “An Efficient Explanation of Individual Classi-fications Using Game Theory”. In: J. Mach. Learn. Res. 11 (Mar. 2010), pp. 1–18. issn: 1532-4435. url: http://dl.acm.org/citation.cfm?id=1756006.1756007.[21] S. Wachter, B. Mittelstadt, and C. Russell. Counterfactual Explanations with-out Opening the Black Box: Automated Decisions and the GDPR. 2017. arXiv:1711.00399 [cs.AI].80



Chapter 5Interpreting Machine LearningMalware Detectors WhichLeverage Convolutional Neural5.1 



IntroductionThe significantly increased processing power since the early 2000’s not only led toincrease use in machine learning but also caused the algorithms being used to growmore complex. Further, the increased availability of large data sets provides theopportunity to learn more complex patterns. This has lead to a significant increasein the ability of machine learning models in image classification and computer visiontasks where architectures such as the Convolutional Neural Network (CNN) can nowout preform humans in some 



Scenarios. As discussed earlier, Machine learning has alsogrown more popular in the malware detection and analysis domain. However, the highperformance of machine learning in machine vision has now lead to the adaptation ofimage classification algorithms, such as the CNN, in the malware detection domainas well. However, with these more complex classification algorithms, it becomesincreasingly difficult to understand what exactly a model has learnt.Machine learning techniques not used for image classification have also been ap-plied to augment both of the traditional malware detection approaches (i.e. static815. INTERPRETING CNN BASED MALWARE DETECTORSand dynamic analysis), as we have scene in chap 4. This typically involves a com-plex feature engineering and extraction phase which has to be fine tuned for differentsystems and different malware families. This incentivized the use of deep learningin order to automate some portion of the feature extraction process. Further more,architectures which are designed to make use of the ordinal information containedwithin the input sample have been favoured. This is because the order in which in-structions appear in a binary is massively significant in determining its functionality.Thus, recurrent neural networks (RNN) which have typically been used for naturallanguage processing are an obvious candidate. However, RNNs have trouble dealingwith long term dependencies within the sample they are classifying. Further, [10]made the observation that malware converted to images belonging to the same familyhave visual similarities between them and have dissimilarities with malware belong-ing to different families which can be distinguished by the human eye. This causedsome researchers to turn to CNNs as they also take advantage of ordinal informationcontained in the input data as well as use the spatial information contained in images.As discussed earlier, the downside to such complex approaches is the resultingmodels are not easy to understand or lack interpretability. Malware analyst preferexplainable solutions as they must fine tune their systems in order to limit the numberof false positives and false negatives. However, if you do not know what the modelhas learnt, or why it is making a prediction, then it is difficult to make adjustmentsas you are essentially working with a black box. Further, the inherent risk involvedwith new technologies means that stake holders must be convinced the model islearning something relevant to the task at hand. This was much easier with traditionalapproaches where the classification was an easy to understand process, however now itis no longer evident how the model is making a classification. Additionally, a growingproblem in malware analysis is the large amounts of data one must sift through todetermine the functionality of a malware binary. Patterns the model learnt shouldbe used to help with this issue.If a fine grained interpretation of a malware classification model can be obtained,one which isolates specific lines of code as significant for a classification of a single825. INTERPRETING CNN BASED MALWARE DETECTORSsample (i.e. a local interpretation), then this interpretation can be used to aid indown stream tasks such as highlighting code snippets which significantly contributedto a classification decision. This would give malware analysts a starting point andhelp limit the amount of time and effort needed to determine the functionality of amalware sample. Further, isolated lines of code which are deemed significant can beused to detect when a model is learning irrelevant relationships. These can then becorrected to decrease false positive and false negative rates. Lastly, if these significantlines of code can be shown to corroborate industry knowledge then this can showthe model has learnt something which is relevant and help improve confidence fromstakeholders. This would not only put stakeholders minds at ease but would increaseindustry adoption for this emergent technology.Thus, in this 



Chapter we focus on augmenting the approach of using a CNN trainedon the image representation of malware binaries for static analysis. We do this withthe goal of providing a fine grained local interpretation of prediction 

Results whilemaintaining good classification performance relative to similar models in the literatureas well as keeping the simple automated feature extraction from raw data whichCNNs provide. We start with a brief review of the application of CNNs to malwareclassification, we then detail the specifics of our method for generating and classifyingmalware images and interpreting our classification 

Results. Next we have a 



Discussionof our 

Results and end with 



Conclusions and 



Future Work. To the best of our knowledge,the interpretation approach used in this work has not been done before.5.2 



Literature ReviewRecently there has been some interest in applying CNNs to malware classification.In [20], they were able to achieve a 96.7% accuracy classifying malicious binariesagainst benign binaries. This was accomplished by first mapping op code sequencesof length 2 from a sample to a 2 dimensional feature map where the value of each“pixel” in the feature map was determined by multiplying the information gain ofthe corresponding op code sequence in the sample by the probability of said op code835. INTERPRETING CNN BASED MALWARE DETECTORSgiven said sample. Next the resulting “images” where enhanced to create a largercontrast between the malicious and benign samples before applying a CNN to thefinal image set for classification.In [19] they converted the first 784 bytes of various network traffic representationsinto 28× 28 grey scale images to train a CNN to detect malicious network traffic anddifferent families of malicious network traffic. With their best preforming representa-tion, their CNN achieved a 100% accuracy when distinguishing between malicious andbenign network traffic and a 98.65% accuracy when distinguishing between familiesof malicious network traffic.In [8], they were able to classify a data set containing both benign and maliciousbinaries belonging to 12 different malware families by using a hybrid feed forward-CNN classifier. The feed forward portion of the classifier used features extracted fromthe PE meta data and imports while the CNN used opcode sequence data where eachrow of the input volume corresponded to the one hot encoding of an opcode vector.Their architecture was able to achieve a 0.92 f1-score, however the feed forward andCNN alone were able to achieve a 0.90 and 0.91 f1-score respectively while an SVMtrained on the same features achieved a 0.92 f1-score, so these 

Results serve more asa proof of concept rather then indicating a superior solution.As you can see there are various methods used to convert malware samples toinput for CNN classifiers. However one popular method put forward in [10] and usedin the following works is to convert the binaries to grey scale images by interpretingthe raw binary data as a sequence of pixels, where each byte represents the grey scalevalue of its corresponding pixel in the range [0,255]. The problem with this processis that the resulting images are not of uniform length, thus they must be reshaped inorder to match the input dimensions of the CNN classifier.In [5], the authors used a CNN with alternating convolutional then subsamplinglayers and several fully connected layers to classify a data set of grey scale images from25 malware families. Here the input was rescaled to uniform dimensions, losing someinformation. They also preform image augmentation such as rotation and shifting toreduce overfitting. The resulting model managed to obtained a 94.5% accuracy when845. INTERPRETING CNN BASED MALWARE DETECTORSclassifying malicious vs. benign samples.The authors in [18] were able to classify malicious Internet of Things (IoT) mal-ware by converting the binaries in a data set containing 365 samples to grey scaleimages and then rescaling the images to uniform dimensions to train a CNN with.Half of the samples were IoT malware belonging to two major IoT malware families,and the other half were benign Ubuntu system files. The resulting classifier achieveda 94% accuracy.Transfer learning was used in [13] by taking the first 49 layers of the ResNet-50 architecture and swapping the last layer for a 25-node softmax layer to makeclassifications on a data set that contained grey scale images of 25 different familiesof malware. The images were first converted to RGB since ResNet-50 is designed for3-channel image input. During training all but the final layer weights were frozen andthe classifier was able to obtain an accuracy of 98.62%. Here, the varying size of themalware binaries created varying sized images that were rescaled, still offering good

Results despite the loss of information.[3] also used transfer learning on the same data set as the above, except theyused the Inception-V1 architecture and froze all but the last fully connected layerand the softmax layer which was replaced with a 25-node softmax layer. Similarlythey converted the grey scale images to RGB images by duplicating the grey scalechannel three times. Their approach obtained a very impressive 99.25% accuracy.They also claim to provide an interpretation of the predictions by using LIME[14] to highlight important areas of an input sample. However, the proposed methodcan only highlight important regions of the input image called “super-pixels” whichencompass very many pixels which each map to a byte of code. The regions are ofvarying size but there are 200 total, meaning that even a modestly sized binary of200,000 Bytes would have super pixels highlighting on average 1000 bytes of codeeach. We would like to improve on this approach in order to provide more granularinterpretations. Further, [3] also used their approach on the same data set used inthis 



Chapter and obtained a 98.13% accuracy. We will return later to these 

Results forcomparison between our methods.855. INTERPRETING CNN BASED MALWARE DETECTORSAdditionally, [6] converts the same data set used in this 



Chapter into grey scaleimages and trains a CNN classifier without the use of transfer learning after downsampling the images to unifrom size. The classifier has 3 convolutional layers followedby a fully connected layer and a softmax classification layer and was able to achievea 97.5% accuracy. We will return also to these 

Results for comparison between ourmethod with a trained from scratch method.There has been a plethora of papers published with differing techniques used tointerpret or visualize what machine learning models and neural networks have learnt.However, for the sake of brevity, we will discuss some of the techniques used forconvolutional neural networks only.Layer-wise Relevance Propagation (LRP), described in [2] as a set of constraints, isused to visualize where the model is placing its emphasis when making classificationsby back propagating a models prediction using its weights and some decompositionfunction which returns the relevance of previous nodes to that prediction. The con-straints ensure that the total relevance is preserved from one layer to the next as wellas that the relevance of each node is equal to the sum of relevance contributions fromits input nodes which in turn is equal to the sum of relevance contributions to itsoutput nodes. Any decomposition function following these constraints is considereda type of LRP.In [17], they propose DeepLIFT which, in contrast to LRP, attributes to each nodea contribution to the difference in prediction from a reference prediction. DeepLIFTback propagates just this relative difference in prediction scaled by the difference inintermediate and initial inputs.The authors in [14] put forward Local Interpretable Model-agnostic Explanations(LIME), which was used in [3] above, to explain predictions using an approach whichtrains an interpretable classifier by heavily weighing samples nearer to a sample of in-terest in order to locally approximate the non-interpretable or black-box model. Thiswork was extended by Tomi Peltola in [11] to generate local interpretable probabilis-tic models by minimizing the Kullback-Leibler divergence of the predictive modeland the interpretable model in order to provide explanations that account for model865. INTERPRETING CNN BASED MALWARE DETECTORSuncertainty.There have also been several implementations of the above methods. The creatorsof LIME developed a python library available at https://github.com/marcotcr/lime. Additionaly, there is the iNNvestigate [1] python library available at https://github.com/albermax/innvestigate which was used in this 



Chapter and providesimplementations of LRP as well as many other useful interpretation methods met forconvolutional neural networks, although many of them can be applied to other typesof neural networks not working with image data.5.3 MethodTraining and classification were done on a subset from a data set of 10,896 malwarefiles belonging to 9 different malware families.1 The data set is discussed in [15]. Eachsample consists of the hexadecimal representation of the malware’s binary content in a.bytes file as well as its corresponding assembly code in an .asm file. The hexadecimalrepresentations were preprocessed as followed. First, we determined the total lengthof each binary. Since our goal is to provide a fine grain interpretation, we wanted toavoid resizing images to fit the input of the CNN if the resizing caused informationloss. Thus, we deiced to only scale up images by padding them with zeros, ratherthen scaling them down. This is because when we scale down an image the resultingimage’s pixels will actually map to more then one pixel in the original, and thereforemore then one byte of code. Therefore, even if we obtain the importance of a singlepixel of the rescaled input image, we still do not have a fine grained approach, sincethe mapping from rescaled input image to full sized image and then to the bytes andfinally the assembly code will be a one-to-many mapping, which is increasingly sowith large binaries that require more drastic rescaling. So, we picked a size rangewhere the majority of the binaries resided, that is the range of 101,400 to 200,934bytes. The files which were less then 200,934 bytes in length were padded with bytesof all 0’s before and after the binary so that all the binaries were the same size.1The data set was downloaded from www.kaggle.com/c/malware-classification/data875. INTERPRETING CNN BASED MALWARE DETECTORSThe padding before and after the binaries was equal so that the actual binary wascentred vertically in the image, although it took up the entire width of the image.The resulting data set contained 2,114 binaries with 6 classes total. The class detailsare summed up in table 5.3.1.Table 5.3.1: Class distribution in Data SetClass No. Family Samples Type1 Ramnit 635 Worm2 Lollipop 68 Adware4 Vundo 188 Trojan6 Tracur 145 TrojanDownloader8 Obfuscator.ACY 810 obfuscated malware9 Gatak 268 BackdoorNext, the binaries where converted into image tensors of the shape (183, 183, 6).This was done by placing the first 6 bytes of the binary in the input tensor positionsat location (0,0,0) through (0,0,5) the next six bytes in the tensor positions at location(0,1,0) through (0,1,5), and so on, until all the bytes were processed. The reason 6 waschosen as the number of channels was because [12], which examined the effectivenessof different lengths of byte-grams for malware classification, found that 6-byte-gramswere the most effective compared to other lengths of byte-grams. A byte-gram is asa sequence of bytes which appear consecutively in a binary. These are analogous ton-grams which are a sequence of n words or characters which appear in text. Theintuition here was that each pixel, which contains the 6-byte-gram in the pixel’s 6channels, would contain what could be thought of as a “byte word” leaving the filtersto learn to detect significant byte words and in later layers significant sequences ofbyte words.To the best of our knowledge, this the first time someone has applied a CNN to amalware binary classification task where the binaries were converted to “images” with6 channels without the use of downsizing. The 6-channel input has an added benefitof fitting more information into a smaller volume, this means we can have a compact885. INTERPRETING CNN BASED MALWARE DETECTORSinput volume which can still contain all the information of a 200,934 byte binary,therefore helping in our task of creating fine grain interpretations. The other twodimensions were set to√200, 934÷ 6 = 183, since this created a square image, whichis what the models we are using for comparison (discussed in 



Section 5.2) also used.Figure 5.3.1 shows the resulting images of two samples for each of the 6 classes. Theimages in the column labeled F are the first three channels of the samples interpretedas RGB channels while the images in the columns labeled L are the last three channelsof the samples interpreted as RGB channels. As you can see there is some similaritybetween images of the same classes and greater difference between images of differentclasses. Additionally, there is a lot of similarity between the last and first threechannels. However, the CNN model is indifferent to the number of colour channelsor human detectable features and can find structure, imperceptible to humans, in anarbitrary number of channels, therefore we must wait until the classification 

Resultsbefore we can draw any 



Conclusions.The neural network starts with 2 blocks of the classic convolution, ReLU, MaxPoolarchitecture. This architecture was chosen as it has been shown to work well in theliterature and is also similar to what was used by the models used for comparison.We went with just 2 blocks as we wanted to limit the number of parameters given thesmall size of our data set. These 2 blocks were followed by a single fully connectedlayer with 512 neurons with the ReLU activation function then a softmax classificationlayer with 6 neurons. 512 neurons were used as experimentation showed this numberto work best on the validation set despite adding a large number of parameters and thepossibility of over fitting. The two convolutional layers used 128, then 256, 5x5 filterswith strides of 2 and the MaxPool layers used 2x2 pool size with strides of 2. This wasdone mainly because the small data set size meant we had to shrink the volume as fastas possible in order not have too many layers or too many neurons in the last volumebefore the first dense layer thus keeping the number of parameters low. To reduce overfitting dropout with a rate of 0.4 was also used on the connections between the lastMaxPool layer and the first fully connected layer since these connections accountedfor 13,107,712 of the 13,949,575 trainable parameters. Further, L2 regularization was895. INTERPRETING CNN BASED MALWARE DETECTORSFig. 5.3.1: Images from two samples from each of the 6 classes. Images in columnslabeled F are the first three channels of the samples interpreted as RGBchannels whilethe images in columns labeled L are the last three channelsused with a 0.1 penalty on both convolutional layer weights and the weights betweenthe last MaxPool layer and the first fully connected layer. Figure 5.3.2 shows a

Summary of the architecture of the CNN used. The figure was created using softwareavailable online at http://alexlenail.me/NN-SVG/LeNet.html which is describedin [9].Fig. 5.3.2: Model ArchitectureThe model was trained as follows. First the data set of 2,114 samples was randomlysplit into 3 disjoint sets, the training set, validation set, and the test set, each with905. INTERPRETING CNN BASED MALWARE DETECTORSapproximately the same class distribution. The Training set had 1,514 samples, thevalidation set 100 samples, and the test set had 500 samples. The validation set wasused to tune the model’s hyper parameters and needed to be small to ensure the testset was large enough to be significant for evaluation while the training set was largeenough for the model to learn generalized patterns despite the small size of the totaldata set. The test set was not used except at the end of training in order to evaluatethe final model. The training was done using the Adam optimizer with 256 batchsize over 80 epochs. Classes were weighted inversely proportionately to the class sizein order to account for class imbalances. The model was implemented and trainedusing the Keras [4] python library.5.4 

Results5.4.1 Evaluation of Our ModelAfter training the model and using the weights with the lowest validation loss over the80 epochs the model obtained a 98.1% balanced categorical accuracy and a 0.237595categorical crossentropy loss on the left out test set. Balanced accuracy was used sincethere was a class imbalance in the data set. Further, the model does not seem to sufferfrom over fitted as indicated in figure 5.4.1 which shows the test and validation losshistory plotted against the number of epochs. This is also evident from figure 5.4.2which shows the test and validation categorical accuracy plotted against the numberof epochs.5.4.2 InterpretationAfter training, a process called Layer-wise Relevance Propagation (LRP) [2], whichreturns the relevances of all input nodes to a sample’s prediction, was used to findimportant input pixels. In our experiment we used the iNNvestigate [1] python li-brary’s LRP implementation. Once we had the relevances of each input node weaveraged them across the 6 channels to get a 2D relevance map. For visualization,915. INTERPRETING CNN BASED MALWARE DETECTORSFig. 5.4.1: Test and Validation Loss HistoryFig. 5.4.2: Test and Validation Balanced Categorical Accuracy Historywe used the seismic colour map from matplotlib [7] to plot the relevance map. Figure5.4.3 shows the image resulting from taking the first 3 channels of the sample associ-ated with the binary with ID 0AnoOZDNbPXIr2MRBSCJ, and the image resultingfrom taking the last 3 channels of the same sample, as well as its correspondingrelevance map. The pixels highlighted with red contributed positively to the mod-els prediction while the pixels highlighted in blue contributed negatively. Sample0AnoOZDNbPXIr2MRBSCJ was correctly classified by our model with a 99.99%chance of belonging to class 1.Although we cannot obtain a lot of specific information by looking at these imagesand the LRP visualization, we can still obtain some broad insight into the modelsprediction. As you can see from figure 5.4.3, the classifier recognized a large set925. INTERPRETING CNN BASED MALWARE DETECTORSFig. 5.4.3: 0AnoOZDNbPXIr2MRBSCJ Relevance Mapof pixels as an indication that this sample belonged to class 1. Further, there wasstill some pixels which contributed negatively to this prediction, mostly in the upperportion of the image above the band of white which corresponds with bytes of 0’s.This suggest that the portion of the code containing functionality related to class 1 inlocated in the lower portion of the binary and the upper portion is mostly related toother classes or is benign. However, these statements are always dependent on howwell the classifier was trained to learn relevant information. Further, if the relevancewas intensely focused on a few small areas we could be worried that the model isrelying on a small set of features to make classifications, meaning small changes couldlead to misclassifications, and this can be taken advantage of by malware authors.To obtain a fine grained interpretation such as highlighting specific lines of code,we obtain a list of indices of the input pixels sorted by their relevance. We then movedown the list in descending order of relevance and obtain the most relevant 6-grams935. INTERPRETING CNN BASED MALWARE DETECTORSFig. 5.4.4: Terminal output when working backwards from the relevant 6-grams tothe code snippetsfor interpretation first. The relevant 6-gram’s position in the sample’s input tensor,the input tensor itself, and the corresponding byte file are needed to determine the6-gram’s address in the assembly code. These are needed to determine the amountof padding to account for, as well as the starting address in the byte file, since theydon’t all start at the same number. However, in a application scenario all of thisinformation would be available. Once we have the exact address in the assemblycode it is a trivial task to find the lines of Assembly code which contain the relevant6-gram.It should be noted that finding the exact lines of code which contributed to aprediction, as well as their exact ordering relative to the size of their contribution, isvery difficult, if not impossible with most other model architectures. For example, ifn-gram analysis was used, where the presence or frequency of an n-gram is used asa feature, then even though we may have the contribution of each n-gram feature,we do not know which occurrence of said n-gram in the binary contributed the most.This is true in some way for most frequency based techniques. Further, for otherCNN based techniques, we have the problem of rescaling causing the contribution ofone input node being distributed across many pixels in the original image. It is only945. INTERPRETING CNN BASED MALWARE DETECTORSwhen positional information of each 6-gram is maintained from raw binary to inputtensor, as we have done so here, where we are able to so easily make such preciseinterpretations of the model.Figure 5.4.4 shows the terminal output when working backwards from the relevant6-grams to the code snippets in the assembly code. Note that some of the assemblycode has been truncated so we could not find the corresponding code snippets tomany of the most significant 6-grams but we have done so for the 100th and 122ndmost significant. This is not a problem however as typically you would have the fullassembly code.The significance of finding these code snippets which contributed heavily to aprediction is large. For example, there is the case where the code snippets are com-pletely irrelevant to classifying binaries according to functionality despite the modelachieving good classification 

Results. In this situation, there is the likely culprit of anincomplete or non-representative data set. It could be that one class has irrelevantbut frequently occurring code-snippets that by chance do not appear in the otherclasses. Here, gathering a larger data set, or even augmenting the current data setso that other classes also include this irrelevant code snippet, can force the modelto learn different patterns that exclude this irrelevant feature, which should also im-prove generalization performance. If the classification performance drops after this,then this could hint at poor feature engineering, since the remaining representativefeatures no longer help the model make predictions. In the case of CNNs applied toimages of binaries, this could mean a deeper model architecture that can create more



Abstract hidden features might be needed, or that the representation of binaries asimages themselves is unhelpful.In the case where code snippets with high relevances to the model’s predictionsare known to be relevant to classifying binaries based off their functionality, then the

Results of the model are in a way, validated. As we said earlier, this can help malwareanalysts as they can be shown where to start their static analysis, as well as helpstakeholders feel confident in the black-box CNN model.955. INTERPRETING CNN BASED MALWARE DETECTORS5.4.3 Comparison With Other ModelsTable 5.4.1 shows the confusion matrix of our model on the left out test set wherewe can see the model preformed well for all classes. Table 5.4.2 and 5.4.3 show theconfusion matrix of the models used in [3] and [6] respectively (both are discussed in



Section 5.2). The columns and rows for classes 3, 5, and 7, which were not used inour experiment, have been omitted.Table 5.4.1: Confusion Matrix for Our Model on the Left Out Test SetClass No. 1 2 4 6 8 91 149 0 0 1 0 02 0 16 0 0 0 04 1 0 44 0 0 06 0 0 0 32 1 18 2 0 0 0 190 09 1 0 0 0 0 62Table 5.4.2: Confusion Matrix for Model used in [3]*Class No. 1 2 4 6 8 91 154 0 0 0 3 02 0 238 0 0 3 14 1 0 33 1 0 06 1 0 0 63 1 08 2 0 0 0 119 09 0 4 0 0 0 102*columns and rows of classes classes3,5, and 7 have been omitted965. INTERPRETING CNN BASED MALWARE DETECTORSTable 5.4.3: Confusion Matrix for Model used in [6]*Class No. 1 2 4 6 8 91 1490 4 2 9 28 32 6 2440 0 7 8 164 3 0 461 1 3 26 8 6 2 713 10 98 44 4 8 17 1138 89 2 2 0 6 5 996*columns and rows of classes classes3,5, and 7 have been omittedUsing these confusion matrices to calculate the balanced accuracy score of eachmodel, we can get a decent comparison. However, the reader should note that theother models were trained on more classes and with much more training data sothese are not perfect direct comparisons of our approaches. Table 5.4.4 sums up thecomparisons between the three models. As you can see, we score competitive balancedaccuracy score with a very light weight model. Further, we are able to give a finegrained analysis of our predictions using the method detailed in 



Section 5.4.2 and thismethod cannot be easily applied to the other models without added processing andsacrificing the preciseness of our method. This is due the decision to not rescale theimages, meaning we can map one relevant input node to exactly one 6-gram in thebinary and then to the corresponding assembly code.Our model does have draw backs however. Unlike the other models ours is onlydesigned to work with samples in a specific size range and therefore one would needmultiple models in order to achieve the same effect across different size ranges. Onepossible solution would be to train on a data set where the samples in the appropriatesize range are not rescaled but padded like we did here, and the images which are toolarge are rescaled to fit. This however would mean the interpretation method would975. INTERPRETING CNN BASED MALWARE DETECTORSonly maintain its fine granularity when classifying samples which were not resized.Table 5.4.4: Model ComparisonsModel Balanced Acc. SizeOur Model 98.1% 2 conv, 1 DenseModel from 97.04%* 20+ layers[3] see [16]Model from 96.8%* 3 conv, 1 Dense[6]Model Interpretation Sample SizeOur Model Fine grained & 104k-200k BytespreciseModel from Broad & any size[3] impreciseModel from none given any size[6]*calculated by omitting columns and rowsof confusion matrix for classes 3,5, and 75.5 

ConclusionIn 

Summary, we were able to obtain competitive classification 

Results on a subset of aclassic benchmark data set. Compared to other methods we made appropriate tradeoffs in terms of broad applicability of our model (in that it only works for malwarein a specific size range) in return for large gains in interpretability. We thus haveprovided a proof of concept for 6-channel image based malware classification usinga simple convolutional neural network that did not suffer from excessive overfitting985. INTERPRETING CNN BASED MALWARE DETECTORSdespite a small data set. To the best of our knowledge, this the first time someonehas been able to interpret a CNN based malware detector with the granularity whichhas been achieved here, by applying CNNs to a malware converted to images withmore then a single channel in order to avoid rescaling of the image and informationloss.For 



Future Work, there is much work to be done in order to better handle binaries ofdifferent sizes. If more sophisticated approaches for dealing with binaries of differentsizes are implemented, which do not result in information loss, then fine grainedinterpretations, in the manner we have done so here, can be possible for any malwarefile. Further, the data set will not shrink as a result of not considering files which aretoo large. This means more advanced models can be deployed without over fittingthe data set, potentially increasing the models performance.Another interesting possibility is to explore is the application of our approach tograph convolutional neural networks (GCNNs), which are CNNs applied to graphrepresentations, trained on malware classification. It is a popular approach in mal-ware analysis to represent the behaviour or other features of a malware binary in agraph which in many cases will contain direct and explicit functional information.If a GCNN is trained on a dataset where each sample is one of these graph repre-sentations of a malware binary, then less time can be spent worrying about weatherthe model learnt to use features indicative of functionality and translating those fea-tures to functionality afterward for interpretation. Instead interpretability can beused to directly make statements about the relevant functionality which the model isperceiving within the sample to make its prediction.



References[1] M. Alber et al. iNNvestigate neural networks! 2018. arXiv: 1808.04260 [cs.LG].[2] S. Bach et al. “On Pixel-Wise Explanations for Non-Linear Classifier Decisionsby Layer-Wise Relevance Propagation”. In: PloS one. 2015.995. INTERPRETING CNN BASED MALWARE DETECTORS[3] L. Chen. Deep Transfer Learning for Static Malware Classification. 2018. arXiv:1812.07606 [cs.LG].[4] F. Chollet et al. Keras. https://keras.io. 2015.[5] Z. Cui et al. “Detection of Malicious Code Variants Based on Deep Learning”.In: IEEE Transactions on Industrial Informatics 14.7 (July 2018), pp. 3187–3196. issn: 1941-0050. doi: 10.1109/TII.2018.2822680.[6] D. Gibert et al. “Using convolutional neural networks for classification of mal-ware represented as images”. In: Journal of Computer Virology and Hack-ing Techniques 15.1 (Mar. 2019), pp. 15–28. issn: 2263-8733. doi: 10.1007/s11416-018-0323-0. url: https://doi.org/10.1007/s11416-018-0323-0.[7] J. D. Hunter. “Matplotlib: A 2D graphics environment”. In: Computing in Sci-ence & Engineering 9.3 (2007), pp. 90–95. doi: 10.1109/MCSE.2007.55.[8] B. Kolosnjaji et al. “Empowering convolutional networks for malware classifica-tion and analysis”. In: 2017 International Joint Conference on Neural Networks(IJCNN). May 2017, pp. 3838–3845. doi: 10.1109/IJCNN.2017.7966340.[9] A. LeNail. “NN-SVG: Publication-Ready Neural Network Architecture Schemat-ics”. In: Journal of Open Source Software 4 (Jan. 2019), p. 747. doi: 10.21105/joss.00747.[10] L. Nataraj et al. “Malware Images: Visualization and Automatic Classification”.In: (July 2011). doi: 10.1145/2016904.2016908.[11] T. Peltola. “Local Interpretable Model-agnostic Explanations of Bayesian Pre-dictive Models via Kullback-Leibler Projections”. In: ArXiv abs/1810.02678(2018).[12] E. Raff et al. “An investigation of byte n-gram features for malware classifi-cation”. In: Journal of Computer Virology and Hacking Techniques 14 (2016),pp. 1–20.1005. INTERPRETING CNN BASED MALWARE DETECTORS[13] E. Rezende et al. “Malicious Software Classification Using Transfer Learning ofResNet-50 Deep Neural Network”. In: Dec. 2017. doi: 10.1109/ICMLA.2017.00-19.[14] M. T. Ribeiro, S. Singh, and C. Guestrin. “”Why Should I Trust You?”: Ex-plaining the Predictions of Any Classifier”. In: CoRR abs/1602.04938 (2016).arXiv: 1602.04938. url: http://arxiv.org/abs/1602.04938.[15] R. Ronen et al. Microsoft Malware Classification Challenge. 2018. arXiv: 1802.10135 [cs.CR].[16] Christian S. et al. Going Deeper with Convolutions. 2014. arXiv: 1409.4842[cs.CV].[17] A. Shrikumar, P. Greenside, and A. Kundaje. “Learning Important FeaturesThrough Propagating Activation Differences”. In: (2017). arXiv: 1704.02685[cs.CV].[18] J. Su et al. “Lightweight Classification of IoT Malware Based on Image Recog-nition”. In: 2018 IEEE 42nd Annual Computer Software and Applications Con-ference (COMPSAC). Vol. 02. July 2018, pp. 664–669. doi: 10.1109/COMPSAC.2018.10315.[19] W. Wang et al. “Malware traffic classification using convolutional neural net-work for representation learning”. In: 2017 International Conference on Infor-mation Networking (ICOIN). Jan. 2017, pp. 712–717. doi: 10.1109/ICOIN.2017.7899588.[20] J. Zhang et al. “IRMD: Malware Variant Detection Using Opcode Image Recog-nition”. In: 2016 IEEE 22nd International Conference on Parallel and Dis-tributed Systems (ICPADS). Dec. 2016, pp. 1175–1180. doi: 10.1109/ICPADS.2016.0155.101



Chapter 6Robustness Metric6.1 



IntroductionIn malware detection a misclassification can cause huge delays if a benign file which isneeded for some time sensitive task is flagged as malicious. Furthermore, there is therisk that a malicious file is permitted to execute causing unforeseen damage to theusers system. Since a small to large business may encounter thousands to millionsof benign files each day, a hard requirement of malware detection systems reliedupon by large companies is a low false positive rate (FPR). Due to the large volumeof files, even a FPR of one in a thousand would lead to daily stoppages and falsealarms. Furthermore, any fragility in the models accuracy can be taken advantageof by malware authors looking to bypass detection. It is clear that misclassificationin this scenario carries a heavy risk and to quantify the rate of misclassification,metrics such as FPR or accuracy are typically used. However, these metrics do notcapture the full story when trying to convey how robust a detection system is to theanti detection efforts of malware authors. A contrived example would be a modelthat learnt to associate a few superficial features strongly with the property of beingbenign but none the less has high accuracies on held out test sets. Here, superficial istaken to mean that the features are not actually indicative of being benign but dueto peculiarities in the model’s training set, the model treats them as such. In sucha case, if a malware author was to learn of this association, they could easily change1026. ROBUSTNESS METRICtheir binaries to bypass the detection system, without having to change the maliciousfunctionality of their malware. This means that despite the high accuracy, the modelis still not robust to anti detection efforts.A metric that better illustrates the robustness of a classification model is needed.This metric should quantify the accuracy in relation to the number of features whichare no longer following the model’s learnt relationships. This is because we want tomeasure how well the model preforms as features are made to no longer have theirexpected values given a samples actual class and thus no longer aid in prediction. Inthis 



Chapter we refer to such features as “deactivated”. Further, the metric should beconcerned only with the inputs and outputs of the model. This allows the model tobe treated as a black box so that the metric can be applied to any model, that is themetric will be model agnostic. Additionally, the metric should have some degree ofcustomization. This is because not all models are the same. They use different typesof features with different valid feature ranges and are applied in varying domains.This means that what it is for a feature to be ”deactivated” will be largely differentamong different applications and 



Scenarios and therefore will have to be determinedand asserted by the user of the metric. Further, the technique for calculating themetric should allow the user to determine which set of features deactivation causedthe accuracy to drop below some minimum performance requirement. This followsfrom the fact that not all models use the same features, thus a model may only needa few features to be deactivated for its performance to drop significantly, however ifthe features use by that model are harder to change without removing the maliciousproperties of the malware, then this model is still robust.In this 



Chapter we propose a new robustness metric inspired by area under curve(AUC) which meets these requirements. We start with a 



Discussion of how the metricis calculated and why the metric is calculated in this way. We then use the metric onseveral classification models that have been trained on a data set of features extractedfrom benign and malicious binaries. Finally we end with a 



Discussion of our 

Resultsand possible 



Future Work.1036. ROBUSTNESS METRIC6.2 The Robustness MetricThe metric is calculated as follows. First, a numerical measure of feature significancemust be found for each feature. For different models this means different things. Inthe case of a logistic or linear regression classifier, the feature significances is equal tothe coefficient or weight of the feature. For decision trees and random forest it is thegini importance and average gini importance among the constituent trees respectively.In the case of neural networks we use layer-wise relevance propagation [1] to obtain therelevance of each input node for each sample. We then average the absolute value ofthese relevances in order to get the average relevance of each node. This value is usedas the feature significance of the node’s corresponding feature. The average absolutevalue is used because for one sample a node may have a large negative contributionand for another sample, a large positive contribution. If the actual relevance valueis used, then during averaging these relevances will cancel out despite the associatedfeature having a large effect on both predictions. For other models there are typicallyalready standard accepted practices for obtaining a feature’s significance but in thecase that there is not, a method known as permutation importance [2] can be used.In this case, classification on a set of samples is done before and after a feature ispermuted. The increase in error is what determines the importance of said feature.After the feature significance is found, the model’s balanced accuracy on a test setis found. A test set is used for the same reason you do not report a models accuracyon the training set. Balanced accuracy is used because it is calculated by taking theweighted average accuracy for each class, where the weights are inversely proportion-ate to the class frequency. This means that a random classifier is expected to get 50%balanced accuracy even on imbalanced data sets. This allows for direct comparisonof the robustness metric when evaluated on test sets with varying class distributions.Next the most significant feature is deactivated and the balanced accuracy with re-spect to the same test set is determined again. This process is repeated, deactivatingthe next most significant feature each time. The features are deactivated in orderof significance because if a feature is not very important then we are not interested1046. ROBUSTNESS METRICin how well the model preforms after its deactivation since a good performance afterremoving irrelevant information is not surprising or noteworthy. The way in whichfeatures are deactivated is discussed at the end of this 



Section.After this we have a list of balanced accuracies {a0, a2, ..., an−1} where ak is thebalanced accuracy of the model when the k most significant features are deactivated.We then plot these accuracies along the y-axis with the number of deactivated featureson the x-axis to obtain a curve. After this, we take the area under the curve and wedivide it by the number of features there are, then subtract 0.5 and multiply it by 2.The result is the value of the robustness metric.The area is taken because it captures the total accuracy across each iteration ofdeactivating a feature then evaluating the model. The area is divided by the numberof features because the balanced accuracy, which is on the y-axis, is always between0 and 1. Thus, if the area is taken between 0 and the number of features, n, thenthe area is always between 0 × n and 1 × n. So dividing by n means the area isscaled between 0 and 1. The scaled area is corrected by subtracting 0.5 becausea random classifier is expected to have a 0.5 accuracy thus half of the area is notactually attributable to the model. In some rare cases the balanced accuracy may dipbelow 0.5 enough that the scaled area is below 0.5, meaning the corrected scaled areawould be negative. In this case, the scaled corrected area is set to 0. This means thatthe scaled and corrected area is now in between 0 and 0.5, so it is then multiplied by2 so that it is between 0 and 1, giving us our final robustness value.For deactivating features there are several possible methods. A naive approach,hence referred to as the zeros method, would be to set the feature’s values to 0. How-ever, this may not correspond to a realistic value for all features and can thereforegive untrustworthy 

Results. Another approach, which we will refer to as the randompermutation method, would be to randomly permute the feature column. This ap-proach is inspired by the permutation importance method discussed early. Anotherapproach could be to use a reference sample and set deactivated features equal tothe corresponding feature value in the reference sample. The reference sample can behand picked to be an average of some class of interest or some other value. We will1056. ROBUSTNESS METRIChence forth refer to this method as the reference method.This gives the user of the metric a good way of customizing it for their specificuse case. For example they may have a mix of binary features and numerical featuresand they may want to set the binary features to 0 and the numerical features to theiraverage value when deactivating them. In any case the user can define exactly howeach specific feature is deactivated rather then doing the same for all of them. In thefollowing 



Section, we test all three of these approaches. The reference sample is set tobe the average of the benign class. This was done because we are typically concernedwith detecting malicious samples when classifying binaries, so setting a feature toits average value within the benign class would isolate the effect that the remainingfeatures had on obtaining a malicious classification.The reader should note that sometimes we are more concerned with FPR as apposeto accuracy. In this case one can replace the balanced accuracy at each step with theFPR and get a similar robustness metric which is conditioned on FPR rather thenaccuracy. The same is true for other accuracy like metrics as well.6.3 MethodIn our experiment we first trained a neural network, a decision tree, random forest,and a logistic regression model on a data set containing 77 features extracted frommalicious and benign binaries. The data set contained 14599 malicious samples and5012 benign ones. The data set was split into a train and test set containing 17649and 1962 samples respectively, with equal class distributions. The features were alsoall scaled using min-max scaling. The neural network had 77 input nodes, two hiddenlayers with 100 and 30 nodes respectively, and an output layer with 2 nodes, one foreach class. Once the training was complete, the models were evaluated on a testset. The neural network obtained a balanced accuracy of 96.16%, the random foresta balanced accuracy of 98.44%, the decision tree 98.26% and the logistic regressionmodel a balanced accuracy of 94.10%. Next we obtained the robustness metric for thefour models using the process detailed in 



Section 6.2, using the test set to determine1066. ROBUSTNESS METRICthe balanced accuracy at each step. Table 6.3.1 shows the 

Results.Table 6.3.1: Robustness Metrics For Trained ModelsModel Zeros Rand. Perm. Ref. SampleNeural Network 0.1236 0.0896 0.0973Random Forest 0.0499 0.0779 0.0880Decision Tree 0.0543 0.0546 0.0798Logistic Reg. 0.0000 0.0519 0.0279As shown, the neural network consistently out preforms the other models in termsof robustness regardless of which method is used for deactivating the features. This isexpected since the neural network has 130 intermediate nodes across two layers each ofwhich can learn a different relationship between the features and the predicted value.This means that if a feature is deactivated, then the nodes which learnt relationshipsnot relying on said feature can still produce correct predictions.The random forest got second except for in the case of the zeros method whereit got third. This makes sense as the random forest has many different constituentclassifiers and much like the neural network, when one feature is deactivated, thetrees that do not rely on that feature can produce a correct prediction. In the case ofboth the random forest and neural networks, redundancies were able to provide morerobustness, as expected.The decision tree got third except for in the case of the zeros method where itgot second. Further, the logistic regression classifier consistently got last. This isto be expected as the logistic regression classifier simply takes the sigmoid of thefeatures weighted sum and in has no redundancies to deal with misbehaving featureswhich are heavily weighted. Further, the decision tree only has a single path fromthe root to each of its leaves and thus cannot correct if the prediction is lead askewby misbehaving features.The resulting plots when finding the robustness measures are shown in figure 6.3.11076. ROBUSTNESS METRICin which you can see the zeros method was much less stable with many spikes in per-formance which may be misleading as these spikes are the effects of highly unrealisticfeature values. This is the suspected reason the random forest obtained worse robust-ness using the zeros method. The other methods were much more stable with a steadydecline and are therefore the recommended choice. The random permutation methodcan be used to test the models robustness against random chance while the referencemethod can be used to test its robustness against samples intentionally designed tobe misleading, such as adversarial malware.Fig. 6.3.1: Robustness plots with balanced accuracy on the y-axis and number offeatures deactivated on the x-axis1086. ROBUSTNESS METRIC6.4 

ConclusionIn 

Summary, we were able to define an effective algorithm for calculating a robustnessmetric which met our stated requirements in 



Section 6.1. That is, the metric is definedin terms of deactivated features, it is model-agnostic as it is only concerned with theinputs and outputs of the model, and it can be customized, meaning it can be usedmeaningfully with many different models, feature types, and use cases. Additionallyit is always between 0 and 1 with 0 representing the negative extreme of a randomclassifier that always scores 50% balanced accuracy and 1 representing the positiveextreme of am omniscient classifier that makes perfect classifications, even with noinput. Further more, it automatically accounts for class imbalances with the use ofbalanced accuracy.Our 

Results also validated our approach since the models which are typically as-sociated with indifference to small changes in input (Neural Network and RandomForest), and who have theoretical support for higher robustness through the redun-dancy present in their design, scored better then those which are typically sensitiveto small changes in input (Decision Tree and Logistic Regression).For 



Future Work, experiments with multi-class models can be conducted. The samemethod may work for models which return a single set of feature significances evenin the multi-class case, such as decision trees, random forests, and neural networks.However in the case of logistic regression, there are a separate set of feature signifi-cances for each class if it is a one-vs-rest scheme. In this case it is not obvious if itis better to average the feature significances to determine which order to deactivatethe features, or to produce a robustness score for each binary classifier, and thenaverage these robustness scores. Lastly, a similar method needs to be implementedfor regression models, ideally one whose value can be directly compared to the valueof the robustness metric defined here. Potentially a plot of the mean squared error(instead of accuracy) the classifier achieves on the test set as features are deactivatedcould be used. In this case a smaller area under the plot would be ideal, as this wouldbe associated with lower mean squared errors as more features were deactivated.1096. ROBUSTNESS METRIC



References[1] S. Bach et al. “On Pixel-Wise Explanations for Non-Linear Classifier Decisionsby Layer-Wise Relevance Propagation”. In: PloS one. 2015.[2] L. Breiman. “Random Forests”. In: Machine Learning 45.1 (Oct. 2001), pp. 5–32. issn: 1573-0565. doi: 10.1023/A:1010933404324. url: https://doi.org/10.1023/A:1010933404324.110



Chapter 7

ConclusionThe work presented in this thesis provided a exploratory 

Overview of machine learn-ing interpretability in the malware detection domain. Starting with 



Chapter 1, abrief 

Overview of machine learning and some of the popular algorithms therein wasprovided, as well as an 



Introduction to machine learning interpretability.In 



Chapter 2, a 



Literature Review concerning the application of machine learningto malware analysis was provided, as well as a 



Discussion of the current strengthsand weakness of the machine learning based malware detection approaches in theirpresent state. Emerging threats in the malware domain were discussed, such as filelessmalware and unconventional computing paradigms, as well as the practical challengesfor machine learning based malware detectors, namely, the cost of training detectors,adversarial malware, and detector interpretability. Lastly, a 



Discussion of possiblesolutions to these issues was also presented.In 



Chapter 3, a Proof of Concept fileless malware, JSLess, was described thor-oughly, then implemented, and finally tested against various malware detection soft-ware in order to showcase the severity of the threat posed by fileless malware andthe necessity for machine learning based malware detectors in the present day. For



Future Work, the functionality for JSLess can be extended, an approach for detectingmalware similar to JSLesss can be researched, and the threat of fileless malware inunconventional computing paradigms can be explored.In 



Chapter 4, we provided a description of interpretability goals for machinelearning based malware detectors and presented techniques for achieving these inter-1117. 

Conclusionpretability goals for detectors which leverage n-gram analysis and some of the mostpopular classification algorithms, namely; Logistic Regression, Random Forest, andNeural Networks. The stated interpretability goals were robustness, improving stake-holder confidence in the detector, and helping malware analysts with downstreamtasks. A suggestion for 



Future Work is the specification of interpretation techniquesfor other machine learning algorithms or different feature sets.In 



Chapter 5, a novel approach for providing fine a grain interpretation of malwaredetectors which leverage Convolutional Neural Networks was provided. The approachwas able to out preform other similar methods in the literature while providing farbetter interpretations. The downside however was the technique was only usable onmalware binaries within a certain size range. A technique which applies to binariesof any size is an objective for future researchIn 



Chapter 6 we gave a novel approach for summarizing the robustness of a sin-gle binary classifier in a single metric. The binary classification case is common inthe malware detection domain where models often classify samples as malicious orbenign, however more work needs to be done on applying the metric to multi-classclassification as well as regression tasks. This is necessary because as we have seen in



Chapters 4 and 5, we are often interested in classifying malware by class as well.Although machine learning has progressed greatly in the last decade or so, anddespite the interest it generates for various high risk applications, including in cybersecurity, it is still a work in progress and there are many unsolved issues machinelearning researchers face. The issue of interpretability is a complex one with nosimple “one size fits all” solution. Even within the malware detection domain, inter-pretability solutions still differ largely from one model to the next. In this thesis wepresented a step in the right direction but there is still much work to be done, in bothmaking machine learning models interpretable and in making them practical for largescale cyber security applications. It is the authors hope that the 



Discussion providedhere is informative to the reader and helps them too form their own opinions aboutinterpretability, inspires their own interpretability solutions, and in the end, helpsmachine learning based malware detectors play an essential role in cyber security.112VITA AUCTORISNAME: William R. BriguglioPLACE OF BIRTH: Windsor, ONYEAR OF BIRTH: 1995EDUCATION: Holy Names High School, Windsor, On-tario, 2014University of Windsor, B.Sc in ComputerScience, Windsor, Ontario, 2019University of Windsor, M.Sc in ComputerScience, Windsor, Ontario, 2020113
