
Automatic Malware Detection (2021) by Martin Jureček
Abstract:
The problem of automatic malware detection presents challenges for antivirus vendors. Since the manual investigation is not possible due to the massive number of samples being submitted every day, automatic malware classication is necessary. Our work is focused on an automatic malware detection framework based on machine learning algorithms. We proposed several static malware detection systems for the Windows operating system to achieve the primary goal of distinguishing between malware and benign software. We also considered the more practical goal of detecting as much malware as possible while maintaining a suciently low false positive rate. We proposed several malware detection systems using various machine learning techniques, such as ensemble classier, recurrent neural network, and distance metric learning. We designed architectures of the proposed detection systems, which are automatic in the sense that extraction of features, preprocessing, training, and evaluating the detection model can be automated. However, antivirus program relies on more complex system that consists of many components where several of them depends on malware analysts and researchers. Malware authors adapt their malicious programs frequently in order to bypass antivirus programs that are regularly updated. Our proposed detection systems are not automatic in the sense that they are not able to automatically adapt to detect the newest malware. However, we can partly solve this problem by running our proposed systems again if the training set contains the newest malware. Our work relied on static analysis only. In this thesis, we discuss advantages and drawbacks in comparison to dynamic analysis. Static analysis still plays an important role, and it is used as one component of a complex detection system.The problem of automatic malware detection presents challenges for antivirus vendors. Since the manual investigation is not possible due to the massive number of samples being submitted every day, automatic malware classication is necessary. Our work is focused on an automatic malware detection framework based on machine learning algorithms. We proposed several static malware detection systems for the Windows operating system to achieve the primary goal of distinguishing between malware and benign software. We also considered the more practical goal of detecting as much malware as possible while maintaining a suciently low false positive rate. We proposed several malware detection systems using various machine learning techniques, such as ensemble classier, recurrent neural network, and distance metric learning. We designed architectures of the proposed detection systems, which are automatic in the sense that extraction of features, preprocessing, training, and evaluating the detection model can be automated. However, antivirus program relies on more complex system that consists of many components where several of them depends on malware analysts and researchers. Malware authors adapt their malicious programs frequently in order to bypass antivirus programs that are regularly updated. Our proposed detection systems are not automatic in the sense that they are not able to automatically adapt to detect the newest malware. However, we can partly solve this problem by running our proposed systems again if the training set contains the newest malware. Our work relied on static analysis only. In this thesis, we discuss advantages and drawbacks in comparison to dynamic analysis. Static analysis still plays an important role, and it is used as one component of a complex detection system

FullText:
Automatic Malware DetectionbyMartin JurečekA dissertation thesis submitted tothe Faculty of Information Technology, Czech Technical University in Prague,in partial fulfilment of the requirements for the degree of Doctor.Dissertation degree study programme: InformaticsDepartment of Information SecurityPrague, March 2021Supervisor:prof. Ing. Róbert Lórencz, CSc.Department of Information SecurityFaculty of Information TechnologyCzech Technical University in PragueThákurova 9160 00 Prague 6Czech RepublicCopyright c© 2021 Martin Jurečekii



Abstract and contributionsThe problem of automatic malware detection presents challenges for antivirus vendors.Since the manual investigation is not possible due to the massive number of samples beingsubmitted every day, automatic malware classification is necessary.Our work is focused on an automatic malware detection framework based on machinelearning algorithms. We proposed several static malware detection systems for the Win-dows operating system to achieve the primary goal of distinguishing between malware andbenign software. We also considered the more practical goal of detecting as much malwareas possible while maintaining a sufficiently low false positive rate.We proposed several malware detection systems using various machine learning tech-niques, such as ensemble classifier, recurrent neural network, and distance metric learning.We designed architectures of the proposed detection systems, which are automatic in thesense that extraction of features, preprocessing, training, and evaluating the detectionmodel can be automated. However, antivirus program relies on more complex system thatconsists of many components where several of them depends on malware analysts andresearchers.Malware authors adapt their malicious programs frequently in order to bypass antivirusprograms that are regularly updated. Our proposed detection systems are not automaticin the sense that they are not able to automatically adapt to detect the newest malware.However, we can partly solve this problem by running our proposed systems again if thetraining set contains the newest malware.Our work relied on static analysis only. In this thesis, we discuss advantages anddrawbacks in comparison to dynamic analysis. Static analysis still plays an importantrole, and it is used as one component of a complex detection system.



Keywords:Malware, PE File Format, Static Analysis, Machine Learning, Detection System.iii



AcknowledgementsI would like to express my gratitude to my dissertation thesis supervisor, prof. Ing. RóbertLórencz, CSc., for his guidance and for having always encouraged me and supported myresearch. I am also very grateful to my colleagues from the Department of InformationSecurity, who shared their research ideas and experiences from the doctoral study.This research has also been partially supported by the OP VVV MEYS funded projectCZ.02.1.01/0.0/0.0/16 019/0000765 ”Research Center for Informatics”.Finally, my greatest thanks go to my wife for her infinite patience and care and to mydaughter, who gave me the motivation to finish the doctoral study.v



Dedication. . .To my wife Olga and my daughter Dáša.viContentsAbbreviations xiv1 



Introduction 11.1 Motivation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11.2 Problem Statement . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21.3 Goals of the Dissertation Thesis . . . . . . . . . . . . . . . . . . . . . . . . 21.4 Structure of the Dissertation Thesis . . . . . . . . . . . . . . . . . . . . . . 32 

Background and State-of-the-Art 52.1 

Background . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 52.1.1 Types of Malware . . . . . . . . . . . . . . . . . . . . . . . . . . . . 52.1.2 Malware Obfuscation Techniques . . . . . . . . . . . . . . . . . . . 72.1.3 Malware Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . 82.1.4 Features for Malware Detection . . . . . . . . . . . . . . . . . . . . 102.2 Previous 

Results and Related Work . . . . . . . . . . . . . . . . . . . . . . 112.2.1 Pioneer Works . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 112.2.2 Recent Works . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 123 

Overview of Our Approach 173.1 Malware Detection using Heterogeneous Distance Function . . . . . . . . . 173.1.1 Heterogeneous Distance Metric for PE Features . . . . . . . . . . . 183.1.2 Malware Detection System . . . . . . . . . . . . . . . . . . . . . . . 193.2 Distance Metric Learning using Particle Swarm Optimization . . . . . . . . 233.3 Malware Detection using LSTM . . . . . . . . . . . . . . . . . . . . . . . . 253.3.1 Type 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 253.3.2 Type 2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 253.4 Malware Family Classification using DML . . . . . . . . . . . . . . . . . . 273.4.1 Distance Metric Learning . . . . . . . . . . . . . . . . . . . . . . . 273.4.2 Our Approach . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28viiContents3.5 Malware Detection using DML . . . . . . . . . . . . . . . . . . . . . . . . . 293.5.1 Minimizing of False Positive Rate . . . . . . . . . . . . . . . . . . . 304 Author’s Relevant Papers 334.1 Paper 1 - Malware Detection Using a Heterogeneous Distance Function . . 354.2 Paper 2 - Distance Metric Learning using Particle Swarm Optimization toImprove Static Malware Detection . . . . . . . . . . . . . . . . . . . . . . . 584.3 Paper 3 - Representation of PE Files using LSTM Networks . . . . . . . . 674.4 Paper 4 - Improving Classification of Malware Families using Learning aDistance Metric . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 784.5 Paper 5 - Application of Distance Metric Learning to Automated MalwareDetection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 895 



Conclusions 1055.1 Contributions of the Dissertation Thesis . . . . . . . . . . . . . . . . . . . 1055.2 



Future Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 107Bibliography 109Reviewed Publications of the Author Relevant to the Thesis 115Remaining Publications of the Author Relevant to the Thesis 117Remaining Publications of the Author 119viii



List of Figures3.1 Architecture of the classification model . . . . . . . . . . . . . . . . . . . . . . 223.2 Two different types of transformers. . . . . . . . . . . . . . . . . . . . . . . . . 263.3 Architecture of our proposed malware detection model using distance metriclearning. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 304.1 Relationships among author’s relevant papers. . . . . . . . . . . . . . . . . . . 34ixList of Algorithms3.1 Statistical classifier – STATS . . . . . . . . . . . . . . . . . . . . . . . . . . 213.2 Combination of the KNN and statistical classifier . . . . . . . . . . . . . . 223.3 PSO algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24xixiiiAbbreviationsAbbreviationsACC AccuracyAPI Application Programming InterfaceAPK Android PackageAUC Area Under CurveAV Antivirus VendorBLSTM Bidirectional Long Short-Term MemoryCOFF Common Object File FormatDLL Dynamic-Link LibraryDML Distance Metric LearningDDoS Distributed Denial-of-ServiceDT Decision TreeERR Error rateFPR False Positive RateGR Gain RatioKNN k-Nearest NeighborLMNN Large Margin Nearest NeighborLSTM Long Short-Term MemoryML Machine LearningNB Naive BayesNCA Neighborhood Components AnalysisMLKR Metric Learning for Kernel RegressionPAM Partitioning around medoidsPE Portable ExecutablePUP Potentially Unwanted ProgramROC Receiver Operating CharacteristicSC Silhouette CoefficientSVM Support Vector MachineTFIDF Term Frequency-Inverse Document FrequencyTPR True Positive RateVDM Value Difference MetricWERR Weighted Error RateWKNN Weighted k-Nearest Neighborxiv



Chapter 1



IntroductionIn information security, malware attacks are one of the main threats over the past sev-eral decades. While malware developers continuously find new exploitable vulnerabilities,create more and more sophisticated techniques to avoid detection, and find new infec-tion vectors, on other hand, malware analysts and researchers continually improve theirdefenses. This game seems to have an infinite number of rounds.The attackers purpose is no longer to cause detriment, such as damaging a computersystem. Nowadays, malware has become a rather profitable business. Malware writers usea variety of techniques to distribute malicious programs and infect devices. They can useself- propagation mechanisms based on various vulnerabilities or use social engineering totrick the user into installing the malware. Malware writers usually employ obfuscationtechniques [1], [2] such as encryption, binary packers, or self- modifying code to evademalware classifiers. Many malware researchers have focused on data mining and machinelearning (ML) algorithms to defeat these techniques and to detect unknown malware.Automated malware detection based on machine learning consists of extraction of usefulinformation from training samples, application of data preprocessing techniques, featureselection, building a detection model, and finally evaluation of the performance. Sincemalware evolves, this whole process runs repeatedly.1.1 MotivationAs the number of malware samples increases every day, the need for automatic classificationof malware that would be able to learn and adapt is crucial. According to the AV-TESTSecurity Report 2019/2020 [3], more than 114 million new malware were developed in2019. To defend against malware, users typically rely on antivirus products to detect athreat before it can damage their systems. Antivirus vendors rely mainly on a database ofsequences of bytes (signatures) that uniquely identify the suspect files and are unlikely tobe found in benign programs.The major weakness of signature detection is that malware writers can easily modifytheir code, thereby changing their program’s signature and evading virus scanners. The11. 



Introductionsignature detection technique is unable to detect obfuscated and zero-day malware.Encryption, polymorphism, metamorphism, and other code obfuscation techniques arewidely used by malware authors to evade signature detection techniques. For this reason,malware researchers are investigating novel detection strategies.During the last years, the current trend is to used a malware detection framework basedon machine learning algorithms [4], [5]. Thanks to cloud-based computing, which makesthe cost of big data computing more affordable, the concept of employing machine learningfor malware detection has become more realistic to deploy.1.2 Problem StatementMalware detection is one of the most important problems since the detection of malwarein advance allows us to block it. Malware detection is a binary classification problemof distinguishing between malware and benign files. Malware family classification is amulticlass classification problem where each testing sample is assigned to a known malwarefamily. The practical use of distinguishing between malware families lies in helping malwareanalysts to deal with a large number of samples.One of the main problems of malware detection systems is insufficient accuracy whilekeeping the false positive rate at an acceptable level. There is a need to build a machinelearning framework suited for real-life practical use that generically detects as many mal-ware samples as possible, with a very low false positives rate. The significant problem tobe solved is how to detect malware that has never been seen before. While signature-baseddetection systems identify known malicious programs, they can be bypassed by unknownmalware. Instead of using static signatures, an adequate alternative solution is to usemachine learning methods to detect malware.1.3 Goals of the Dissertation ThesisIn this thesis, we attempt to reach the following four goals via machine learning techniques.1. To detect malware with a minimal error rate. More precisely, to achieve the errorrate of less than 1%.2. To detect as much malware as possible while maintaining a low false positive rate.More precisely, to achieve the error rate and false positive rate, both of less than 1%.3. To experimentally verify the usefulness of distance metric learning for malware de-tection and classification of malware families.4. To automate the process of malware detection and malware family classification.21.4. Structure of the Dissertation Thesis1.4 Structure of the Dissertation ThesisThe dissertation thesis is organized into the following five 



Chapters:1. 



Introduction describes the motivation behind our efforts, defines problem statement,and lists the goals of this dissertation thesis.2. 

Background and State-of-the-Art introduces the reader to the necessary theoretical

Background and surveys the current state-of-the-art.3. 

Overview of Our Approach summarizes author’s work in the field of automatic mal-ware detection.4. Author’s Relevant Papers presents a collection of five author’s papers relevant to thisthesis.5. 



Conclusions summarizes the 

Results of our research, suggests possible topics for fur-ther research, and concludes the thesis.3



Chapter 2

Background and State-of-the-Art2.1 

BackgroundThe term malware, or malicious software, is defined as any software that does somethingthat causes detriment to the user. Malware includes viruses, worms, trojan horses, rootkits,spyware, and any other program that exhibits malicious behavior. The attacker’s purposeis no longer either to infiltrate or to damage a computer system. Nowadays, malware hasbecome a rather profitable business.Malware writers usually employ obfuscation techniques such as encryption, binary pack-ers, or self-modifying code to evade malware classifiers.Malware detection techniques can be typically classified into two categories dependingon how code is analyzed: static and dynamic analysis. The static analysis aims at searchingfor information about the structure and data in the file. The disassembly technique is astatic analysis technique, which is used to extract various features from the executables.The dynamic analysis aims to examine a program that is executed in a real or virtualenvironment. Many malware researchers have focused on machine learning algorithms todefeat obfuscation techniques and detect unknown malware.The choice of the most suitable machine learning algorithm is affected by the typesof features extracted from samples and their representation. This 



Section presents severaltypes of features extracted from static or dynamic analysis.2.1.1 Types of MalwareThe term malware is short for malicious software, and it refers to any software that doessomething that causes detriment to the user. The problem with each definition of mal-ware is that it is very broad and not rigorous. Malicious activities may include disrupt acomputer operation, gather sensitive information, or unauthorized access to a computersystem or network.To the best of our knowledge, there is no definition of what precisely malware is.This lack causes practical consequences in the antivirus industry and poses the following52. 

Background and State-of-the-Artquestion. If we do not know the exact definition of malware, then is it possible to createsome malware detection models with 100% of accuracy? Malware classification models areevaluated using labeled data from the test set. However, there is an assumption that thetesting data are labeled correctly. If we want to achieve perfect accuracy for each user ofsome antivirus program, there must be a consensus among all users on the definition ofmalware. Since there is no such exact definition, the evaluation 

Results of each malwaredetection model are only relative to the labels of samples from the test set. An exampleof programs where consensus is not achieved is adware which is sometimes referred to asmalware and sometimes as benign files.Malware classification can take into account the purpose of malware or its functionality.However, classification based on malware’s functionality may not be possible since malwarecan have many functionalities. For example, malware can behave like a worm (i.e., scansthe network and exploits vulnerabilities) and can download another malware componentsuch as backdoor [1]. As a result, the following types of malware are not mutually exclusive,and they are solely intended to familiarize the reader with the various types of malware.Backdoor is classified as a Trojan horse, and it enables the attacker to get access to asystem and execute commands.Bot is malware that allows the attacker (called botmaster) to control the compromisedsystem remotely. A group of interconnected bots remotely-controlled by a botmas-ter using Command and Control (C&C) software [1] is called a botnet. Usual mali-cious activities of a botnet are Distributed Denial-of-Service (DDoS) attacks, spywareactivities, sending spam emails, or distributing other malware.Downloader also called dropper, is designed to download and install additional malwareor malicious components.Ransomware is type of malware that locks victim’s screen and encrypts chosen typesof files (such as popular .xsl, .docx, .txt, .sql, .jpg, .cpp, .mp3, and many others).The AES, RSA, and Elliptic curve cryptography are the most common encryptiontransformations. The attacker then demands a ransom (usually paid in Bitcoin [6])for providing the decryption key.Rootkit is used to modify the operating system in order for an attacker can keep ad-ministrator privileges. The characteristic of rootkit is to conceal its presence or thepresence of other malicious programs.Spyware retrieves sensitive data from a victim’s system and sends them to the attacker.Such sensitive data may include passwords, credit card numbers, history of visitedweb pages, emails, and various documents. An example of spyware is keylogger 1 thatcaptures keystrokes and transfer them to the attacker. Another example of spywareis a sniffer that monitors internet traffic [8].1Note that keystroke dynamics can be used to identify a user in the system [7], and as a result, increasethe security of the system.62.1. 

BackgroundTrojan horse disguises itself as benign software; however, it performs malicious activitiesin the 

Background.Virus is malware that is attached to a host file. Virus depends on human activity, andwhen such an infected host is run, the virus is activated and performs some mali-cious activity, and spread itself to other computers. A comprehensive 



Discussion oncomputer viruses can be found in [9].Worm is similar to a virus; however, it does not need a host file nor human activity toactivate itself. A worm can self-replicate and spreads itself to other computers.Potentially Unwanted Programs (PUP) are a specific type of software that is consideredas a gray area among malware and benign files. The intent of PUP may be unclear, orfor some users, the benefit of PUP may outweigh the potential risk. Antivirus vendorsdeal with PUPs in with lower-risk category. Some antivirus vendors allow users to decidewhether PUPs will be detected or not on their system. An example of PUP is an adwarethat displays advertisements, often in the form of pop-up messages. Another example ofPUP is toolbars, extensions, or plugins installed on the user’s browser. Note that adwareis often determined as malware, however, this statement is dependent on the definition ofmalware which is not fixed.Malware writers use a variety of infection vectors to distribute malicious programs andinfect devices. They can exploit vulnerable services over the network, vulnerabilities inthe Web browser application, or social engineering. Popular techniques used to spreadmalware to users are presented in [10].Malware authors usually use various obfuscation techniques to avoid malware detection.The following 



Section presents the most used techniques to evade detection from anti-virusproducts.2.1.2 Malware Obfuscation TechniquesMalware authors often use techniques to modify malware to make it more difficult to detectit. These techniques are called obfuscation techniques, and they are used to protect themalware from malware analysts and reverse engineers. These techniques successfully avoidsignature-based detection. Obfuscation can be applied on several layers, such as code, asequence of instructions, or binary. In this 



Section, we will outline some techniques usedto make it more difficult to detect malware. Among the most popular techniques belongpacking, encryption, polymorphism, and metamorphism.Packing is a process that uses compression (one or more layers) to obfuscate an executablefile. As a result, a new executable file with obfuscated content is created. Theunpacking process consists of a decompression routine that retrieves the original file(or code).72. 

Background and State-of-the-ArtEncryption is similar to packing; however, encryption is used instead of compression.Encrypted and packed malware must contain a decryption module, which can beused for signature-based detection.Polymorphism uses encryption, and in addition, the decryptor module is morphed, andas a result, exhibits no signature. However, polymorphic malware still needs tobe decrypted, and original (non-obfuscated) code can be used for signature-baseddetection.Metamorphism is the most advanced obfuscation technique and the most challengingfor malware authors. Metamorphic malware changes internal structure while main-taining its original functionality.Packing and encryption are two popular techniques to avoid signature-based detectionand static analysis. Polymorphic and metamorphic malware have the ability to changetheir code with each new generation. When such kind of malware is executed, it can beobfuscated again to avoid signature-based detection.2.1.3 Malware AnalysisThe purpose of malware analysis is to provide the information used in classification orclustering problems.2.1.3.1 Static vs. Dynamic AnalysisMalware detection techniques can be classified into two main categories depending on howcode is analyzed: static and dynamic analysis. Static analysis [11], [12] aims at searchinginformation about structure of a file. The disassembly technique is one technique of staticanalysis, which is used to extract various features from the executables. Dynamic analysis[13], [10] aims to examine a program which is executed in a real or virtual environment.Since dynamic analysis involves running the program, information from this kind ofanalysis is more relevant than information from static analysis.Several works [14], [15], [16], [17] have described various 

Limitations of static analysis.The most important drawback is that data captured from the static analysis does notdescribe the complete behavior of a program since the program is not executed. However,dynamic analysis is more time-consuming in comparison to static analysis, and there areanti-virtual machine technologies that evade detection systems based on dynamic analysis.Consequently, dynamic analysis could be impractical for a large volume of samples thatcome to antivirus vendors every day. For these reasons, the static analysis still has itsplace in malware detection systems.A combination of static analysis and dynamic analysis is called hybrid analysis. Severalworks [18], [19] demonstrated that hybrid analysis has the potential to leverage advantagesfrom both static and dynamic analysis.82.1. 

Background2.1.3.2 Signatures vs. Machine Learning ApproachesSignaturesMost AV vendors rely primarily on the signature detection technique, a relatively simpleand efficient rule-based method for detecting known malware [20]. Signature (unique hexcode strings) of the malware is extracted and added to the database. The antivirus enginecompares the file contents with all malware signatures in the database, and if a match isfound, the file is reported as malware. A good signature must capture malware with min-imal false positive probability. The major weakness of signature detection is its inability todetect obfuscated and zero-day malware. Another drawback is that human analysts helpcreate signatures that result in prone to errors.Non-Signature Techniques based on Machine Learning MethodsMachine learning methods can partly solve the problem of an inability to detect unknownmalware. They can detect previously unknown or obfuscated malware, and they do notneed humans to create any kind of signature. However, ML methods are prone to have ahigh false positive rate and have large processing overheads.Machine learning algorithms can be divided into three main categories:Supervised learning - labeled data are utilized to gain knowledge that is used to predictlabels of new samples.Unsupervised learning - unlabeled input data are utilized to acquire knowledge.Semi-supervised learning - labeled and unlabeled data are inputs to a statistical model.Unlabeled data with a small amount of labeled data can improve the accuracy of themodel.The workflow of ML-based malware detection is an iteration process and consists ofthe following five steps:1. Feature extraction (static and/or dynamic). The process of feature extractionis performed through either static and dynamic analysis, and it depends on the typesof features.2. Feature preprocessing. Feature extracted from the previous step can have variousrepresentations. Depending on the data representation, features can be normalized,encoded to a more appropriate representation, missing values can be filled by averagevalues, and noisy values can be removed.3. Feature selection. After preprocessing step, a number of features can be reducedto improve performance. A subset of the most relevant features can be selected, ororiginal data can be transformed into a reduced number of features.92. 

Background and State-of-the-Art4. Machine learning algorithms. Malware detection problems are usually definedas classification or clustering problems. The choice of ML algorithms depends onwhether training data is labeled or not, as we mentioned above, and this choicedepends on data representation as well.5. Evaluation of performance. Performance metrics are used to evaluate ML al-gorithms. Evaluation 

Results indicate how good 

Results were achieved and which MLalgorithm performed better with respect to a given dataset.More information on feature selection and preprocessing as well as evaluation metricscan be found in [21]. The works [22], [23], [24] survey the most popular machine learningtechniques for malware classification in the Windows operating system. Several types offeatures are described in the following 



Section.2.1.4 Features for Malware DetectionA program can be represented on various levels of 



Abstraction. Static and dynamic analysistechniques can be applied to different representations of a program. Some types of featurescan be extracted from both static and dynamic analysis. For example list of ApplicationProgramming Interface (API) functions is included in the Portable Executable (PE) filewithout running the program. On the other hand, API calls can be extracted dynamicallyduring the execution of the program, which could be significantly more time-consuming.Byte sequences - static analysis - byte sequences are extracted from a program that istreated as a sequence of bytes. Examples of bytes sequence can be found in [25].The most popular method of using byte sequences or opcode sequences is based onfrequency distribution, such as the n-gram method [25].API & system calls - static or dynamic analysis - API functions and system calls provideinformation on the program’s behavior related to file systems, networking, security,and other resources provided by the operating system.opcodes - static analysis - opcode (operation code) sequences are extracted from the as-sembly language source code. Common techniques are based on the frequency ofappearance of opcode-sequences [26], examination of opcode frequency distributiondifference between malicious and benign code [27], or identification of critical instruc-tion sequences [28].PE file characteristics - static analysis - the features used in our experiments are ex-tracted from the portable executable (PE) file format [29], which is the file format forexecutables, Dynamis-Link Libraries (DLL), object code, and others used in 32-bitand 64-bit versions of the Windows operating system. A PE file consists of headersand 



Sections that encapsulate the information necessary to manage the executablecode. The PE file header provides all the descriptive information concerning the loc-ations and sizes of structures in the PE file to the loader process. The header of a PE102.2. Previous 

Results and Related Workfile consists of the DOS header, the PE signature, the Common Object File Format(COFF) file header, the optional header, and the 



Section headers. The optional fileheader is followed immediately by the 



Section headers, which provide informationabout 



Sections, including locations, sizes, and characteristics.Strings - static analysis - printable string extracted from a program can reveal valuableinformation, such as URLs where the program connects, file names, and file paths.Entropy - static analysis - compressed or encrypted programs have a higher statisticalvariation of bytes sequence, and as a result, higher entropy than native code.Image - static analysis - malwares binary content can be represented as a grayscale imagewhere every byte of a program represents one pixel. The array of pixels is thenreorganized to a 2D image.Instruction Traces - dynamic analysis - a program can be represented as a sequenceof processor instructions. While packing and encryption can avoid static analysisof instruction traces, dynamic analysis based on instruction traces bypasses suchanti-malware analysis techniques.Features from the previous list belong among the most used features for malware de-tection. However, there are several other types of features, such as features extracted fromfilesystem, memory, network activity [24]. Some features can be represented as a directedgraph. For example, function calls are represented as a function call graph, and controlflow paths are represented as a control flow graph. Both types of features are described in[30].2.2 Previous 

Results and Related WorkIn this 



Section, we survey some relevant previous work in the area of malware detection. Theapplication of machine learning techniques to malware detection has been an active researcharea for about the last twenty years. Researchers have tried to apply various well-knowntechniques such as Neural Networks, Decision Trees, Support Vector Machines, ensemblemethods, and many other popular machine learning algorithms. Recent survey papers [23],[24], [30], [31] provide comprehensive information on malware detection techniques usingmachine learning algorithms.We mainly discuss the papers on static malware detection based on machine learningtechniques. Then, we briefly discuss various existing works related to malware familyclassification.2.2.1 Pioneer WorksSchultz et al. [32] introduced the concept of data mining for detecting previously unknownmalware. Their research presented three different static feature sources for malware classi-112. 

Background and State-of-the-Artfication: information from the portable executable (PE) header, strings, and byte sequencesextracted from binaries. These features were used in three different kinds of algorithms: aninductive rule-based learner, a probabilistic method, and a multi-classifier system. A ruleinduction algorithm called Ripper [33] was applied to find patterns in the dynamic-linklibrary (DLL) data (such as the list of DLLs used by the binary, the list of DLL functioncalls, and the number of different system calls used within each DLL). The well-knownprobabilistic method, learning algorithm Naive Bayes, was used to find patterns in thestring data and n-grams of byte sequences. Multinomial Naive Bayes algorithm that com-bined the output of several classifiers reached the highest detection rate of 97.76%. Theauthors tested data mining methods against standard signatures. Their 

Results indicatethat the data mining detection rate of a previously unknown malware was twice as highcompared to the signature-based methods.Kolter and Maloof [34] improved Schulz’s third technique by using overlapping byte se-quences instead of non-overlapping sequences. They used different kinds of classifiers: na-ive Bayes, instance-based learner, similarity-based classifier called Term Frequency-InverseDocument Frequency (TFIDF), Support Vector Machine (SVM), Decision Trees (DT), andboosted variants of SVM, DT, and TFIDF. Authors evaluated their classifiers’ performanceby computing the area under a receiver operating characteristic curve. Boosted Decisiontree model (J48) achieved the best accuracy, an area under the ROC curve of 0.996, andoutperformed the rest of the classifiers.2.2.2 Recent WorksNext, we review some most recent works related to malware detection based on machinelearning techniques. We mainly focus on works using static analysis of Windows PE files.Wadkar et al. [35] proposed the system based on static features extracted from PE filesfor detecting evolutionary modifications within malware families. Support Vector Machines(SVM) models were trained over a sliding time window, and the differences in SVM weightswere quantified using χ2 statistic. For most of all 13 malware families considered in theexperiments, the system detected significant changes.Yang and Liu [36] proposed a detection model called TuningMalconv with two layers:raw bytes model in the first layer and gradient boosting classifier in the second layer.The feature set was based on static analysis and consisted of raw bytes, n-grams of bytecodes, string patterns, and information in the PE header. The experimental 

Results of theTuningMalconv detection model on the dataset with 41,065 samples showed an accuracyof 98.69%.Another malware detection model based on static analysis was proposed in [37]. Thedetection model is based on semi-supervised transfer learning and was deployed on thecloud as a SaaS (Software as a Service). The detection model was evaluated on Kagglemalware datasets, and it improved classification accuracy from 94.72% to 96.90%.In [38], the authors proposed a classification system, Malscore, which combines staticand dynamic analysis. In static analysis, grayscale images were processed by the Con-volutional Neural Network. In dynamic analysis, API call sequences were represented as122.2. Previous 

Results and Related Workn-grams and analyzed using five machine learning algorithms: Support Vector Machine,Random Forest, Adaboost, Näıve Bayes, and k-Nearest Neighbors. The authors performedexperiments on more than 170,000 malware samples from 63 malware families and achieved98.82% of malware classification accuracy.Zhong and Gu [39] improved the performance of deep learning models by organizingthem to the tree structure called Multiple-Level Deep Learning System (MLDLS). Eachdeep learning model focuses on a specific malware family. As a result, the MLDLS canhandle complex malware data distribution. Experimental 

Results indicate that the proposedmethod outperforms the Support Vector Machine, Decision Tree, the single Deep Learningmethod, and an ensemble-based approach.All information on executables used in work proposed in [40] was from the PE header,more specifically, from MS-DOS, COFF, and Optional Header. Neural networks werelearned from raw bytes, which were not parsed to explicit features, and as a result, nopreprocessing nor feature engineering was required. More than 400,000 samples were usedfor training, and the Fully Connected Neural Network model achieved the highest accuracy.The neural network architecture combining convolutional and feedforward neural layerswas proposed in [41]. The authors used only static malware analysis where inputs tofeedforward layers were fields of the PE header, while inputs to convolutional layers wereassembly opcode sequences. The proposed hybrid neural network achieved 93% on precisionand recall.The work [42] contains three statistical-based scoring techniques: Hidden Markov mod-els, Simple substitution distance, and Opcode graph-based detection. Authors showed thata combination of these scoring techniques with Support Vector Machine yields significantlymore robust 

Results than those obtained using any of the individual scores.In [43], the authors proposed a data structure called aggregation overlay graph thatis suitable to compress metadata without any loss of information. A side effect of thisstructure is that similar files are stored in the same cluster. Besides analyzing PE metadatafrom the Windows operating system, the work also focuses on Android APK files. Hugedataset consists of 82 million PE files was reduced by over 93%. Clarification is based onthe fact that for many malware families, their variants are highly similar to each other.In other words, a significantly high number of features’ values remain the same for severalmalware variants, and the aggregation overlay graph allows to decrease redundancy whenstoring metadata.A malware detection system based on a deep neural network was proposed in [44]. Thework is based on static features consisted of bin values of a two-dimensional byte entropyhistogram, binary’s import address table, features extracted from printable sequences ofcharacters, numerical features extracted from binary’s portable executable packaging. Theauthors achieved a 95% detection rate at 0.1% false positive rate based on more than400,000 samples.A static malware detection system based on data mining techniques was proposed in[45]. The feature set consists of information in PE header, DLLs, and API functions. In-formation Gain was used to selecting relevant features, and Principal Component Analysiswas used to reduce the dimension of the feature vector. The dataset consists of almost132. 

Background and State-of-the-Art250,000 Windows programs in PE file format. However, only less than 11,000 samples werebenign. For the imbalanced dataset, the detection rate of 99.6% was achieved by the J48decision tree classifier implemented in the WEKA [46].A framework, called PE-Miner, for automatic extraction of features from PE file format,was proposed in [47]. The features are then preprocessed, and finally, machine learningtechniques are applied to distinguish between malware and benign files. Using the J48decision tree classifier, the authors achieved more than 99% detection rate with less than0.5% false alarm rate.A statistical-based feature extractor applied on structural features of binary PE fileswas proposed in [48]. After identifying relevant features, a hypothesis-based classificationmodel and machine learning techniques were applied to a collection of more than 22,000samples. The J84 decision tree classifier achieved the highest accuracy.In [49], the authors proposed the Intelligent Malware Detection System (IMDS) thatis based on window APIsequence. The system consists of a PE parser, an Objective-oriented association rule generator, and a rule-based classifier. The experimental 

Resultswere evaluated on almost 30,000 executables. The IMDS achieved 93.07% of accuracy andoutperformed the J48 decision tree classifier.The rest of this 



Section briefly reviews the previous research papers on malware familyclassification related to our work.In [50], the authors conducted experiments based on byte n-gram features, and theyconsidered 20 malware families. A binary classification was performed on different levels.In the first level, for each of the 20 families, they performed binary classification for 1,000malware samples from one family and 1,000 benign samples. In the second level, themalware class consists of two malware families; in the third level, the malware class consistsof three malware families, and so on up to level 20, where the malware class contains allof the 20 malware families. The authors applied four state-of-the-art machine learningalgorithms: KNN, Support Vector Machines, Random Forest, and Multilayer Perceptron.The best classification 

Results (balanced accuracy) were achieved using KNN and RandomForest, over 90% (at level 20), while KNN achieves the most consistent 

Results.A fully automated system for analysis, classification, and clustering of malware sampleswas introduced in [51]. This system is called AMAL, and it collects behavior-based artifactsdescribing files, registry, and network communication, to create features that are then usedfor classification and clustering of malware samples into families. The authors achievedmore than 99% of precision and recall in classification and more than 98% of precision andrecall for unsupervised clustering.In [52], the authors proposed a malware classification system using different malwarecharacteristics to assign malware samples to the most appropriate malware family. Thesystem allows the classification of obfuscated and packed malware without doing any deo-bfuscation and unpacking processes. High classification accuracy of 99.77% was achievedon the publicly accessible Microsoft Malware Challenge dataset.The work in [53] presents a classification method based on static (function length fre-quency and printable sting) and dynamic (API function names with API parameters)features that were integrated into one feature vector. The obtained 

Results showed that in-142.2. Previous 

Results and Related Worktegrating features improved classification accuracy significantly. The meta-Random Forestclassifier achieved the highest weighted average accuracy.Another malware family classification system referred to as VILO is presented in [54].They used TFIDF-weighted opcode mnemonic permutation features and achieved between0.14% and 5.42% fewer misclassifications using KNN classifier than does the usage of n-gram features.15



Chapter 3

Overview of Our ApproachThis 



Chapter describes our contributions that are divided into the following 



Sections. Het-erogeneous distance function specially designed for PE the file format and combinationof weighted k-Nearest Neighbors classifier and statistical-based classifier are proposed in



Section 3.1. In 



Section 3.2, we modified the Particle Swarm Optimization algorithm andapplied it to the problem of finding the most appropriate feature weights used in the het-erogeneous distance function. 



Section 3.3 describes transformation of PE features usingvarious LSTM network architectures. The detection system is based on supervised machinelearning algorithms that are applied to the transformed feature space. 



Section 3.4 focuseson the multiclass classification of six prevalent malware families and benign files. Threestate-of-the-art distance metric learning algorithms were employed to learn the Mahalan-obis distance metric to improve the performance of k-Nearest Neighbors classifier. Finally,



Section 3.5 describes the architecture of our proposed malware detection model using dis-tance metric learning. We focused on two tasks: (1) to classify malware and benign fileswith a minimal error rate, (2) to detect as much malware as possible while maintaining alow false positive rate. To consider the higher cost of false positives, we constructed a costfunction called weighted error rate. We used it as a fitness function in the PSO algorithmto minimize error rate and false positive rate.3.1 Malware Detection using Heterogeneous Distance Func-tionMany classifiers require some measure of dissimilarity or distance between feature vectors,and their performance depends upon a good choice of the distance function. Especiallythe KNN classifier depends significantly on the metric used to compute distances betweentwo feature vectors.In this 



Section, we propose a similarity metric for features extracted from PE file format.We used this metric to compute distances to find k nearest neighbors used in the KNNclassifier. Note that the features used in our work are of various types and ranges. These173. 

Overview of Our Approachfeatures can be divided into three types: numbers, bit fields, and strings. For example,number of 



Sections or various addresses can be represented by numbers, 



Section flags orcharacteristics by bit fields, and checksums by strings. Furthermore, some features havedifferent ranges. For example, the number of 



Sections is considerably smaller than the totalnumber of called API functions. The proposed distance function can handle these types offeatures and also takes into account their different ranges.3.1.1 Heterogeneous Distance Metric for PE FeaturesThe most commonly used metric is the Euclidean distance which works well for numericalattributes (features). However, it does not appropriately handle nominal attributes. Weproposed a suitable distance function for nominal and numeric attributes, as well as forboolean arrays.Let x and y be two feature vectors of dimension m. The heterogenenous distancefunction is defined as follows:D(x,y) =√√√√m∑a=1d2a(xa, ya) (3.1)whereda(x, y) =H(x, y) if a is a bit arrayδ(x, y) if a is a checksumNorm diffa(x, y) if a is a numericNorm vdma(x, y) otherwise.(3.2)H(x, y) de

Notes Hamming distance defined for binary vectors x = (x1, . . . , xn), y = (y1, . . . , yn)asH(x, y) = |{i|xi 6= yi, i = 1, . . . , n}| (3.3)and δ(x, y) is the characteristic function defined asδ(x, y) ={0 if x = y1 otherwise.(3.4)The Value Difference Metric (VDM) was introduced by [55] and the normalized VDM isdefined asNorm vdma(x, y) =C∑c=1∣∣∣∣na,x,cna,x− na,y,cna,y∣∣∣∣ (3.5)where◦ C is the number of classes,183.1. Malware Detection using Heterogeneous Distance Function◦ na,x,c is the number of instances in training set T which have value x for attribute aand the instance belongs to class c,◦ na,x is the number of instances in T that have value x for attribute a.Function Norm diffa(x, y) is defined as:Norm diffa(x, y) =|x− y|4σa(3.6)where σa is the standard deviation of the values of numeric attribute a.The distance D is a modification of Heterogeneous Value Difference Metric (HVDM)[56], and it can be used for our PE feature space since it handles both numeric and nominalattributes.Since the distance functions da are metrics, D is also a metric. Properties of a metric,especially a triangle inequality, can be used to find nearest neighbors in a metric spacemore effectively.Note that we distinguish between a checksum and a string attribute that is not achecksum. For the demonstration of distance function D, we present the examples of PEattributes of each type:- array of bits: 



Section flags, Characteristics, DllCharacteristics- numeric attribute: number of 



Sections, number of DLLs, size of all imports- checksum: checksums of various pieces of the file content- string: major/minor version of linker, operating system, subsystem3.1.2 Malware Detection SystemThis 



Section presents a system for detecting malware composed of a weighted KNN classifierand a statistical scoring technique introduced in [48]. We first describe the weighted KNNclassifier and the statistical scoring technique. Then, we present our approach based onthe combination of these classifiers and describe the architecture of the detection system.3.1.2.1 The Weighted k-Nearest Neighbors ClassifierThe k-Nearest Neighbors (KNN) classifier is one of the most popular supervised learningmethods introduced by Fix and Hodges [57]. It is one of the simplest and best-knownnonparametric algorithms in pattern classification.Distance-weighted k-Nearest Neighbor procedure (WKNN) was first introduced in [58]as an improvement to KNN. This extension is based on the idea that closer neighborsare weighted more heavily than such neighbors that are far away from the query point.KNN implicitly assumes that all k nearest neighbors are equally important in making aclassification decision, regardless of their distances to the query point. In WKNN, nearest193. 

Overview of Our Approachneighbors are weighted according to their distances to the query point as follows. LetT = {(x1, c1), . . . , (xm, cm)} be the training set, where xi is training vector and ci is thecorresponding class label. For a query point xq, its unknown class cq is determined asfollows. First, select the set T ′ = {(x1, c1), . . . , (xk, ck)} of k nearest neighbors to thequery point xq. Let x1, . . . , xk be k nearest neighbors of the query object and d1, . . . , dkthe corresponding distances arranged in increasing order. The weight wi for i-th nearestneighbor is defined as:wi ={dk−didk−d1 if dk 6= d11 otherwise(3.7)The resulting class of the query point is then defined by the majority weighted vote asfollows:cq = arg maxc∑(xi,ci)∈T ′wi · δ(c, ci) (3.8)Note that finding the nearest neighbors is a very expensive operation for a dataset ofthe enormous size. The nearest neighbors can be found more efficiently by representingthe training dataset as a tree.3.1.2.2 Statistical Classifier – STATSIn this 



Section, we present the scoring techniques that we used in our research. In contrastto the KNN classifier, a statistical-based classifier ignores the positions of points in ourmetric space and focuses on statistical properties of attribute (feature) values.The following statistical classifier was introduced in [48]. Let x = (x1, . . . , xn) be avector from our feature space and M a class of malware. Then probabilityP (x ∈M|xi = h) =nxi,h,Mnxi,h(3.9)is the conditional probability that the output class of x is malware given that attribute xihas the value h. Denote this probability by pi, i = 1, . . . , n. Note that the notations nxi,h,Mand nxi,h were used in the definition of VDM discussed in 



Section 3.1.1. Let function fwith two parameters pi and Sc be defined asf(pi, Sc) = max{0, pi − Sc}, (3.10)where Sc is an empirical constant. For each sample x we define a score asscore =n∑i=1f(pi, Sc) (3.11)From this score, we can determine a threshold Ss, above which we will classify a sampleas malware. The decision rule is then defined as follows:203.1. Malware Detection using Heterogeneous Distance Functionx is classified as{malware, if score > Ss,benign file, otherwise.The pseudocode of the statistical-based classifier is described in Algorithm 3.1.Algorithm 3.1 Statistical classifier – STATSInput: original training set, query point x, distance metric DOutput: label of x1: score = 02: Compute probability vector (p1, . . . , pn)3: for i = 1 to n do4: if pi > Sc then5: score += pi − Sc6: end if7: end for8: if score > Ss then9: return malware10: else11: return benign file12: end ifIn the rest of 



Section 3.1.2, the statistical-based classifier is denoted as STATS.3.1.2.3 Our ApproachWe propose a malware detection approach based on a combination of the well-knownKNN classifier and the chosen statistically motivated classifier. In order to achieve higherdetection rates, there should be some kind of diversity between the classifiers. KNN is ageometric-based classifier that uses labels of the nearest neighbors in some metric spaceto classify an unlabeled point. On the other hand, statistical-based approaches like NaiveBayes or the STATS classifier mentioned above use conditional probabilities of attributesof a sample point and do not use information about its position in feature space.The proposed detection method works as follows. First, set the threshold to some suffi-ciently high value. Then compute the score using the chosen statistical scoring technique.If the score of the unknown file exceeds the threshold, then the resulting class will bemalware. Otherwise, apply distance-weighted KNN. The pseudocode for the classificationscheme is shown in Algorithm 3.2.We chose KNN since it is a relatively accurate classifier for large datasets. The 

Resultsof our experiments demonstrate that the statistical classifier can correctly classify sampleslying in the area of feature space where the accuracy of KNN is low. The statistical classifieruses information from the training dataset in a different way than the KNN classifier. Itchecks whether a feature vector contains values typical for malware, in contrast to KNNthat considers only differences between feature vectors.213. 

Overview of Our ApproachAlgorithm 3.2 Combination of the KNN and statistical classifierInput: original training set, query point x, distance metric DOutput: label of x1: compute score from the statistical scoring technique2: if score > threshold then3: return malware4: else5: apply WKNN6: end ifDataset ofknown PEfeaturesPEfeaturesConditionalprobabilitiesFeaturevectorsFeaturevectorsClassificationTraining phase:Testing phase:modulePE filesUnknownPE filesFigure 3.1: Architecture of the classification modelFor example, consider a feature vector x = (x1, . . . , xn) containing only a few values(typically checksums), for which there is a high probability that x belongs to malware.Many other attributes could have previously unseen values or ones with a low prevalence.Therefore, malicious nearest neighbors could not be closer than benign nearest neighbors,and in this case, the KNN classifier would not be an appropriate method.3.1.2.4 The system architectureThe system consists of three major components: a PE parser, a database of conditionalprobabilities, and a classification module, as illustrated in Figure 3.1.The functionality of the PE parser is to extract all PE file header information, DLLs,and API functions from programs in the dataset and store all the extracted information ina database. Recall that our system is applied only to Windows PE files, and the PE parserextracts only the most useful features for discriminating between benign and maliciousfiles. These features were determined by the feature selection algorithm Gain Ratio [59].223.2. Distance Metric Learning using Particle Swarm OptimizationDuring the training phase, once the structural information of the PE files is extracted,the conditional probabilities P (x is malware|xi = h) are computed for each PE attributexi and for each possible value h of attribute xi. Note that only the PE features extractedfrom labeled samples of the training dataset are used in the computation of the conditionalprobabilities.After extracting PE features and computing the conditional probabilities, feature vec-tors are created for every known PE file. The set of these feature vectors called trainingset will be used in the classification module, where the classification algorithm is appliedto feature vectors of unknown PE files.Experimental 

Results and more details on heterogenenous distance function and theproposed ensemble classifier are described in the paper included in 



Section 4.1.3.2 Distance Metric Learning using Particle Swarm Op-timizationWe applied the PSO algorithm to the problem of finding the most appropriate featureweights used in the heterogeneous distance function defined for the features extracted fromPE file format. First, we present a modification of the heterogeneous distance function de-scribed in 



Section 3.1.1. We then present our proposed method based on a modificationof the PSO algorithm used to learn the heterogeneous distance function. The paper in-cluded in 



Section 4.2 describes the malware detection system’s architecture and presentsthe experimental 

Results.Let x and y be two feature vectors of dimension m, and let wa be weight correspondingto the attribute (feature) a. We modified the heterogeneous distance function describedin Eq. (3.1) by considering weight for each feature. The weighted heterogeneous distancefunction is defined as follows:D(x,y) =√√√√m∑a=1w2ad2a(xa, ya) (3.12)The rest of this 



Section presents our approach for finding the feature weights usingParticle swarm optimization. Particle Swarm Optimization (PSO) [60] is a biologically-motivated stochastic optimization algorithm based on swarm intelligence. Each particle isrepresented as a point in the search space, and a fitness function determines the quality ofeach point. Each particle updates its position, which is influenced by the current velocity,the previous best particle’s position, and the most successful particle in the swarm.Concept and notation of the PSO elements concerning finding the feature weights usedin weighted heterogeneous distance function in KNN classification is as follows:◦ particle is represented as a vector of weights w. The current position of i-th particleis denoted by xi, and vi de

Notes its current velocity.233. 

Overview of Our Approach◦ swarm or population is an array of all particles considered in the PSO algorithm.◦ local best position pi of i-th particle is its best position among all positions visited sofar, and pbesti is the corresponding value of the fitness function f , i.e. pbesti = f(pi).◦ global best position pg is the position of the most successful particle in the swarm,and gbesti = f(pg).◦ fitness function f is an objective function used to measure the quality of a particle. Inour malware detection problem, the optimization criterion can be defined as the errorrate of the KNN classifier. Note that in 



Section 3.5, we will also consider anotheroptimization criterion focused on minimizing the false positive rate.The PSO algorithm has three inputs: fitness function f , a training set Tpso, and vectorp of feature importance scores [61] achieved from the feature selection algorithm. Thepseudocode of the modified PSO algorithm is presented in Algorithm 3.3.Algorithm 3.3 PSO algorithmInput: fitness function f , Tpso, pOutput: vector of weights1: initialize particles: xi = p⊗Rand(0, ε1), vi = Rand(−ε2, ε2)2: repeat3: for each particle xi do4: compute fitness function f(xi)5: if f(xi) > pbesti then6: pbesti = f(xi)7: pi = xi8: end if9: end for10: select the most successful particle in swarm so far, and denote it by pg11: for each particle xi do12: vi = ωvi + Rand(0, φ1)⊗ (pi − xi) + Rand(0, φ2)⊗ (pg − xi)13: xi = xi + vi14: end for15: until maximum number of iterations is attained16: return global best positionRand(0, ε) represents a vector of random numbers uniformly distributed in [0, ε], whereε is a small constant. Operation ⊗ de

Notes component-wise multiplication. Note that eachparticle can memorize its best previous position, and it also knows the best position ofthe whole swarm so far. Each component of velocity v is kept in the range [−Vmax, Vmax],where parameter Vmax influences search ability of the particles. An inertia weight ω isused to better control the search scope and reduce the importance of Vmax. Higher valuesof ω tend to global search while lower values tend to local search. Parameters φ1 and φ2243.3. Malware Detection using LSTMrepresent the weights, and they are used to balance the global and the local search. Thepurpose of the initialization is in the acceleration of PSO, i.e., reducing the searching spaceis done using the feature selection algorithm 

Results.Inertia weight ω depends on the number of iterations. At the first iteration, ω is set toone, and it linearly decreases at each iteration to the value ωmin = 0.8.This work concerns the classification problem where the definition of the fitness func-tion depends on the KNN classifier. The fitness function of the clustering problem canalternatively be defined using purity or silhouette coefficient.The PSO was chosen among other optimization heuristics because its convergence rateis fast, and the algorithm is easy to implement and execute in parallel. The drawback ofthe algorithm is that it is vulnerable to stuck into the local minima.3.3 Malware Detection using LSTMThis 



Section presents the transformation of PE features using the LSTM network [62]. As aresult, classification 

Results achieved using transformed feature space improved significantly.We experimented with various LSTM architectures, which we used for feature transform-ation. The paper included in 



Section 4.3 describes experimental 

Results and presents ourapproach in more detail.Our research is not limited to only LSTM networks; however, a bidirectional version ofLSTM networks (BLSTM) [63] was also included in our experiments. We considered twodifferent types of neural networks: the Basic version consisting of one (B)LSTM layer andthe Deep version with four (B)LSTM layers, each layer containing 50 LSTM units equalto the number of input features. All networks were trained up to 50 epochs with a batchsize of 32, Adam optimization, and mean squared error loss function.3.3.1 Type 1The first type of LSTM network we experimented with is based on autoencoder’s architec-ture [64]. In this case, we worked only with explanatory variables with a network designedto predict the same values which were given on input. The predicted transformation wastaken from the penultimate layer’s last hidden state. Schema of the Type 1 transformeris illustrated in Figure 3.2a. Note that hidden state ht represents the short-term memory,and the detailed description of LSTM network is presented in paper included in 



Section4.3.3.3.2 Type 2The second type was similar to the regular use of the LSTM network, where we work withboth the explanatory and response variables. For prediction, we used the last hidden stateof the penultimate LSTM layer as with Type 1. The last layer was occupied by a single253. 

Overview of Our Approach(B)LSTM layeryOutput PredictedtransformationhtXInput(a) Schema of Basic version Type 1 trans-former.(B)LSTM layeryInputOutputPredictedhtXDenselayertransformation(b) Schema of Basic version Type 2 trans-former.Figure 3.2: Two different types of transformers.neuron with a sigmoid activation function. Diagram of the Type 2 transformer is presentedin Figure 3.2b.Experiment workflow consits of the following steps:1. Feature extraction. Python module pefile [65] was used to extract features fromthe PE file format.2. Feature preprocessing. Numeric features were transformed min-max normaliza-tion, strings were transformed into term frequency times inverse document frequencyrepresentation using TfidfVectorizer from the scikit-learn library [66], and non-string data were encoded into numeric values using feature hashing FeatureHasheralso from the scikit-learn.3. Feature selection. Using Principal Component Analysis algorithm, we reduced thedimensionality by extracting the most relevant features.4. Feature transformation. Features were transformed using (B)LSTM network asdescribed above.5. Classification. Several state-of-the-art ML algorithms were applied on the trans-formed dataset.6. Evaluation. Classification 

Results were evaluated using common evaluation metrics.Experimental 

Results and a detailed description of our approach can be found in thepaper included in 



Section 4.3.263.4. Malware Family Classification using DML3.4 Malware Family Classification using DMLThis 



Section concerns the application of selected state-of-the-art distance metric learn-ing techniques to the multiclass classification problem for six prevalent malware familiesand benign files. This multiclass classification problem is more challenging than a binaryclassification problem where the goal is to distinguish between malicious and benign files.3.4.1 Distance Metric LearningThis 



Section provides basic information on distance metric learning. Euclidean distance isby far the most commonly used distance. Let x and y be two feature vectors from realn-dimensional space Rn, and let wi, i = 1, . . . , n, be a non-negative real number associatedwith the i-th feature. The weighted Euclidean distance is defined as follows:dw(x,y) =√√√√n∑i=1w2i (xi − yi)2 (3.13)The goal of learning the weighted Euclidean distance is to find an appropriate weightvector w = (w1, . . . , wn) concerning some optimization criterion, usually minimizing errorrate. Several other distance functions have been presented [56]. In order to improve 

Results,many weighting schemes were proposed. A review of feature weighting methods for lazylearning algorithms was proposed in [67].Mahalanobis distance is another popular distance. It is defined for two vectors x,y ∈ Rnof dimension n asdM(x,y) =√(x− y)>M (x− y) , (3.14)where M is a positive semidefinite matrix. Mahalanobis distance can be considered asa generalization of Euclidean distance, since if M is the identity matrix, then dM in Eq.(3.14) is reduced to common Euclidean distance. If M is diagonal, then this correspondsto learning the feature weights Mii = wi defined for weighted Euclidean distance in Eq.(3.13).The goal of learning the Mahalanobis distance is to find an appropriate matrix Mconcerning some optimization criterion. Regarding the KNN classifier, the goal can bedefined as to find a matrix M which is estimated from the training set, leading to thelowest error rate of the KNN classifier. Since a positive semidefinite matrix M can alwaysbe decomposed as M = L>L, distance metric learning problem can be viewed as findingeither M or L = M12 . Mahalanobis distance defined in Eq. (3.14) expressed in terms ofthe matrix L is defined asdM(x,y) = dL(x,y) = ‖L>(x− y)‖2 (3.15)Another application of distance metric learning is dimensionality reduction. The matrixL can be used to project the original feature space into a new embedding feature space.273. 

Overview of Our ApproachThis projection is a linear transformation defined for feature vector x asx′ = Lx (3.16)Mahalanobis distance of two points x,y from the original space defined in Eq. (3.14)corresponds to the Euclidean distance between transformed points x’ = Lx,y’ = Lydefined as follows:dL(x,y) = ‖L>(x− y)‖2 =√(x’− y’)> (x’− y’) (3.17)This transformation is useful since the computation of Euclidean distance has lowertime complexity than Mahalanobis distance computation.Distance metric learning has attracted a lot of attention in the machine learning fieldand is still an active research area [68].3.4.2 Our ApproachThe paper included in 



Section 4.4 presents the application of three state-of-the-art distancemetric learning techniques to malware families classification.We employed the following three DML techniques, Large Margin Nearest Neighbor(LMNN) [69], Neighborhood Component Analysis (NCA) [70], and Metric Learning forKernel Regression (MLKR) [71], to learn the Mahalanobis distance metric to improve mul-ticlass classification performance for our dataset containing six prevalent malware familiesand benign files. LMNN and NCA were selected since they were designed to improve theKNN clas- sifier. MLKR was included in our experiments since our preliminary experi-ments indicated the potential to achieve competitive 

Results. All three DML techniquesare described in the paper included in 



Section 4.4.Our approach can be divided into the following steps:1. Feature extraction. The features used in our experiments were extracted from thePE file format via Python module pefile [65]. We extracted 358 numeric featuresthat are based on static information only.2. Feature normalization. All features were normalized using procedurepreprocessing.normalize from the Scikit-learn library.3. Feature normalization. We then employed the six feature selection methods alsoimported from the Scikit-learn library. The lowest error rate was achieved for 25selected features by Recursive Feature Elimination [72] with Logistic Regression es-timator.4. Distance Metric Learning. We employed the DML algorithm to learn the Ma-halanobis distance metric.5. Feature Vector Transformation We transformed original feature set by lineartransformation described in Eq. (3.16).283.5. Malware Detection using DML6. Classification. We applied several state-of-the-art machine learning algorithms ontransformed feature vectors.7. Evaluation. We evaluated classification 

Results using common performance metrics.Experimental 

Results are described in the paper included in 



Section 4.4.3.5 Malware Detection using DMLSimilar to 



Section 3.4, this 



Section deals with the application of DML to malware detection.However, this 



Section focuses on binary classification concerning the following two tasks:(1) to classify malware and benign files with a minimal error rate, (2) to detect as muchmalware as possible while maintaining a low false positive rate.In this 



Section, we first describe the architecture of the malware detection system usingDML. Then, we present our approach for dealing with the task (2). More details on ourapproach and the experimental 

Results can be found in the paper included in 



Section 4.5.3.5.0.1 ArchitectureWe present the architecture of the malware detection system based on distance metriclearning. The system uses static analysis of PE file headers and 



Sections. The proposedarchitecture is depicted in Figure 3.3 and outlined in the following seven basic steps:Step 1: Splitting the data. The set of samples is randomly divided into the trainingset and testing set. The training set is used for training a distance metric and classifier.Step 2: Parsing binaries. For each sample, we extract and store information fromPE file format. These features will be preprocessed in the following two steps, and relevantfeatures only will be selected and considered in experiments.Step 3: Preprocessing of features. Conditional probability P (x is malware|xi = h)is computed for each nominal feature xi and for each value h of the feature xi appearedin training set. Numeric features are normalized according to min-max normalization. Bitarrays are split up into single boolean features.Step 4: Feature selection. Feature selection algorithm is used to determine therelevant features and produced the final version of the feature set.Step 5: Learning the distance metric. The distance metric learning method isapplied to training feature vectors to produce appropriate distance metric parameters. Inthe case of high computational complexity, only a subset of training vectors can be usedto learn distance metric.Steps 6: Classification. Distance metric learned in the previous step is used in theKNN classifier to classify samples from the testing set.Steps 7: Evaluation: Performance metrics are used to measure classification 

Results.Computing the conditional probabilities for nominal features and performing featureselection algorithm for all three types of features are done only to the training samples. The293. 

Overview of Our ApproachmetriclearningClassification EvaluationweightsFeatureselectionParsingbinarynumericSplitting datasetConditionalprobabilitiesnominalDistancefilesParsingbinaryfilesTrainingPE filesPE filesfeaturevectorsTrainingfeaturevectorsTestingTestingFigure 3.3: Architecture of our proposed malware detection model using distance metriclearning.corresponding conditional probabilities and selected features are applied to design trainingand testing feature vectors.3.5.1 Minimizing of False Positive RateTo deal with task (2), we proposed two different approaches. The first approach is basedon the PSO algorithm with the optimization criterion called WERR based on a weightederror rate to penalize false positives. The second approach is based on the modification ofLMNN.3.5.1.1 WERRIn this 



Section, we propose optimization criteria for detecting as much malware as possiblewhile keeping a low false positive rate. To consider different costs of a false positive andfalse negative, we adjust the loss function that penalized false positives.Since our dataset is well-balanced, we consider the error rate as the appropriate meas-ure of performance. The error rate is defined as the percentage of incorrectly classifiedinstances. We can rewrite the error rate in terms of the number of false positives (FP) andnumber of false negatives (FN) asERR =FP + FN|Ttest|, (3.18)where |Ttest| is the number of testing samples. We modify Eq. (3.18) by adding theparameter c > 1, which corresponds to the cost for false positive. Then we define theoptimization criterion called weighted error rate (WERR), which takes into account thecost of false positive:WERR =c FP + FN|T |+ (c− 1)FP (3.19)303.5. Malware Detection using DMLOne interpretation of WERR is that if we would change parameters of the classifier andachieve the same error rate (with possibly different FPnew and FNnew than the previousvalues FPold and FNold corresponding to original parameters), then these 

Results will bebetter with respect to WERR ifc FPnew − FPold < FNold − FNnew (3.20)One point of view on the WERR criterion is that we agree to ”exchange” one falsepositive for c false negatives while keeping the error rate unchanged. Note that when c = 1,then WERR is equal to the error rate. In all experiments, we used the WERR criterion asa fitness function of the PSO algorithm described in Algorithm 3.3. Experimental 

Resultsare presented in the paper included in 



Section 4.5.3.5.1.2 Modification of LMNNThis 



Section first briefly presents LMNN and then introduces our modification of LMNNsuitable for the task (2).Large Margin Nearest Neighbor (LMNN) [69] is one of the state-of-the-art distancemetric learning algorithms used to learn a Mahalanobis distance metric for KNN classific-ation. LMNN consists of two steps. In the first step, for each instance, x, a set of k nearestinstances belonging to the same class as x (referred as target neighbors) is identified. In thesecond step, we adapt the Mahalanobis distance to reach the goal that the target neigh-bors are closer to x than instances from different classes separated by a large margin. TheMahalanobis distance metric is estimated by solving semidefinite programming problemdefined as:minL∑i,j:j i(dL(xi,xj)2 ++ µ∑k:yi 6=yk[1 + dL(xi,xj)2 − dL(xi,xk)2]+)(3.21)The notation j  i reffers that the sample xj is a target neighbor of the sample xi, andyi de

Notes the class of xi. The parameter µ defines a trade-off between the two objectives:1. to minimize distances between samples xi and their target neghbors xj,2. to maximize distances between samples xi and their impostors xk which are sampleswhich belong among the nearest neighbors of xi and have different class labels (i.e.yi 6= yk ).Finally, [x]+ is defined as the hinge-loss, i.e. [x]+ = max{0, x}.Regarding minimizing FPR using LMNN, we modified Eq. (3.21) by adding the para-meter ηk which corresponds to the cost of false positive. This modification aims to minimizethe number of impostors belonging to the class of benign files. Let T be a training set313. 

Overview of Our Approachand let Ni de

Notes the set of k target neighbors of xi. Then the modification of LMNNconcerning minimizing false positives is as follows:minL∑xi∈T∑xj∈Ni(dL(xi,xj)2 ++ µ∑xk∈T :yi 6=ykηk[1 + dL(xi,xj)2 − dL(xi,xk)2]+)(3.22)where ηk de

Notes cost of false positive and it is define as follows:ηk ={1 if yk is class of benign files,c ≥ 1 if yk is class of malware.Similar to the WERR optimization criterion, the purpose of the parameter c in thedefinition of ηk is to set the amount of penalization for one false positive. The differencebetween the modification of LMNN and the WERR criterion is that the modification ofLMNN takes into account the distance between a sample and its impostor.The paper included in 



Section 4.5 contains more details on the approach and presentsexperimental resuts.32



Chapter 4Author’s Relevant PapersThis 



Section includes a collection of five papers that present the main 

Results of this thesis.A brief description is provided for each paper.The following papers are presented:Paper 1 [A.1] Malware Detection Using a Heterogeneous Distance Function.. This paperpresents the distance function that can handle various types of PE features. Thedistance function is used in the proposed malware detection system based on thecombination of the k-Nearest Neighbors classifier and the statistical-based classifier.Paper 2 [A.2] Distance Metric Learning using Particle Swarm Optimization to ImproveStatic Malware Detection. The distance from the Paper 1 is modified by consideringthe feature weights. The PSO algorithm is applied to the problem of finding themost appropriate feature weights.Paper 3 [A.3] Representation of PE Files using LSTM Networks. Various LSTM net-work architectures were used to transform the PE features, and state-of-the-art MLalgorithms were applied to the transformed features to improve classification 

Results.Paper 4 [A.4] Improving Classification of Malware Families using Learning a DistanceMetric. This paper describes the application of three DML algorithms to learn theMahalanobis distance metric to improve multiclass classification performance for thedataset containing six prevalent malware families and benign files.Paper 5 [A.5] Application of Distance Metric Learning to Automated Malware Detection.This paper extends Paper 2 and partially Paper 4 and presents the architecture ofthe malware detection model based on distance metric learning. Besides minimizingthe error rate, the paper also focuses on the task that considers the cost of falsepositives.334. Author’s Relevant PapersFig. 4.1 illustrates the relationships among all five author’s relevant papers.Paper 1Paper 2Paper 3Paper 4Paper 5The modified Particle Swarm Optimiza-tion algorithm proposed in Paper 2 wasused in Paper 5 to learn weighted Eu-clidean distance. Paper 5 used the modified Particle SwarmOptimization algorithm proposed in Paper2 and the distance metric learning methodsapplied in Paper 4 to classify malware fam-ilies. Paper 5 concerned binary classifica-tion, and the paper extended the experimentsconducted in Paper 4 with additional exper-iments focused on minimizing false positiverate.In Paper 2, we used the modified ParticleSwarm Optimization algorithm to learn theheterogeneous distance function, specially de-fined for the PE file format, proposed in Pa-per 1.Using various LSTM network architectures,we transformed the PE features and trainedother ML algorithms on the transformeddataset.Figure 4.1: Relationships among author’s relevant papers.344.1. Paper 1 - Malware Detection Using a Heterogeneous Distance Function4.1 Paper 1 - Malware Detection Using a HeterogeneousDistance FunctionMgr. Martin Jureček (60%), prof. Ing. Róbert Lórencz, CSc. (40%)In: Computing and Informatics. Volume 37, No. 3, pp. 759-780, 2018.The most commonly used metric is the Euclidean distance which works well for nu-merical attributes. However, it does not appropriately handle nominal attributes, whichare included in PE file format. This paper describes the distance function that can handlevarious types of PE features, such as nominal and numeric features and boolean array.The paper also presents a malware detection approach based on a combination of thewell-known KNN classifier and the statistical classifier. The statistical classifier uses in-formation from the training dataset in a different way than the KNN classifier. It checkswhether a feature vector contains values typical for malware, in contrast to KNN thatconsiders only differences between feature vectors.The paper also deals with clustering malware into families. Partitioning Around Medoidsalgorithms using the heterogeneous distance function was applied for five prevalent malwarefamilies.35Computing and Informatics, Vol. 37, 2018, 759–780, doi: 10.4149/cai 2018 3 759MALWARE DETECTION USING A HETEROGENEOUSDISTANCE FUNCTIONMartin Jureček, Róbert LórenczFaculty of Information TechnologyCzech Technical University in PragueThákurova 9, 160 00 Prague, Czech Republice-mail: {martin.jurecek, lorencz}@fit.cvut.cz



Abstract. Classification of automatically generated malware is an active researcharea. The amount of new malware is growing exponentially and since manual in-vestigation is not possible, automated malware classification is necessary. In thispaper, we present a static malware detection system for the detection of unknownmalicious programs which is based on combination of the weighted k-nearest neigh-bors classifier and the statistical scoring technique from [12]. We have extracted themost relevant features from portable executable (PE) file format using gain ratioand have designed a heterogeneous distance function that can handle both linearand nominal features. Our proposed detection method was evaluated on a datasetwith tens of thousands of malicious and benign samples and the experimental re-sults show that the accuracy of our classifier is 98.80 %. In addition, preliminary

Results indicate that the proposed similarity metric on our feature space could beused for clustering malware into families.



Keywords: Malware detection system, feature selection, similarity measure,k-nearest neighbors classifier, partitioning around medoids1 



IntroductionThe problem of automated malware detection presents challenges for antivirus ven-dors (AV). Most AV rely primarily on a signature detection technique which isrelatively simple and efficient rule-based method for detecting known malware [10].Signature (unique hex code strings) of the malware is extracted and added to thedatabase. The antivirus engine compares the contents of a file with all malware4. Author’s Relevant Papers36760 M. Jureček, R. Lórenczsignatures in its database and if a match is found, the file is reported as malware.A good signature must capture malware with a minimal false positive probability.The major weakness of signature detection is its inability to detect obfuscatedand zero-day malware. A number of non-signature based malware detection tech-niques have been proposed [19, 11, 20]. These techniques are used in an effort todetect new or unknown malware and can be grouped into two main approaches:static and dynamic heuristic methods. Static methods can be based on an analysisof the file format without actually running the program. Dynamic analysis aimsto examine a program which is executed in a real or virtual environment. Non-signature based malware detection techniques suffer from two main problems: highfalse positive rate and large processing overhead.In this paper, we present a static malware detection system based on com-bination of the statistical classifier and the k-nearest neighbors (KNN) classifier.Experimental 

Results indicate that the combination of the classifiers may providea potential benefit for detecting samples not detected by KNN.In our work we propose the following four main contributions:• We present a feature space extracted from PE file format by using feature se-lection method based on information gain.• We design a new distance function that can handle both nominal and linearattributes.• We present a malware detection system for detecting previously unknown ma-licious PE files. In order to achieve a higher detection rate, the system usesa combination of two different kinds of classifiers.• We evaluate the effectiveness of our detection system and distance function ona real-world malware collection.The rest of the paper is organized in the following way. 



Section 2 provides an

Overview of previous work on malware classification. In 



Section 3 we present thefeature space and the distance function used in KNN classifier. 



Section 4 discussesour proposed detection technique, while 



Section 5 covers our experimental 

Results.Finally, 



Conclusions are given in 



Section 6.2 RELATED WORKIn this 



Section, we survey some relevant previous work in the area of classificationschemes for malware detection. To maintain the focus, we mainly discuss the workusing static detection based on machine learning techniques. Then we briefly dis-cuss various existing statistical-based scores and also several methods that rely ondynamic analysis.Schultz et al. [19] introduced the concept of data mining for detecting pre-viously unknown malware. In their research they presented three different staticfeature sources for malware classification: information from the portable executable4.1. Paper 1 - Malware Detection Using a Heterogeneous Distance Function37Malware Detection Using a Heterogeneous Distance Function 761(PE) header and strings and byte sequences extracted from binaries. These featureswere used in three different kinds of algorithms: an inductive rule-based learner,a probabilistic method, and a multi-classifier system. A rule induction algorithmcalled Ripper [4] was applied to find patterns in the dynamic-link library (DLL)data (such as the list of DLLs used by the binary, the list of DLL function calls,and the number of different system calls used within each DLL). The well-knownprobabilistic method, learning algorithm Naive Bayes, was used to find patterns inthe string data and n-grams of byte sequences. Multinomial Naive Bayes algorithmthat combined the output of several classifiers reached the highest detection rateof 97.76 %. The authors tested the data mining methods against standard signa-tures and their 

Results indicate that the data mining detection rate of a previouslyunknown malware was twice as high in comparison to the signature-based meth-ods.Kolter and Maloof [11] improved the Schulz’s third technique by using overlap-ping byte sequences instead of non-overlapping sequences. They used different kindsof classifiers: naive Bayes, instance-based learner, similarity-based classifier calledTFIDF, Support Vector Machine (SVM), Decision Trees (DT) and boosted variantsof SVM, DT and TFIDF. Authors evaluated their classifiers performance by com-puting the area under a receiver operating characteristic curve. Boosted Decisiontree model (J48) achieved the best accuracy, an area under the ROC curve of 0.996and outperformed the rest of the classifiers.In other studies, operational code (opcode) has been used as static informa-tion for malware detection. Common techniques are based on the frequency ofappearance of opcode-sequences [18], examination of opcode frequency distributiondifference between malicious and benign code [2], or identification of critical instruc-tion sequences [22]. Other techniques use similarity of executables based on opcodegraphs [17]. However, some executable files cannot be disassembled properly, there-fore the opcode approach is not always feasible [2].The more recent work [23] contains three statistical-based scoring techniques,namely Hidden Markov models, Simple substitution distance, and Opcode graph-based detection. Authors showed that a combination of these scoring techniqueswith a Support Vector Machine yields significantly more robust 

Results than thoseobtained using any of the individual scores.We also briefly mention a few existing detection methods that rely on dynamicanalysis. Examples of the information we can obtain from dynamic analysis includeapplication programming interface (API) and system calls, instruction traces, me-mory writes, registry changes, and so on. In [24], an artificial neural network wasemployed to detect previously unknown worms based on the computer’s behavioralmeasures. Eskandari et al. [25] extracted a set of program API calls and combinedthem with control flow graph. Qiao et al. [26] proposed a new malware analysismethod based on frequency analysis of API call sequences. Note that dynamicanalysis is time-consuming as each malware sample must be executed for a certaintime period.4. Author’s Relevant Papers38762 M. Jureček, R. Lórencz3 FEATURE SPACE AND METRICWe design our proposed detection system for the portable executable (PE) file for-mat [5], which is the most widely used file format for malware samples. In orderto classify an executable file in the PE format, we extract static format informationand translate it into a feature vector suitable for classification.3.1 Feature SpaceBefore presenting attributes used in our feature vector, let us firstly look at thegeneral outline of the PE file format. A simplified 

Overview of the PE file format isillustrated in Figure 1.DOS headerCOFF headerOptional header



Section headersHeadersCodeImportsData 



SectionsPE fileFigure 1. PE file structureA PE file consists of headers and 



Sections that encapsulate the information nece-ssary to manage the executable code. The PE file header provides all the descriptiveinformation concerning the locations and sizes of structures in the PE file to theloader process. The header of a PE file consists of the DOS header, the PE signature,the COFF file header, the optional header, and the 



Section headers. The optionalfile header is followed immediately by the 



Section headers which provide informationabout 



Sections, including locations, sizes, and characteristics. 



Sections divide thefile content into code, resources, and various types of data.Based on our empirical studies and analysis of the PE format, we selected a setof static features that are helpful in distinguishing malware and benign files andused gain ratio for selection the most relevant features.3.1.1 Features SelectionIn order to determine which attribute in a given training set is the most usefulfor discriminating between the classes, we use entropy-based measure, informationgain (IG) [13]. The information gain is the expected reduction in entropy causedby knowing the value of attribute a. IG(T , a) of an attribute a relative to training4.1. Paper 1 - Malware Detection Using a Heterogeneous Distance Function39Malware Detection Using a Heterogeneous Distance Function 763dataset T and is defined asIG(T , a) = Entropy(T )−∑v∈V (a)|Tv||T |Entropy(Tv) (1)where V (a) de

Notes the set of all possible values for attribute a, and Tv de

Notes thesubset of T for which attribute a has value v. Note that the entropy of the trainingdataset T is given by:Entropy(T ) = −∑c∈Cpc log2 pc (2)where pc is the proportion of T belonging to class c.The information gain measure is biased towards attributes with many values.One way of avoiding this difficulty is to use a modification of the measure calledthe gain ratio (GR) [15]. The gain ratio measure penalizes attributes with largenumbers of possible values by incorporating a term called split information (SI):SI(T , a) = −d∑i=1|Ti||T | log2|Ti||T | (3)where Ti are the d subsets of training dataset T resulting from partitioning T bythe d-valued attribute a. Split information SI(T , a) is the entropy of T with respectto the values of attribute a. The gain ratio is then defined asGR(T , a) = IG(T , a)SI(T , a) (4)and we select only features with the highest values of gain ratio.3.1.2 Our Proposed Feature SpaceThe following feature set was extracted using gain ratio and used in our work:• Many fields from the PE headers, such as the number of 



Sections, date/timestamp, major or minor versions of linker, operating system, image, subsystem;sizes and addresses of data directories; DLL characteristics, etc. Table 1 lists allfeatures that are derived from the PE headers. For detailed description of thesefeatures, see 



Chapter 3 in [5].• Features from 



Sections and their headers: VirtualSize, VirtualAddress, Size-OfRawData, PointerToRawData, 



Section Flags (see 



Chapter 4 in [5]), and fea-tures not contained within the PE structure, including entropies and checksumsof 



Sections.• Resources of the PE file are used to provide supporting content, such as icons,fonts, strings and other elements. In case of malicious files, resources are often4. Author’s Relevant Papers40764 M. Jureček, R. Lórenczused to store code and configuration data. For example, the number of resourcesand the number of types of resources were used in our work.• Overlay is a data that is appended at the end of the executable file. We consid-ered the size of the overlay.• Other features: the size of all imports, the number of DLLs referred, the numberof APIs referred.Feature FeatureNumberOf



Sections MajorOperatingSystemVersionTimeDateStamp MajorImageVersionSizeOfOptionalHeader MajorSubsystemVersionCharacteristics MinorSubsystemVersionMajorLinkerVersion SizeOfImageMinorLinkerVersion CheckSumAddressOfEntryPoint SubsystemImageBase DllCharacteristics



SectionAlignment NumberOfRvaAndSizesFileAlignment Addresses and sizes of data directoriesTable 1. List of features from the PE headersNote that our feature set is similar to that in the existing works [12, 21, 1].3.2 Distance FunctionMany classifiers require some measure of dissimilarity or distance between featurevectors, and its performance depends upon a good choice of distance function.Especially the KNN classifier depends significantly on the metric used to computedistances between two feature vectors.In this 



Section, we propose a similarity metric on our feature space. We used thismetric to compute distances to find k nearest neighbors used in KNN classifier. Notethat the features used in our work are of various types and sizes. These features canbe divided into three types: numbers, bit fields, and strings. For example, numberof 



Sections or various addresses can be represented by numbers, 



Section flags orcharacteristics by bit fields, and checksums by strings. Furthermore, some featureshave different ranges. For example, the number of 



Sections is considerably smallerthan the total number of called API functions. The proposed distance function canhandle these types of features and also takes into account their different ranges.The most commonly used metric is the Euclidean distance which works well fornumerical attributes. However, it does not appropriately handle nominal attributes.The Value Difference Metric (VDM) [27] was proposed to define a suitable distancefunction for nominal attributes. A version of the VDM without a weighting scheme4.1. Paper 1 - Malware Detection Using a Heterogeneous Distance Function41Malware Detection Using a Heterogeneous Distance Function 765is defined for values x and y of an attribute a as:VDMa(x, y) =C∑c=1∣∣∣∣na,x,cna,x− na,y,cna,y∣∣∣∣q(5)where• C is the number of classes,• na,x,c is the number of instances in the training set T which have value x forattribute a and the instance belongs to class c,• na,x is the number of instances in T that have value x for attribute a.Since the Euclidean distance is not suitable for nominal attributes, and VDMis inappropriate for numeric attributes, heterogeneous metric can be used to handleour feature space. Wilson and Martinez introduced Heterogeneous Value DifferenceMetric (HVDM) [29] which is defined for feature vectors x and y as:HVDM(x,y) =√√√√m∑a=1d2a(xa, ya) (6)where m is the number of attributes of the feature vector and the definition ofdistance function da(x, y) depends on the type of attribute a as follows:da(x, y) =1, if x or y is unknown,NORM VDMa(x, y), if a is nominal,NORM DIFFa(x, y), if a is linear.(7)Functions NORM VDMa(x, y) and NORM DIFFa(x, y) are defined as:NORM VDMa(x, y) =C∑c=1∣∣∣∣na,x,cna,x− na,y,cna,y∣∣∣∣, (8)NORM DIFFa(x, y) =|x− y|4σa(9)where σa is the standard deviation of the values of numeric attribute a.3.2.1 Our Proposed Distance FunctionSince the feature vector described in 



Section 3.1.2 contains more types of nominalattributes we propose the following distance function:D(x,y) =√√√√m∑a=1d2a(xa, ya) (10)4. Author’s Relevant Papers42766 M. Jureček, R. Lórenczwhereda(x, y) =H(x, y), if a is an array of bits,δ(x, y), if a is a checksum,NORM DIFFa(x, y), if a is numeric,NORM VDMa(x, y), otherwise (a is a string).(11)H(x, y) de

Notes Hamming distance defined for binary x = (x1, . . . , xn), y = (y1, . . . ,yn) asH(x, y) = |{i | xi 6= yi, i = 1, . . . , n}| (12)and δ(x, y) is the characteristic function defined asδ(x, y) ={0, if x = y,1, otherwise.(13)Since the distance functions da are metrics, D is also a metric. Properties ofa metric, especially the triangle inequality, can be used in effective finding of nearestneighbors in a metric space.Note that we distinguish between a checksum and a string attribute that is nota checksum. For the demonstration of distance function D on our feature space, wepresent the examples of attributes of each type:• array of bits: 



Section flags, Characteristics, DllCharacteristics,• numeric attribute: number of 



Sections, number of DLLs, size of all imports,• checksum: checksums of various pieces of the file content,• string: major/minor version of linker, operating system, subsystem.4 PROPOSED SYSTEM FOR DETECTING MALWAREIn this 



Section, we present a system for detecting malware which is composed ofa KNN classifier and a statistical scoring technique.4.1 The k-Nearest Neighbors ClassifierThe k-nearest neighbors (KNN) classifier is one of the most popular supervisedlearning methods introduced by Fix and Hodges [8]. It is one of the simplest andbest-known nonparametric algorithms in pattern classification.Let T = {(x1, c1), . . . , (xm, cm)} be the training set, where xi is training vectorand ci is the corresponding class label. Given a query point xq, its unknown class cqis determined as follows. First, select the set T ′ = {(x1, c1), . . . , (xk, ck)} of k nearest4.1. Paper 1 - Malware Detection Using a Heterogeneous Distance Function43Malware Detection Using a Heterogeneous Distance Function 767neighbors to the query point xq. Then assign the class label to the query point xqby majority vote of its nearest neighbors:cq = arg maxc∑(xi,ci)∈T ′δ(c, ci) (14)where c is a class label, ci is the class label for ith neighbor among k nearest neighborsof the query point, and δ(c, ci) takes a value of one if c = ci and zero otherwise.Cover and Hart [6] found that if the number of samples approaches infinity, thenearest-neighbor error rate is bounded from above by twice the Bayes error rate.Distance-weighted k-nearest neighbor procedure (WKNN) was first introducedin [7] as an improvement to KNN. This extension is based on the idea that closerneighbors are weighted more heavily than such neighbors that are far away fromthe query point. KNN implicitly assumes that all k nearest neighbors are equallyimportant in making a classification decision, regardless of their distances to thequery point. In WKNN, nearest neighbors are weighted according to their distancesto the query point as follows. Let x1, . . . , xk be k nearest neighbors of the queryobject and d1, . . . , dk the corresponding distances arranged in increasing order. Theweight wi for i-th nearest neighbor is defined as:wi ={dk−didk−d1 , if dk 6= d1,1, otherwise.(15)The resulting class of the query point is then defined by the majority weightedvote as follows:cq = arg maxc∑(xi,ci)∈T ′wi · δ(c, ci). (16)Note that finding the nearest neighbors is a very expensive operation due to theenormous size of our dataset. The nearest neighbors can be found more efficientlyby representing the training dataset as a tree.4.2 The Statistical-Based ClassifiersIn this 



Section, we present the scoring techniques that we used in our research. Inthe case of the statistical-based classifier, we ignore the positions of points in ourmetric space and we focus on statistical properties of attribute values, in contrastto the KNN classifier.4.2.1 Naive BayesThis 



Section introduces the Naive Bayes classifier [28] for binary (two-class) clas-sification problems. A Naive Bayes classifier is a probabilistic algorithm based onBayes’ Theorem that predicts the class with the highest a posteriori probability.Assume a set of two classes {C,M}, where C de

Notes the class of benign samples4. Author’s Relevant Papers44768 M. Jureček, R. Lórenczand M de

Notes the class of malware. Training datasets are provided and a new(unknown) sample, which is represented by a feature vector x = (x1, . . . , xn), ispresented. Let P (M|x) denote the probability that a sample is malicious given thefeature vector x that describes the sample. Similarly, P (C|x) de

Notes the probabilitythat a sample is benign given the feature vector x that represents the sample. TheNaive Bayes classification rule is stated asIf P (M|x) < P (C|x), x is classified as benign sample,If P (M|x) > P (C|x), x is classified as malware. (17)The a posteriori probabilities P (C|x) may be expressed in terms of the a prioriprobabilities and the P (x|C) probabilities using Bayes’ theorem asP (C|x) = P (x|C) P (C)P (x). (18)Assuming that the values of the attributes (features) are conditionally independenton one another, Equation (18) may be expressed asP (C|x) =∏ni=1 P (xi|C) P (C)P (x). (19)Probabilities P (xi|C) can be estimated from the training set by counting theattribute values for each class. More precisely, the probability P (xi = h|C) isrepresented as the number of samples of class C in the training set having thevalue h for attribute xi, divided by the number of samples of class C in the trainingset. The output of the classifier is the highest probability class C ′:C ′ = arg maxC(P (C)n∏i=1P (xi|C)). (20)4.2.2 Statistical Classifier – STATSThe following statistical classifier was introduced in [12]. Let x = (x1, . . . , xn) bea vector from our feature space and M a class of malware. Then probabilityP (x ∈M|xi = h) =nxi,h,Mnxi,h(21)is the conditional probability that the output class of x is malware given that at-tribute xi has the value h. Denote this probability by pi, i = 1, . . . , n. Note thatthe notations nxi,h,M and nxi,h were used in the definition of VDM discussed in



Section 3.2. Define a function f with two parameters pi and Sc asf(pi, Sc) = max{0, pi − Sc} (22)4.1. Paper 1 - Malware Detection Using a Heterogeneous Distance Function45Malware Detection Using a Heterogeneous Distance Function 769where Sc is an empirical constant. For each file x we define a score asscore =n∑i=1f(pi, Sc). (23)From this score, we can determine a threshold Ss, above which we will classifya file as malware. The decision rule is then defined as follows:x is classified as{malware, if score > Ss,benign file, otherwise.(24)The pseudocode of the statistical-based classifier is described in Algorithm 1.Algorithm 1 Statistical classifier – STATSInput: original training set, query point x, distance metric DOutput: label of x1: score = 02: Compute probability vector (p1, . . . , pn)3: for i = 1 to n do4: if pi > Sc then5: score += pi − Sc6: end if7: end for8: if score > Ss then9: return malware10: else11: return benign file12: end ifIn the rest of this paper, the statistical-based classifier is denoted as STATS.4.3 Our ApproachWe propose a malware detection approach based on a combination of the well-knownKNN classifier and the chosen statistical motivated classifier. In order to achievehigher detection rates, there should be some kind of diversity between the classifiers.KNN is a geometric-based classifier which uses labels of the nearest neighbors insome metric space to classify an unlabeled point. On the other hand, statistical-based approaches like Naive Bayes or the STATS classifier mentioned above useconditional probabilities of attributes of sample point and do not use informationabout its position in feature space.The proposed detection method works as follows. First, set the threshold tosome sufficiently high value. Then compute score using the chosen statistical scoringtechnique. If the score of the unknown file exceeds the threshold, then the resulting4. Author’s Relevant Papers46770 M. Jureček, R. Lórenczclass will be malware, otherwise apply distance-weighted KNN. The pseudocode forthe classification scheme is shown in Algorithm 2.Algorithm 2 Our detection systemInput: original training set, query point x, distance metric DOutput: label of x1: compute score from the statistical scoring technique2: if score > threshold then3: return malware4: else5: apply WKNN6: end ifThe reason why we chose KNN is that it is a relatively accurate classifier for largedatasets and the 

Results of our experiments demonstrate that the statistical classifieris able to correctly classify samples lying in the area of feature space where theaccuracy of KNN is low. The statistical classifier uses information from the trainingdataset in a different way than the KNN classifier. It checks whether a featurevector contains values typical for malware, in contrast to KNN that considers onlydifferences between feature vectors.For example, consider a feature vector x = (x1, . . . , xn) containing only a fewvalues (typically checksums), for which there is a high probability that x belongsto malware. Many other attributes could have previously unseen values or oneswith a low prevalence. Therefore, malicious nearest neighbors could not be closerthan benign nearest neighbors and in this case, KNN classifier would not be anappropriate method.4.3.1 The System ArchitectureThe system consists of three major components: a PE parser, a database of condi-tional probabilities and a classification module, as illustrated in Figure 2.The functionality of the PE parser is to extract all PE format file’s headerinformation, DLLs, and API functions from programs in the dataset and store allthe extracted information in a database. Recall that our system is applied onlyto Windows PE files and the PE parser extracts only the most useful features fordiscriminating between benign and malicious files. These features were determinedby the feature selection algorithm mentioned in 



Section 3.During the training phase, once the structural information of the PE files isextracted, the conditional probabilities P (x is malware|xi = h) are computed foreach PE attribute xi and for each possible value h of attribute xi. Note that onlythe PE features extracted from labeled samples of the training dataset are used inthe computation of the conditional probabilities.After extracting PE features and computing the conditional probabilities, fea-ture vectors are created for every known PE file. The set of these feature vectors4.1. Paper 1 - Malware Detection Using a Heterogeneous Distance Function47Malware Detection Using a Heterogeneous Distance Function 771Dataset ofknown PEfeaturesPEfeaturesConditionalprobabilitiesFeaturevectorsFeaturevectorsClassificationTraining phase:Testing phase:modulePE filesUnknownPE filesFigure 2. Architecture of the classification modelcalled training set will be used in the classification module where the classificationalgorithm is applied to feature vectors of unknown PE files.5 EVALUATION 

Results AND ANALYSISIn this 



Section, we introduce the performance metrics and present the 

Results ofour experiments. We compare our approach with several other machine learningmethods for malware detection.5.1 Performance MetricsWe present the evaluation metric we used to measure the accuracy of our proposedapproach for the detection of unknown malicious codes. For evaluation purposes,the following classical quantities are employed:• True Positive (TP) represents the number of malicious samples classified asmalware,• True Negative (TN) represents the number of benign samples classified as be-nign,• False Positive (FP) represents the number of benign samples classified as mal-ware,• False Negative (FN) represents the number of malicious samples classified asbenign.The performance of our classifier on the test set is measured using three standardparameters. The most intuitive and commonly used evaluation measure in Machine4. Author’s Relevant Papers48772 M. Jureček, R. LórenczLearning is the Accuracy (ACC):ACC =TP + TNTP + TN + FP + FN. (25)It is defined on a given test set as the percentage of correctly classified instances.However, since our dataset is not well-balanced, the accuracy measure could bean inappropriate measure of performance. If we use a classifier which labels everysample as benign, then TN will be very high and TP will be very low. As a result,the accuracy obtained on our dataset will be very high.The second parameter, True Positive Rate (TPR) (or detection rate), is definedas:TPR =TPTP + FN. (26)TPR is the percentage of truly malicious samples that were classified as malware.The third parameter is False Positive Rate (FPR) and is defined as follow:FPR =FPTN + FP. (27)FPR is the percentage of benign samples that were wrongly classified as malware.We also evaluate our classifier using Receiver Operating Characteristic (ROC)analysis [3]. ROC curve is represented as a two-dimensional plot, in which truepositive rate is plotted against false positive rate at various threshold settings. Thearea under the ROC curve (AUC) serves as the performance measure of our detectiontechniques. An AUC of 1.0 represents the ideal case where both false positive andfalse negative equal zero. On the other hand, AUC of 0.5 means that the classifier’sperformance is no better than flipping a coin.5.2 DatasetThe dataset used in this research consists of a total of 101,604 Windows programsin the PE file format, out of which 21,087 are malicious and 80,517 are legitimate orbenign programs. There were no duplicate programs in our dataset. The maliciousand benign programs were obtained from the laboratory of the industrial partner.In order to expose any biases in the data, we used the 5-fold cross-validationprocedure. Generally in k-fold cross-validation [14], the dataset is randomly dividedinto k subsets of equal size, where k-1 subsets are used for training and 1 subsetis used for testing. In each of the k folds a different subset is reserved for testingand the accuracies obtained for each fold are averaged to produce a single crossvalidation estimate.In the cluster analysis we used five prevalent malware families that have appearedduring the year 2016. Specifically, we have used the following malware families:• Allaple – a polymorphic network worm that spreads to other computers andperforms denial-of-service (DoS) attacks.4.1. Paper 1 - Malware Detection Using a Heterogeneous Distance Function49Malware Detection Using a Heterogeneous Distance Function 773• Dinwod – a trojan horse that silently downloads and installs other malware onthe compromised computer.• Virlock – a ransomware that locks victims’ computer and demands a paymentin order to unlock it.• Virut – a virus with backdoor functionality that operates over an IRC-basedcommunications protocol.• Vundo – a trojan horse that displays pop-up advertisements and also injectsJavaScript into HTML pages.5.3 Classification 

ResultsWe implemented the classifiers as described in 



Section 4. The feature space andthe distance function proposed in 



Section 3 were used in the KNN and the WKNNclassifiers. The combination of the WKNN and the statistical scoring techniquefrom [12] is denoted as WKNN STATS and the combination of the WKNN and theNaive Bayes classifier is denoted as WKNN NB. For each experiment, we performed5-fold cross-validation that gives approximately unbiased estimate of a classifier’saccuracy.In our first experiment, we attempt to distinguish between benign and maliciousPE files. We used accuracy, discussed in 



Section 5.1, as a comparison criterion forcomparing classifiers. The accuracies obtained after applying the WKNN and theKNN classifiers for various numbers of nearest neighbors are depicted in Figure 3.■ ■■■ ■ ■ ■ ■■■■ ■▲ ▲▲▲ ▲▲ ▲▲▲▲▲▲■ WKNN▲ KNN0 10 20 30 40 500.9750.9800.985Number of nearest neighborsAccuracyFigure 3. Classification accuracies of the WKNN and the KNN classifiers, for variousnumbers of nearest neighborsThe WKNN classifier achieved the highest accuracy using nine nearest neighbors,while the KNN classifier achieved the highest accuracy using only three nearestneighbors.The classification 

Results of the classifiers implemented in this research are listedin Table 2.4. Author’s Relevant Papers50774 M. Jureček, R. LórenczClassifier TPR FPR AccuracyKNN 96.23 % 1.07 % 98.37 %WKNN 96.82 % 0.99 % 98.56 %NB 82.78 % 1.17 % 95.50 %STATS 90.08 % 0.76 % 97.34 %WKNN NB 97.37 % 1.05 % 98.62 %WKNN STATS 98.08 % 1.01 % 98.80 %Table 2. Classification 

Results of six approaches implemented in this workAmong these classifiers, the WKNN STATS outperformed others with the high-est accuracy of 98.8 %. Note that the WKNN STATS classifier was tested for variousthreshold values, and the best result was achieved with the following parameters:• the number of nearest neighbors k = 9 used in the WKNN classifier,• the thresholds Sc = 0.8 and Ss = 0.53 used in the STATS classifier.In addition to that, we constructed the ROC curves which are shown in Figure 4for three chosen classifiers.àààààààààààààààààààààààòòòòòòòòòòòòòòòòòòòòò òòò òòò òò ò òxxxxxxxxxxxxxxxxxxxxxxxxxxxxx xx xx xx x xà WKNN_Statsò WKNNx Stats0.00 0.02 0.04 0.06 0.08 0.10 0.12 0.140.800.850.900.951.00False positive rateTruepositiverateROC curvesFigure 4. ROC curves for the WKNN, STATS and WKNN STATS classifiersWe can conclude from Figure 4 that a combination of the classifiers outperformsboth individual classifiers.Table 3 reports the AUC for three classifiers discussed in 



Section 4 and tworelated static methods: KM [11] and PE Miner [21]. As the table illustrates,WKNN STATS classifier provides the best AUC value with 0.998. The ROC curveand AUC values confirm that our experiment provides excellent 

Results regardingmalware detection.4.1. Paper 1 - Malware Detection Using a Heterogeneous Distance Function51Malware Detection Using a Heterogeneous Distance Function 775Classifier AUCWKNN 0.993STATS 0.983WKNN STATS 0.998KM 0.996PE Miner 0.992Table 3. Comparison of the AUC value for five static methods5.4 Clustering 

ResultsIn the second experiment we apply cluster analysis to five prevalent malware fami-lies described in 



Section 5.2. First, we present the clustering algorithm used in thisexperiment and then describe the evaluation measures and show the 

Results.5.4.1 Partitioning Around MedoidsPartitioning around medoids (PAM) proposed by Kaufman and Rousseeuw [9] isa well-known technique for performing non-hierarchical clustering. The reason whywe have decided to use the PAM algorithm is that it allows clustering with respectto any distance metric. The pseudocode of the PAM algorithm is described inAlgorithm 3.Algorithm 3 PAM algorithmInput: Number of clusters k, set of data points TOutput: k clusters1: Initialize: randomly select k data points from T to become the medoids2: Assign each data point to its closest medoid3: for all cluster do4: identify the observation that would yield the lowest average distance if it wereto be re-assigned as the medoid5: if the observation is not current medoid then6: make this observation the new medoid7: end if8: end for9: if at least one medoid has changed then10: go to step 211: else12: end the algorithm.13: end if4. Author’s Relevant Papers52776 M. Jureček, R. Lórencz5.4.2 Evaluation MeasuresWe evaluated the quality of clusters through the measures of purity and silhouettecoefficient (SC). Let nij be the number of samples of class i in cluster Cj and letpij =nij|Cj | . The probability pij is the probability that a randomly selected samplefrom cluster Cj belongs to class i. The purity of cluster Cj is defined as Purity(Cj) =maxi pij.The overall purity value is defined as the weighted sum of individual purities foreach cluster, taking into account the size of each cluster:Purity =1nk∑j=1|Cj|Purity(Cj). (28)To measure the quality of clusters, we compute the average silhouette coeffi-cient [16] for each cluster. Suppose there are n samples x1, . . . , xn that have beendivided into k clusters C1, . . . , Ck. Consider a sample xi ∈ Cj, and define the averagedistance between xi to all other samples in cluster Cj:a(xi) =1|Cj| − 1∑y∈Cjy 6=xid(xi, y). (29)Let bk(xi) be the average distance from sample xi ∈ Cj to all samples in clusterCk not containing xi:bk(xi) =1|Ck|∑y∈Ckd(xi, y). (30)After computing bk(xi) for all clusters Ck, where k 6= j, we select the minimumof those numbers:b(xi) = mink 6=jbk(xi). (31)The silhouette coefficient of xi is obtained by combining a(xi) and b(xi) asfollows:s(xi) =b(xi)− a(xi)max(a(xi), b(xi)). (32)The value of s(xi) in Equation (32) can vary between -1 and 1. It is desirableto have the value s(xi) as close to 1 as possible, since then the clusters are well-separated. The average silhouette coefficient for a given cluster is defined as theaverage value of s(xi) over all samples in the cluster.5.4.3 Experimental 

ResultsWe computed the silhouette coefficient, as discussed above. For computing thesilhouette coefficient, we used our proposed distance function on the feature space4.1. Paper 1 - Malware Detection Using a Heterogeneous Distance Function53Malware Detection Using a Heterogeneous Distance Function 777Majority Class Size Purity SCAllaple 424 0.9343 0.3298Dinwod 285 0.7429 0.7172Virlock 452 0.9771 0.5635Virut 337 0.68 0.2389Vundo 252 0.6886 0.1921Overall 1 750 0.8298 0.3883Table 4. The purity and the silhouette coefficient for clustersdiscussed in 



Section 3. Table 4 summarizes the 

Results of silhouette coefficient basedexperiments using the PAM algorithm.According to the experiences of authors of SC [16], silhouette coefficient valuesbetween 0.7 and 1.0 indicate excellent clustering 

Results. SC values between 0.5 and0.7 indicate a reasonable structure of cluster. SC values below 0.25 indicate that nosubstantial structure has been found.Regarding the clustering malware into families, our 

Results show that the qualityof clusters varies widely, depending on the particular family. From the 

Results inTable 4, we see that the PAM algorithm can correctly classify the malware familywith an accuracy of about 68 % to over 97 %, depending on the particular fam-ily.Note that such accuracies are lower than those obtained with classifiers presentedin 



Section 4. The reason is that distinguishing between malware families is a morechallenging problem than a binary classification of malware and benign files.6 

ConclusionIn this paper, we proposed a new detection system using a combination of thek-nearest neighbors classifier and the statistical-based classifier. The system canautomatically detect unknown malware samples. The feature set used in our workwas a collection of properties extracted from the PE file format. We designed a newdistance function that is capable of handling various types of features.Experimental 

Results indicate that the combination of the classifiers may pro-vide a potential benefit to detect samples not detected by KNN. We compared thedifferent classification methods and concluded that the combination of the weightedk-nearest neighbors classifier and the statistical-based classifier achieves the highestaccuracy, 98.8 %. The 

Results also indicate that the proposed heterogeneous distancefunction and the feature space are appropriate for malware detection and could bealso used for clustering malware into families.The proposed static malware detection system is relatively easy to implement,and can be utilized to support commercial antivirus systems. For 



Future Work, itwould be interesting to experiment with additional statistical scoring techniques inthe context of malware classification.4. Author’s Relevant Papers54778 M. Jureček, R. Lórencz



AcknowledgementsThe authors acknowledge the support of the OP VVV funded project CZ.02.1.01/0.0/0.0/16 019/0000765 “Research Center for Informatics”.



References[1] Asquith, M.: Extremely Scalable Storage and Clustering of Malware Metadata.Journal of Computer Virology and Hacking Techniques, Vol. 12, 2016, No. 2,pp. 49–58, doi: 10.1007/s11416-015-0241-3.[2] Bilar, D.: Opcodes as Predictor for Malware. International Journal of Elec-tronic Security and Digital Forensics, Vol. 1, 2007, No. 2, pp. 156–168, doi:10.1504/IJESDF.2007.016865.[3] Bradley, A. P.: The Use of the Area Under the ROC Curve in the Evaluation of Ma-chine Learning Algorithms. Pattern Recognition, Vol. 30, 1997, No. 7, pp. 1145–1159,doi: 10.1016/S0031-3203(96)00142-2.[4] Cohen, W. W.: Learning Trees and Rules with Set-Valued Features. Proceedings ofthe Thirteenth National Conference on Artificial Intelligence (AAAI/IAAI), Vol. 1,1996, pp. 709–716.[5] Microsoft Corporation: Visual Studio, Microsoft Portable Executable and CommonObject File Format Specification, Revision 9.3, 2015.[6] Cover, T.—Hart, P.: Nearest Neighbor Pattern Classification. IEEE Trans-actions on Information Theory, Vol. 13, 1967, No. 1, pp. 21–27, doi:10.1109/TIT.1967.1053964.[7] Dudani, S. A.: The Distance-Weighted k-Nearest-Neighbor Rule. IEEE Transactionson Systems, Man, and Cybernetics, Vol. SMC-6, 1976, No. 4, pp. 325–327, doi:10.1109/TSMC.1976.5408784.[8] Fix, E.—Hodges Jr., J. L.: Discriminatory Analysis – Nonparametric Discrimina-tion: Consistency Properties. Technical Report, DTIC Document, 1951.[9] Kaufman, L.—Rousseeuw, P. J.: Finding Groups in Data: An 



Introduction toCluster Analysis. John Wiley and Sons, Wiley Series in Probability and Statistics,Vol. 334, 2009.[10] Kephart, J. O.—Arnold, W. C.: Automatic Extraction of Computer Virus Sig-natures. 4th Virus Bulletin International Conference, 1994, pp. 178–194.[11] Kolter, J. Z.—Maloof, M. A.: Learning to Detect and Classify Malicious Ex-ecutables in the Wild. The Journal of Machine Learning Research, Vol. 7, 2006,pp. 2721–2744.[12] Merkel, R.—Hoppe, T.—Kraetzer, C.—Dittmann, J.: Statistical Detec-tion of Malicious PE-Executables for Fast Offline Analysis. In: De Decker, B.,Schaumüller-Bichl, I. (Eds.): Communications and Multimedia Security (CMS 2010).Springer, Berlin, Heidelberg, Lecture 

Notes in Computer Science, Vol. 6109, 2010,pp. 93–105.[13] Mitchell, T. M.: Machine Learning. New York, 1997.4.1. Paper 1 - Malware Detection Using a Heterogeneous Distance Function55Malware Detection Using a Heterogeneous Distance Function 779[14] Picard, R. R.—Cook, R. D.: Cross-Validation of Regression Models. Journal ofthe American Statistical Association, Vol. 79, 1984, No. 387, pp. 575–583, doi:10.1080/01621459.1984.10478083.[15] Quinlan, J. R.: Induction of Decision Trees. Machine Learning, Vol. 1, 1986, No. 1,pp. 81–106, doi: 10.1007/BF00116251.[16] Rousseeuw, P. J.: Silhouettes: A Graphical Aid to the Interpretation and Valida-tion of Cluster Analysis. Journal of Computational and Applied Mathematics, Vol. 20,1987, pp. 53–65, doi: 10.1016/0377-0427(87)90125-7.[17] Runwal, N.—Low, R. M.—Stamp, M.: Opcode Graph Similarity and Metamor-phic Detection. Journal in Computer Virology, Vol. 8, 2012, No. 1–2, pp. 37–52, doi:10.1007/s11416-012-0160-5.[18] Santos, I.—Brezo, F.—Nieves, J.—Penya, Y. K.—Sanz, B.—Laor-den, C.—Bringas, P. G.: Idea: Opcode-Sequence-Based Malware Detection. In:Massacci, F., Wallach, D., Zannone, N. (Eds.): Engineering Secure Software and Sys-tems (ESSoS 2010). Springer, Berlin, Heidelberg, Lecture 

Notes in Computer Science,Vol. 5965, 2010, pp. 35–43.[19] Schultz, M. G.—Eskin, E.—Zadok, F.—Stolfo, S. J.: Data Mining Methodsfor Detection of New Malicious Executables. Proceedings of the 2001 IEEE Sympo-sium on Security and Privacy (S & P 2001), IEEE Computer Society, 2001, pp. 38–49,doi: 10.1109/SECPRI.2001.924286.[20] Shabtai, A.—Moskovitch, R.—Elovici, Y.—Glezer, C.: Detection of Mali-cious Code by Applying Machine Learning Classifiers on Static Features: A State-of-the-Art Survey. Information Security Technical Report, Vol. 14, 2009, No. 1,pp. 16–29, doi: 10.1016/j.istr.2009.03.003.[21] Shafiq, M. Z.—Tabish, S. M.—Mirza, F.—Farooq, M.: PE-Miner: MiningStructural Information to Detect Malicious Executables in Realtime. In: Kirda, E.,Jha, S., Balzarotti, D. (Eds.): Recent Advances in Intrusion Detection (RAID 2009).Springer, Berlin, Heidelberg, Lecture 

Notes in Computer Science, Vol. 5758, 2009,pp. 121–141.[22] Siddiqui, M.—Wang, M. C.—Lee, J.: Data Mining Methods for Malware De-tection Using Instruction Sequences. Proceedings of the 26th IASTED InternationalConference on Artificial Intelligence and Applications (AIA ’08), 2008, pp. 358–363.[23] Singh, T.—Di Troia, F.—Corrado, V. A.—Austin, T. H.—Stamp, M.: Sup-port Vector Machines and Malware Detection. Journal of Computer Virology andHacking Techniques, Vol. 12, 2016, No. 4, pp. 203–212.[24] Stopel, D.—Boger, Z.—Moskovitch, R.—Shahar, Y.—Elovici, Y.: Ap-plication of Artificial Neural Networks Techniques to Computer Worm Detection.Proceedings of the 2006 IEEE International Joint Conference on Neural Networks(IJCNN ’06), 2006, pp. 2362–2369.[25] Eskandari, M.—Hashemi, S.: A Graph Mining Approach for Detecting Un-known Malwares. Journal of Visual Languages and Computing, Vol. 23, 2012, No. 3,pp. 154–162, doi: 10.1016/j.jvlc.2012.02.002.[26] Qiao, Y.—Yang, Y.—Ji, L.—He, J.: Analyzing Malware by 



Abstracting theFrequent Itemsets in API Call Sequences. 2013 12th IEEE International Conference4. Author’s Relevant Papers56780 M. Jureček, R. Lórenczon Trust, Security and Privacy in Computing and Communications (TrustCom), 2013,pp. 265–270.[27] Stanfill, C.—Waltz, D.: Toward Memory-Based Reasoning. Communications ofthe ACM, Vol. 29, 1986, No. 12, pp. 1213–1228, doi: 10.1145/7902.7906.[28] Webb, A. R.—Copsey, K. D.: Statistical Pattern Recognition. Third Edition. Wi-ley, 2011.[29] Wilson, D. R.—Martinez, T. R.: Improved Heterogeneous Distance Functions.Journal of Artificial Intelligence Research, Vol. 6, 1997, No. 1, pp. 1–34.Martin Jurecek graduated from the Charles University inPrague, Faculty of Mathematics and Physics, with the speciali-zation in mathematical methods of information security. He isnow a Ph.D. student at the Faculty of Information Technologyof the Czech Technical University in Prague. His main researchinterests focus on the application of machine learning and artifi-cial intelligence approaches to malware detection. Another areaof his interest is cryptography and information security.Róbert Lorencz graduated from the Faculty of Electrical En-gineering of the Czech Technical University in Prague in 1981.He received his Ph.D. degree in 1990 from the Institute of Mea-surement and Measuring Methods, Slovak Academy of Sciencesin Bratislava. Currently he is Full Professor at the Faculty ofInformation Technology of the Czech Technical University inPrague. His research interests are cryptography and arithmeticunits for cryptography primitives, various cryptoanalysis meth-ods of block and stream ciphers. Another topic of his interest isalternative arithmetic for numerical computation.4.1. Paper 1 - Malware Detection Using a Heterogeneous Distance Function574. Author’s Relevant Papers4.2 Paper 2 - Distance Metric Learning using ParticleSwarm Optimization to Improve Static Malware De-tectionMgr. Martin Jureček (70%), prof. Ing. Róbert Lórencz, CSc. (30%)In Proceedings of 6th International Conference on Information Systems Security and Pri-vacy (ICISSP), pp. 725-732, Malta, Valletta, 2020This paper deals with finding the most appropriate parameters of the heterogenenousdistance metric proposed in Paper 1. This task is formulated as the following optimizationproblem: to minimize the error rate of the KNN classifier using a weighted heterogeneousdistance function. A modification of a biologically-motivated algorithm, Particle SwarmOptimization (PSO), was used to handle this problem. In the proposed modification ofPSO, 

Results from the feature selection algorithm (feature importance scores) are used toinitialize the particles instead of random initialization. The purpose of the initializationis to accelerate PSO, i.e., reducing the searching space is done using the feature selectionalgorithm 

Results.The main purpose of this research is to improve the accuracy of the malware detectionsystem based on the KNN classifier in the case when standard methods such as featureselection or algorithm tuning have already been applied.58Distance Metric Learning using Particle Swarm Optimization to ImproveStatic Malware DetectionMartin Jureček and Róbert LórenczFaculty of Information Technology, Czech Technical University in Prague, Czech Republic{jurecmar, lorencz}@fit.cvut.cz



Keywords: Distance Metric Learning, Malware Detection, Static Analysis, Heterogeneous Distance Function, ParticleSwarm Optimization, k-Nearest Neighbor.



Abstract: Distance metric learning is concerned with finding appropriate parameters of distance function with respectto a particular task. In this work, we present a malware detection system based on static analysis. We use k-nearest neighbors (KNN) classifier with weighted heterogeneous distance function that can handle nominal andnumeric features extracted from portable executable file format. Our proposed approach attempts to specifythe weights of the features using particle swarm optimization algorithm. The experimental 

Results indicate thatKNN with the weighted distance function improves classification accuracy significantly.1 



IntroductionDuring the last years, the current trend is to use mal-ware detection frameworks based on machine lear-ning algorithms. Thanks to cloud-based computingwhich makes the cost of big data computing more af-fordable, the concept of employing machine learningto malware detection has become more realistic to de-ploy. The problem to be solved is to detect malwarewhich has never been seen before. While signature-based detection systems (Kephart and Arnold, 1994)identify known malicious programs, these systemscan be bypassed by unknown malware. However, thesignature-based methods are still popular because oftheir low false positive rate. Instead of using staticsignatures, an effective alternative solution is to usemachine learning methods to detect malware.Malware detection techniques can be typicallyclassified into two categories depending on how codeis analyzed: static and dynamic analysis. Static ana-lysis (Nath and Mehtre, 2014), (Alrabaee et al., 2016)aims at searching information about structure of afile. Disassembly technique is one of the techniquesof static analysis which is used for extracting variousfeatures from the executables. Dynamic analysis (Or-Meir et al., 2019), (Egele et al., 2012) aims to exa-mine a program which is executed in a real or virtualenvironment.Our research is based on static analysis and featurevectors used in the experiments contains data from theportable executable (PE) file format. Several works(Saad et al., 2019), (Damodaran et al., 2017) havedescribed various 

Limitations of static analysis. Themost important drawback is that data captured fromstatic analysis does not describe the complete beha-vior of a program since the program is not executed.However, dynamic analysis is more time-consumingin comparison to static analysis and there are anti-virtual machine technologies that evade detection sys-tems based on dynamic analysis. Consequently, dyna-mic analysis could be impractical for a large volumeof samples that come to antivirus vendors every day.For these reasons, static analysis has still its place inmalware detection systems.Good similarity measure plays an important rolein the performance of geometric-based classifiers,such as k-nearest neighbors (KNN). The similarity be-tween two feature vectors is determined by the dis-tance metric between them. The distance betweentwo feature vectors having the same class label mustbe minimized while the distance between two featurevectors of different classes must be maximized.A distance metric learning algorithm aims at fin-ding the most appropriate parameters of the metricwith respect to some optimization criteria. This task istypically formulated as an optimization problem andin this work, it is related to the malware detectionproblem. This work concerns with learning a distancefunction used in the KNN classifier for the malwaredetection problem. Note that learning the distancemetric is an important preprocessing step which is of-ten ignored in practice.4.2. Paper 2 - Distance Metric Learning using Particle Swarm Optimization to ImproveStatic Malware Detection59The main contribution of this paper is in findingan appropriate weights for the heterogeneous distancefunction used in the KNN classifier, and as a 

Results,improving classification accuracy of malware detec-tion system. Searching for the most suitable weightswith respect to classification accuracy can be consid-ered as an optimization problem. Evolutionary algo-rithms, swarm algorithms and other heuristics (Luke,2013) are suitable for our optimization problem. Inour experiment, a biologically motivated algorithmcalled particle swarm optimization (PSO) was used tosolve this problem. Experimental 

Results indicate thatthe performance of KNN using the weighted distancefunction is considerably better than the performanceof KNN without weights.The rest of the paper is organized as follows. Sec-tion 2 briefly reviews some related work in the field ofmalware detection based on data mining techniques.Some weighted distance functions and distance met-ric learning techniques are also reviewed in this sec-tion. Our proposed malware detection model and the-oretical 

Background are presented in 



Section 3. Ex-perimental setup and 

Results are presented in 



Section4. 

Conclusion and 



Future Work are given in 



Section 5.2 RELATED WORKIn this 



Section, we briefly review some works relatedto malware detection based on machine learning tech-niques. We also review several approaches of how tofind the most suitable feature weights for a distancefunction used in KNN or other techniques workingwith distances.2.1 Malware DetectionOver the past two decades, a large number of mal-ware detection techniques has been proposed. Toevade malware classifiers, malware writers usuallyemploy obfuscation techniques such as encryption,binary packers, or self-modifying code. In recentyears, many malware researchers have focused ondata mining and machine learning algorithms to de-tect unknown malware (Gandotra et al., 2014), (Yeet al., 2017).(Schultz et al., 2000) were the first who introducedthe concept of data mining techniques for detectionof malicious code. The authors used three differentfeatures: information from the PE header, string fea-tures, and byte sequences extracted from binaries.They used three machine learning algorithms: NaiveBayes, Multinomial Naive Bayes, rule induction al-gorithm called Ripper (Cohen, 1996), and comparedthem with the signature-based method. Their 

Resultsindicate that the data mining detection rate of previ-ously unknown malware was twice as high in compa-rison to the signature-based method.(Shafiq et al., 2009) extracted structural informa-tion from the PE file format and selected the mostimportant features with respect to distinguishing be-tween benign files and malware. The authors haveused three feature selection algorithms: RedundantFeature Removal (RFR), Principal Component Ana-lysis (PCA), and Haar Wavelet Transform (HWT)(Witten et al., 2016), and applied five machine lear-ning classifiers: instance based learner (IBk), decisiontree (J48), naive bayes (NB), inductive rule learner(RIPPER), and support vector machine (SVM) usingsequential minimal optimization. The authors con-cluded that J48 outperforms the rest of the classifiersin terms of the detection accuracy.More recently, (Zhong and Gu, 2019) improvedperformance of deep learning models by organi-zing them to the tree structure called Multiple-LevelDeep Learning System (MLDLS). Each deep learningmodel focuses on specific malware family. As a re-sult, the MLDLS can handle complex malware datadistribution. Experimental 

Results indicate that pro-posed method outperforms the SVM, decision tree,the single deep learning method and ensemble basedapproach.2.2 Weighted Distance Functions forKNN ClassifierThe k-nearest neighbors classifier (Cover and Hart,1967) is one of the simplest and best-known nonpara-metric algorithms in machine learning. Several ap-proaches have been proposed to increase the perfor-mance of KNN. The work (Ghosh, 2006) presents thetechnique for estimation of the optimal parameter k.Many studies include research on the similarity mea-sures. The work (Yu et al., 2008) studies distancemeasure based on statistical analysis and presentsboosting heterogeneous measure for similarity esti-mation. Work (Hsu and Chen, 2008) has derived con-ditions for stability of the distance function in high-dimensional space.Several distance functions have been presented(Wilson and Martinez, 1997). To improve 

Results,many weighting schemes were proposed. Reviewof feature weighting methods for lazy learning algo-rithms was proposed in (Wettschereck et al., 1997).4. Author’s Relevant Papers602.3 Distance Metric LearningDistance metric learning is an active research area(Yang and Jin, 2006), (Kulis et al., 2013). Dis-tance metric learning is defined as follows. LetT = {(x1,c1), . . . ,(xm,cm)} be the training set of mfeature vectors xi in d-dimensional metric space S ,and ci be class labels. The goal is to learn a line-ar transformation L : S → S , where squared distancebetween two feature vectors xi and x j is defined asd(xi,x j) = ‖L(xi−x j)‖2. Note that d is a valid metricif and only if the matrix L is full rank. We reformulatethe definition of the squared distance as D(xi,x j) =(xi− x j)T M(xi− x j), where M = LT L. Matrix M isguaranteed to be positive semidefinite and the dis-tance D is called Mahalanobis metric. Note that whenM is equal to the identity matrix, then the distance Dis reduced to Euclidean distance metric. The goal is tofind a matrix M which is estimated from the data, thatleads to the highest classification accuracy of KNNclassifier.Large Margin Nearest Neighbor (LMNN) (Wein-berger et al., 2006) classification is used to learn aMahanalobis distance metric for KNN classification.LMNN consists of two steps. In the first step, set of ksimilarly labeled neighbors is identified for each fea-ture vector. In the second step, the Mahalanobis dis-tance metric is learned using convex optimization.Similar to our approach, (Xu et al., 2017) searchedfor suitable weight vector using PSO. However, thereare several differencies: we used a heterogeneous dis-tance function that can handle both nominal and nu-meric features, we used different classifier for evalu-ation, we applied different modification of the PSOalgorithm, and our goal is to improve malware detec-tion for a different operating system. (Kong and Yan,2013) proposed a malware detection method based onstructural information. Discriminant distance metricis learned to cluster the malware samples belongingto same malware family.3 THE PROPOSED MALWAREDETECTION MODELIn this 



Section, we present our proposed malware de-tection system and describe all its components. Ar-chitecture of the detection system is illustrated inFig. 1.The detection system consists of the metric lear-ning phase and the classification phase. First, rele-vant features are extracted from the binaries. Thenwe split the dataset into two disjoint subset: Tpso forthe metric learning phase, and Teval for the classifi-cation phase. In the metric learning phase, featureweights are learned from the data. The feature selec-tion method described in 



Section 3.3 is performed, asa 

Results, dimension of the feature vectors is reduced.Then the data is split into training (80%) and testing(20%) subsets and they are used for computation ofthe fitness function used in the PSO algorithm.In the classification phase, we evaluate the bestweight vector from the metric learning phase usingthe KNN classifier. First, we also reduce the dimen-sion of the feature vectors with respect to the featureselection 

Results from the metric learning phase. Thenwe apply KNN with fivefold cross validation (Picardand Cook, 1984) to obtain reliable experimental re-sults. Teval is randomly divided into five subsets ofequal size, where four subsets are used for trainingand one subset for testing. The experiment is repeatedfive times on different subsets of data. The accuraciesobtained for each fold are averaged to produce a sin-gle cross validation estimate.We do not use cross-validation in the metric lear-ning phase since evaluation of the fitness functionis very time consuming. Note that if we used thesame training dataset in the metric learning phase andalso in the classification phase, we could possibly ob-tain better classification 

Results than when the trainingdatasets in both phases were disjoint. The aim of thisarchitecture is to show robustness of the resulted fea-ture weights.3.1 Heterogeneous Distance MetricIn this 



Section, we describe weighted heterogeneousdistance function that is used in our experiments. Thedistance without weights was proposed in (Jurečekand Lórencz, 2018). Let x and y be two feature vec-tors of dimension m, and let wa be weight correspon-ding to the attribute (feature) a. The weighted distanceis defined as follows:D(x,y) =√m∑a=1w2ad2a(xa,ya) (1)whereda(x,y) =H (x,y) if a is a bit arrayδ(x,y) if a is a checksumNorm diffa(x,y) if a is a numericNorm vdma(x,y) otherwise.(2)H (x,y) de

Notes Hamming distance defined for binaryvectors x = (x1, . . . ,xn),y = (y1, . . . ,yn) asH (x,y) = |{i|xi 6= yi, i = 1, . . . ,n}| (3)4.2. Paper 2 - Distance Metric Learning using Particle Swarm Optimization to ImproveStatic Malware Detection61ParsingbinariesSplitdatasetEvaluationKNN with5-foldcross-validationreductionClassification PhaseFeatureselectionSplitdatasetPSOMetric Learning PhaseDimensio-nalityFigure 1: Architecture of our proposed malware detection system.and δ(x,y) is the characteristic function defined asδ(x,y) ={0 if x = y1 otherwise. (4)The Value Difference Metric (VDM) was introducedby (Stanfill and Waltz, 1986) and the normalizedVDM is defined asNorm vdma(x,y) =C∑c=1∣∣∣∣na,x,cna,x− na,y,cna,y∣∣∣∣ (5)where• C is the number of classes,• na,x,c is the number of instances in the training setT which have value x for attribute a and the in-stance belongs to class c,• na,x is the number of instances in T that havevalue x for attribute a.Function Norm diffa(x,y) is defined as:Norm diffa(x,y) =|x− y|4σa(6)where σa is the standard deviation of the values ofnumeric attribute a.The distance D is a modification of Heteroge-neous Value Difference Metric (HVDM) (Wilson andMartinez, 1997), and it can be used for our PE fea-ture space since it handles both numeric and nominalattributes.3.2 Particle Swarm OptimizationParticle swarm optimization (PSO) is a stochasticoptimization algorithm proposed by (Eberhart andKennedy, 1995). Many variants and modifications ofPSO are described in (Wang et al., 2018).PSO is a biologically motivated algorithm basedon swarm intelligence. Each particle is representedas a point in the search space and the quality of eachpoint is determined by a fitness function. Each par-ticle updates its position which is influenced by: thecurrent velocity, previous best particle’s position andposition of the most successful particle in the swarm.Concept and notation of the PSO elements with re-spect to our distance metric learning problem appliedon malware detection, is as follows:• Particle represents vector of weights w. The cur-rent position of i-th particle is denoted by xi andvi de

Notes its current velocity.• Swarm or population is an array of all particlesconsidered in the PSO algorithm.• Local best position pi of i-th particle is its best po-sition among all positions visited so far, and pbestiis the corresponding value of the fitness functionf , i.e. pbesti = f (pi).• Global best position pg is the position of the mostsuccessful particle in the swarm, and gbesti =f (pg).• Fitness function f is an objective function that isused to measure the quality of a particle. In ourmalware detection problem, the fitness function isdefined as the accuracy of the KNN classifier.The pseudocode of the PSO algorithm is presentedin Algorithm 1.4. Author’s Relevant Papers62Algorithm 1: PSO algorithm.Input: fitness function f , TpsoOutput: vector of weights1: initialize particles with random positions xi andvelocities vi2: repeat3: for each particle xi do4: compute fitness function f (xi)5: if f (xi)> pbesti then6: pbesti = f (xi)7: pi = xi8: end if9: end for10: select the most successful particle in swarm sofar, and denote it by pg11: for each particle xi do12: vi = vi + Rand(0,φ1) ⊗ (pi − xi) +Rand(0,φ2)⊗ (pg− xi)13: xi = xi + vi14: end for15: until maximum number of iterations or suffi-ciently good fitness is attained16: return global best positionRand(0,ε) represents a vector of random numbersuniformly distributed in [0,ε]. Operation ⊗ de

Notescomponent-wise multiplication. Note the each parti-cle is able to memorize its best previous position andalso it knows the best position of the whole swarmso far. Each component of velocity v is kept in therange [−Vmax,Vmax], where parameter Vmax influencessearch ability of the particles.To better control the scope of the search and re-duce the importance of Vmax, (Shi and Eberhart, 1998)proposed the following modification of particle’s ve-locity equation (step 12 of Algorithm 1):vi = ωvi +Rand(0,φ1)⊗ (pi− xi)++Rand(0,φ2)⊗ (pg− xi), (7)where ω is an inertia weight. Higher values ofω tend to global search while lower values tend tolocal search. Parameters φ1,φ2 and ω represents theweights and they are used to balance the global andthe local search.The PSO was chosen among other optimizationheuristics because its convergence rate is fast and thealgorithm is easy to implement and execute in paral-lel. The drawback of the algorithm is that it is vulne-rable to stuck into the local minima.3.3 Feature SelectionIn the proposed approach, the feature vector consistsof information from PE file format (Microsoft, 1999)which is the most widely used file format for malware.Gain ratio (GR) (Quinlan, 1986) is used to determinethe most useful features with respect to discriminatingbetween malware and benign files.Gain ratio is a modification of entropy-based mea-sure called information gain (IG) (Mitchell, 1997).Information gain IG(T ,a) is the expected reductionin entropy caused by knowing the value of an attributea relative to training dataset T , and it is defined asIG(T ,a) = Entropy(T )− ∑v∈V (a)|Tv||T |Entropy(Tv),(8)where V (a) de

Notes the set of all possible values forattribute a, and Tv de

Notes the subset of T for whichattribute a has value v.Gain ratio penalizes attributes with large numbersof possible values by incorporating a term called splitinformation (SI):SI(T ,a) =−d∑i=1|Ti||T | log2|Ti||T | , (9)where Ti are the d subsets of training dataset T re-sulting from partitioning T by the d-valued attributea. Split information SI(T ,a) is the entropy of T withrespect to the values of attribute a. The gain ratio isthen defined asGR(T ,a) =IG(T ,a)SI(T ,a). (10)The more the gain ratio, the more relevant a fea-ture will be.The following feature set with the highest gain ratiowas extracted and used in our experiment:• Fields from the PE headers: number of sec-tions, date/time stamp, major or minor versions oflinker, operating system, image, subsystem; sizesand addresses of data directories; DLL character-istics, and many others.• Features from 



Sections and their headers: Virtu-alSize, VirtualAddress, SizeOfRawData, Pointer-ToRawData, 



Section Flags.• Resources: number of resources and the numberof types of resources.• Overlay: size of the overlay.• Other features: entropies and checksums of sec-tions, the size of all imports, the number of DLLsreferred, the number of APIs referred.4.2. Paper 2 - Distance Metric Learning using Particle Swarm Optimization to ImproveStatic Malware Detection63Detailed description of these features can be foundin the documentation (Microsoft, 1999).3.4 Performance MetricsIn this 



Section, we present the performance metricwe used to measure the accuracy of our proposed ap-proach for the detection of unknown malicious codes.For evaluation purposes, the following classical quan-tities are employed:- True Positive (TP) represents the number of mali-cious samples classified as malware- True Negative (TN) represents the number of be-nign samples classified as benign- False Positive (FP) represents the number of be-nign samples classified as malware- False Negative (FN) represents the number of ma-licious samples classified as benignThe performance of our classifier on the test set ismeasured using three standard parameters. The mostintuitive and commonly used evaluation measure inMachine Learning is the accuracy (ACC):ACC =TP+TNTP+TN+FP+FN(11)It is defined on a given test set as the percentageof correctly classified instances. The second param-eter, True Positive Rate (TPR) (or detection rate), isdefined as:TPR =TPTP+FN(12)TPR is the percentage of truly malicious samplesthat were classified as malware. The third parameteris False Positive Rate (FPR), and it is defined as fol-lows:FPR =FPTN+FP(13)FPR is the percentage of benign samples that werewrongly classified as malware.4 EXPERIMENTAL SETUP AND

ResultsIn this 



Section, we describe experimental setup andpresent the 

Results of our experiments.4.1 Experimental Setup – Dataset andImplementationIn this research, we use dataset consisting of 150,145Windows programs in the PE file format, out of which74,978 are malware, and 75,167 are benign programs.The malicious and benign programs were obtainedfrom the laboratory of the industrial partner and alsofrom (VirusShare, 2019).There are many variants and modifications of thePSO algorithm. Initialization of the population con-cerns with random generation of particles and theirvelocities, however there are more advadced meth-ods, such as nonlinear simplex method or centroidalVoronoi tessellations and many others (Wang et al.,2018). In our implementation of modified PSO, re-sults from the feature selection algorithm (describedin 



Section 3.3) are used for initialization of the par-ticles, instead of random initialization. Values of thegain ratio can be considered as particle p and eachparticle is initialized as p⊗Rand(0,ε), where ε is asmall constant. The purpose of this initialization is inthe acceleration of PSO, i.e. reducing the searchingspace is done using 

Results of the feature selection al-gorithm.Another modification in our implementation isfeature scaling of the weight vector. Since each com-ponent wi of the weight vector has to be non-negative,in computing the fitness function, we use a normali-zed weight vector where each component is rescalingusing min-max normalization:xnorm =x−minmax−min , (14)where x is an original value and min, resp. max, isminimal, resp. maximal value of the original vector.There are several control techniques (Robinsonand Rahmat-Samii, 2004) that are able to avoid par-ticles running out of the search space. In our imple-mentation, positions of particles are not constrained.We use a static topological structure where each par-ticle is fully informed, i.e. it uses information of theentire neighborhood.Our implementation was executed on a singlecomputer platform having two processors (Intel XeonGold 6136, 3.0GHz, 12 cores each), with 32 GB ofRAM running the Ubuntu server 18.04 LTS operatingsystem.4.2 Experimental 

ResultsTo ensure a fine tuning of the hyperparameters of ourmalware detection model, grid search (Bergstra and4. Author’s Relevant Papers64Bengio, 2012) was used to explore the following PSOparameters:• φ1,φ2 ∈ {0.5,1.,1.5,2.},• Vmax ∈ {0.5,1.,2.,4.}.The rest of the PSO parameters are considered asconstants: population size is 40, and number of iter-ations is 30. At the first iteration, inertia weight ω isset to one, and it linearly decreases at each iteration tothe value ωmin = 0.8. All these parameters were cho-sen following the guidelines from (Wang et al., 2018)and (Poli et al., 2007). However, the choice of pa-rameters of the PSO is problem-specific, and to deter-mine the parameters appropriately and effectively isan open problem (Wang et al., 2018).We evaluated the performance of KNN (k = 5)with respect to the following initialization techniquesin PSO:• PSO-RAND de

Notes PSO where position and ve-locity of each particle are initialized randomly• PSO-GR de

Notes PSO where velocity of each par-ticle p is initialized randomly, however, its posi-tion is initialized as p⊗Rand(0,ε), where ε is asmall constant and p is the vector of gain ratiovalues.For our experiments, we used the heterogeneousdistance function described in 



Section 3.1. The clas-sification 

Results of the KNN with fivefold cross vali-dation are listed in Table 1.Table 1: Classification 

Results of the KNN classifier withand without feature weights.KNN TPR FPR ACCwithout weights 96.51% 4.03% 96.24%PSO-RAND 96.69% 3.46% 96.59%PSO-GR 96.67% 3.30% 96.72%Using weighted distance, we reduced the averageKNN classification error rate from 3.76% to 3.28%,i.e. the error rate has been decreased by 12.77%.5 



ConclusionsWe applied the PSO algorithm to the problem of fin-ding the most appropriate feature weights used in theheterogeneous distance function defined for the fea-tures extracted from PE file format. Our 

Results in-dicate that classification performance of KNN canbe improved by using weighted distance function.By comparing with the experiment of KNN withoutweights, classification error rate of KNN with weightshas been decreased by 12.77%. As a 

Results, the accu-racy of malware detection system using a geometric-based classifier such as KNN, can be increased signi-ficantly by using appropriate weights of the features.For 



Future Work, it would be interesting to experi-ment with several distance metric learning algorithmsand incorporate them in our proposed malware detec-tion system. Important goal for 



Future Work is to learnweights that vary between malware families.



AcknowledgementsThe authors acknowledge the support of the OP VVVMEYS funded project CZ.02.1.01/0.0/0.0/16 019/0000765 ”Research Center for Informatics”.



ReferencesAlrabaee, S., Shirani, P., Debbabi, M., and Wang, L.(2016). On the feasibility of malware authorship at-tribution. In International Symposium on Foundationsand Practice of Security, pages 256–272. Springer.Bergstra, J. and Bengio, Y. (2012). Random search forhyper-parameter optimization. Journal of MachineLearning Research, 13(Feb):281–305.Cohen, W. W. (1996). Learning trees and rules with set-valued features. In AAAI/IAAI, Vol. 1, pages 709–716.Cover, T. and Hart, P. (1967). Nearest neighbor pattern clas-sification. IEEE transactions on information theory,13(1):21–27.Damodaran, A., Di Troia, F., Visaggio, C. A., Austin,T. H., and Stamp, M. (2017). A comparison ofstatic, dynamic, and hybrid analysis for malware de-tection. Journal of Computer Virology and HackingTechniques, 13(1):1–12.Eberhart, R. and Kennedy, J. (1995). Particle swarmoptimization. In Proceedings of the IEEE inter-national conference on neural networks, volume 4,pages 1942–1948. Citeseer.Egele, M., Scholte, T., Kirda, E., and Kruegel, C. (2012). Asurvey on automated dynamic malware-analysis tech-niques and tools. ACM computing surveys (CSUR),44(2):6.Gandotra, E., Bansal, D., and Sofat, S. (2014). Malwareanalysis and classification: A survey. Journal of In-formation Security, 5(02):56.Ghosh, A. K. (2006). On optimum choice of k in near-est neighbor classification. Computational Statistics& Data Analysis, 50(11):3113–3123.Hsu, C.-M. and Chen, M.-S. (2008). On the design and ap-plicability of distance functions in high-dimensionaldata space. IEEE Transactions on Knowledge andData Engineering, 21(4):523–536.4.2. Paper 2 - Distance Metric Learning using Particle Swarm Optimization to ImproveStatic Malware Detection65Jureček, M. and Lórencz, R. (2018). Malware detectionusing a heterogeneous distance function. Computingand Informatics, 37(3):759–780.Kephart, J. O. and Arnold, W. C. (1994). Automatic extrac-tion of computer virus signatures. In 4th virus bulletininternational conference, pages 178–184.Kong, D. and Yan, G. (2013). Discriminant malware dis-tance learning on structural information for automatedmalware classification. In Proceedings of the 19thACM SIGKDD international conference on Knowl-edge discovery and data mining, pages 1357–1365.ACM.Kulis, B. et al. (2013). Metric learning: A survey. Founda-tions and Trends R© in Machine Learning, 5(4):287–364.Luke, S. (2013). Essentials of Metaheuristics. Lulu, secondedition.Microsoft (1999). Microsoft portable executable and com-mon object file format specification.Mitchell, T. M. (1997). Machine learning. New York.Nath, H. V. and Mehtre, B. M. (2014). Static malwareanalysis using machine learning methods. In Interna-tional Conference on Security in Computer Networksand Distributed Systems, pages 440–450. Springer.Or-Meir, O., Nissim, N., Elovici, Y., and Rokach, L. (2019).Dynamic malware analysis in the modern era—a stateof the art survey. ACM Computing Surveys (CSUR),52(5):88.Picard, R. R. and Cook, R. D. (1984). Cross-validation ofregression models. Journal of the American StatisticalAssociation, 79(387):575–583.Poli, R., Kennedy, J., and Blackwell, T. (2007). Particleswarm optimization. Swarm intelligence, 1(1):33–57.Quinlan, J. R. (1986). Induction of decision trees. Machinelearning, 1(1):81–106.Robinson, J. and Rahmat-Samii, Y. (2004). Particle swarmoptimization in electromagnetics. IEEE transactionson antennas and propagation, 52(2):397–407.Saad, S., Briguglio, W., and Elmiligi, H. (2019). The cu-rious case of machine learning in malware detection.In Proceedings of the 5th International Conference onInformation Systems Security and Privacy - Volume 1:ICISSP, pages 528–535. INSTICC, SciTePress.Schultz, M. G., Eskin, E., Zadok, F., and Stolfo, S. J. (2000).Data mining methods for detection of new maliciousexecutables. In Proceedings 2001 IEEE Symposiumon Security and Privacy. S&P 2001, pages 38–49.IEEE.Shafiq, M. Z., Tabish, S. M., Mirza, F., and Farooq, M.(2009). Pe-miner: Mining structural information todetect malicious executables in realtime. In Interna-tional Workshop on Recent Advances in Intrusion De-tection, pages 121–141. Springer.Shi, Y. and Eberhart, R. (1998). A modified particleswarm optimizer. In 1998 IEEE international confer-ence on evolutionary computation proceedings. IEEEworld congress on computational intelligence (Cat.No. 98TH8360), pages 69–73. IEEE.Stanfill, C. and Waltz, D. L. (1986). Toward memory-basedreasoning. Commun. ACM, 29(12):1213–1228.VirusShare (2019). Virusshare.com.Wang, D., Tan, D., and Liu, L. (2018). Particle swarm op-timization algorithm: an 

Overview. Soft Computing,22(2):387–408.Weinberger, K. Q., Blitzer, J., and Saul, L. K. (2006). Dis-tance metric learning for large margin nearest neigh-bor classification. In Advances in neural informationprocessing systems, pages 1473–1480.Wettschereck, D., Aha, D. W., and Mohri, T. (1997). Areview and empirical evaluation of feature weightingmethods for a class of lazy learning algorithms. Arti-ficial Intelligence Review, 11(1-5):273–314.Wilson, D. R. and Martinez, T. R. (1997). Improved het-erogeneous distance functions. Journal of artificialintelligence research, 6:1–34.Witten, I. H., Frank, E., Hall, M. A., and Pal, C. J. (2016).Data Mining: Practical machine learning tools andtechniques. Morgan Kaufmann.Xu, Y., Wu, C., Zheng, K., Wang, X., Niu, X., and Lu, T.(2017). Computing adaptive feature weights with psoto improve android malware detection. Security andCommunication Networks, 2017.Yang, L. and Jin, R. (2006). Distance metric learning:A comprehensive survey. Michigan State Universiy,2(2):4.Ye, Y., Li, T., Adjeroh, D., and Iyengar, S. S. (2017). Asurvey on malware detection using data mining tech-niques. ACM Computing Surveys (CSUR), 50(3):41.Yu, J., Amores, J., Sebe, N., Radeva, P., and Tian, Q.(2008). Distance learning for similarity estimation.IEEE Transactions on Pattern Analysis and MachineIntelligence, 30(3):451–462.Zhong, W. and Gu, F. (2019). A multi-level deep learningsystem for malware detection. Expert Systems withApplications, 133:151–162.4. Author’s Relevant Papers664.3. Paper 3 - Representation of PE Files using LSTM Networks4.3 Paper 3 - Representation of PE Files using LSTMNetworksMgr. Martin Jureček (60%), Bc. Matouš Kozák (40%)In Proceedings of 7th International Conference on Information Systems Security and Pri-vacy (ICISSP), pp. 516-525, Virtual event, 2021This paper presents the transformation of PE features using various LSTM network ar-chitectures. The research was not limited to only LSTM networks, however, a bidirectionalversion of LSTM networks (BLSTM) was also included in our experiments. State-of-the-artML classifiers were then trained on the transformed feature vectors.On these transformed datasets, we ran a cross-validation benchmark using multiplesupervised ML algorithms to see whether the feature transformation based on (B)LSTMnetworks can increase the performance of the ML algorithms in comparison to the per-formance achieved for the non-transformed dataset.The main idea, the use of output sequence from the LSTM as an input to ML classifier,was the contribution of the author of this dissertation thesis. This idea was successfullydeveloped by Matouš Kozák as a bachelor thesis [73] supervised by the author of thisdissertation thesis.67Representation of PE Files using LSTM NetworksMartin Jureček and Matouš KozákFaculty of Information Technology, Czech Technical University in Prague, Czech Republic{jurecmar, kozakmat}@fit.cvut.cz



Keywords: Malware Detection, PE File Format, Recurrent Neural Network, Long Short-term Memory.



Abstract: An ever-growing number of malicious attacks on IT infrastructures calls for new and efficient methods ofprotection. In this paper, we focus on malware detection using the Long Short-Term Memory (LSTM) as apreprocessing tool to increase the classification accuracy of machine learning algorithms. To represent themalicious and benign programs, we used features extracted from files in the PE file format. We created a largedataset on which we performed common feature preparation and feature selection techniques. With the help ofvarious LSTM and Bidirectional LSTM (BLSTM) network architectures, we further transformed the collectedfeatures and trained other supervised ML algorithms on both transformed and vanilla datasets. Transformationby deep (4 hidden layers) versions of LSTM and BLSTM networks performed well and decreased the errorrate of several state-of-the-art machine learning algorithms significantly. For each machine learning algorithmconsidered in our experiments, the LSTM-based transformation of the feature space 

Results in decreasing thecorresponding error rate by more than 58.60 %, in comparison when the feature space was not transformedusing LSTM network.1 



IntroductionMalware is a software that conducts malicious activ-ities on the infected computer. Cybersecurity profes-sionals across the globe are trying to tackle this un-wanted behaviour. Even though they are developingdefense systems on a daily basis, cybercriminals pro-cess at the same, if not, in a faster manner.Antivirus programs detect more than 370,000 ma-licious programs each day (AV-test, 2019), and thenumber keeps rising. Although Windows remains themost attacked platform, macOS and IoT devices arebecoming attractive targets as well. The most popularweapon for cybercriminals on Windows remains Tro-jan, for instance, Emotet, WannaCry, Mirai and manyothers (Symantec, 2019).In May 2017, the world was struck by newransomware WannaCry. This virus quickly spread allaround the world, infecting more than 230,000 com-puters in 150 countries. Between infected organiza-tions were, e.g. FedEx, O2, or Britain’s NHS and thecost of damage was estimated at around 4 billion dol-lars (Latto, 2020).In the paper, we focus on static malware detectionwhere features are collected from the PE file format.We are not examining files’ working behaviour formultiple reasons. Firstly, extracting API calls fromexecutable files needs to be performed in a sandboxenvironment to secure the leak of possible maliciousactivities into our system. However, this is bypassedby the unnatural behaviour of many programs in thesesurroundings. Secondly, it’s time-consuming runninglarge datasets and capturing their activities.During the last years, the current trend is toused malware detection framework based on machinelearning algorithms. Thanks to cloud-based comput-ing which makes the cost of big data computing moreaffordable, the concept of employing machine learn-ing to malware detection has become more realistic todeploy.This paper aims to explore whether the LSTM net-works can transform features to more convenient fea-ture space, and as a result, improve the classificationaccuracy. This problem is tackled in two stages. Inthe first stage, we collect malware and benign files,extract useful information, prepare and select the bestfeatures to create our dataset. The second stage con-sists of training different LSTM network architec-tures, transforming our dataset using these networks,and evaluating our 

Results with the help of several su-pervised machine learning (ML) algorithms.The structure of the paper is as follows. In 



Section2, we review related work on malware detection us-ing neural networks, especially recurrent neural nets.4. Author’s Relevant Papers68



Section 3 describes fundamental 

Background, such asPE file format and LSTM networks. In 



Section 4,we describe feature preprocessing and propose fea-ture transformation using LSTM networks. Descrip-tion of our experimental setup, from the dataset andhardware used to final evaluation using supervisedML algorithms, is placed in 



Section 5. We concludeour work in 



Section 6.2 RELATED WORKIn this part, we review related research in the field ofstatic malware detection. We focused on the paperslinked to neural networks, notably recurrent neuralnetworks (RNNs). However, we didn’t find muchwork dealing with the use of LSTM networks as afeature pre-treatment before the classification itself.In (Lu, 2019), the authors used opcodes (opera-tion code, part of machine language instruction (Bar-ron, 1978)) extracted from a disassembled binary file.From these opcodes, they created a language with thehelp of word embedding. The language is then pro-cessed by the LSTM network to get the prediction.They achieved an AUC-ROC score of 0.99, however,their dataset consisted of only 1,092 samples.A much larger dataset of 90,000 samples was usedin (Zhou, 2018). They used an LSTM network to pro-cess API call sequences combined with the convolu-tional neural network to detect malicious files. Whilealso using static and dynamic features, they managedto achieve an accuracy of 97.3%.Deep neural networks were also used in (Saxeand Berlin, 2015) with the help of Bayesian statist-ics. They worked with a large dataset of more than400 thousand binaries. With fixed FPR at 0.1%, theyreported AUC-ROC of 0.99964 with TPR of 95.2%.The authors of (Hardy et al., 2016) used stackedautoencoders for malware classification and achievedan accuracy of 95.64% on 50,000 samples.In (Vinayakumar et al., 2018), they trained thestacked LSTM network and achieved an accuracy of97.5% with an AUC-ROC score of 0.998. That saidthey focused on android files and collected only 558APKs (Android application package).3 

BackgroundIn this 



Chapter, we explain the necessary 

Backgroundfor this paper. The first part deals with the PortableExecutable file format, describing the use cases andstructure. In the second part, we study the LSTM net-works in detail. In the end, we also briefly mentionthe autoencoder networks.3.1 Portable ExecutablePortable Executable (PE) format is a file formatfor Windows operation systems (Windows NT) ex-ecutables, DLLs (dynamic link libraries) and otherprograms. Portable in the 



Title de

Notes the trans-ferability between 32-bit and 64-bit systems. Thefile format contains all basic information for the OSloader (Kowalczyk, 2018).The structure of the PE file is strictly set as fol-lows. Starting with MS-DOS stub and header, fol-lowed with file, optional, and 



Section headers and fin-ished with program 



Sections as illustrated in Figure 1.The detailed description can be found in (Karl Bridge,2019).Figure 1: Structure of a PE file.3.2 LSTM NetworkLong short-term memory or shortly LSTM networkis a subdivision of recurrent neural networks. Thisnetwork architecture was introduced in (Hochreiterand Schmidhuber, 1997). The improvement lies inreplacing a simple node from RNN with a compoundunit consisting of hidden state or ht (as with RNNs)and so-called cell state or ct . Further, adding in-put node gt compiling the input for every time stept and three gates controlling the flow of information.Gates are binary vectors, where 1 allows data to passthrough, 0 blocks the circulation. Operations withgates are handled by using Hadamard (element-wise)productwith another vector (Leskovec et al., 2020).As mentioned above, the LSTM cell is formed bya group of simple units. The key difference from RNNis the addition of three gates which regulate the in-put/output of the cell.Note that Wx, Wh and~b with subscripts in all ofthe equations below are learned weights matrices andvectors respectively, and f de

Notes an activation func-tion, e.g. sigmoid. Subscripts are used to distinguishmatrices and vectors used in specific equations.4.3. Paper 3 - Representation of PE Files using LSTM Networks691. Input Gate. Determines which information canbe allowed inside the unit:it = f (Wxixt +Whiht−1 +~bi) (1)2. Forget Gate. Allows us to discard informationfrom memory we do not longer need:ft = f (Wx f xt +Wh f ht−1 +~b f ) (2)3. Output Gate. This gate learns what data is para-mount at a given moment and enables the unit tofocus on it:ot = f (Wxoxt +Whoht−1 +~bo) (3)The input node takes as an input xt and previoushidden state:gt = f (Wxgxt +Whght−1 +~bg) (4)As an activation function is typically used tanheven though ReLU might be easier to train (Liptonet al., 2015).The cell state is calculated as follows:ct = it gt + ft  ct−1 (5)In equation (5), we can see the intuition behindusing the input and forget gates. The gates handlehow much of the input node and previous cell statewe allow into the cell. This formula is the essen-tial improvement to simple RNNs as the forget gatevector applied to the previous cell state is what al-lows the gradient to safely pass during backpropaga-tion, thus abolishing the problem of vanishing gradi-ent (Leskovec et al., 2020).The hidden state is then updated with the contentof the current cell state modified with output gate otas follows:ht = f (ct ot) (6)We can imagine the hidden state as the short-termmemory and cell state as the long-term memory of theLSTM network.The output ŷt is then computed as:ŷt = f (Whyht +~by) (7)To see the detailed illustration of LSTM cell seeFigure 2.Presented LSTM architecture in Figure 2 closelymaps the state-of-the-art design from (Zaremba et al.,2014). Note that we dropped the network’s parame-ters, matrices of weights, and vectors of biases to keepit well-arranged.Figure 2: Example of the LSTM architecture.3.2.1 Bidirectional Long Short-term MemoryThe traditional LSTM networks, the same as standardrecurrent neural networks and bidirectional recurrentneural networks (BRNNs), are not suitable for sometasks as the hidden and cell states are determined onlyby prior states. Such tasks include text and speech re-cognition and many more where the output at a time tdepends on the past as well as future inputs or labelingproblems where the output is only expected after fin-ishing the whole input sequence (Graves, 2012). Bi-directional Long Short-Term Memory or shortly(BLSTM) networks try to solve this problem by hav-ing connections both from the past and future cells.Input to the BLSTM network is then presented in tworounds, once forwards as with the LSTM network andthen in a reversed direction from the back. This archi-tecture was introduced in (Graves and Schmidhuber,2005).Figure 3: Structure of BLSTM network.In Figure 3 we can see the structure of BLSTMnetwork, the (0) and (1) in superscripts stand for for-wards and backwards directions, respectively. Weomitted the detailed representation of LSTM cells tomake the illustration simpler.BLSTM networks can be used to solve similarproblems as bidirectional RNNs where we have entireinput available beforehand. Training the network in4. Author’s Relevant Papers70forward and backward directions helps to gain contextfrom the past and future as well (Brownlee, 2019). Inaddition, having hidden and cell state enables betterstorage of information across the timeline even fromthe distant past or future.BLSTM networks were found to outperformstandard BRNNs in many tasks, e.g. speech recog-nition. This was proven in the first application ofBLSTM networks by Graves et al. for phoneme clas-sification problem (Graves and Schmidhuber, 2005).BLSTMs are not suitable for all tasks, such as wherewe do not know the final length of the input, andthe 

Results are required after each timestamp (onlinetasks).3.3 AutoencoderAutoencoder is a type of neural network that canlearn a representation of given data by compressingand decompressing the input values. As described in(Chollet, 2016), it consists of two parts, the encoderand decoder. The encoder is typically a dense feed-forward neural network (other types of neural net-works can be used as well) with subsequent layersshrinking in width. The decoder mirrors the struc-ture of the encoder with expanding layers. The au-toencoder is then trained with a set of data where in-put matches the target output. After training, the de-coder is detached and the encoder is used as the solemodel for prediction. The illustration of the autoen-coder setup can be seen in Figure 4.Figure 4: Example of autoencoder for digit compression(Chollet, 2016).Although the data compressed by autoencodercould be used in image compression, generally au-toencoders do not outperform well-known compres-sion algorithms. Since the compression inside autoen-coders is not lossless (the output is fuzzy), they are notsuitable for practical use of image compression.Among places where autoencoders found utiliza-tion belong dimension reduction and data denoisingproblems. In dimension reduction, autoencoders areused either as a preprocessing stage in machine learn-ing problems or before data visualization where largedata dimension hinders the comprehension of the im-age. In data denoising, the autoencoder is trained withnoisy images as the input and clear pictures being theoutput. The use of autoencoders is not limited to im-ages, however, they can also be used with audio andother problems affected by noisiness.4 FEATURETRANSFORMATIONS USINGLSTM NETWORKSIn this 



Section, we present our approach - featuretransformation using LSTM networks. We describefeature extraction and preparation, then feature selec-tion along with the central part of this paper, the fea-ture transformation using LSTM networks. Our com-plete workflow is illustrated in Figure 8 at the end ofthis 



Section.4.1 Feature ExtractionFor extracting features from PE files, we used Py-thon module pefile (Carrera, 2017). This moduleextracts all PE file attributes into an object from whichthey can be easily accessed. The structure of the PEfiles is briefly explained in 



Section 3.1. We used asmany PE attributes as possible and reached the totalnumber of 303 features. Features can be divided intomultiple categories based on their origin from the PEfile. A 

Summary of all target static features used inour experiments is as follows:Headers: Data from DOS, NT, File, and Optionalheaders.Data Directories: Names and sizes of all data dir-ectories. Also adding detailed information fromprevalent directories for instance IMPORT, EX-PORT, RESOURCE, and DEBUG directories.



Sections: Names, sizes, entropies of all PE 



Sectionsexpressed by their average, min, max, mean andstandard deviation. To cooperate with a variableamount of 



Sections in different files, we decidedto describe only the first four and last 



Sections in-dividually.Others: Extra characteristics associated with a file,e.g. byte histogram, printable strings, or versioninformation.4.2 Feature PreparationSince not all machine learning models used in ourexperiments can handle strings and other categoricaldata, we must such data types encode into numericvalues. This strategy is necessary for more than 60out of 303 columns. We chose to perform common4.3. Paper 3 - Representation of PE Files using LSTM Networks71transformation techniques on the entire dataset as op-posed to only using the training set. We believe thatby doing so, we can better focus on designing LSTMarchitectures and our 

Results won’t be affected by thecapability of other algorithms.4.2.1 VectorizationUpfront, we transformed string features into sparsematrix representation using TfidfVectorizer fromthe scikit-learn Python library (Pedregosa et al.,2011). This class demands corpus (collection of doc-uments) as an input. We also adjusted parametersstop_words and max_df that influence which wordsto exclude from further calculations. Among the ex-cluded words are either commonly used words in agiven language, words that do not bear any mean-ing, and words that occur with such high frequenciesthat they are not statistically interesting for us. Toeliminate the massive rise of dimensionality, we setmax_features parameter according to the feature’scardinality. The transformation itself consists of con-verting sentences to vectors of token counts. Thenthey are transformed into tf-idf representation. Tf-idfis an abbreviation for the term frequency times inversedocument frequency. It is a way to express the weightof a single word in the corpus (Maklin, 2019).Term Frequency is the frequency of a word insidethe document. The formula is:tf(w,d) =nw,d∑k nk,d, (8)where nw,d is the number of times word w appearsin a document d and the denominator is the sum of allwords found in d.Inverse Document Frequency is a scale of howmuch a word is rare across the whole corpus:idf(w,D) = log|D||d ∈ D : w ∈ d| (9)It is a fraction of the total number of documentsin corpus D divided by the number of documents con-taining the specific word.Tf-idf is then calculated as a multiplication ofthese two values as follows:tf-idf(w,d) = tf(w,d) · idf(w,D) (10)All of this is done by the aforementioned classTfidfVectorizer, and as a result, we get a matrixof tf-idf features that can be used in further computa-tions.4.2.2 HashingFor non-string values, we used a technique called fea-ture hashing. This approach turns the column ofvalues into a sparse matrix using the value’s hashas an index to the matrix. For this task, we usedFeatureHasher also from the scikit-learn. Theclass takes an optional argument n_features whichlimits the number of columns in the output matrix. Weset this argument dynamically according to the size ofthe feature’s value set.4.3 Feature SelectionEven though we tried to limit the rise of new features,we ended up with 1488 features. To speed up theforthcoming training process, we tried several featureselection techniques to reduce the dimensionality ofthe dataset.Before all else, we filled missing values bycolumn’s mean and divided data into train and testsplits to ensure correct evaluation of the model’s per-formance. For this, we used train_test_splitfrom sklearn.model_selection with test splittaking 20% of the dataset. Afterwards, wetransformed features to stretch across a smallerrange. For this task, we looked for another classfrom sklearn.preprocessing library and selectedMinMaxScaler. This scaler turns each feature x to liebetween zero and one. The transformation is calcu-lated as:xi−min(x)max(x)−min(x) (11)For feature selection, we settled with PCA (Prin-cipal Component Analysis) with the number of com-ponents determined by testing conducted with thestate-of-the-art ML algorithms: AdaBoost, Decisiontree, Feed-forward neural network, Random forest,K-nearest neighbours, Support vector machine, Gaus-sian naive bayes, and Logistic regression. The sameML algorithms were used to evaluate performance ofLSTM-based transformation (see 



Section 5.2). Wetested a number of components ranging from 2 to1400, however increasing benefits were found onlyuntil 50 components, after which we did not measureany significant improvements. The 

Results are presen-ted in Figure 5.Note that while the resulting components are notprimarily in the form of sequences, they can still besequentially processed using the LSTM and achievesolid classification 

Results (see 



Section 5.3).4. Author’s Relevant Papers722 10 50 100 200 350 550 700 1000 1400number of components0.020.040.060.080.100.120.14ERRmeanFigure 5: Average error rate (ERR) of ML algorithms acrossnumber of components.4.4 Feature Transformation usingLSTM NetworkWe experimented with various LSTM architectureswhich we used for feature transformation. All net-works were trained only on the train set. After thetraining process, the train and test set were trans-formed using the LSTM network.Our research is not limited to only LSTM net-works, however, bidirectional version of LSTM net-works (BLSTM) was also included in our exper-iments. We considered two different types ofneural networks: the Basic version consisting ofone (B)LSTM layer and the Deep version with four(B)LSTM layers, each layer containing 50 LSTMunits equal to the number of input features. All net-works were trained up to 50 epochs with a batch sizeof 32, Adam optimization, and mean squared errorloss function.4.4.1 Type 1The first type of LSTM network we experimented isbased on autoencoder’s architecture. In this case, weworked only with explanatory variables with a net-work designed to predict the same values which weregiven on input. The predicted transformation wastaken from the penultimate layer’s last hidden state.Schema of the Type 1 transformer is illustrated in Fig-ure 6.4.4.2 Type 2The second type was similar to the regular use of theLSTM network, where we work with both the explan-atory and response variables. For prediction, we usedthe last hidden state of the penultimate LSTM layer aswith Type 1. The last layer was occupied by a single(B)LSTM layeryOutput PredictedtransformationhtXInputFigure 6: Schema of Basic version Type 1 transformer.neuron with a sigmoid activation function. Diagramof the Type 2 transformer is presented in Figure 7.(B)LSTM layeryInputOutputPredictedhtXDenselayertransformationFigure 7: Schema of Basic version Type 2 transformer.4.4.3 Description of All Transformed DatasetsThe following is a description of the datasets used intesting. Recall that ”Basic” and ”Deep” in the de-scription below denote one layer and four layers ofthe deep network, respectively:BLSTM AE basic Transformed by Basic version ofBLSTM Type 1 (autoencoder) network.BLSTM AE deep Transformed by Deep version ofBLSTM Type 1 (autoencoder) network.BLSTM basic Transformed by Basic version ofBLSTM Type 2 network.BLSTM deep Transformed by Deep version ofBLSTM Type 2 network.LSTM AE basic Transformed by Basic version ofLSTM Type 1 (autoencoder) network.LSTM AE deep Transformed by Deep version ofLSTM Type 1 (autoencoder) network.4.3. Paper 3 - Representation of PE Files using LSTM Networks73LSTM basic Transformed by Basic version ofLSTM Type 2 network.LSTM deep Transformed by Deep version of LSTMType 2 network.VANILLA Control dataset, no transformationsmade.4.5 Evaluation using Supervised MLAlgorithmsThe final part of the experiment workflow consistsof evaluation of the aforementioned transformations.We tested several supervised ML algorithms and com-pared their performance on vanilla and transformeddatasets. Detailed description of this part can befound in 



Section 5.2. Figure 8 

Overviews the exper-iment pipeline.PE filesStatic featuresVanilla Dataset(B)LSTMnetworkTransformed Dataset

ResultsML algorithmsFeature selection(PCA)Feature preparationFeature extractionFigure 8: Experiment pipeline.5 EXPERIMENTSIn this 



Section, we firstly describe the dataset used inour experiments. Then we specify our experimentalsetup in detail and evaluation methods, and in the end,we present our 

Results.5.1 DatasetWe gathered a dataset of 30,154 samples whichare evenly distributed between malware and be-nign files. For amassing benign files, we searcheddisks on university computers and the malware fileswere obtained from an online repository https://virusshare.com which we thanks for the access.5.2 Experimental Setup and EvaluationMethodsThe performance of LSTM pre-treatment was eva-luated by the following supervised ML algorithms.Among the ML algorithms we used were Supportvector classification (SVC) with kernel rbf, deepFeed-forward network (FNN) with 8 hidden layers(128-128-64-64-32-32-16-16 neurons per layer) allwith ReLU activation function, trained up to 200epochs with Adam optimization and binary cross-entropy loss function. Further, we tested Decisiontree, Random forest, AdaBoost, K-nearest neighbours(k=5), Gaussian naive bayes, and Logistic regres-sion. The hyperparameters which we did not men-tion were left to default settings as set by authors ofthe scikit-learn library (Pedregosa et al., 2011) ex-cept for the FNN which was modeled with the help ofthe Python deep learning library Keras (Chollet et al.,2015).Our implementation was executed on a singlecomputer platform having two processors (Intel XeonGold 6136, 3.0GHz, 12 cores each), with 32 GB ofRAM running the Ubuntu server 18.04 LTS operatingsystem.5.2.1 MetricsIn this 



Section, we present the metrics we used tomeasure the performance of our proposed classific-ation models. For evaluation purposes, the followingclassical quantities are employed:True Positive (TP) represents the number of mali-cious samples classified as malware.True Negative (TN) represents the number of benignsamples classified as benign.False Positive (FP) represents the number of benignsamples classified as malwareFalse Negative (FN) represents the number of mali-cious samples classified as benign.The performance of our classifiers on the test setis measured using the following standard metrics:4. Author’s Relevant Papers74Accuracy (ACC) Proportion of correctly classifiedsamples out of all predictions:ACC =T P+T NT P+T N +FP+FN(12)Error rate (ERR) The inverse of accuracy:ERR = 1−ACC (13)Sensitivity (TPR, Recall) How many samples fromthe positive class were predicted correctly:T PR =T PT P+FN(14)Fall-out (FPR) Probability of predicting samplesfrom the negative class as positives:FPR =FPFP+T N(15)5.3 

ResultsIn order to expose any biases in the data, we testedthe ML algorithms with 5-fold cross-validation usingcross_validate from scikit-learn library.We found that the 

Results did not only varybetween different network architectures but alsoamong particular ML algorithms. These observationsare presented in the heatmap in Figure 9. These res-ults indicate that Type 1 based on autoencoder designdoes not seem to improve the performance whatso-ever. However, Type 2, especially deep versions ofLSTM and BLSTM networks, seem to enhance theperformance of many algorithms significantly.AB DT FFN LR NB RF SVC kNNML AlgorithmBLSTM_AE_basicBLSTM_AE_deepBLSTM_basicBLSTM_deepLSTM_AE_basicLSTM_AE_deepLSTM_basicLSTM_deepvanilladataset5.19 3.96 2.47 5.33 24.83 2.39 3.04 2.645.22 4.11 2.43 4.93 7.55 2.37 3.21 2.632.46 3.19 1.17 0.97 3.24 1.83 1.09 1.880.86 1.31 0.78 0.85 0.92 0.89 0.87 0.885.13 3.85 2.44 5.33 24.92 2.36 3.03 2.624.29 3.82 2.40 4.84 6.00 2.35 3.58 2.572.41 3.38 1.20 0.88 3.25 1.84 0.98 1.881.00 1.48 0.82 0.99 0.99 1.05 0.98 1.044.13 3.53 2.05 4.55 42.60 2.15 5.60 2.39816243240ERR %Figure 9: Heatmap comparing the ERR of ML algorithmswith respect to different transformer architectures.Tables 1, 2 and 3 present the improvements madeby pre-treatment with LSTM and BLSTM networksfor different ML algorithms used for evaluation. Notethat the performance of Logistic regression, NaiveBayes, SVC, or AdaBoost algorithms increased themost significantly.Table 1: Baseline 

Results of ML algorithms on unedited(vanilla) dataset.ML Algorithm ACC TPR FPR ROC-AUCAdaBoost 95.87 ± 0.39 95.49 ± 0.55 3.75 ± 0.46 95.87 ± 0.39DecisionTree 96.47 ± 0.20 96.37 ± 0.25 3.44 ± 0.40 96.47 ± 0.20Feed-ForwardNetwork 97.95 ± 0.12 97.75 ± 0.36 1.86 ± 0.23 97.95 ± 0.12LogisticRegression 95.45 ± 0.38 94.62 ± 0.38 3.73 ± 0.45 95.45 ± 0.38NaiveBayesGaussian 57.40 ± 16.01 16.63 ± 36.13 1.84 ± 4.11 57.40 ± 16.01RandomForest 97.85 ± 0.20 97.52 ± 0.24 1.82 ± 0.19 97.85 ± 0.20SVC(kernel=rbf) 94.40 ± 1.74 93.49 ± 1.74 4.69 ± 1.81 94.40 ± 1.74kNN(k=5) 97.61 ± 0.21 97.17 ± 0.28 1.94 ± 0.16 97.61 ± 0.21Table 2: 

Results of ML algorithms on dataset transformedby deep LSTM network.ML Algorithm ACC TPR FPR ROC-AUCAdaBoost 99.00 ± 0.71 98.76 ± 0.78 0.76 ± 0.66 99.00 ± 0.71DecisionTree 98.52 ± 0.55 98.43 ± 0.60 1.40 ± 0.50 98.52 ± 0.55Feed-ForwardNetwork 99.18 ± 0.77 99.10 ± 0.64 0.75 ± 0.90 99.18 ± 0.77LogisticRegression 99.01 ± 0.72 98.89 ± 0.78 0.87 ± 0.67 99.01 ± 0.72NaiveBayesGaussian 99.01 ± 0.67 98.70 ± 0.58 0.69 ± 0.78 99.01 ± 0.67RandomForest 98.95 ± 0.77 98.85 ± 0.77 0.95 ± 0.78 98.95 ± 0.77SVC(kernel=rbf) 99.02 ± 0.72 98.73 ± 0.74 0.69 ± 0.70 99.02 ± 0.72kNN(k=5) 98.96 ± 0.75 98.82 ± 0.80 0.91 ± 0.71 98.96 ± 0.75The performance of the two most successful clas-sifiers evaluated on all transformed datasets con-sidered in our experiments, Feed-forward neural net-work, and Logistic regression, is presented in Figure10.To emphasize our 

Results, we express the perform-ance of the ML algorithms in terms of error rate (in[%]). In Table 4, we 

Overview the error rates (ERR)of ML algorithms evaluated on the original and trans-formed dataset by deep BLSTM network.6 



ConclusionsWe collected a large number of PE binaries fromavailable resources. From these binaries, we extrac-ted as many features as possible, which we later scaledown by the feature selection algorithm PCA in orderto reduce the dimension of our dataset. After that, weconducted extensive testing with various (B)LSTMnetwork architectures used to transform the selec-ted features. On these transformed datasets, we rana cross-validation benchmark using multiple super-vised ML algorithms to see whether the feature trans-formation based on (B)LSTM networks can increasethe performance of the ML algorithms in comparisonto the performance to the accuracy on the vanilla data-set.We have found that the feature transformation by(B)LSTM nets was hugely successful, decreasing er-ror rate from 58.6% to 97.84% depending on the MLalgorithm used. These gains were achieved by so-called Type 2 architecture which was similar to thestandard use of recurrent neural networks for clas-sification problems. In contrast, the Type 1 designbased on autoencoder structure didn’t prove to en-4.3. Paper 3 - Representation of PE Files using LSTM Networks75(a) Feed-forward neural network. (b) Logistic regression.Figure 10: Boxplots showing the performance of the two most successfull classifiers evaluated on multiple datasets.Table 3: 

Results of ML algorithms on dataset transformedby deep BLSTM network.ML Algorithm ACC TPR FPR ROC-AUCAdaBoost 99.14 ± 0.77 99.06 ± 0.81 0.78 ± 0.80 99.14 ± 0.77DecisionTree 98.69 ± 0.71 98.67 ± 0.79 1.30 ± 0.65 98.69 ± 0.71Feed-ForwardNetwork 99.22 ± 0.84 99.12 ± 0.87 0.67 ± 0.83 99.22 ± 0.84LogisticRegression 99.15 ± 0.78 99.07 ± 0.81 0.78 ± 0.79 99.15 ± 0.78NaiveBayesGaussian 99.08 ± 0.78 98.65 ± 0.82 0.48 ± 0.77 99.08 ± 0.78RandomForest 99.11 ± 0.74 99.01 ± 0.80 0.78 ± 0.72 99.11 ± 0.74SVC(kernel=rbf) 99.13 ± 0.82 98.94 ± 0.87 0.67 ± 0.79 99.13 ± 0.82kNN(k=5) 99.12 ± 0.82 99.02 ± 0.87 0.78 ± 0.79 99.12 ± 0.82Table 4: Comparison of the 

Results achieved from the MLalgorithms evaluated on the vanilla (non-transformed) data-set and the transformed dataset by deep BLSTM network.ML Algorithm ERR (no LSTM) ERR (with LSTM) ERR decreased byAdaBoost 4.13 0.86 79.18DecisionTree 3.53 1.31 62.89Feed-ForwardNetwork 2.05 0.78 61.95LogisticRegression 4.55 0.85 81.32NaiveBayesGaussian 42.60 0.92 97.84RandomForest 2.15 0.89 58.60SVC(kernel=rbf) 5.60 0.87 84.46kNN(k=5) 2.39 0.88 63.18hance performance. The transformation by Type 2deep transformers brought all tested ML algorithmsto a similar level. The smaller performance in-crements were observed among the ML algorithmswhich already performed well on the non-transformeddataset.



AcknowledgementsThe authors acknowledge the support of the OP VVVMEYS funded project CZ.02.1.01/0.0/0.0/16 019/0000765 ”Research Center for Informatics”.



ReferencesAV-test (2019). Security report 2018/19. https://www.av-test.org/fileadmin/pdf/security report/AV-TEST Security Report 2018-2019.pdf.Barron, D. W. (1978). Assemblers and loaders. ElsevierScience Inc.Brownlee, J. (2019). How to develop a bidirectionallstm for sequence classification in python withkeras. https://machinelearningmastery.com/develop-bidirectional-lstm-sequence-classification-python-keras/.Carrera, E. (2017). Pefile. https://github.com/erocarrera/pefile.Chollet, F. (2016). Building autoencoders in keras. https://blog.keras.io/building-autoencoders-in-keras.html.Chollet, F. et al. (2015). Keras. https://keras.io.Graves, A. (2012). Supervised sequence labelling. In Su-pervised sequence labelling with recurrent neural net-works, pages 13–39. Springer.Graves, A. and Schmidhuber, J. (2005). Framewise phon-eme classification with bidirectional lstm and otherneural network architectures. Neural networks, 18(5-6):602–610.Hardy, W., Chen, L., Hou, S., Ye, Y., and Li, X. (2016).Dl4md: A deep learning framework for intelligentmalware detection. In Proceedings of the Interna-tional Conference on Data Mining (DMIN), page 61.The Steering Committee of The World Congress inComputer Science, Computer . . . .Hochreiter, S. and Schmidhuber, J. (1997). Long short-termmemory. Neural computation, 9(8):1735–1780.Karl Bridge, M. (2019). Pe format - win32 apps.”https://docs.microsoft.com/en-us/windows/win32/debug/pe-format”.4. Author’s Relevant Papers76Kowalczyk, K. (2018). Portable executable fileformat. https://blog.kowalczyk.info/articles/pefileformat.html.Latto, N. (2020). What is wannacry? https://www.avast.com/c-wannacry.Leskovec, J., Rajaraman, A., and Ullman, J. D. (2020). Min-ing of massive data sets. Cambridge university press.Lipton, Z. C., Berkowitz, J., and Elkan, C. (2015). A crit-ical review of recurrent neural networks for sequencelearning. arXiv preprint arXiv:1506.00019, pages 5–25.Lu, R. (2019). Malware detection with lstm using opcodelanguage. arXiv preprint arXiv:1906.04593.Maklin, C. (2019). Tf idf: Tfidf python example.https://towardsdatascience.com/natural-language-processing-feature-engineering-using-tf-idf-e8b9d00e7e76.Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V.,Thirion, B., Grisel, O., Blondel, M., Prettenhofer,P., Weiss, R., Dubourg, V., Vanderplas, J., Passos,A., Cournapeau, D., Brucher, M., Perrot, M., andDuchesnay, E. (2011). Scikit-learn: Machine learningin Python. Journal of Machine Learning Research,12:2825–2830.Saxe, J. and Berlin, K. (2015). Deep neural network basedmalware detection using two dimensional binary pro-gram features. In 2015 10th International Conferenceon Malicious and Unwanted Software (MALWARE),pages 11–20. IEEE.Symantec, C. (2019). Internet security threat report 2019.https://docs.broadcom.com/doc/istr-24-2019-en.Vinayakumar, R., Soman, K., Poornachandran, P., andSachin Kumar, S. (2018). Detecting android malwareusing long short-term memory (lstm). Journal of In-telligent & Fuzzy Systems, 34(3):1277–1288.Zaremba, W., Sutskever, I., and Vinyals, O. (2014). Re-current neural network regularization. arXiv preprintarXiv:1409.2329, pages 1–3.Zhou, H. (2018). Malware detection with neural networkusing combined features. In China Cyber Security An-nual Conference, pages 96–106. Springer.4.3. Paper 3 - Representation of PE Files using LSTM Networks774. Author’s Relevant Papers4.4 Paper 4 - Improving Classification of Malware Famil-ies using Learning a Distance MetricMgr. Martin Jureček (70%), Mgr. Olha Jurečková (20%), prof. Ing. Róbert Lórencz, CSc.(10%)In Proceedings of 7th International Conference on Information Systems Security and Pri-vacy (ICISSP), pp. 643-652, Virtual event, 2021The main topic of this paper is a multiclass classification problem where each malwarefamily and benign files have their own class. Three distance metric learning algorithmswere employed to learn the Mahalanobis distance metric to improve the multiclass classific-ation performance of the KNN classifier. Paper provides practical information concerningperformance, computational time, and resource usage.The practical use of distinguishing between malware families lies in helping malwareanalysts deal with a large number of samples.The paper was written in cooperation with Olha Jurečková, who worked on experimentsconcerning the low-dimensional representation of malware and benign files.78Improving Classification of Malware Families using Learning a DistanceMetricMartin Jureček, Olha Jurečková and Róbert LórenczFaculty of Information Technology, Czech Technical University in Prague, Czech Republic{jurecmar, jurecolh, lorencz}@fit.cvut.cz



Keywords: Malware Family, PE File Format, Distance Metric Learning, Machine Learning.



Abstract: The objective of malware family classification is to assign a tested sample to the correct malware family. Thispaper concerns the application of selected state-of-the-art distance metric learning techniques to malware fam-ilies classification. The goal of distance metric learning algorithms is to find the most appropriate distancemetric parameters concerning some optimization criteria. The distance metric learning algorithms consideredin our research learn from metadata, mostly contained in the headers of executable files in the PE file format.Several experiments have been conducted on the dataset with 14,000 samples consisting of six prevalent mal-ware families and benign files. The experimental 

Results showed that the average precision and recall of thek -Nearest Neighbors algorithm using the distance learned on training data were improved significantly com-paring when the non-learned distance was used. The k -Nearest Neighbors classifier using the Mahalanobisdistance metric learned by the Metric Learning for Kernel Regression method achieved average precision andrecall, both of 97.04% compared to Random Forest with a 96.44% of average precision and 96.41% of averagerecall, which achieved the best classification 

Results among the state-of-the-art ML algorithms considered inour experiments.1 



IntroductionA large number of new malicious samples are cre-ated every day, which makes manual analysis imprac-tical. The majority of these samples are generated bymalware generators, which need to input some pa-rameters. These malware generators, together withtheir particular settings, define corresponding mal-ware families. Samples generated from the same ge-nerator with a fixed setting (i.e., from the malwarefamily) may be potentially similar to each other anddifferent from samples belonging to other malwarefamilies or benign files. This work focuses on lever-aging these differences to distinguish between mal-ware families. Note that samples from the same mal-ware family, however, generated in a different timeperiod may be different from each other (Wadkaret al., 2020).Since the samples are usually obfuscated, it is dif-ficult to classify new (previously unseen) samples intothe correct malware families. Moreover, there is noknown general similarity measure suitable for a fea-ture set extracted from the PE file format to correctlycluster all malware families. (Jureček and Lórencz,2018) presented distance metric specially designedfor the PE file format that can handle all data typesof features.Our work focuses on the multiclass classificationproblem where each malware family and benign fileshave their own class. This multiclass classificationproblem is more challenging than a binary classifica-tion problem where the goal is to distinguish betweenmalicious and benign files. However, the 

Results of(Basole et al., 2020) may indicate that an increasingnumber of families (from 2 to 20 families) drops anaverage balanced accuracy slightly.The practical use of distinguishing between mal-ware families lies in helping malware analysts to dealwith a large number of samples. Due to a large num-ber of malicious files that come to antivirus vendors,there is a need to automatically categorize malwareinto groups corresponding to malware families. Sam-ples belonging to the same group are similar to eachother with respect to some similarity measure (deter-mined by distance metric). These groups are then dis-tributed to malware analysts and assuming that filesbelonging to the same group have similar behavior, itmay help speed up the further analysis.Usually, malware analysts are specialists for somelimited number of malware families. If we assume4.4. Paper 4 - Improving Classification of Malware Families using Learning a DistanceMetric79that samples were classified correctly and samples ofthe same family are similar to each other and dissim-ilar to the samples of other families, using our ap-proach, the analysts can focus only on those sampleswhich belong to the malware families for which theanalysts are specialized.Good similarity measure plays an important rolein the performance of distance-based classifiers, suchas k -Nearest Neighbors (KNN). The distance be-tween two feature vectors having the same class la-bel must be minimized while the distance betweentwo feature vectors of different classes must be max-imized. This is the goal of distance metric learningmethods used to learn the parameters of distance met-rics from training data. As a result, they can poten-tially improve the performance of the classifiers.In our experiments, we consider six malwarefamilies, which is a relatively small number. An-other limitation of our work lies in assuming that ourdataset is large enough for training distance metriclearning (DML) algorithms. However, in practice,new families or new malware variants are continu-ously emerging. Therefore the training set, at somemoment, may not contain enough samples of the de-sired malware family to train some supervised learn-ing classifier.The contributions of this paper are as follows:• We determined and described the list of 25 fea-tures all extracted (except one, i.e., size of a file)from the PE file format. For each feature froma 



Section header, we considered the order of the



Section rather than the type of the 



Section (such as.text, .data, .rsrc, etc.). While the 



Sections’ orderturns out to be important for malware detection,this kind of information is often not mentioned inresearch papers.• Using three DML algorithms, LMNN, NCA, andMLKR, we achieved significantly better multi-class classification 

Results than any state-of-the-art ML algorithms considered in our experiments.We provided practical information concerningperformance, computational time, and resourceusage.• We showed that the DML-based methods mightimprove multiclass classification 

Results evenwhen standard methods such as feature selectionor algorithm tuning were already applied. As aresult, we suggest using DML algorithms as animportant preprocessing step.The rest of the paper is organized as follows. In



Section 2, we review recent malware detection me-thods based on machine learning focusing on the clas-sification of malware families. In 



Section 3, we givesome theoretical 

Background and discuss three dis-tance metric learning techniques used in our experi-ments. The experimental setup and 

Results of featureselection algorithms are presented in 



Section 4. Sec-tion 5 describes DML-based experiments and 

Results.We summarize our research work in 



Section 6.2 RELATED WORKThis 



Section briefly reviews the previous research pa-pers on malware family classification related to ourwork.In (Basole et al., 2020), the authors conducted ex-periments based on byte n-gram features, and theyconsidered 20 malware families. A binary classi-fication were performed on different levels. In thefirst level, for each of 20 families, they performed bi-nary classification for 1,000 malware samples fromone family and 1,000 benign samples. In the se-cond level, the malware class consists of two malwarefamilies; in the third level, the malware class consistsof three malware families, and so on up to level 20,where the malware class contains all of the 20 mal-ware families. The authors applied four state-of-the-art machine learning algorithms: KNN, Support Vec-tor Machines, Random Forest, and Multilayer Percep-tron. The best classification 

Results (balanced accu-racy) was achieved using KNN and Random Forest,over 90% (at level 20), while KNN achieves the mostconsistent 

Results.A fully automated system for analysis, classifi-cation, and clustering of malware samples was in-troduced in (Mohaisen et al., 2015). This system iscalled AMAL and it collects behavior-based artifactsdescribing files, registry, and network communica-tion, to create features that are then used for classifica-tion and clustering of malware samples into families.The authors achieved more than 99% of precision andrecall in classification and more than 98% of precisionand recall for unsupervised clustering.In (Ahmadi et al., 2016), the authors proposeda malware classification system using different mal-ware characteristics to assign malware samples to themost appropriate malware family. The system allowsthe classification of obfuscated and packed malwarewithout doing any deobfuscation and unpacking pro-cesses. High classification accuracy of 99.77% wasachieved on the publicly accessible Microsoft Mal-ware Challenge dataset.(Islam et al., 2013) presented a classificationmethod based on static (function length frequency andprintable sting) and dynamic (API function nameswith API parameters) features that were integrated4. Author’s Relevant Papers80into one feature vector. The obtained 

Results showedthat integrating features improved classification accu-racy significantly. The highest weighted average ac-curacy was achieved by the meta-Random Forest clas-sifier.Another malware family classification systemreferred to as VILO is presented in (Lakhotiaet al., 2013). They used TFIDF-weighted opcodemnemonic permutation features and achieved bet-ween 0.14% and 5.42% fewer misclassifications u-sing KNN classifier than does the usage of n-gramfeatures.In the rest of this 



Section, we survey some previ-ous works on distance metric learning applied to theproblem of malware detection. There is only a cou-ple of works that address this topic. (Jureček andLórencz, 2020) deals with measure learning and itsapplication to malware detection. Particle swarm op-timization (PSO) was used to find appropriate featureweights for the heterogeneous distance function usedin the KNN classifier. Positions of particles in the ini-tialization step of PSO were set according to the in-formation gain computed in the feature selection steprather than randomly. As a result, PSO was acceler-ated, and better classification accuracy was achievedusing the weighted distance function.Work (Kong and Yan, 2013) concerns with a mal-ware detection method based on structural informa-tion. The discriminant distance metric is learned tocluster the malware samples belonging to the samemalware family.3 

BackgroundPerformance of some ML classifiers, such as KNN,depends significantly on the distance metric used tocompute similarity measure between two samples.These classifiers rely on the assumption that samplesbelonging to the same class are close to each other(with respect to the distance function), and they arefar from samples belonging to the different classes.The DML algorithms were designed to improvethe performance of distance-based classifiers vialearning the distance metric. This 



Section provides

Background and a brief description of three state-of-the-art distance metric learning algorithms, LMNN,NCA, and MLKR, used in our experiments.Euclidean distance is by far the most commonlyused distance metric. Let x and y be two n-dimensional feature vectors. The weighted Euclideandistance is defined as follows:dw(x,y) =√n∑i=1w2i (xi− yi)2 (1)where wi is a weight (non-negative real number)associated with the jth feature. The distance metriclearning problem for weighted Euclidean distance isdefined as finding (or learning) an appropriate weightvector w = (w1, . . . ,wn) using training data, with re-spect to some optimization criterion, usually mini-mizing error rate.Several distance functions have been presented(Wilson and Martinez, 1997). To improve classifi-cation or clustering 

Results, many weighting schemeswere designed. A review of feature weighting me-thods for lazy learning algorithms was proposed in(Wettschereck et al., 1997).Mahalanobis distance for two n-dimensional fea-ture vectors x and y is defined asdM(x,y) =√(x−y)>M(x−y) (2)where M is a positive semidefinite matrix. Maha-lanobis distance can be considered as a generalizationof Euclidean distance, since if M is the identity ma-trix, then dM in Eq. (2) is reduced to Euclidean dis-tance. If M is diagonal, this corresponds to learningthe feature weights Mii = wi from Eq. (1) defined forweighted Euclidean distance.The goal of learning the Mahalanobis distance isto find an appropriate matrix M with respect to someoptimization criterion. In the context of the KNNclassifier, the goal is to find a matrix M, which is es-timated from the training set, which leads to the lo-west error rate of the KNN classifier. Since a positivesemidefinite matrix M can always be decomposed asM = L>L, distance metric learning problem can beviewed as finding either M or L = M12 . Mahalanobisdistance defined in Eq. (2) expressed in terms of thematrix L is defined asdM(x,y) = dL(x,y) = ‖L>(x−y)‖2 (3)The matrix L can be used to projects the origi-nal feature space into a new embedding feature space.This projection is a linear transformation defined forfeature vector x asx′ = Lx (4)Note that the Mahanalobis distance dL(x,y) fortwo samples from the original feature space equals theEuclidean distance d(x′,y′) =√(x′−y′)> (x′−y′)4.4. Paper 4 - Improving Classification of Malware Families using Learning a DistanceMetric81in the space transformed by Eq. (4). This transfor-mation is usefull since computation of Euclidean dis-tance has lower time complexity than computation ofMahalanobis distance.In the rest of this paper, we will consider thefeature space as a real n-dimensional space Rn. Thefollowing sub



Sections briefly describe three distancemetric learning methods that we used in our experi-ments.3.1 Large Margin Nearest NeighborLarge Margin Nearest Neighbor (LMNN) (Wein-berger et al., 2006) is one of the state-of-the-artdistance metric learning algorithms used to learn aMahalanobis distance metric for KNN classification.LMNN consists of two steps. In the first step, for eachinstance, x, a set of k nearest instances belonging tothe same class as x (referred to as target neighbors)is identified. In the second step, we adapt the Maha-lanobis distance with the goal that the target neighborsare closer to x than instances from different classesthat are separated by a large margin.The Mahalanobis distance metric is estimated bysolving a semidefinite programming problem definedas:minL ∑i, j: j→i(dL(xi,x j)2 ++ µ ∑k:yi 6=ykmax(0,1+dL(xi,x j)2−dL(xi,xk)2))(5)The notation j→ i refers that the sample xj is atarget neighbor of the sample xi, and yi de

Notes theclass of xi. The parameter µ defines a trade-off be-tween the two objectives.3.2 Neighborhood Component Analysis(Goldberger et al., 2005) proposed the NeighborhoodComponent Analysis (NCA), a distance metric lear-ning algorithm specially designed to improve KNNclassification.Let pi j be the probability that the sample xi is theneighbor of the sample xj belonging to the same classas xi. This probability is defined as:pi j =exp(−||Lxi−Lx j||22)∑l 6=i exp(−||Lxi−Lxl ||22), pii = 0 (6)The goal of NCA is to find the matrix L that ma-ximizes the sum of probabilities pi:argmaxLN−1∑i=0∑j: j 6=i,y j=yipi j (7)The well-known gradient ascent algorithm is usedto solve this optimization problem. Note that bothLMNN and NCA algorithms do not make any as-sumptions on the class distributions.3.3 Metric Learning for KernelRegression(Weinberger and Tesauro, 2007) proposed MetricLearning for Kernel Regression (MLKR), which aimsat training a Mahalanobis matrix by minimizing theerror loss over the training samples:L = ∑i(yi− ŷi)2 (8)where the prediction class ŷi is derived from ker-nel regression by calculating a weighted average ofthe training samples:ŷi =∑ j 6=i y jK(xi,x j)∑ j 6=i K(xi,x j)(9)MLKR can be applied to many types of kernelfunctions K(xi,x j) and distance metrics d(x,y).Note that the mentioned distance metric learningalgorithms can be used as supervised dimensionalityreduction algorithms. Considering the matrix L ∈Rd×n with d < n then the dimension of transformedsample x′ = Lx is reduced to d.4 EXPERIMENTAL SETUPIn this 



Section, we present our dataset, describe eval-uation measures and feature selection 

Results.4.1 DatasetOur experiments are based on the dataset contain-ing 14,000 samples consisting of 6 malware familiesand benign files. The dataset is well-balanced sinceeach of the 6 malware families is of equal size, i.e.,2,000 samples, and the number of benign files is also2,000. The malicious programs were obtained from(VirusShare, 2020), an online repository containingvarious malware families. Benign files were gatheredfrom university computers. We confirm that all mali-cious samples considered in our experiments match4. Author’s Relevant Papers82known signatures from antivirus companies. Also,none of our benign programs was detected as mal-ware.In our experiments, we used the following sixprevalent malware families:Allaple – a polymorphic network worm that spreadsto other computers and performs denial-of-service(DoS) attacks.Skeeyah – a Trojan horse that infiltrates systems andsteals various personal information and adds thecomputer to a botnet.Virlock – ransomware that locks victims’ computerand demands a payment to unlock it.Virut – a virus with backdoor functionality that ope-rates over an IRC-based communications proto-col.Vundo – a Trojan horse that displays pop-up adver-tisements and also injects JavaScript into HTMLpages.Zbot – also known as Zeus, is a Trojan horse thatsteals configuration files, credentials, and bankingdetails.4.2 Evaluation MeasuresIn this 



Section, we present the metrics we used to mea-sure the performance of the classification models. In abinary classification problem, the following classicalquantities are employed:• True Positive (TP) represents the number of mali-cious samples classified as malware• True Negative (TN) represents the number of be-nign samples classified as benign• False Positive (FP) represents the number of be-nign samples classified as malware• False Negative (FN) represents the number of ma-licious samples classified as benignThe performance of binary classifiers consideredin our experiments is measured using three standardmetrics. The most intuitive and commonly used eval-uation metric is the error rate:ERR =FP+FNTP+TN+FP+FN(10)It is defined on a given test set as the percentageof incorrectly classified samples. Alternative for errorrate is accuracy defined as ACC= 1−ERR. The se-cond metric is precision, and it is defined as follows:precision =TPTP+FP(11)Precision is the percentage of samples classified asmalware that are truly malware. The third parameter,recall (or true positive rate), is defined as:recall =TPTP+FN(12)Recall is the percentage of truly malicious sam-ples that were classified as malware.In the multiclass evaluation, since all the classeshave the same number of samples, we use averagedversions of error rate, precision and recall. Averageerror rate is defined as follows:(average) ERR =1N ∑i≤N1classpred 6= classtrue (13)where N is the size of our dataset, and 1 is theindicator function. Average precision and average re-call is defined as an average resulting precisions andrecalls, respectively, across all classes.4.3 Feature SelectionThe features used in our experiments are extractedfrom the portable executable (PE) file format (Mi-crosoft, 2019), which is the file format for executa-bles, DLLs, object code, and others used in 32-bit and64-bit versions of the Windows operating system. ThePE file format is the most widely used file format formalware samples run on desktop platforms.For extracting features from PE files, we usedPython module pefile (Carrera, 2017). This modu-le extracts all PE file attributes into an object fromwhich they can be easily accessed. We extracted 358numeric features that are based on static informationonly, i.e., without running the program. The dimen-sionality is high since for each 



Section, and for eachkind of characteristics (array of flags), we considereach flag as a single feature.Before applying feature selection methods,all features were normalized using procedurepreprocessing.normalize from the Scikit-learnlibrary (Scikit-learn, 2020). We then employed thesix feature selection methods also imported from theScikit-learn library.Table 1 shows error rates of the KNN (k = 1) clas-sifier applied to the feature set reduced using the cor-responding feature selection algorithms. The lowesterror rate of 4.13% was achieved for 25 selected fea-tures by RFE Logistic Regression. The KNN for theoriginal feature set (i.e., 358 features) achieved an er-ror rate of 4.31%. All feature selection algorithmswere evaluated by 5-fold cross-validation on the ran-domly chosen training data containing 80% of thewhole dataset. The remaining 20% of the dataset was4.4. Paper 4 - Improving Classification of Malware Families using Learning a DistanceMetric83Table 1: Evaluation of the feature selection algorithms in terms of error rates of the KNN (k = 1) classifier. The abbreviationSFM refers to Scikit-learn procedure feature selection.SelectFromModel. The abbreviation RFE refers to RecursiveFeature Elimination implemented in feature selection.RFE from the Scikit-learn library as well.Error rates [%] for specific number of featuresFeature selection method 2 5 10 25 50 75Principal component analysis 11.00 5.30 4.85 4.22 4.26 4.31SFM Logistic Regression 13.61 7.90 4.76 4.20 4.29 4.31SFM Decision Tree 26.56 8.44 6.21 4.72 4.50 4.37Information Gain 15.17 8.77 7.79 5.61 4.31 4.52RFE Logistic Regression 17.08 6.49 5.30 4.13 4.29 4.31RFE Decision Tree 11.67 7.53 4.76 4.63 4.65 4.22reserved for testing the DML and ML algorithms (see



Section 5).The following Fig. 1 illustrates the performanceof RFE Logistic regression for a various number offeatures. For 50 and more features, the correspondingerror rates are approximately the same as the errorrate achieved from the original feature set (i.e., 358features).10  15 25 50 75 100 125Number of features4.24.44.64.85.05.2Error rate [%]Reduced feature setOriginal feature setFigure 1: Relation between dimensionality and error rate ofKNN classifier (k = 1).Notice that for each feature selection algorithmunder consideration, except SFM Decision Tree, weachieved a surprisingly low error rate with only twofeatures, as shown in Table 1. We will provide moreexperiments for this extremely low dimensionality in



Section 5.2.We also performed all six feature selection algo-rithms to explore an even higher number of features:100, 125, and 150. However, the corresponding er-ror rates achieved from all the feature selection algo-rithms were higher than 4.13%. As a result, in all ex-periments (except those in 



Section 5.2), we will con-sider 25 features selected by RFE Logistic regressionalgorithm. To make our 

Results reproducible, Table 2summarizes all features used in our experiments. Wekeep the name of the fields in the same form as inthe documentation (Microsoft, 2015), in order that thereader can easily find the detailed description.The field file size (size of the file on disk) is notcontained within the PE structure, and note that it dif-fers from the field SizeOfImage, which is the size ofthe image loaded in memory.PE files are divided into one or more 



Sections. The



Sections contain code, data, imports, and various cha-racteristics. PE 



Section features are considered sepa-rately for each 



Section. The order of the 



Sections isnot the same for each PE file. Moreover, malware au-thors can change the order of the 



Sections. Therefore,we prefer to consider only the order of 



Sections (ratherthan their names). The special importance among all



Sections of a PE file has the last one since it maycontain useful information, especially for some typesof malware, such as file infector, which typically at-taches malicious code at the end of the file. To dealwith a various number of 



Sections across the samples,we have decided to consider only the first four sec-tions and the last 



Section.5 EXPERIMENTAL 

ResultsThis 



Section presents multiclass classification 

Resultsbased on six base ML classifiers: k-Nearest Neigh-bor (k = 1), Logistic Regression, (Gaussian) NaiveBayes, Random Forest (number of trees in the for-est = 100), and Multilayer Perceptron (hidden layersizes=(200,100), maximum number of iterations =300, activation function = ’relu’, solver for weight op-timization = ’adam’, random number generation forweights and bias initialization = 1). Implementationsof the DML algorithms, the ML classifiers, and theclassification metrics, are based on the Scikit-learnlibrary (Scikit-learn, 2020). If not mentioned, thehyperparameters of the ML classifiers and the DMLmethods were set to their default values as set in theScikit-learn library.The input feature vectors used in the following ex-periments are described in 



Section 4.3, and its dimen-sionality is 25, except in the experiment described in



Section 5.2 where we consider only two-dimensional4. Author’s Relevant Papers84Table 2: List of 25 features selected by the RFE Logistic Regression algorithm sorted by importance. All except one (filesize) are extracted from the PE file format.Position Feature name Structure1. PointerToRawData 



Section Header (the first 



Section)2. Characteristics, flag IMAGE SCN TYPE DSECT 



Section Header (the first 



Section)3. Characteristics, flag IMAGE SCN TYPE COPY 



Section Header (the first 



Section)4. Characteristics, flag IMAGE SCN TYPE NOLOAD 



Section Header (the first 



Section)5. RVA of Exception Table Optional Header Data Directories6. PointerToRawData 



Section Header (the third 



Section)7. Characteristics, flag IMAGE SCN TYPE GROUP 



Section Header (the first 



Section)8. RVA of Certificate Table Optional Header Data Directories9. RVA of Base RelocationTable Optional Header Data Directories10. RVA of Bound Import Optional Header Data Directories11. VirtualSize 



Section Header (the first 



Section)12. SizeOfRawData 



Section Header (the first 



Section)13. Size of file not part of PE format14. VirtualAddress 



Section Header (the fourth 



Section)15. VirtualSize 



Section Header (the second 



Section)16. RVA of Import Table Optional Header Data Directories17. Characteristics, flag IMAGE SCN TYPE REG 



Section Header (the first 



Section)18. AddressOfEntryPoint Optional Header Standard Fields19. RVA of Export Table Optional Header Data Directories20. VirtualAddress 



Section Header (the first 



Section)21. RVA of TLS Table Optional Header Data Directories22. PointerToRawData 



Section Header (the second 



Section)23. VirtualAddress 



Section Header (the last 



Section)24. Size of Import Table Optional Header Data Directories25. VirtualAddress 



Section Header (the second 



Section)feature vector.All the following experiments were executed on asingle computer platform having two processors (IntelXeon Gold 6136, 3.0GHz, 12 cores each), with 32GB of RAM running the Ubuntu server 18.04 LTSoperating system.5.1 Application of Distance MetricLearning AlgorithmsIn the first set of experiments, we applied theKNN classifier using the following four distances:Euclidean (non-learned) distance, and three Maha-lanobis distances learned by three DML algorithms(separately) LMNN, NCA, and MLKR. We used 5-fold cross-validation as follows. The training dataset(80 % of the whole dataset) was randomly dividedinto five subsets of equal size, where four subsetswere used for training the DML algorithms, and onesubset was used for testing. First, the DML algorithmwas trained on the four subsets, and then KNN withlearned Mahalanobis distance metric was employedusing training and testing sets. This procedure wasrun five times with different subset reserved for tes-ting. Classification 

Results obtained for each fold arethen averaged to produce a single cross-validation es-timate.The first experiment focuses on the hyperpara-meter k that expresses the number of nearest neigh-bors considered in the KNN classifier and LMNN (thelearning rate of the optimization procedure = 10−6)algorithm. Note that both MLKR nor NCA do not de-pend on k. Fig. 2 shows the effect of k on the errorrate of the KNN using all four distances.1 3 5 7 9 11 13 15 17 19 21Number of neighbors3.54.04.55.05.56.06.57.0Error rate [%]LMNNMLKRNCAEuclideanFigure 2: The relation between the number of nearest neigh-bors (k) and error rate (ERR) compared for four distances.4.4. Paper 4 - Improving Classification of Malware Families using Learning a DistanceMetric85The KNN classifier for k = 1 with Euclidean dis-tance achieved the ERR of 3.70%. Error rates of theKNN using Mahalanobis distance learned by DML al-gorithms are equal to: 3.23% for LMNN, 3.51% forNCA, and 3.57% for MLKR.The result of distance metric learning algorithmsis n×n matrix, where n is the dimension of the featurevector. Since the number of components of the matrixto be learned grows at a quadratic rate and the size ofthe training data is fixed, we can expect that the size oftraining data stops being sufficient for high values ofn. In the next experiment, we used the Principal com-ponent analysis to reduce the data’s dimension andexamine the learning ability of distance metric learn-ing algorithms. We applied 5-fold cross-validationtechnique described above. For our fixed-size trainingdataset, the highest performance improvement gainedby using DML algorithms was achieved for the fol-lowing dimensions: n= 3 for LMNN, n= 4 for NCA,and n = 6 for MLKR. These 

Results may indicate thatconsidering 25-dimensional feature vectors used inour experiments, our dataset’s size is insufficient forlearning as many as 625 parameters (i.e., the numberof components of the matrix M).We also explored the variation of classification re-sults based on DML algorithms across six malwarefamilies and benign class. Precisions and recalls ofthe KNN classifier using the hyperparameter k = 1are summarize in Table 3. The 

Results indicate thatthe precisions and recalls corresponding to malwarefamilies depend significantly on the DML algorithms.Regarding resource usage of DML algorithms,32GB of RAM was sufficiently enough (i.e., with-out a need to use the disk as swap memory) for allconducted experiments. The average computationaltimes of the DML algorithms applied on 8,960 sam-ples are as follows: LMNN took 550 seconds, NCAtook 960 seconds, and MLKR took 4,800 seconds.5.2 Representation of Malware Familiesin Two DimensionsIn this 



Section, we examine the classification 

Resultsbased on two-dimensional feature vectors. Two of themost important features, PointerToRawData and flagIMAGE SCN TYPE DSECT (see Table 2), were se-lected by the RFE Logistic Regression and used formulticlass classification.Fig. 3 presents the effectiveness of the KNN (k =1) classification of malware families and benign filesrepresented by only two-dimensional feature vectors.While we achieved 99% accuracy for the malwarefamilies Skeeyah and Virlock, benign files’ accuracywas 58%.benignallapleskeeyah virlock virut vundo zbotPredicted labelbenignallapleskeeyahvirlockvirutvundozbotTrue label0.58 0.04 0.01 0.0 0.2 0.09 0.090.02 0.95 0.0 0.0 0.02 0.0 0.010.0 0.0 0.99 0.0 0.0 0.0 0.00.0 0.0 0.0 0.99 0.0 0.0 0.00.14 0.03 0.0 0.0 0.7 0.05 0.070.06 0.0 0.0 0.0 0.04 0.87 0.020.08 0.01 0.0 0.0 0.06 0.01 0.84Normalized Confusion Matrix0.00.20.40.60.8Figure 3: Normalized confusion matrix comparing the ac-curacy of KNN (k= 1) using Euclidean distance for six mal-ware families and benign samples.Two-dimensional representation of feature vectorsallows us to show malware families as points in theplane. Three malware families, Allaple, Virut, andVundo, are illustrated in Fig. 4. One hundred sampleswere chosen randomly from each of these classes,and we achieved the average classification accuracyof 92.00%.0.00 0.05 0.10 0.15 0.20 0.25PointerToRawData (normalized)0.00.10.20.30.40.5IMAGE_SCN_TYPE_DSECT (normalized)allaplevirutvundoFigure 4: Three malware families: Allaple, Virut, andVundo represented in two dimensions.5.3 Comparison with theState-of-the-Art ML AlgorithmsIn the last experiment, LMNN, NCA, and MLKRmethods (each separately) were used to transform thedata, as it is shown in Eq. (4) in 



Section 3. We com-pared the performance of the state-of-the-art ML al-gorithms for original (non-transformed) data and forthe transformed data. Table 4 shows that the high-4. Author’s Relevant Papers86Table 3: KNN (k = 1) classification 

Results of particular malware families and class of benign samples.Precision [%] Recall [%]class Euclid LMNN NCA MLKR Euclid LMNN NCA MLKRallaple 98.58 98.79 92.32 92.39 98.42 98.49 92.60 91.69benign 94.48 94.24 99.24 99.09 92.08 92.15 97.47 97.47skeeyah 99.36 98.45 98.88 98.41 98.89 98.30 99.04 99.04virlock 98.79 99.55 99.72 100 99.39 99.40 99.15 99.15virut 97.24 96.51 97.38 96.19 95.44 97.07 96.49 96.49vundo 95.38 97.26 94.85 95.27 98.07 97.71 98.43 98.11zbot 92.65 92.59 93.03 93.50 94.21 94.34 92.33 93.08Averaged 96.64 96.77 96.49 96.41 96.64 96.78 96.50 96.43Table 4: Classification 

Results of DML algorithms evaluated for several state-of-the-art ML algorithms.Average precision [%] Average recall [%]KNN LR NB DT RF MLP KNN LR NB DT RF MLPoriginal 96.15 86.38 82.98 94.76 96.44 96.22 96.14 86.17 77.79 94.78 96.41 96.17LMNN 96.77 89.55 82.02 95.20 97.05 96.39 96.78 89.27 81.03 95.20 97.00 96.35NCA 96.45 90.78 78.08 94.87 96.76 95.11 96.46 90.60 75.02 94.86 96.72 95.07MLKR 97.04 87.94 77.96 95.15 97.05 96.50 97.04 88.12 75.41 95.13 97.02 96.49est average precision of 97.05% was achieved usingRandom Forest on the data transformed by LMNN orby MLKR. The KNN classifier achieved the highestaverage recall of 97.04% on the data transformed byMLKR.Regarding original (non-transformed) data, thehighest average precision of 96.44% and the highestaverage recall of 96.41% among base ML algorithmswere both achieved by Random Forest.Focusing on the KNN (k = 1) classifier, any ofthe three DML methods achieved better classifica-tion 

Results (both average precision and recall) thanthe KNN classifier using common (non-learned) Eu-clidean distance. Regarding the Naive Bayes classi-fier, we achieved a very low precision of 54.53% forVundo and a very low recall of 47.02% for Zbot com-pared to other ML classifiers. These two 

Results causethat average precision and recall for Naive Bayes aresignificantly lower compared to other ML algorithms.6 



ConclusionsIn this paper, we employed three distance metriclearning algorithms to learn the Mahalanobis dis-tance metric to improve multiclass classification per-formance for our dataset containing six prevalent mal-ware families and benign files. We classified thepreviously unseen samples using the KNN classifierwith the learned distance and achieved significantlybetter 

Results than using common (non-learned) Eu-clidean distance. The classification 

Results demon-strate that DML-based methods outperform any of thestate-of-the-art ML algorithms considered in our ex-periments. Our 

Results indicate that the classificationperformance based on DML methods could be furtherimproved if we use a larger dataset for training thedistance metric. Another experiment was concernedwith low-dimensional representations of the input fea-ture space. We achieved surprisingly good classifica-tion 

Results even for two-dimensional feature vectors.In 



Future Work, other types of features, such asbyte sequences, opcodes, API and system calls, andothers, could be used and possibly improve the classi-fication 

Results. It would also be interesting to explorethe application of distance metric learning algorithmsto clustering into malware families.



AcknowledgementsThe authors acknowledge the support of the OP VVVMEYS funded project CZ.02.1.01/0.0/0.0/16 019/0000765 ”Research Center for Informatics”.



ReferencesAhmadi, M., Ulyanov, D., Semenov, S., Trofimov, M., andGiacinto, G. (2016). Novel feature extraction, selec-tion and fusion for effective malware family classifi-cation. In Proceedings of the sixth ACM conferenceon data and application security and privacy, pages183–194.Basole, S., Di Troia, F., and Stamp, M. (2020). Multifamilymalware models. Journal of Computer Virology andHacking Techniques, pages 1–14.Carrera, E. (2017). Pefile. https://github.com/erocarrera/pefile.4.4. Paper 4 - Improving Classification of Malware Families using Learning a DistanceMetric87Goldberger, J., Hinton, G. E., Roweis, S. T., and Salakhutdi-nov, R. R. (2005). Neighbourhood components anal-ysis. In Advances in neural information processingsystems, pages 513–520.Islam, R., Tian, R., Batten, L. M., and Versteeg, S. (2013).Classification of malware based on integrated staticand dynamic features. Journal of Network and Com-puter Applications, 36(2):646–656.Jureček, M. and Lórencz, R. (2018). Malware detectionusing a heterogeneous distance function. Computingand Informatics, 37(3):759–780.Jureček, M. and Lórencz, R. (2020). Distance metriclearning using particle swarm optimization to improvestatic malware detection. In Int. Conf. on InformationSystems Security and Privacy (ICISSP), pages 725–732.Kong, D. and Yan, G. (2013). Discriminant malware dis-tance learning on structural information for automatedmalware classification. In Proceedings of the 19thACM SIGKDD international conference on Knowl-edge discovery and data mining, pages 1357–1365.ACM.Lakhotia, A., Walenstein, A., Miles, C., and Singh, A.(2013). Vilo: a rapid learning nearest-neighbor classi-fier for malware triage. Journal of Computer Virologyand Hacking Techniques, 9(3):109–123.Microsoft (2019). Pe format - win32 apps.https://docs.microsoft.com/en-us/windows/win32/debug/pe-format.Microsoft (Revision 9.3, 2015). Visual studio, microsoftportable executable and common object file formatspecification.Mohaisen, A., Alrawi, O., and Mohaisen, M. (2015).Amal: High-fidelity, behavior-based automated mal-ware analysis and classification. computers & secu-rity, 52:251–266.Scikit-learn (2020). scikit-learn.org. https://scikit-learn.org/.VirusShare (2020). Virusshare.com. http://virusshare.com/.Wadkar, M., Di Troia, F., and Stamp, M. (2020). Detect-ing malware evolution using support vector machines.Expert Systems with Applications, 143:113022.Weinberger, K. Q., Blitzer, J., and Saul, L. K. (2006). Dis-tance metric learning for large margin nearest neigh-bor classification. In Advances in neural informationprocessing systems, pages 1473–1480.Weinberger, K. Q. and Tesauro, G. (2007). Metric learn-ing for kernel regression. In Artificial Intelligence andStatistics, pages 612–619.Wettschereck, D., Aha, D. W., and Mohri, T. (1997). Areview and empirical evaluation of feature weightingmethods for a class of lazy learning algorithms. Arti-ficial Intelligence Review, 11(1-5):273–314.Wilson, D. R. and Martinez, T. R. (1997). Improved het-erogeneous distance functions. Journal of artificialintelligence research, 6:1–34.4. Author’s Relevant Papers884.5. Paper 5 - Application of Distance Metric Learning to Automated Malware Detection4.5 Paper 5 - Application of Distance Metric Learning toAutomated Malware DetectionMgr. Martin Jureček (80%), prof. Ing. Róbert Lórencz, CSc. (20%)This paper was submitted to the journal IEEE Access on 2nd February.This paper presents the malware detection model based on distance metric learning.The detection system processed the data from PE file format where numeric features arenormalized and nominal features are turned to conditional probabilities. Training sampleswere firstly used to train distance metric, and then the same samples were used in KNNclassifier with already learned distance metric to classify testing samples.The paper describes the proposed approach based on the KNN classifier using weightedEuclidean distance learned by the modification of the PSO algorithm that was proposedin Paper 2. This approach was compared with three distance metric learning algorithmsapplied in experiments from Paper 4.In addition, the paper focuses on the problem of detecting as much malware as possiblewhile keeping a low false positive rate. Insufficiently low false positive error is consideredseriously in the antivirus industry. An optimization criterion based on an error rate, andmodification of the LMNN method, are proposed to penalize false positives.89Date of publication xxxx 00, 0000, date of current version xxxx 00, 0000.Digital Object Identifier 10.1109/ACCESS.2017.DOIApplication of Distance Metric Learningto Automated Malware DetectionMARTIN JUREČEK1 and RÓBERT LÓRENCZ11Department of Information Security, Faculty of Information Technology, Czech Technical University in Prague, 160 00 Prague, Czech RepublicCorresponding author: Martin Jureček (e-mail: jurecmar@fit.cvut.cz).The authors acknowledge the support of the OP VVV MEYS funded project CZ.02.1.01/0.0/0.0/16 019/0000765 "Research Center forInformatics".



Abstract The goal of distance metric learning is to find the most appropriate distance metricparameters to improve similarity-based models, such as k-Nearest Neighbors or k-Means. In this paper,we applied distance metric learning for the problem of malware detection. We focused on two tasks:(1) to classify malware and benign files with a minimal error rate, (2) to detect as much malware aspossible while maintaining a low false positive rate. We proposed a malware detection system using ParticleSwarm Optimization that finds the feature weights to optimize the similarity measure. We compared theperformance of the approach with three state-of-the-art distance metric learning techniques. We found thatmetrics trained in this way lead to significant improvements in the k-Nearest Neighbors classification. Weconducted and evaluated experiments with more than 150,000 Windows-based malware and benign samples.Features consisted of metadata contained in the headers of executable files in the PE file format. Ourexperimental 

Results showed that our malware detection system based on distance metric learning achieves a1.09% of error rate at 0.74% of false positive rate (FPR) and outperformed all machine learning algorithmsconsidered in the experiment. Considering the second task related to keeping minimal FPR, we achieved a1.15% of error rate at only 0.13% of FPR.INDEX TERMS Distance metric learning, Malware detection, Particle Swarm Optimization, k-NearestNeighbors.I. 



IntroductionThe term malware, or malicious software, is defined as anysoftware that does something that causes detriment to theuser. Malware includes viruses, worms, trojan horses, rootk-its, spyware, and any other program that exhibits maliciousbehavior [1]. In information security, malware attacks areone of the main threats over the past several decades. Whilemalware developers continuously find new exploitable vul-nerabilities, create more and more sophisticated techniques toavoid detection, and find new infection vectors, on the otherhand malware analysts and researchers continually improvetheir defenses. This game seems to have an infinite numberof rounds.The attacker’s purpose is no longer to cause detriment,such as damaging a computer system and not getting money.Nowadays, malware has become a rather profitable business.Malware writers use a variety of techniques to distributemalicious programs and infect devices. They can use self-propagation mechanisms based on various vulnerabilitiesor use social engineering to trick the user into installingthe malware. Malware writers usually employ obfuscationtechniques [2] such as encryption, binary packers, or self-modifying code to evade malware classifiers. Many mal-ware researchers have focused on data mining and machinelearning (ML) algorithms to defeat these techniques and todetect unknown malware. The performance of many MLalgorithms, such as k-Nearest Neighbors (KNN) or k-Means,depends on the distance metric used to measure dissimilaritybetween samples over some input space. The distance be-tween two samples having the same class label must be min-imized, while the distance between two samples of differentclasses must be maximized.Distance metric learning (DML) aims to automaticallylearn distance metric parameters from data to improvethe performance of classification and clustering algorithms.Finding the most appropriate parameters of the metric con-cerning some optimization criterion is typically formulatedas an optimization problem. Evolutionary algorithms, swarmVOLUME 4, 2016 14. Author’s Relevant Papers90algorithms, and other heuristics [3] are suitable for thisproblem. In this work, we used a biologically-motivatedalgorithm, Particle Swarm Optimization (PSO), to handle thisproblem related to malware detection.Most distance metric learning methods learn a Maha-lanobis distance concerning some objective function. Thedefinition of this objective function depends on the trainingdataset and specific tasks, such as classification or clustering.Malware detection can be defined as a classification problemwith two classes: malware and benign samples. The morechallenging problem is to cluster malware into malwarefamilies [4]. In this work, we empirically demonstrated howto apply distance metric learning on malware detection usinga KNN classifier. We experimented with different distancemetric learning methods and evaluated them concerning var-ious optimization criteria, such as error rate or its modifica-tion.In this work, we consider portable executables in theWindows environment. Features consist of metadata fromportable executable (PE) file format [5]. Our proposed detec-tion model is based only on static malware analysis, aimingto search for information about the file structure withoutrunning a program. While the static analysis can be evadedby anti-malware techniques, such as obfuscation, it still has aplace in the malware detection system since it is much fasterthan dynamic analysis, which involves running the program.High malware detection accuracy is not the only goal of theclassification models from the antivirus vendors’ perspective.In practice, a false positive error is considered seriously sincebenign software owners could complain that their productwas detected as malware, which potentially can ruin theirbusiness. For this reason, we proposed an optimization cri-terion that takes into account the cost of false positives.The main contributions of our work are as follows:Architecture of malware detection system: We proposedthe architecture of the malware detection model based ondistance metric learning. The detection system processedthe data from PE file format where numeric features arenormalized, and nominal features are turned to conditionalprobabilities. Training samples are firstly used to train dis-tance metric, and then they are used in KNN classifier withalready learned distance metric to classify testing samples.Scalable optimization criterion for PSO-based model:To consider the higher cost of false positive, we constructeda cost function called weighted error rate which we used as afitness function in the PSO algorithm to minimize error rateand false positive rate.Application of DML algorithms to malware detection:We explored the use of three state-of-the-art distance metriclearning algorithms, namely Large Margin Nearest Neighbor,Neighborhood Component Analysis, and Metric Learning forKernel Regression, for KNN classification of malware and le-gitimate software. We compared these models with the PSO-based model and provided practical information concerningperformance, computational time, and resource usage. Weshowed that the DML-based methods might improve mal-ware classification 

Results even when standard methods suchas feature selection or algorithm tuning were already applied.The rest of the paper is organized as follows. 



Section IIreviews recent works on malware detection based on machinelearning techniques. In 



Section III, we define the distancemetric learning problem, and we give some theoretical back-ground. Our proposed malware detection model is presentedin 



Section IV. 



Section V provides an experimental setup.Detailed information about experiments and 

Results is pre-sented in 



Section VI. 

Conclusion and 



Future Work are givenin 



Section VII.II. RELATED WORKThis 



Section briefly reviews some recent works related tomalware detection based on machine learning techniques. Wemainly focus on works using static analysis of Windows PEfiles.The application of machine learning techniques to mal-ware detection has been an active research area for aboutthe last twenty years. Researchers have tried to apply variouswell-known techniques such as Neural Networks, DecisionTrees, Support Vector Machines, ensemble methods, andmany other popular machine learning algorithms. Recentsurvey papers [6], [7] provide comprehensive informationon malware detection techniques using machine learningalgorithms.Wadkar et al. [8] proposed the system based on static fea-tures extracted from PE files for detecting evolutionary mod-ifications within malware families. Support Vector Machines(SVM) models were trained over a sliding time window, andthe differences in SVM weights were quantified using χ2statistic. For most of all 13 malware families considered inthe experiments, the system detected significant changes.Yang and Liu [9] proposed a detection model called Tun-ingMalconv with two layers: raw bytes model in the firstlayer and gradient boosting classifier in the second layer.The feature set was based on static analysis and consistedof raw bytes, n-grams of byte codes, string patterns, andinformation in the PE header. The experimental 

Results of theTuningMalconv detection model on the dataset with 41,065samples showed an accuracy of 98.69%.Another malware detection model based on static analysiswas proposed by Gao et al. [10]. The detection model isbased on semi-supervised transfer learning and was deployedon the cloud as a SaaS (Software as a Service). The detectionmodel was evaluated on Kaggle malware datasets, and itimproved classification accuracy from 94.72% to 96.90%.Xue et al. [11] proposed a classification system Malscore,which combine static and dynamic analysis. In static analy-sis, grayscale images were processed by the ConvolutionalNeural Network. In dynamic analysis, API call sequenceswere represented as n-grams and analyzed using five ma-chine learning algorithms: Support Vector Machine, RandomForest, Adaboost, Naïve Bayes, and k-Nearest Neighbors.The authors performed experiments on more than 170,0002 VOLUME 4, 20164.5. Paper 5 - Application of Distance Metric Learning to Automated Malware Detection91malware samples from 63 malware families and achieved98.82% of malware classification accuracy.Zhong and Gu [12] improved the performance of deeplearning models by organizing them to the tree structurecalled Multiple-Level Deep Learning System (MLDLS).Each deep learning model focuses on a specific malwarefamily. As a result, the MLDLS can handle complex mal-ware data distribution. Experimental 

Results indicate that theproposed method outperforms the Support Vector Machine,Decision Tree, the single Deep Learning method, and anensemble-based approach.All information on executables used in work proposed byRaff et al. [13] was from the PE header, more specifically,from MS-DOS, COFF, and Optional Header. Neural net-works were learned from raw bytes, which were not parsed toexplicit features, and as a result, no preprocessing nor featureengineering was required. More than 400,000 samples wereused for training, and the Fully Connected Neural Networkmodel achieved the highest accuracy.Kolosnjaji et al. [14] proposed neural network architecturethat combines convolutional and feedforward neural layers.The authors used only static malware analysis where inputs tofeedforward layers were fields of the PE header, while inputsto convolutional layers were assembly opcode sequences.The proposed hybrid neural network achieved 93% on pre-cision and recall.Surprisingly, there is a lack of experimentation with dis-tance metric learning techniques applied on large and real-world data sets from the Windows environment. In the restof the 



Section, we briefly mention two of our previous workson malware detection methods that rely on distance metriclearning. This paper can be considered as an extension ofthe two following works. In [15], we applied the ParticleSwarm Optimization algorithm to the problem of findingthe appropriate feature weights used in the heterogeneousdistance function [16] specially defined for the PE file formatto classify malware and benign files. We showed that the errorrate of the KNN classifier could be decreased by 12.77%using the weighted distance function. Our other work [4]focused on the application of three distance metric learningmethods applied to multiclass classification problem withseven classes: six prevalent malware families and benignfiles. Using Metric Learning for Kernel Regression methodto learn Mahalanobis distance metric, we achieved averageprecision and recall, both of 97.04%, evaluated with k-Nearest Neighbors classifier.III. PROBLEM STATEMENT AND 

BackgroundThis 



Section provides basic information on distance metriclearning and briefly discusses three selected distance metriclearning methods used in our experiments.Euclidean distance is by far the most commonly useddistance. Let x and y be two feature vectors from realn−dimensional space Rn, and let wi, i = 1, . . . , n, be a non-negative real number associated with the i-th feature. Theweighted Euclidean distance is defined as follows:dw(x,y) =√√√√n∑i=1w2i (xi − yi)2 (1)The goal of learning the weighted Euclidean distance is tofind an appropriate weight vector w = (w1, . . . , wn) con-cerning some optimization criterion, usually minimizing er-ror rate. Several other distance functions have been presented[17]. In order to improve 

Results, many weighting schemeswere proposed. A review of feature weighting methods forlazy learning algorithms was proposed in [18].Mahalanobis distance is another popular distance. It isdefined for two vectors x,y ∈ Rn of dimension n asdM(x,y) =√(x− y)>M (x− y) , (2)where M is a positive semidefinite matrix. Mahalanobisdistance can be considered as a generalization of Euclideandistance, since if M is the identity matrix, then dM in Eq. (2)is reduced to common Euclidean distance. If M is diagonal,then this corresponds to learning the feature weights Mii =wi defined for weighted Euclidean distance in Eq. (1).The goal of learning the Mahalanobis distance is to findan appropriate matrix M concerning some optimization cri-terion. Regarding the KNN classifier, the goal can be definedas to find a matrix M which is estimated from the training set,leading to the lowest error rate of the KNN classifier. Since apositive semidefinite matrix M can always be decomposed asM = L>L, distance metric learning problem can be viewedas finding either M or L = M12 . Mahalanobis distancedefined in Eq. (2) expressed in terms of the matrix L isdefined asdM(x,y) = dL(x,y) = ‖L>(x− y)‖2 (3)Another application of distance metric learning is dimen-sionality reduction. The matrix L can be used to project theoriginal feature space into a new embedding feature space.This projection is a linear transformation defined for featurevector x asx′ = Lx (4)Mahalanobis distance of two points x,y from the originalspace defined in Eq. (2) corresponds to the Euclidean dis-tance between transformed points x′ = Lx,y′ = Ly definedas follows:dL(x,y) = ‖L>(x− y)‖2 =√(x′ − y′)> (x′ − y′) (5)This transformation is useful since the computation of Eu-clidean distance has lower time complexity than Mahalanobisdistance computation.Distance metric learning has attracted a lot of attention inthe machine learning field and is still an active research area[19]. There have been proposed many methods [20], [21],[22]. Next, we briefly describe three state-of-the-art distancemetric learning methods that we used in our experiments.In this work, weighted Euclidean distance was learned byVOLUME 4, 2016 34. Author’s Relevant Papers92the Particle Swarm Optimization algorithm, and Mahalanobisdistance was learned by the distance metric learning methodsdescribed in the rest of this 



Section.A. LARGE MARGIN NEAREST NEIGHBORLarge Margin Nearest Neighbor (LMNN) [23] is one of thestate-of-the-art distance metric learning algorithms used tolearn a Mahalanobis distance metric for KNN classification.LMNN consists of two steps. In the first step, for eachinstance, x, a set of k nearest instances belonging to thesame class as x (referred as target neighbors) is identified.In the second step, we adapt the Mahalanobis distance toreach the goal that the target neighbors are closer to x thaninstances from different classes separated by a large margin.The Mahalanobis distance metric is estimated by solvingsemidefinite programming problem defined as:minL∑i,j:j i(dL(xi,xj)2 ++ µ∑k:yi 6=yk[1 + dL(xi,xj)2 − dL(xi,xk)2]+)(6)The notation j  i reffers that the sample xj is a targetneighbor of the sample xi, and yi de

Notes the class of xi. Theparameter µ defines a trade-off between the two objectives:1) to minimize distances between samples xi and theirtarget neghbors xj,2) to maximize distances between samples xi and theirimpostors xk which are samples which belong amongthe nearest neighbors of xi and have different classlabels (i.e. yi 6= yk ).Finally, [x]+ is defined as the hinge-loss, i.e. [x]+ =max{0, x}. In [24], LMNN was extended to multiple localmetrics, and the learning time of LMNN was reduced usingmetric ball trees.B. NEIGHBORHOOD COMPONENT ANALYSISGoldberger et al. [25] proposed the Neighborhood Compo-nent Analysis (NCA), which is a distance metric learningalgorithm specially designed to improve KNN classification.Let pij be the probability that the sample xi is the neighborof the sample xj belonging to the same class as xi. Thisprobability is defined as:pij =exp(−||Lxi − Lxj ||22)∑l 6=i exp(−||Lxi − Lxl||22), pii = 0 (7)The goal of NCA is to find the matrix L that maximisesthe sum of probabilities pi:argmaxL∑i∑j:j 6=i,yj=yipij (8)The gradient ascent algorithm solves this optimizationproblem. Both LMNN and NCA algorithms do not make any



Assumptions on the class distributions.C. METRIC LEARNING FOR KERNEL REGRESSIONWeinberger et al. proposed Metric Learning for Kernel Re-gression (MLKR) [26], which aims at training a Mahalanobismatrix by minimizing the error loss over the training samples:L =∑i(yi − ŷi)2, (9)where the prediction class ŷi is derived from kernel re-gression by calculating a weighted average of the trainingsamples:ŷi =∑j 6=i yjK(xi,xj)∑j 6=iK(xi,xj)(10)MLKR can be applied apply to many types of kernelfunctions K(xi,xj) and distance metrics d(xi,xj).Recall that the mentioned distance metric learning algo-rithms can be used as supervised dimensionality reductionalgorithms. Considering the matrix L ∈ Rd×n with d < nthen the dimension of transformed sample x′ = Lx isreduced to d.IV. PROPOSED MODELIn this 



Section, we describe our proposed malware detectionmodel based on distance metric learning. First, the featuresdescription and engineering are provided. Then we describethe modification of the Particle Swarm Optimization algo-rithm, which we used to find appropriate feature weights ofweighted Euclidean distance. Finally, we complete this sec-tion by proposing the architecture of the malware detectionmodel.A. FEATURE DESCRIPTIONThe features used in our experiments are extracted from theportable executable (PE) file format [5], which is the fileformat for executables, DLLs, object code, and others used in32-bit and 64-bit versions of the Windows operating system.PE file format is the most widely used file format for malwaresamples run on desktop platforms. Before describing thefeatures used in our experiments, let us first examine the shortoutline of the PE file format.A PE file consists of headers and 



Sections that encapsulatethe information necessary to manage the executable code.The PE file header provides all the descriptive informationconcerning the locations and sizes of structures in the PEfile to the loader process. The header of a PE file consistsof the DOS header, the PE signature, the COFF file header,the optional header, and the 



Section headers. The optionalfile header is followed immediately by the 



Section headers,which provide information about 



Sections, including loca-tions, sizes, and characteristics.



Sections divide the file content into code, resources, andvarious types of data. The order of the 



Sections is not thesame for each PE file. Moreover, malware authors can changethe order of the 



Sections. Therefore, we prefer to consideronly the order of 



Sections rather than the name of the 



Sections4 VOLUME 4, 20164.5. Paper 5 - Application of Distance Metric Learning to Automated Malware Detection93(such as .text, .data, .rsrc). The special importance among all



Sections of a PE file has the last one. It may contain usefulinformation, especially for some types of malware, such asfile infector, which typically attaches malicious code at theend of the file. To deal with a various number of 



Sectionsacross the samples, we have decided to consider only the firstfour 



Sections and the last 



Section.Based on our empirical studies and the PE format analysis,we selected a set of static features that help to distinguishmalware and benign files. The features used in our experi-ments are of three types: nominal, numeric, and bit fields. Inthe following 



Section, we describe how these three types offeatures were preprocessed.Let T = {(x1, c1), . . . , (xm, cm)} be the training set,where xi is a feature vector and ci = cl(xi) is the corre-sponding class label. In our binary classification task we willconsider two classes C and M, where C de

Notes the classof benign samples andM de

Notes the class of malware. Leteach sample is represented by the feature set {f1, . . . , fn}.Let the feature fj be nominal, and let s be the feature vectorcorresponding to some unknown sample. Then P (cl(s) =M|fj = h) de

Notes the conditional probability that theoutput class of s is malware given that feature fj has the valueh.Using data from training set T,we estimate this probabilityasP (cl(s) =M|fj = h) =nfj ,h,Mnfj ,h, (11)where• nf,x,c is the number of samples in training set T whichhave value x for feature f and the sample belongs toclass c,• nf,x is the number of samples in T that have value x forfeature f .If some feature vector s from the testing set would havepreviously unseen value h of some feature fj then we setP (cl(s) =M|fj = h) = P (cl(s) =M) ≈ 1/2with respect to our dataset.Following this approach, for each sample s, we transformeach value h of each nominal attribute fj according to thefollowing rule:h 7−→ P (cl(s) =M|fj = h) (12)Regarding numeric features, it is necessary to take intoaccount their different ranges. Therefore the following datanormalization method is employed on each numeric featuref to rescale its original value h using min-max normalization.For each feature vector s, we transform each value h of eachnumeric feature f according to the following rule:hnorm =h− fminfmax − fmin, (13)where fmin, resp. fmax, is minimal, resp. maximal valueamong all known values of the feature f .To handle features that are bit arrays (b1, . . . , bk), we splitup each component bi from the array and consider it asan independent feature. Finally, after preprocessing all threetypes of features, we applied several feature selection andextraction algorithms and selected the most relevant features.B. FINDING THE FEATURE WEIGHTS USING PARTICLESWARM OPTIMIZATIONParticle Swarm Optimization (PSO) [27] is a biologically-motivated stochastic optimization algorithm based on swarmintelligence. Each particle is represented as a point in thesearch space, and a fitness function determines the qualityof each point. Each particle updates its position, which isinfluenced by the current velocity, the previous best particle’sposition, and the most successful particle in the swarm.Concept and notation of the PSO elements concerningfinding the feature weights used in weighted Euclidean dis-tance Eq. (1) in KNN classification is as follows:• particle is represented as a vector of weights w. Thecurrent position of i-th particle is denoted by xi and vide

Notes its current velocity.• swarm or population is an array of all particles consid-ered in the PSO algorithm.• local best position pi of i-th particle is its best posi-tion among all positions visited so far, and pbesti isthe corresponding value of the fitness function f , i.e.pbesti = f(pi).• global best position pg is the position of the mostsuccessful particle in the swarm, and gbesti = f(pg).• fitness function f is an objective function used to mea-sure the quality of a particle. In our malware detectionproblem, the optimization criterion can be defined as theerror rate of the KNN classifier. In this work, we willalso consider another optimization criterion focused onminimizing the false positive rate.The PSO algorithm has three inputs: fitness function f , atraining set Tpso, and vector p of feature importance scores[28] achieved from the feature selection algorithm. Thepseudocode of the modified PSO algorithm is presented inAlgorithm 1.Rand(0, ε) represents a vector of random numbers uni-formly distributed in [0, ε], where ε is a small constant.Operation ⊗ de

Notes component-wise multiplication. Notethat each particle can memorize its best previous position,and it also knows the best position of the whole swarmso far. Each component of velocity v is kept in the range[−Vmax, Vmax], where parameter Vmax influences searchability of the particles. An inertia weight ω is used to bettercontrol the search scope and reduce the importance of Vmax.Higher values of ω tend to global search while lower valuestend to local search. Parameters φ1 and φ2 represent theweights, and they are used to balance the global and the localsearch. The purpose of the initialization is in the accelerationof PSO, i.e., reducing the searching space is done using thefeature selection algorithm 

Results.This work concerns the classification problem where thedefinition of the fitness function depends on the KNN clas-VOLUME 4, 2016 54. Author’s Relevant Papers94Algorithm 1 PSO algorithmInput: fitness function f , Tpso, pOutput: vector of weights1: initialize particles:xi = p⊗Rand(0, ε1)vi = Rand(−ε2, ε2)2: repeat3: for each particle xi do4: compute fitness function f(xi)5: if f(xi) > pbesti then6: pbesti = f(xi)7: pi = xi8: end if9: end for10: select the most successful particle in swarm so far, anddenote it by pg11: for each particle xi do12: vi = ωvi+Rand(0, φ1)⊗(pi−xi)+Rand(0, φ2)⊗(pg − xi)13: xi = xi + vi14: end for15: until maximum number of iterations is attained16: return global best positionsifier. The fitness function of the clustering problem canalternatively be defined using purity or silhouette coefficient.The PSO was chosen among other optimization heuristicsbecause its convergence rate is fast, and the algorithm iseasy to implement and execute in parallel. The drawback ofthe algorithm is that it is vulnerable to stuck into the localminima.In the rest of this 



Section, we propose optimization criteriafor detecting as much malware as possible while keeping alow false positive rate. To consider different costs of a falsepositive and false negative, we adjust the loss function thatpenalized false positives.Since our dataset is well-balanced, we consider the errorrate as the appropriate measure of performance. The errorrate is defined as the percentage of incorrectly classifiedinstances. We can rewrite the error rate in terms of thenumber of false positives (FP) and number of false negatives(FN) asERR =FP + FN|Ttest|, (14)where |Ttest| is number of testing samples. We modify Eq.(14) by adding the parameter c > 1, which corresponds tothe cost for false positive. Then we define the optimizationcriterion called weighted error rate (WERR), which takesinto account the cost of false positive:WERR =c FP + FN|T |+ (c− 1)FP (15)One interpretation of WERR is that if we would changeparameters of the classifier and achieve the same error rate(with possibly different FPnew and FNnew than the previousvalues FPold and FNold corresponding to original parame-ters) then these 

Results will be better with respect to WERRifc FPnew − FPold < FNold − FNnew (16)One point of view on the WERR criterion is that we agreeto "exchange" one false positive for c false negatives whilekeeping the error rate unchanged. Note that when c = 1,then WERR is equal to the error rate. In all experiments, weused the WERR criterion as a fitness function of the PSOalgorithm. When not mentioned, the value of the parameter cwas set to one.C. ARCHITECTUREWe present the malware detection system based on distancemetric learning. The system uses static analysis of PE fileheaders and 



Sections. The proposed architecture is depictedin Fig. 1 and outlined in the following seven basic steps:Step 1: Splitting the data. The set of samples is randomlydivided into the training set and testing set. The training setis used for training a distance metric and classifier.Step 2: Parsing binaries. For each sample, we extract andstore information from PE file format. These features will bepreprocessed in the following two steps, and relevant featuresonly will be selected and considered in experiments.Step 3: Preprocessing of features. Conditional probabil-ity P (x is malware|xi = h) is computed for each nominalfeature xi and for each value h of the feature xi appearedin training set. Numeric features are normalized accordingto min-max normalization. Bit arrays are split up into singleboolean features.Step 4: Feature selection. Feature selection algorithm isused to determine the relevant features and produced the finalversion of the feature set.Step 5: Learning the distance metric. The distance metriclearning method is applied to training feature vectors toproduce appropriate distance metric parameters. In the caseof high computational complexity, only a subset of trainingvectors can be used to learn distance metric.Steps 6: Classification. Distance metric learned in theprevious step is used in the KNN classifier to classify samplesfrom the testing set.Steps 7: Evaluation: Performance metrics are used tomeasure classification 

Results.Computing the conditional probabilities for nominal fea-tures and performing feature selection algorithm for all threetypes of features are done only to the training samples. Thecorresponding conditional probabilities and selected featuresare applied to design training and testing feature vectors.V. EXPERIMENTAL SETUPIn this 



Section, we present a detailed description of theexperimental setup. First, we introduce the dataset used inour experiments. Then, we describe performance metrics andpresent the 

Results of feature selection.6 VOLUME 4, 20164.5. Paper 5 - Application of Distance Metric Learning to Automated Malware Detection95metriclearningClassification EvaluationweightsFeatureselectionParsingbinarynumericSplitting datasetConditionalprobabilitiesnominalDistancefilesParsingbinaryfilesTrainingPE filesPE filesfeaturevectorsTrainingfeaturevectorsTestingTestingFIGURE 1: Architecture of our proposed malware detection model using distance metric learning.A. DATASET AND IMPLEMENTATIONWe validated our approach using datasets containing real-world data from 150,145 Windows programs in the PE fileformat, out of which 74,978 are malicious, and 75,167 arebenign programs. The malicious and benign programs wereobtained from the industrial partner’s laboratory, and theVirusshare repository [29]. We confirm that all malicioussamples considered in our experiments match known signa-tures from anti-virus companies. Also, none of our benignprograms was detected as malware.For extracting features from PE files, we used Python mod-ule pefile [30]. This module extracts all PE file attributesinto an object from which they can be easily accessed. Weextracted 370 features based on static information only, i.e.,without running the program. The dimensionality is highsince, in each 



Section, flags of each kind of characteristic (i.e.,an array of flags) were considered as single features.Our implementations of the feature selection algorithms,DML algorithms, the ML classifiers, and the classificationmetrics are based on the Scikit-learn library [31]. If notmentioned, the hyperparameters of the ML classifiers and theDML methods were set to their default values as set in theScikit-learn library.Our implementation was executed on a single computerplatform having two processors (Intel Xeon Gold 6136,3.0GHz, 12 cores each), with 64 GB of RAM running theUbuntu server 18.04 LTS operating system. Note that mem-ory usage was not exceeded in each experiment conducted inthis work.B. PERFORMANCE METRICSThis 



Section presents the performance metrics we used tomeasure the accuracy of our proposed approach. For eval-uation purposes, the following classical quantities are em-ployed:• True Positive (TP) represents the number of malicioussamples classified as malware• True Negative (TN) represents the number of benignsamples classified as benign• False Positive (FP) represents the number of benignsamples classified as malware• False Negative (FN) represents the number of malicioussamples classified as benignThe performance of our classifier on the test set is mea-sured using three standard metrics. The most intuitive andcommonly used evaluation metric in machine learning is theerror rate (ERR):ERR =FP + FNTP + TN+ FP + FN(17)It is defined on a given test set as the percentage of incor-rectly classified instances. Alternative for ERR is accuracydefined as ACC = 1−ERR. The second parameter, TruePositive Rate (TPR) (or detection rate), is defined as:TPR =TPTP + FN(18)TPR is the percentage of truly malicious samples that wereclassified as malware. The third parameter is False PositiveRate (FPR), and it is defined as follows:FPR =FPTN+ FP(19)FPR is the percentage of benign samples that were wronglyclassified as malware.C. FEATURE SELECTION ALGORITHMSTo reduce the high dimension of the feature vector, we used afeature selection algorithm to select the most relevant subsetof features. We applied six feature selection algorithms andevaluated them using the KNN (k = 3) classifier. Fig. 2shows that the highest accuracy was achieved by the Recur-sive Feature Elimination (RFE) Logistic Regression for 75selected features. Feature selection algorithms were evalu-ated on the whole training data, that is, 70% of samples of all150,145 samples. To make our 

Results reproducible, Table 6VOLUME 4, 2016 74. Author’s Relevant Papers9625 50 75 100 125 150 175Number of features1.41.61.82.02.22.42.62.83.0Error rate [%]Principal Component AnalysisSFM Decision TreeSFM Logistic RegressionInformation GainRFE Logistic RegressionRFE Decision TreeFIGURE 2: Evaluation of the feature selection algo-rithms in terms of error rates of the KNN (k =3) classifier. The abbreviation SFM refers to procedurefeature_selection.SelectFromModel, and theabbreviation RFE refers to Recursive Feature Eliminationimplemented in feature_selection.RFE, both fromthe Scikit-learn library.in 



Appendix A summarizes 75 selected features used in ourexperiments. We kept the name of the fields in the same formas in the documentation [32] so that the reader can easilyfind the detailed description. In all following experiments,we used the dataset processed by the RFE logistic regression,which reduced the dimensionality from 370 to 75.VI. EXPERIMENTAL 

ResultsA collection of experiments concerning distance metriclearning techniques has been conducted. Firstly, we com-pared the DML techniques and performed additional exper-iments with the two most successful techniques. Then wefocused on minimizing false positive rate, and finally, wecompared our approach based on PSO with the state-of-the-art machine learning algorithms.We first searched for the hyper-parameters of the DMLmethods. Appropriate hyper-parameters can have large im-pact on the predictive or computation performance. Tun-ing the hyper-parameters of the LMNN algorithm us-ing grid search exhaustively considers all parameter com-binations. The following searching grids were explored:Number of nearest neigbors k ∈ {1, 3, 5, 7, . . . , 21},Maximum number of iterations of the optimization pro-cedure nmax ∈ {500, 1000, 1500, 2000, 2500, 3000},learning rate of the optimization procedure r ∈{10−2, 10−3, 10−4, 10−5, 10−6, 10−7, 10−8}. Note that inall experiments with LMNN, we used the parameter µ = 1defined in Eq. (6) as trade-off between the two objectives.The lowest error rate was achieved with the following LMNNhyper-parameters: number of neighbors k=3, maximum num-ber of iterations nmax = 1000, and learning rate r = 10−6.These hyper-parameters were used in all next experiments.We left the hyper-parameters of NCA and MLKR in thedefault values as stated in the Scikit-learn library. Regardingthe PSO algorithm, we explored the following PSO parame-ters: φ1, φ2 ∈ {0.5, 1., 1.5, 2.}, and Vmax ∈ {0.5, 1., 2., 4.}.The lowest error rate was achieved with the following hyper-parameters: φ1 = φ2 = 1, and Vmax = 2. The rest of thePSO parameters are as follows: population size is 40, andnumber of iterations is 30. At the first iteration, inertia weightω is set to one, and it linearly decreases at each iteration tothe value ωmin = 0.8. All these PSO parameters were chosenfollowing the guidelines from [33].We run the PSO algorithm ten times, and Fig. 3 illustratesthe mean and standard deviation of error rate correspondingto the various number of iterations. The PSO algorithmwas run with 50 iterations, and however, for each run, thealgorithm converged to the local minima before reaching 30iterations. Note that even after the first iteration, PSO outper-forms LMNN. The reason lies in the initialization step of theAlgorithm 1. Positions of particles in the initialization stepof PSO were set according to the feature importance scorecomputed in the feature selection step rather than randomly.As a result, PSO was accelerated, and better classification

Results were achieved.1 5 10 15 20 25 30Number of PSO iterations1.001.051.101.151.20Error rate [%]LMNNMLKRNCAPSO meanFIGURE 3: Average classification error with the standarddeviation is illustrated as a function of the maximum numberof iteration in the PSO algorithm.A. COMPARISON OF DISTANCE METRIC LEARNINGALGORITHMSSeveral distance metric learning algorithms, such as LMNN,NCA, and MLKR, were designed to improve the KNN clas-sifier. For this reason, these three algorithms were includedin our experiments. Table 1 shows the performance of theKNN classifier (k = 3) using common Euclidean distance,Mahalanobis distance learned by three selected DML al-gorithms, and weighted Euclidean distance learned by thePSO algorithm. The KNN classifier achieved the lowest errorrate for the weighted Euclidean metric learned by the PSOalgorithm.Recall that while PSO aims at learning a diagonal matrix,the goal of LMNN, NCA, and MLKR is to learn a full8 VOLUME 4, 20164.5. Paper 5 - Application of Distance Metric Learning to Automated Malware Detection97TABLE 1: The performance of three selected distance metriclearning algorithms compared with the performance of thePSO-based model and the non-learned model referred toEuclidean.Method TPR[%] FPR[%] ERR[%] Learning timeEuclidean 97.66 0.31 1.33 –LMNN 97.88 0.32 1.22 2h 7minMLKR 98.04 0.32 1.14 80h 11minNCA 98.08 0.28 1.10 10h 20minPSO 98.25 0.22 0.99 1h 5minmatrix. Due to the high computational complexity of theDML algorithms, we conducted the experiment for the ran-domly chosen subset of the training dataset. Distance metriclearning algorithms were trained on 50,000 samples, and theKNN classifier with learned distance was tested on 21,430samples. These numbers of samples follow the ratio of 70:30between the sizes of training and testing sets. Based on thetrade-off between minimizing the error rate and executiontime, we chose only LMNN and PSO for the rest of theexperiments.B. ADDITIONAL EXPERIMENTS FOR LMNN AND PSO1) Comparison of LMNN and PSOIn the first experiment, we explored the performance of theLMNN-based model and the PSO-based model for differentsizes of datasets. The experiment was conducted ten timesfor randomly chosen training and testing dataset keeping theratio of their sizes 70:30. The number of training samples,learning method, and the average learning times, TPR, FPR,and ERR estimated on the testing set are summarized inTable 2. The number of nearest neighbors considered in bothLMNN-based and PSO-based models was k = 3.For smaller datasets (i.e., few thousand samples), theLMNN-based model achieved a lower error rate with approx-imately the same learning time as the PSO-based model. The

Results indicate that with the increasing volume of data, theratio of computing time and error rate decreases in favor ofPSO.2) Effect of parameter kWe discuss how different parameter settings of k (i.e.,number of neighbors) affects the performance of the KNNclassifier. We explored the variation of error rates for thefollowing three variants: Euclidean distance (i.e., withoutfeature weights), Mahalanobis distance learned by LMNN,and weighted Euclidean distance, where the weights werecomputing using PSO. For these three variants, the KNN wastrained on 50,000 training samples, and the error rates wereestimated on 21,430 testing samples. The experiment wasperformed ten times, and Fig. 4 shows the averaged 

Resultsof the KNN classifier for various values of the parameter kfrom the set {1, 3, 5, . . . , 21}.In the additional experiment, we explored the relationbetween the number of neighbors and learning time. Fig. 51 3 5 7 9 11 13 15 17 19 21Number of neighbors1.11.21.31.41.51.6Error rate [%]PSOLMNNEuclideanFIGURE 4: The relation between the number of neighborsand the performance of KNN using various distances.shows that with the increasing number of neighbors learningtime of PSO increases only negligibly compared to the learn-ing time of LMNN.1 3 5 7 9 11 13 15 17 19 21Number of neighbors6K8K10K12K14K16K18K20KCPU time [s]PSOLMNNFIGURE 5: Learning time of LMNN and PSO (with 30iterations). The experiment was conducted ten times, and thecomputational times were averaged.3) LMNN projection of original feature spaceIn the next experiment, we used the weight matrix L, definedin Eq. (3), learned by LMNN to project the original featurespace into a new embedding feature space following thegoal that the k-Nearest Neighbors of each instance belongto the same class while a large margin separates instancesfrom different classes. Recall that this projection is lineartransformation defined as x′ = Lx. This experiment aims toillustrate the difference between original (non-transformed)data and transformed data using LMNN. Two-dimensionalembedding of 700 samples using t-SNE algorithm [34] isshown in Fig. 6 where similarity plots for four 



Scenarios arecompared.VOLUME 4, 2016 94. Author’s Relevant Papers98TABLE 2: Comparison of the LMNN-based model and PSO-based model for various sizes of datasets.# train samples Learning method Learning time TPR[%] FPR[%] ERR[%]1000 LMNN 8s 96.26 4.17 3.95PSO 9s 95.92 1.44 2.795000 LMNN 2min 34s 96.51 1.90 2.71PSO 2min 32s 97.41 1.97 2.2920000 LMNN 23min 51s 97.94 1.50 1.78PSO 18min 11s 98.39 1.49 1.5550000 LMNN 2h 6min 40s 97.88 0.32 1.22PSO 1h 5min 20s 98.25 0.22 0.99benignmalware(a) Dataset A (error rate = 3.29%)benignmalware(b) Transformed dataset A by LMNN that was trained on dataset A(error rate = 1.43%)benignmalware(c) Dataset B (error rate = 3.14%)benignmalware(d) Transformed dataset B by LMNN that was trained on dataset A(error rate = 2.29%)FIGURE 6: Visualization of the impact on similarities of samples achieved by LMNN using the t-SNE algorithm. Red crossesrepresent malicious files, while blue dots represent benign files. There are two different datasets, and both consisted of 700samples. For dataset A transformed by LMNN that was trained on the same dataset A, we achieved the error rate of 1.43%,while for dataset B transformed by LMNN that was trained on the different dataset, we achieved an error rate of 2.29%. All

Results were achieved by the KNN classifier (k = 3).4) Limitation of LMNN for larger datasetsThe result of the DML algorithms for the Mahalanobis dis-tance metric is n × n matrix, where n is the dimension ofthe feature vector. Since the number of components of thematrix grows at a quadratic rate with n and the size of thetraining data is fixed, we can expect that the size of trainingdata stops being sufficient for high values of n. Note that thePSO-based model using weighted Euclidean distance needsonly n parameters to be learned.In the next experiment, we used the Principal ComponentAnalysis [35] to reduce the data’s dimension and examinethe learning ability of the LMNN-based model for variousdimensions of feature vectors. We defined performance im-provement expressed in percent as100 (1− ERRlmnnERReuclid), (20)where ERRlmnn de

Notes the error rate of the KNN clas-sifier (k = 3) using the Mahalanobis distance learned byLMNN, and ERReuclid de

Notes the error rate for (non-learned) Euclidean distance. Our fixed-size dataset consisted10 VOLUME 4, 20164.5. Paper 5 - Application of Distance Metric Learning to Automated Malware Detection995 10 15 20 25 30 35 40 45 50 55 60 65 70 75Dimensionality1213141516Improvement of ERR [%] linear least-squares fitFIGURE 7: The relation between the dimensionality of thefeature vector and performance improvement achieved usingthe KNN classifier with Mahalanobis distance metric learnedby LMNN.of 50,000 training samples and 21,430 testing samples.Fig. 7 illustrates performance improvement for LMNN-basedmodel. The result of linear regression represented by the reddashed line shows that the corresponding improvement oferror rate declines with increasing dimension. This result mayindicate that for higher dimensions, the size of our dataset canbe a limiting factor.C. MINIMIZING OF FALSE POSITIVE RATEThis 



Section concerns the problem of detecting as muchmalware as possible while maintaining a low false positiverate. We first focus on minimizing the false positive rate usingthe PSO algorithm. We analyzed how the coefficient c inthe WERR criterion defined in Eq. (15) influences the falsepositive rate and error rate. In this experiment, we performedPSO with WERR optimization criterion for c ∈ {1, . . . , 10}.Fig. 8 presents the relation between the coefficient c and falsepositive rate and error rate achieved by the KNN classifier(k = 3). The PSO was performed ten times for randomlychosen 50,000 training samples and 21,430 testing samples.The figure shows the mean values of FPR and ERR with thestandard deviation.As expected, with increasing coefficient c the correspond-ing FPR decreases. However, for c > 8, FPR does notdecrease anymore since KNN using Mahanalobis distanceproduces only 20 to 30 false positives. WERR criterion inthe PSO algorithm does not affect such a low number of falsepositives. Concerning the size of our dataset, the lowest FPR,0.13%, was achieved for c = 8. Note that with increasingcoefficient c, the corresponding ERR increases as well, untilc ≤ 8.While 0.13% FPR with 1.15 % error rate achieved inour experiment seems reasonable, it can still be impracticalin real-world applications. It is undesirable that antivirusprograms would delete benign samples for every 769 scannedsamples on average. However, our proposed malware de-tection model can be used as one component of a morecomplex system relying on more data types from both staticand dynamic analysis.Regarding minimizing FPR using LMNN, we modifiedEq. (6) by adding the parameter ηk which corresponds to thecost of false positive. This modification aims to minimize thenumber of impostors belonging to the class of benign files.Let T be a training set and let Ni de

Notes the set of k targetneighbors of xi. Then the modification of LMNN concerningminimizing false positives is as follows:minL∑xi∈T∑xj∈Ni(dL(xi,xj)2 ++ µ∑xk∈T :yi 6=ykηk[1+dL(xi,xj)2−dL(xi,xk)2]+)(21)where ηk de

Notes cost of false positive and it is define asfollows:ηk ={1 if yk is class of benign files,c ≥ 1 if yk is class of malware.Similar to the WERR optimization criterion, the purposeof the parameter c in the definition of ηk is to set the amountof penalization for one false positive. The difference betweenthe modification of LMNN and WERR criterion is thatthe modification of LMNN takes into account the distancebetween a sample and its impostor.To summarize the result, Table 3 shows the performance ofthe modified LMNN according to Eq. (21), and PSO methodswith the WERR criterion.TABLE 3: 

Results of the experiment with modified LMNNand PSO-based method with emphasis on the low falsepositive rate.Method TPR[%] FPR[%] ERR[%]PSO with WERR 97.87 0.13 1.15modified LMNN 97.50 0.19 1.42Note that the PSO-based method resulted in a lower falsepositive rate when compared to the LMNN-based method.D. COMPARISON TO THE STATE-OF-THE-ART MACHINELEARNING ALGORITHMSIn the last experiment, we compared several state-of-the-artmachine learning algorithms with the Our proposed methodwhich refers to the KNN classifier with weighted Euclideandistance where the weights were learned by PSO algorithmwith WERR criterion.A list of machine learning classifiers considered, togetherwith implementation details, is presented in Table 4. Webriefly describe the machine learning techniques applied inthe experiment.The k-Nearest Neighbors classifier [36] is one of the mostpopular supervised learning methods. It is a non-parametricVOLUME 4, 2016 114. Author’s Relevant Papers1001 2 3 4 5 6 7 8 9 10Coefficient c in WERR criteria0.160.180.200.220.240.26FPR [%]FPR criteriaWERR criteria1 2 3 4 5 6 7 8 9 10Coefficient c in WERR criteria1.0251.0501.0751.1001.1251.1501.1751.200Error rate [%]FPR criteriaWERR criteriaFIGURE 8: The relation between the coefficient c defined in the WERR criterion and false positive rate and error rate.TABLE 4: List of machine learning classifiers with the corresponding names of algorithms from the Scikit-learn library andthe corresponding parameters. For some classifiers, we used parameters with default values as stated in the Scikit-learn library.Name of classifier Name of algorithm in Scikit-learn Parametersk -Nearest Neighbor neighbors.KNeighborsClassifier n_neighbors = 3Support Vector Machine svm.SVC default parametersLogistic Regression linear_model.LogisticRegression default parametersNaïve Bayes naive_bayes.GaussianNB default parametersDecision Tree tree.DecisionTreeClassifier default parametersDeep Neural Network neural_network.MLPClassifier hidden_layer_sizes=(200,100), max_iter=300, activation = relu, solver=adamAda Boost ensemble.AdaBoostClassifier n_estimators=100Random Forest ensemble.RandomForestClassifier n_estimators=100method that assigns a class label to each testing sample by amajority vote of its k nearest neighbors.Support Vector Machine method (SVM) [37] is mainlydefined for two-class classification problems. The main ideais to maximize the margin, which is the smallest distancebetween the training data and the decision boundary. SVMmethod can also be applied in multiclass classification prob-lems using a binary classifier in a one-against-all situation.Logistic Regression [38] is a parametric binary classifierthat estimates the coefficients from the training data usingmaximum-likelihood estimation. Similar to SVM, the One-against-all strategy can also be applied to multiclass classifi-cation problems.Naïve Bayes classifier [39] is a probabilistic algorithmbased on Bayes’ theorem that predicts the class with thehighest a posteriori probability. Naïve Bayes classifier isbased on the assumption that the features are conditionallyindependent of one another, which is often not valid inpractice.Decision Tree classifier [40] is represented as a tree,where internal nodes correspond to features and leaf nodescorrespond to class labels. Edges leading to children nodecorrespond to feature’ values. The feature vector determinesthe path from the root node to the leaf node.Deep Neural network [41] is a feedforward artificial neuralnetwork that consists of three types of interconnected layersof perceptrons. The input layer takes a feature vector, whichis then processed in hidden layers, and finally, perceptrons inthe output layer output a result.Adaboost [42] is one of the most popular boosting algo-rithms. It performs several weak classifiers and assigns themweights that are based on the corresponding error rates. Theseweights are then used to predict the output class.Random forest [43] is an ensemble learning method thatcombines the 

Results made by several decision trees using avoting mechanism.Table 5 provides average classification 

Results of selectedsupervised machine learning algorithms compared with re-sults of Our proposed method defined as the KNN classifierusing weighted Euclidean distance learned by the PSO algo-rithm as described in 



Section IV.TABLE 5: Averaged classification 

Results.ML Method TPR[%] FPR[%] ERR[%]Our proposed method 98.64 0.74 1.09k-Nearest Neighbor 98.21 1.11 1.45Support Vector Machine 98.20 1.76 1.78Logistic Regression 98.22 1.82 1.80Naïve Bayes 87.59 1.51 7.63Decision Tree 98.26 1.70 1.72Deep Neural Network 98.87 1.45 1.30Ada Boost 98.66 2.07 1.71Random Forest 98.49 1.00 1.26All machine learning algorithms were run 20 times forrandomly chosen training set and testing set with 50,000samples and 21,430 samples, respectively. Our proposed12 VOLUME 4, 20164.5. Paper 5 - Application of Distance Metric Learning to Automated Malware Detection101method outperformed all the machine learning classifiersachieving the lowest FPR and the lowest error rate. DeepNeural Network and Ada Boost were the only ML algorithmshaving a higher TPR than the PSO-based model; however,they both achieved significantly higher FPR.VII. 



ConclusionsThis paper proposed a malware detection system based on thek-Nearest Neighbor classifier using weighted Euclidean dis-tance learned by the Particle Swarm Optimization algorithm.We empirically demonstrated that our approach achieved thelowest error rate and the lowest false positive rate amongall state-of-the-art machine learning algorithms consideredin our experiment. We described the architecture of thedetection system based on structural information from staticanalysis for Windows PE files. This approach can also beapplied to executable formats of other operating systems,such as MAC OS or Linux.In addition, we focused on the problem of detecting asmuch malware as possible while keeping a low false positiverate. Insufficiently low false positive error is considered seri-ously in the antivirus industry. We proposed an optimizationcriterion based on a weighted error rate to penalize falsepositives. Using this criterion as a fitness function in theParticle Swarm Optimization algorithm, which was used tolearned feature weights of weighted Euclidean distance, weachieved 0.13% of false positive rate with an error rate of1.15%.Ongoing work is focused in the following two directions.First, we are working on learning multiple local distancemetrics for different malware families. We plan to investi-gate both unsupervised and supervised methods. Secondly,it would be interesting to experiment with other distancemetric learning algorithms with various optimization criteriato achieve even lower FPR on an acceptable error rate level.



References[1] D. Salomon, Foundations of computer security. Springer Science &Business Media, 2006.[2] K. Monnappa, Learning Malware Analysis: Explore the concepts, tools,and techniques to analyze and investigate Windows malware. PacktPublishing Ltd, 2018.[3] S. Luke, Essentials of Metaheuristics, 2nd ed. Lulu, 2013.[4] M. Jureček, O. Jurečková, and R. Lórencz, “Improving classificationof malware families using learning a distance metric,” in Int. Conf. onInformation Systems Security and Privacy (ICISSP), 2021, to be published.[5] Microsoft, “Pe format - win32 apps,” Accessed: Jan. 29, 2021. [on-line], Available: https://docs.microsoft.com/en-us/windows/win32/debug/pe-format.[6] D. Gibert, C. Mateu, and J. Planes, “The rise of machine learning fordetection and classification of malware: Research developments, trendsand challenges,” Journal of Network and Computer Applications, vol. 153,p. 102526, 2020.[7] Ö. A. Aslan and R. Samet, “A comprehensive review on malware detectionapproaches,” IEEE Access, vol. 8, pp. 6249–6271, 2020.[8] M. Wadkar, F. Di Troia, and M. Stamp, “Detecting malware evolutionusing support vector machines,” Expert Systems with Applications, vol.143, p. 113022, 2020.[9] L. Yang and J. Liu, “Tuningmalconv: malware detection with not just rawbytes,” IEEE Access, vol. 8, pp. 140 915–140 922, 2020.[10] X. Gao, C. Hu, C. Shan, B. Liu, Z. Niu, and H. Xie, “Malware classi-fication for the cloud via semi-supervised transfer learning,” Journal ofInformation Security and Applications, vol. 55, p. 102661, 2020.[11] D. Xue, J. Li, T. Lv, W. Wu, and J. Wang, “Malware classificationusing probability scoring and machine learning,” IEEE Access, vol. 7, pp.91 641–91 656, 2019.[12] W. Zhong and F. Gu, “A multi-level deep learning system for malwaredetection,” Expert Systems with Applications, vol. 133, pp. 151–162, 2019.[13] E. Raff, J. Sylvester, and C. Nicholas, “Learning the pe header, malwaredetection with minimal domain knowledge,” in Proceedings of the 10thACM Workshop on Artificial Intelligence and Security, 2017, pp. 121–132.[14] B. Kolosnjaji, G. Eraisha, G. Webster, A. Zarras, and C. Eckert, “Empow-ering convolutional networks for malware classification and analysis,” in2017 International Joint Conference on Neural Networks (IJCNN). IEEE,2017, pp. 3838–3845.[15] M. Jureček and R. Lórencz, “Distance metric learning using particleswarm optimization to improve static malware detection,” in Int. Conf. onInformation Systems Security and Privacy (ICISSP), 2020, pp. 725–732.[16] M. Jureček and R. Lórencz, “Malware detection using a heterogeneousdistance function,” Computing and Informatics, vol. 37, no. 3, pp. 759–780, 2018.[17] D. R. Wilson and T. R. Martinez, “Improved heterogeneous distancefunctions,” Journal of artificial intelligence research, vol. 6, pp. 1–34,1997.[18] D. Wettschereck, D. W. Aha, and T. Mohri, “A review and empiricalevaluation of feature weighting methods for a class of lazy learningalgorithms,” Artificial Intelligence Review, vol. 11, no. 1-5, pp. 273–314,1997.[19] J. L. Suárez, S. García, and F. Herrera, “A tutorial on distance metriclearning: Mathematical foundations, algorithms, experimental analysis,prospects and challenges,” Neurocomputing, 2020, to be published.[20] L. Yang and R. Jin, “Distance metric learning: A comprehensive survey,”Michigan State Universiy, vol. 2, no. 2, p. 4, 2006.[21] B. Kulis et al., “Metric learning: A survey,” Foundations and Trends® inMachine Learning, vol. 5, no. 4, pp. 287–364, 2013.[22] A. Bellet, A. Habrard, and M. Sebban, “A survey on metric learningfor feature vectors and structured data,” arXiv preprint arXiv:1306.6709,2013.[23] K. Q. Weinberger, J. Blitzer, and L. K. Saul, “Distance metric learningfor large margin nearest neighbor classification,” in Advances in neuralinformation processing systems, 2006, pp. 1473–1480.[24] K. Q. Weinberger and L. K. Saul, “Fast solvers and efficient implementa-tions for distance metric learning,” in Proceedings of the 25th internationalconference on Machine learning, 2008, pp. 1160–1167.[25] J. Goldberger, G. E. Hinton, S. T. Roweis, and R. R. Salakhutdinov,“Neighbourhood components analysis,” in Advances in neural informationprocessing systems, 2005, pp. 513–520.[26] K. Q. Weinberger and G. Tesauro, “Metric learning for kernel regression,”in Artificial Intelligence and Statistics, 2007, pp. 612–619.[27] R. Eberhart and J. Kennedy, “Particle swarm optimization,” in Proceedingsof the IEEE international conference on neural networks, vol. 4. Citeseer,1995, pp. 1942–1948.[28] M. Kuhn, K. Johnson et al., Applied predictive modeling. Springer, 2013,vol. 26.[29] VirusShare, “Accessed: Jan. 29, 2021. [online],” Available: http://virusshare.com.[30] E. Carrera, “Pefile,” Accessed: Jan. 29, 2021. [online], Available: https://github.com/erocarrera/pefile.[31] Scikit-learn, “Accessed: Jan. 29, 2021. [online].”[32] Microsoft, “Microsoft portable executable and common object file formatspecification,” 1999.[33] D. Wang, D. Tan, and L. Liu, “Particle swarm optimization algorithm: an

Overview,” Soft Computing, vol. 22, no. 2, pp. 387–408, 2018.[34] L. v. d. Maaten and G. Hinton, “Visualizing data using t-sne,” Journal ofmachine learning research, vol. 9, no. Nov, pp. 2579–2605, 2008.[35] L. I. Smith, “A tutorial on principal components analysis,” 2002.[36] T. Cover and P. Hart, “Nearest neighbor pattern classification,” IEEEtransactions on information theory, vol. 13, no. 1, pp. 21–27, 1967.[37] B. E. Boser, I. M. Guyon, and V. N. Vapnik, “A training algorithm foroptimal margin classifiers,” in Proceedings of the fifth annual workshopon Computational learning theory, 1992, pp. 144–152.[38] J. Friedman, T. Hastie, and R. Tibshirani, The elements of statisticallearning. Springer series in statistics New York, 2001, vol. 1, no. 10.VOLUME 4, 2016 134. Author’s Relevant Papers102[39] M. E. Maron and J. L. Kuhns, “On relevance, probabilistic indexing andinformation retrieval,” Journal of the ACM (JACM), vol. 7, no. 3, pp. 216–244, 1960.[40] J. R. Quinlan, “Induction of decision trees,” Machine learning, vol. 1,no. 1, pp. 81–106, 1986.[41] Y. LeCun, Y. Bengio, and G. Hinton, “Deep learning,” nature, vol. 521,no. 7553, pp. 436–444, 2015.[42] R. E. Schapire and Y. Freund, “Boosting: Foundations and algorithms,”Kybernetes, 2013.[43] L. Breiman, “Random forests,” Machine learning, vol. 45, no. 1, pp. 5–32,2001..



Appendix A FEATURES USED IN EXPERIMENTSTable 6 summarizes the list of 75 features all extracted fromthe PE file format. For each feature from a 



Section header, weconsidered the order of the 



Section rather than the name of the



Section (such as .text, .data, .rsrc). While the 



Sections’ orderturns out to be important for malware detection, this kind ofinformation is often not mentioned in research papers. Wekeep the name of the fields in the same form as in the do-cumentation [32], in order that the reader can easily find thedetailed description. A detailed description of these featurescan be found in the documentation [5].MARTIN JUREČEK graduated from the CharlesUniversity in Prague, Faculty of Mathematicsand Physics, with a specialization in mathemat-ical methods of information security. He is nowa Ph.D. student at the Faculty of InformationTechnology of the Czech Technical University inPrague. His main research interests focus on theapplication of machine learning and artificial in-telligence approaches to malware detection. Otherareas of his interest are algebraic cryptanalysis andthe security of cryptocurrencies.RÓBERT LÓRENCZ graduated from the Fac-ulty of Electrical Engineering of the Czech Tech-nical University in Prague in 1981. He receivedhis Ph.D. degree in 1990 from the Institute ofMeasurement and Measuring Methods, SlovakAcademy of Sciences in Bratislava. Currently heis Full Professor at the Faculty of InformationTechnology of the Czech Technical University inPrague. His research interests are cryptographyand arithmetic units for cryptography primitives,various cryptoanalysis methods of block and stream ciphers. Another topicof his interest is alternative arithmetic for numerical computation.14 VOLUME 4, 20164.5. Paper 5 - Application of Distance Metric Learning to Automated Malware Detection103TABLE 6: List of 75 features selected by RFE Logistic Regression algorithm. Some numeric fields were considered as nominalsince they have a low number of different values.Field Structure # features typeNumberOfSymbols COFF File Header 1 numericNumberOf



Sections COFF File Header 1 numericAddressOfEntryPoint Optional Header Standard Fields 1 numericMajorLinkerVersion Optional Header Standard Fields 1 nominalMinorLinkerVersion Optional Header Standard Fields 1 nominalSizeOfHeapCommit Optional Header Windows-Specific Fields 1 numericImageBase Optional Header Windows-Specific Fields 1 nominal



SectionAlignment Optional Header Windows-Specific Fields 1 nominalFileAlignment Optional Header Windows-Specific Fields 1 nominalMajorOperatingSystemVersion Optional Header Windows-Specific Fields 1 nominalMajorImageVersion Optional Header Windows-Specific Fields 1 nominalMajorSubsystemVersion Optional Header Windows-Specific Fields 1 nominalMinorSubsystemVersion Optional Header Windows-Specific Fields 1 nominalSizeOfImage Optional Header Windows-Specific Fields 1 numericCheckSum Optional Header Windows-Specific Fields 1 nominalSubsystem Optional Header Windows-Specific Fields 1 nominalNumberOfRvaAndSizes Optional Header Windows-Specific Fields 1 nominalRVA - all 16 fields Optional Header Data Directories 16 numericSize - all 16 fields Optional Header Data Directories 16 numericPointerToRawData 



Section Header - all 5 



Sections 5 numericSizeOfRawData 



Section Header - all 5 



Sections 5 numericVirtualAddress 



Section Header - all 5 



Sections 5 numericVirtualSize 



Section Header - all 5 



Sections 5 numericCharacteristics - IMAGE_SCN_TYPE_DSECT 



Section Flags for the first 



Section 1 booleanCharacteristics - IMAGE_SCN_TYPE_COPY 



Section Flags for the first 



Section 1 booleanCharacteristics - IMAGE_SCN_TYPE_NOLOAD 



Section Flags for the first 



Section 1 booleanCharacteristics - IMAGE_SCN_TYPE_GROUP 



Section Flags for the first 



Section 1 booleanCharacteristics - IMAGE_SCN_TYPE_REG 



Section Flags for the first 



Section 1 booleanfile_size not part of PE format 1 numericVOLUME 4, 2016 154. Author’s Relevant Papers104



Chapter 5



ConclusionsNowadays, antivirus vendors face several problems concerning malware detection. Theconcept of employing machine learning to malware detection provides promising solutions.Thousands of papers dealing with machine learning methods for malware detection wereproposed. Moreover, since malware developers create more and more sophisticated tech-niques, it is necessary to use the latest techniques from machine learning to keep errorrate and false positive rate as low as possible. This game can converge to the point whenartificial intelligence of attackers will fight against the artificial intelligence of malwareresearchers.Our work can have practical application since all the malware detection systems men-tioned in this thesis are based on static analysis that is significantly faster than dynamicanalysis, which involves running the program. Each of our proposed malware detectionmodels can be used as a component of a more complex system relying on 

Results from bothstatic and dynamic analysis.The proposed static malware detection systems are relatively easy to implement andcan be utilized to support commercial antivirus systems. We achieved the most significant

Results using a forward neural network, which we applied to PE features transformed usinga BLSTM network. Specifically, we achieved an accuracy of 99.22% with a 0.67% falsepositive rate.5.1 Contributions of the Dissertation ThesisContributions of our work are as follows:Paper 1. We designed the heterogeneous distance metric specially defined for the PE fileformat. We proposed a classifier combining the weighted k-Nearest Neighbor methodand the statistical scoring technique. The 

Results indicate that the proposed hetero-geneous distance metric is appropriate for malware detection and that combinationof the classifiers may provide a potential benefit to detect samples not detected byWKNN.1055. 



ConclusionsPaper 2. We modified the heterogenenous distance function by considering the featureweights. We then applied the PSO algorithm to the problem of finding the mostappropriate feature weights. The 

Results indicate that the classification performanceof KNN can be improved significantly by using appropriate weights of the features.Paper 3. Using various LSTM and Bidirectional LSTM network architectures, we trans-formed the PE features and trained other supervised machine learning algorithms ontransformed dataset dataset to improve classification accuracy. Transformation bydeep (4 hidden layers) versions of LSTM and BLSTM networks decreased the errorrate of several state-of-the-art machine learning algorithms significantly.Paper 4. We showed that the DML-based methods might improve multiclass classification

Results even when standard methods such as feature selection or algorithm tuningwere already applied. Using three DML algorithms, LMNN, NCA, and MLKR, weachieved significantly better multiclass classification 

Results than any state-of-the-artML algorithms considered in our experiments.Paper 5. We proposed the architecture of the malware detection model based on dis-tance metric learning. The detection system processed the PE file format data wherenumeric features are normalized and nominal features are turned to conditional prob-abilities. To consider the higher cost of false positive, we constructed a cost functioncalled weighted error rate which we used as a fitness function in the PSO algorithmto minimize error rate and false positive rate.Finally, we try to evaluate our effort and answer whether we reached the goals presentedin 



Section 1.3. Let recall the first two goals that are related to the binary classificationproblem. If we accept the error rate that is less than 1% and the false positive rate is alsounder 1%, then we can say that we reached both goals. In Paper 3, using Feed-ForwardNetwork on dataset transformed by deep BLSTM network, we achieved 99.22% of accuracyat only 0.67% of false positive rate. Note that this result is competitive in comparison tothe state-of-the-art. However, to achieve a fair comparison, the same conditions, such asbenchmarking dataset, have to be ensured.Regarding the third goal of the thesis, in Paper 4 and Paper 5, we experimentallyverify the usefulness of DML methods. Paper 4 deals with malware family classification.The k-Nearest Neighbors classifier using the Mahalanobis distance metric learned by theMetric Learning for Kernel Regression method achieved average precision and recall, bothof 97.04% compared to Random Forest with a 96.44% of average precision and 96.41%of average recall, which achieved the best classification 

Results among the state-of-the-artML algorithms considered in our experiments. Paper 5 deals with malware detection.Our experimental 

Results showed that our malware detection system based on distancemetric learning achieves a 1.09% of error rate at 0.74% of false positive rate (FPR) andoutperformed all machine learning algorithms considered in the experiment.1065.2. 



Future WorkWe claim that we fulfilled the fourth goal since in each of our papers, Paper 1 toPaper 5, we applied and described automated processes such as extraction of features,preprocessing, feature selection, training, and evaluating.5.2 



Future WorkThe author of the dissertation thesis suggests exploring the following main issues andchallenges:Adversarial learning. Machine learning models are vulnerable to adversarial attacksthat can fool the models. For instance, an adversary can craft malware that has asimilar feature vector to some benign file’s feature vector. As a result, the trainingset may have different statistical distribution than the distribution of the testing set.The goal is to proposed defense techniques in order for machine learning algorithmscan resist such adversarial attacks.Interpretability of the models. Several malware detection models based on machinelearning techniques, such as neural networks, are considered as a black box in thesense that it is difficult (for humans) to determine exactly the reason why a givenfalse positive or false negative occurs. Malware researchers preferred interpretabledetection systems, such as rule-based methods, since they can better understand andcontrol. The goal of this challenge is to improve the interpretability of classificationmodels.Minimizing of reaction time. The majority of new malicious samples are generated bymalware generators that need to input some parameters. Since attackers have allantivirus products at their disposal, a common strategy of attackers is to change thesetting of malware generators and generate samples as long as none of the antivirusesdetect them. New malware is then spread among users by some infection vector. Thetime period between spreading the malware and creating detection rule, referred toas reaction time, should be minimal since users are not protected during this timeperiod.107Bibliography[1] Monnappa, K. Learning Malware Analysis: Explore the concepts, tools, and techniquesto analyze and investigate Windows malware. Packt Publishing Ltd, 2018.[2] Singh, J.; Singh, J. Challenge of malware analysis: malware obfuscation techniques.International Journal of Information Security Science, volume 7, no. 3, 2018: pp.100–110.[3] AV-TEST Institute. AV-TEST Security Report 2019/2020. https://www.av-test.org/fileadmin/pdf/security report/AV-TEST Security Report 2019-2020.pdf, 2020.[4] Mitchell, T. M. Machine learning. New York, 1997.[5] Friedman, J.; Hastie, T.; et al. The elements of statistical learning, volume 1. Springerseries in statistics New York, 2001.[6] Nakamoto, S. Bitcoin: A peer-to-peer electronic cash system. Technical report,Manubot, 2019.[7] Gunetti, D.; Picardi, C. Keystroke analysis of free text. ACM Transactions on In-formation and System Security (TISSEC), volume 8, no. 3, 2005: pp. 312–347.[8] Latto, N. What is a sniffer and how can you prevent sniffing? Accessed: Feb. 28, 2021.[online], Available: https://www.avg.com/en/signal/what-is-sniffer.[9] Szor, P. The Art of Computer Virus Research and Defense. Addison Wesley Profes-sional, 2005.[10] Egele, M.; Scholte, T.; et al. A survey on automated dynamic malware-analysis tech-niques and tools. ACM computing surveys (CSUR), volume 44, no. 2, 2012: p. 6.[11] Nath, H. V.; Mehtre, B. M. Static malware analysis using machine learning meth-ods. In International Conference on Security in Computer Networks and DistributedSystems, Springer, 2014, pp. 440–450.109Bibliography[12] Alrabaee, S.; Shirani, P.; et al. On the feasibility of malware authorship attribution.In International Symposium on Foundations and Practice of Security, Springer, 2016,pp. 256–272.[13] Or-Meir, O.; Nissim, N.; et al. Dynamic malware analysis in the modern eraA stateof the art survey. ACM Computing Surveys (CSUR), volume 52, no. 5, 2019: p. 88.[14] Moser, A.; Kruegel, C.; et al. Limits of static analysis for malware detection. InTwenty-Third Annual Computer Security Applications Conference (ACSAC 2007),IEEE, 2007, pp. 421–430.[15] Damodaran, A.; Di Troia, F.; et al. A comparison of static, dynamic, and hybridanalysis for malware detection. Journal of Computer Virology and Hacking Techniques,volume 13, no. 1, 2017: pp. 1–12.[16] Saad, S.; Briguglio, W.; et al. The Curious Case of Machine Learning in MalwareDetection. In Proceedings of the 5th International Conference on Information SystemsSecurity and Privacy - Volume 1: ICISSP, INSTICC, SciTePress, 2019, pp. 528–535.[17] Vinayakumar, R.; Alazab, M.; et al. Robust intelligent malware detection using deeplearning. IEEE Access, volume 7, 2019: pp. 46717–46738.[18] Kumar, N.; Mukhopadhyay, S.; et al. Malware classification using early stage behavi-oral analysis. In 2019 14th Asia Joint Conference on Information Security (AsiaJCIS),IEEE, 2019, pp. 16–23.[19] Han, W.; Xue, J.; et al. MalInsight: a systematic profiling based malware detectionframework. Journal of Network and Computer Applications, volume 125, 2019: pp.236–250.[20] Kephart, J. O.; Arnold, W. C. Automatic extraction of computer virus signatures. In4th virus bulletin international conference, 1994, pp. 178–184.[21] Webb, A. R. Statistical pattern recognition. John Wiley & Sons, 2003.[22] Raff, E.; Nicholas, C. A Survey of Machine Learning Methods and Challenges forWindows Malware Classification. arXiv preprint arXiv:2006.09271, 2020.[23] Ye, Y.; Li, T.; et al. A survey on malware detection using data mining techniques.ACM Computing Surveys (CSUR), volume 50, no. 3, 2017: pp. 1–40.[24] Ucci, D.; Aniello, L.; et al. Survey of machine learning techniques for malware analysis.Computers & Security, volume 81, 2019: pp. 123–147.[25] Raff, E.; Zak, R.; et al. An investigation of byte n-gram features for malware classific-ation. Journal of Computer Virology and Hacking Techniques, volume 14, no. 1, 2018:pp. 1–20.110Bibliography[26] Santos, I.; Brezo, F.; et al. Idea: Opcode-sequence-based malware detection. In In-ternational Symposium on Engineering Secure Software and Systems, Springer, 2010,pp. 35–43.[27] Bilar, D. Opcodes as predictor for malware. International Journal of Electronic Se-curity and Digital Forensics, volume 1, no. 2, 2007: pp. 156–168.[28] Siddiqui, M.; Wang, M. C.; et al. Data mining methods for malware detection usinginstruction sequences. In Artificial Intelligence and Applications, 2008, pp. 358–363.[29] Microsoft. PE Format - Win32 apps. Accessed: Feb. 28, 2021. [online], Available:https://docs.microsoft.com/en-us/windows/win32/debug/pe-format.[30] Gibert, D.; Mateu, C.; et al. The rise of machine learning for detection and classific-ation of malware: Research developments, trends and challenges. Journal of Networkand Computer Applications, volume 153, 2020: p. 102526.[31] Aslan, Ö. A.; Samet, R. A comprehensive review on malware detection approaches.IEEE Access, volume 8, 2020: pp. 6249–6271.[32] Schultz, M. G.; Eskin, E.; et al. Data mining methods for detection of new mali-cious executables. In Security and Privacy, 2001. S&P 2001. Proceedings. 2001 IEEESymposium on, IEEE, 2001, pp. 38–49.[33] Cohen, W. W. Learning Trees and Rules with Set-valued Features. In AAAI/IAAI,Vol. 1, 1996, pp. 709–716.[34] Kolter, J. Z.; Maloof, M. A. Learning to detect and classify malicious executablesin the wild. Journal of Machine Learning Research, volume 7, no. Dec, 2006: pp.2721–2744.[35] Wadkar, M.; Di Troia, F.; et al. Detecting malware evolution using support vectormachines. Expert Systems with Applications, volume 143, 2020: p. 113022.[36] Yang, L.; Liu, J. TuningMalconv: malware detection with not just raw bytes. IEEEAccess, volume 8, 2020: pp. 140915–140922.[37] Gao, X.; Hu, C.; et al. Malware classification for the cloud via semi-supervised trans-fer learning. Journal of Information Security and Applications, volume 55, 2020: p.102661.[38] Xue, D.; Li, J.; et al. Malware classification using probability scoring and machinelearning. IEEE Access, volume 7, 2019: pp. 91641–91656.[39] Zhong, W.; Gu, F. A multi-level deep learning system for malware detection. ExpertSystems with Applications, volume 133, 2019: pp. 151–162.111Bibliography[40] Raff, E.; Sylvester, J.; et al. Learning the pe header, malware detection with minimaldomain knowledge. In Proceedings of the 10th ACM Workshop on Artificial Intelligenceand Security, 2017, pp. 121–132.[41] Kolosnjaji, B.; Eraisha, G.; et al. Empowering convolutional networks for malwareclassification and analysis. In 2017 International Joint Conference on Neural Networks(IJCNN), IEEE, 2017, pp. 3838–3845.[42] Singh, T.; Di Troia, F.; et al. Support vector machines and malware detection. Journalof Computer Virology and Hacking Techniques, 2015: pp. 1–10.[43] Asquith, M. Extremely scalable storage and clustering of malware metadata. Journalof Computer Virology and Hacking Techniques, volume 12, no. 2, 2016: pp. 49–58.[44] Saxe, J.; Berlin, K. Deep neural network based malware detection using two dimen-sional binary program features. In 2015 10th International Conference on Maliciousand Unwanted Software (MALWARE), IEEE, 2015, pp. 11–20.[45] Baldangombo, U.; Jambaljav, N.; et al. A static malware detection system using datamining methods. arXiv preprint arXiv:1308.2831, 2013.[46] Hall, M.; Frank, E.; et al. The WEKA data mining software: an update. ACMSIGKDD explorations newsletter, volume 11, no. 1, 2009: pp. 10–18.[47] Shafiq, M. Z.; Tabish, S. M.; et al. Pe-miner: Mining structural information to detectmalicious executables in realtime. In International Workshop on Recent Advances inIntrusion Detection, Springer, 2009, pp. 121–141.[48] Merkel, R.; Hoppe, T.; et al. Statistical detection of malicious PE-executables for fastoffline analysis. In IFIP International Conference on Communications and MultimediaSecurity, Springer, 2010, pp. 93–105.[49] Ye, Y.; Wang, D.; et al. IMDS: Intelligent malware detection system. In Proceedingsof the 13th ACM SIGKDD international conference on Knowledge discovery and datamining, 2007, pp. 1043–1047.[50] Basole, S.; Di Troia, F.; et al. Multifamily malware models. Journal of ComputerVirology and Hacking Techniques, 2020: pp. 1–14.[51] Mohaisen, A.; Alrawi, O.; et al. Amal: High-fidelity, behavior-based automated mal-ware analysis and classification. computers & security, volume 52, 2015: pp. 251–266.[52] Ahmadi, M.; Ulyanov, D.; et al. Novel feature extraction, selection and fusion foreffective malware family classification. In Proceedings of the sixth ACM conference ondata and application security and privacy, 2016, pp. 183–194.112Bibliography[53] Islam, R.; Tian, R.; et al. Classification of malware based on integrated static anddynamic features. Journal of Network and Computer Applications, volume 36, no. 2,2013: pp. 646–656.[54] Lakhotia, A.; Walenstein, A.; et al. Vilo: a rapid learning nearest-neighbor classifierfor malware triage. Journal of Computer Virology and Hacking Techniques, volume 9,no. 3, 2013: pp. 109–123.[55] Stanfill, C.; Waltz, D. Toward memory-based reasoning. Communications of the ACM,volume 29, no. 12, 1986: pp. 1213–1228.[56] Wilson, D. R.; Martinez, T. R. Improved heterogeneous distance functions. Journalof artificial intelligence research, volume 6, 1997: pp. 1–34.[57] Fix, E.; Hodges Jr, J. L. Discriminatory analysis-nonparametric discrimination: con-sistency properties. Technical report, DTIC Document, 1951.[58] Dudani, S. A. The distance-weighted k-nearest-neighbor rule. IEEE Transactions onSystems, Man, and Cybernetics, volume SMC-6, no. 4, 1976: pp. 325–327.[59] Quinlan, J. R. Induction of decision trees. Machine learning, volume 1, no. 1, 1986:pp. 81–106.[60] Eberhart, R.; Kennedy, J. Particle swarm optimization. In Proceedings of the IEEEinternational conference on neural networks, volume 4, Citeseer, 1995, pp. 1942–1948,doi:10.1109/ICNN.1995.488968.[61] Kuhn, M.; Johnson, K.; et al. Applied predictive modeling, volume 26. Springer, 2013.[62] Hochreiter, S.; Schmidhuber, J. Long short-term memory. Neural computation,volume 9, no. 8, 1997: pp. 1735–1780.[63] Graves, A.; Schmidhuber, J. Framewise phoneme classification with bidirectionalLSTM and other neural network architectures. Neural networks, volume 18, no. 5-6, 2005: pp. 602–610.[64] Vincent, P.; Larochelle, H.; et al. Stacked denoising autoencoders: Learning usefulrepresentations in a deep network with a local denoising criterion. Journal of machinelearning research, volume 11, no. 12, 2010.[65] Carrera, E. Pefile. https://github.com/erocarrera/pefile, 2017.[66] Scikit-learn. scikit-learn.org. https://scikit-learn.org/, 2021.[67] Wettschereck, D.; Aha, D. W.; et al. A review and empirical evaluation of featureweighting methods for a class of lazy learning algorithms. Artificial Intelligence Re-view, volume 11, no. 1-5, 1997: pp. 273–314, doi:10.1023/A:1006593614256.113Bibliography[68] Suárez, J. L.; Garćıa, S.; et al. A tutorial on distance metric learning: Mathematicalfoundations, algorithms, experimental analysis, prospects and challenges. Neurocom-puting, 2020, to be published.[69] Weinberger, K. Q.; Blitzer, J.; et al. Distance metric learning for large margin nearestneighbor classification. In Advances in neural information processing systems, 2006,pp. 1473–1480.[70] Goldberger, J.; Hinton, G. E.; et al. Neighbourhood components analysis. In Advancesin neural information processing systems, 2005, pp. 513–520.[71] Weinberger, K. Q.; Tesauro, G. Metric learning for kernel regression. In ArtificialIntelligence and Statistics, 2007, pp. 612–619.[72] Guyon, I.; Weston, J.; et al. Gene selection for cancer classification using supportvector machines. Machine learning, volume 46, no. 1, 2002: pp. 389–422.[73] Kozák, M. Static Malware Detection using Recurrent Neural Networks. Bachelor’sthesis, Czech Technical University in Prague, Faculty of Information Technology, 2020.114Reviewed Publications of the AuthorRelevant to the Thesis[A.1] Jureček, M., Lórencz, R. Malware Detection Using a Heterogeneous Distance Func-tion. In: Computing and Informatics. Volume 37, no. 3, pp. 759-780, 2018.The paper has been cited in:◦ Wang, Z., Han, W., Lu, Y., & Xue, J. A Malware Classification Method Basedon the Capsule Network. In: International Conference on Machine Learning forCyber Security, pp. 35-49, 2020. (



Citation Indexed in Scopus and Google Scholar)[A.2] Jureček, M., Lórencz, R. Distance Metric Learning using Particle Swarm Optim-ization to Improve Static Malware Detection. In: Proceedings of Int. Conf. on In-formation Systems Security and Privacy (ICISSP). pp. 725-732, Valletta, Malta,2020.[A.3] Jureček, M., Kozák, M. Representation of PE Files using LSTM Networks. In:Proceedings of Int. Conf. on Information Systems Security and Privacy (ICISSP).pp. 516-525, Vienna / Virtual event, Austria, 2021.[A.4] Jureček, M., Jurečková, O., Lórencz, R. Improving Classification of Malware Familiesusing Learning a Distance Metric. In: Proceedings of Int. Conf. on Information Sys-tems Security and Privacy (ICISSP). pp. 643-652, Vienna / Virtual event, Austria,2021.[A.5] Jureček, M., Lórencz, R. Application of Distance Metric Learning to AutomatedMalware Detection. 2021, (the paper was submitted to the journal IEEE Access).115Remaining Publications of the AuthorRelevant to the Thesis[A.6] Jureček, M. Automatic Malware Detection. Ph.D. Minimum Thesis, Faculty ofInformation Technology, Prague, Czech Republic, 2017.[A.7] Jureček, M. Automatická detekcia malware. In: Sborńık Poč́ıtačové architektury adiagnostika (PAD), Doksy, Czech Republic, pp. 35-38, 2019.117Remaining Publications of the Author[A.8] Jureček, M., Buček, J., Lórencz, R. Side-Channel Attack on the A5/1 Stream Cipher.In: Proceedings of 22nd Euromicro Conference on Digital System Design (DSD). pp.633-638, Kallithea, Greece, 2019.119
