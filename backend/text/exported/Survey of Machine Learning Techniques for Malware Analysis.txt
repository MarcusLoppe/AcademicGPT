
Survey of Machine Learning Techniques for Malware Analysis (2018) by Aniello, Leonardo, Baldoni, Roberto, Ucci, Daniele
Abstract:
Coping with malware is getting more and more challenging, given their

relentless growth in complexity and volume. One of the most common approaches

in literature is using machine learning techniques, to automatically learn

models and patterns behind such complexity, and to develop technologies for

keeping pace with the speed of development of novel malware. This survey aims

at providing an overview on the way machine learning has been used so far in

the context of malware analysis. We systematize surveyed papers according to

their objectives (i.e., the expected output, what the analysis aims to), what

information about malware they specifically use (i.e., the features), and what

machine learning techniques they employ (i.e., what algorithm is used to

process the input and produce the output). We also outline a number of problems

concerning the datasets used in considered works, and finally introduce the

novel concept of malware analysis economics, regarding the study of existing

tradeoffs among key metrics, such as analysis accuracy and economical costs

FullText:
Survey of Machine Learning Techniques
for Malware Analysis
Daniele Uccia,, Leonardo Aniellob, Roberto Baldonia
aResearch Center of Cyber Intelligence and Information Security, “La Sapienza” University
of Rome
bCyber Security Research Group, University of Southampton




Abstract
Coping with malware is getting more and more challenging, given their re-
lentless growth in complexity and volume. One of the most common approaches
in literature is using machine learning techniques, to automatically learn mod-
els and patterns behind such complexity, and to develop technologies to keep
pace with malware evolution. This survey aims at providing an 

Overview on
the way machine learning has been used so far in the context of malware analy-
sis in Windows environments, i.e. for the analysis of Portable Executables. We
systematize surveyed papers according to their objectives (i.e., the expected out-
put), what information about malware they specifically use (i.e., the features),
and what machine learning techniques they employ (i.e., what algorithm is used
to process the input and produce the output). We also outline a number of
issues and challenges, including those concerning the used datasets, and identify
the main current topical trends and how to possibly advance them. In partic-
ular, we introduce the novel concept of malware analysis economics, regarding
the study of existing trade-offs among key metrics, such as analysis accuracy
and economical costs.




Keywords: portable executable, malware analysis, machine learning,
benchmark, malware analysis economics
Email addresses: ucci@diag.uniroma1.it (Daniele Ucci), l.aniello@soton.ac.uk
(Leonardo Aniello), baldoni@diag.uniroma1.it (Roberto Baldoni)
Preprint submitted to Computers and Security November 27, 2018
ar
X
iv
:1
71
0.
08
18
9v
3 
 [c
s.C
R]
  2
6 N
ov
 20
18
1. 



Introduction
Despite the significant improvement of cyber security mechanisms and their
continuous evolution, malware are still among the most effective threats in the
cyber space. Malware analysis applies techniques from several different fields,
such as program analysis and network analysis, for the study of malicious sam-
ples to develop a deeper understanding on several aspects, including their be-
haviour and how they evolve over time. Within the unceasing arms race between
malware developers and analysts, each advance in security technology is usually
promptly followed by a corresponding evasion. Part of the effectiveness of novel
defensive measures depends on what properties they leverage on. For example, a
detection rule based on the MD5 hash of a known malware can be easily eluded
by applying standard techniques like obfuscation, or more advanced approaches
such as polymorphism or metamorphism. For a comprehensive review of these
techniques, refer to Ye et al. [1]. These methods change the binary of the mal-
ware, and thus its hash, but leave its behaviour unmodified. On the other side,
developing detection rules that capture the semantics of a malicious sample is
much more difficult to circumvent, because malware developers should apply
more complex modifications. A major goal of malware analysis is to capture
additional properties to be used to improve security measures and make evasion
as hard as possible. Machine learning is a natural choice to support such a
process of knowledge extraction. Indeed, many works in literature have taken
this direction, with a variety of approaches, objectives and 

Results.
This survey aims at reviewing and systematising existing literature where
machine learning is used to support malware analysis of Windows executables,
i.e. Portable Executables (PEs). The intended audience of this survey includes
any security analysts, i.e. security-minded reverse engineer or software devel-
oper, who may benefit from applying machine learning to automate part of
malware analysis operations and make the workload more tractable. Although
mobile malware represents an ever growing threat, Windows largely remains
the preferred target [2] among all the existing platforms. Malware analysis
2
techniques for PEs are slightly different from those for Android apps because
there are significant dissimilarities on how operating system and applications
work. As a matter of fact, literature papers on malware analysis commonly
point out what specific platform they target, so we specifically focus on works
that consider the analysis of PEs. 64 recent papers have been selected on the
basis of their bibliographic significance, reviewed and systematised according
to a taxonomy with three fundamental dimensions: (i) the specific objective of
the analysis, (ii) what types of features extracted from PEs they consider and
(iii) what machine learning algorithms they use. We distinguish three main
objectives: malware detection, malware similarity analysis and malware cate-
gory detection. PE features have been grouped in eight types: byte sequences,
APIs/System calls, opcodes, network, file system, CPU registers, PE file char-
acteristics and strings. Machine learning algorithms have been categorized de-
pending on whether the learning is supervised, unsupervised or semi-supervised.
The characterisation of surveyed papers according to such taxonomy allows to
spot research directions that have not been investigated yet, such as the impact
of particular combination of features on analysis accuracy. The analysis of such
a large literature leads to single out three main issues to address. The first
concerns overcoming modern anti-analysis techniques such as encryption. The
second regards the inaccuracy of malware behaviour modelling due to the choice
of what operations of the sample are considered for the analysis. The third is
about the obsolescence and unavailability of the datasets used in the evalua-
tion, which affect the significance of obtained 

Results and their reproducibility.
In this respect, we propose a few guidelines to prepare suitable benchmarks
for malware analysis through machine learning. We also identify a number of
topical trends that we consider worth to be investigated more in detail, such as
malware attribution and triage. Furthermore, we introduce the novel concept of
malware analysis economics, regarding the existing trade-offs between analysis
accuracy, time and cost, which should be taken into account when designing a
malware analysis environment.
The novel contributions of this work are
3
• the definition of a taxonomy to synthesise the state of the art on machine
learning for malware analysis of PEs;
• a detailed comparative analysis of existing literature on that topic, struc-
tured according to the proposed taxonomy, which 

Highlights possible new
research directions;
• the determination of present main issues and challenges on that subject,
and the proposal of high-level directions to investigate to overcome them;
• the identification of a number of topical trends on machine learning for
malware analysis of PEs, with general guidelines on how to advance them;
• the definition of the novel concept of malware analysis economics.
The rest of the paper is structured as follows. Related work are described
in 



Section 2. 



Section 3 presents the taxonomy we propose to organise reviewed
malware analysis approaches based on machine learning, which are then charac-
terised according to such a taxonomy in 



Section 4. From this characterisation,
current issues and challenges are pointed out in 



Section 5. 



Section 6 

Highlights
topical trends and how to advance them. Malware analysis economics is in-
troduced in 



Section 7. Finally, 



Conclusions and 



Future Works are presented in




Section 8.
2. Related Work
Other academic works have already addressed the problem of surveying con-
tributions on the usage of machine learning techniques for malware analysis.
The survey written by Shabtai et al. [3] is the first one on this topic. It specifi-
cally deals with how classifiers are used on static features to detect malware. As
most of the other surveys mentioned in this sub



Section, the main difference with
our work is that our scope is wider as we target other objectives besides malware
detection, such as similarities analysis and category detection. Furthermore, a
novel contribution we provide is the idea of malware economics, which is not
4
mentioned by any related work. Also in [4], the authors provide a compara-
tive study on papers using pattern matching to detect malware, by reporting
their advantages, disadvantages and problems. Souri and Hosseini [5] proposes
a taxonomy of malware detection approaches based on machine learning. In
addition to consider detection only, their work differs from ours because they do
not investigate what features are taken into account. LeDoux and Lakhotia [6]
describe how machine learning is used for malware analysis, whose end goal is
defined there as “automatically detect malware as soon as possible, remove it,
and repair any damage it has done”.
Bazrafshan et al. [7] focus on malware detection and identify three main
methods for detecting malicious software, i.e. based on signatures, behaviours
and heuristics, the latter using also machine learning techniques. They also
identify what classes of features are used by reviewed heuristics for malware
detection, i.e. API calls, control flow graphs, n-grams, opcodes and hybrid
features. In addition to going beyond malware detection, we propose a larger
number of feature types, which reflects the wider breadth of our research.
Basu et al. [8] examine different works relying on data mining and machine
learning techniques for the detection of malware. They identify five types of
features: API call graph, byte sequence, PE header and 



Sections, opcode se-
quence frequency and kernel, i.e. system calls. In our survey we establish more
feature types, such as strings, file system and CPU registers. They also compare
surveyed papers by used features, used dataset and mining method.
Ye et al. [1] examine different aspects of malware detection processes, fo-
cusing on feature extraction/selection and classification/clustering algorithms.
Also in this case, our survey looks at a larger range of papers by also including
many works on similarity analysis and category detection. They also highlight a
number of issues, mainly dealing with machine learning aspects (i.e. incremental
learning, active learning and adversarial learning). We instead look at current
issues and 

Limitations from a distinct angle, indeed coming to a different set of
identified problems that complement theirs. Furthermore, they outline several
trends on malware development, while we rather report on trends about machine
5
learning for malware analysis, again complementing their contributions.
Barriga and Yoo [9] briefly survey literature on malware detection and mal-
ware evasion techniques, to discuss how machine learning can be used by mal-
ware to bypass current detection mechanisms. Our survey focuses instead on
how machine learning can support malware analysis, even when evasion tech-
niques are used. Gardiner and Nagaraja [10] concentrate their survey on the
detection of command and control centres through machine learning.
3. Taxonomy of Machine Learning Techniques for Malware Analysis
This 



Section introduces the taxonomy on how machine learning is used for
malware analysis in the reviewed papers. We identify three major dimensions
along which surveyed works can be conveniently organised. The first one char-
acterises the final objective of the analysis, e.g. malware detection. The second
dimension describes the features that the analysis is based on in terms of how
they are extracted, e.g. through dynamic analysis, and what features are con-
sidered, e.g. CPU registers. Finally, the third dimension defines what type of
machine learning algorithm is used for the analysis, e.g. supervised learning.
Figure 1 shows a graphical representation of the taxonomy. The rest of this




Section is structured according to the taxonomy. Sub



Section 3.1 describes in
details the objective dimension, features are pointed out in sub



Section 3.2 and
machine learning algorithms are reported in sub



Section 3.3.
3.1. Malware Analysis Objectives
Malware analysis, in general, demands for strong detection capabilities to
find matches with the knowledge developed by investigating past samples. Any-
way, the final goal of searching for those matches differs. For example, a malware
analyst may be specifically interested in determining whether new suspicious
samples are malicious or not, while another may be rather inspecting new mal-
ware looking for what family they likely belong to. This sub



Section details
the analysis goals of the surveyed papers, organized in three main objectives:
6
Figure 1: Taxonomy of machine learning techniques for malware analysis
malware detection (§ 3.1.1), malware similarity analysis (§ 3.1.2) and malware
category detection (§ 3.1.3).
3.1.1. Malware Detection
The most common objective in the context of malware analysis is detecting
whether a given sample is malicious. This objective is also the most important
because knowing in advance that a sample is dangerous allows to block it before
it becomes harmful. Indeed, the majority of reviewed works has this as main
goal [11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30,
31, 32, 33, 34, 35, 36]. Depending on what machine learning technique is used,
the generated output can be provided with a confidence value that can be used
by analysts to understand if a sample needs further inspection.
3.1.2. Malware Similarity Analysis
Another relevant objective is spotting similarities among malware, for ex-
ample to understand how novel samples differ from previous, known ones. We
find four slightly different versions of this objective: variants detection, families
detection, similarities detection and differences detection.
7
Variants Detection. Developing variants is one of the most effective and cheap-
est strategies for an attacker to evade detection mechanisms, while reusing as
much as possible already available codes and resources. Recognizing that a sam-
ple is actually a variant of a known malware prevents such strategy to succeed,
and paves the way to understand how malware evolve over time through the
development of new variants. Also this objective has been deeply studied in
literature, and several reviewed papers target the detection of variants. Given
a malicious sample m, variants detection consists in selecting from the avail-
able knowledge base the samples that are variants of m [37, 30, 38, 39, 40, 41].
Considering the huge number of malicious samples received daily from major se-
curity firms, recognising variants of already known malware is crucial to reduce
the workload for human analysts.
Families Detection. Given a malicious sample m, families detection consists in
selecting from the available knowledge base the families that m likely belongs
to [42, 43, 44, 45, 46, 47, 48, 49, 50, 31, 51, 52, 53, 54, 36]. In this way, it
is possible to associate unknown samples to already known families and, by
consequence, provide an added-value information for further analyses.
Similarities Detection. Analysts can be interested in identifying the specific
similarities and differences of the binaries to analyse with respect to those al-
ready analysed. Similarities detection consists in discovering what parts and
aspects of a sample are similar to something that has been already examined
in the past. It enables to focus on what is really new, and hence to discard the
rest as it does not deserve further investigation [55, 56, 57, 58, 59].
Differences Detection. As a complement, also identifying what is different from
everything else already observed in the past 

Results worthwhile. As a matter
of fact, differences can guide towards discovering novel aspects that should be
analysed more in depth [56, 60, 57, 58, 61, 62].
8
3.1.3. Malware Category Detection
Malware can be categorized according to their prominent behaviours and
objectives. They can be interested in spying on users’ activities and stealing
their sensitive information (i.e., spyware), encrypting documents and asking for
a ransom (i.e., ransomware), or gaining remote control of an infected machine
(i.e., remote access toolkits). Using these categories is a coarse-grained yet
significant way of describing malicious samples [63, 64, 65, 66, 32, 67]. Although
cyber security firms have not still agreed upon a standardized taxonomy of
malware categories, effectively recognising the categories of a sample can add
valuable information for the analysis.
3.2. Malware Analysis Features
This sub



Section deals with the features of samples that are considered for
the analysis. How features are extracted from executables is reported in subsec-
tion 3.2.1, while sub



Section 3.2.2 details which specific features are taken into
account.
3.2.1. Feature Extraction
The information extraction process is performed through either static or dy-
namic analysis, or a combination of both, while examination and correlation are
carried out by using machine learning techniques. Approaches based on static
analysis look at the content of samples without requiring their execution, while
dynamic analysis works by running samples to examine their behaviour. Several
techniques can be used for dynamic malware analysis. Debuggers are used for
instruction level analysis. Simulators model and show a behaviour similar to the
environment expected by the malware, while emulators replicate the behaviour
of a system with higher accuracy but require more resources. Sandboxes are vir-
tualised operating systems providing an isolated and reliable environment where
to detonate malware. Refer to Ye et al. [1] for a more detailed description of
these techniques. Execution traces are commonly used to extract features when
dynamic analysis is employed. Reviewed articles generate execution traces by
9
using either sandboxes [42, 56, 68, 15, 16, 60, 57, 58, 69, 51, 52, 33] or em-
ulators [70, 40]. Also program analysis tools and techniques can be useful in
the feature extraction process by providing, for example, disassembly code and
control- and data-flow graphs. An accurate disassembly code is important for
obtaining correct Byte sequences and Opcodes features (§ 3.2.2), while control-
and data-flow graphs can be employed in the extraction of API and System
Calls (§ 3.2.2). For an extensive dissertation on dynamic analyses, refer to [71].
Among reviewed works, the majority relies on dynamic analyses [42, 55, 56,
15, 44, 16, 60, 57, 66, 46, 50, 58, 24, 26, 28, 30, 51, 52, 53, 35, 40], while the
others use, in equal proportions, either static analyses alone [11, 12, 63, 64, 72,
17, 65, 19, 47, 49, 61, 22, 23, 25, 31, 73, 27, 29, 37, 38, 54, 67, 74, 39] or a
combination of static and dynamic techniques [75, 18, 21, 48, 20, 59, 69, 62, 41].
Depending on the specific features, extraction processes can be performed by
applying either static, dynamic, or hybrid analysis.
3.2.2. Portable Executable Features
This 



Section provides an 

Overview on what features are used by reviewed
papers to achieve the objectives outlined in 



Section 3.1. In many cases, surveyed
works only refer to macro-classes without mentioning the specific features they
employed. As an example, when n-grams are used, only a minority of works
mention the size of n.
Byte Sequences. A binary can be characterised by computing features on its
byte-level content. Analysing the specific sequences of bytes in a PE is a widely
employed static technique. A few works use chunks of bytes of specific sizes [11,
74, 36], while many others rely on n-grams [12, 16, 75, 57, 18, 46, 26, 31, 27,
29, 52, 67, 74, 39, 35].
An n-gram is a sequence of n bytes, and features correspond to the different
combination of these n bytes, namely each feature represents how many times
a specific combination of n bytes occurs in the binary. The majority of works
that specified the size of used n-grams relies on sequences no longer than 3 (i.e.
10
trigrams) [74, 52, 31, 16, 18, 67, 46, 48]. Indeed, the number of features to
consider grows exponentially with n.
Opcodes. Opcodes identify the machine-level operations executed by a PE, and
can be extracted through static analyses by examining the assembly code [63,
64, 45, 16, 18, 47, 49, 61, 20, 31, 37, 38, 54, 67, 74]. Opcode frequency is one
of the most commonly used feature. It measures the number of times each
specific opcode appears within the assembly or is executed by a PE [45, 38].
Others [18, 38] count opcode occurrences by aggregating them by operation
type, e.g., mathematical instructions, memory access instructions. Similarly to
n-grams, also sequences of opcodes are used as features [45, 37, 38, 74].
API and System Calls. Similarly to opcodes, APIs and system calls enable the
analysis of samples’ behaviour, but at a higher level. They can be either ex-
tracted statically or dynamically by analysing the disassembly code (to get the
list of all calls that can be potentially executed) or the execution traces (for the
list of calls actually invoked). While APIs allow to characterise what actions
are executed by a sample [13, 48, 49, 23, 59, 31, 51, 40], looking at system call
invocations provides a view on the interaction of the PE with the operating sys-
tem [42, 56, 44, 57, 18, 46, 58, 20, 59, 26, 70, 28, 33]. Data extracted by observing
APIs and system calls can be really large, and many works carry out additional
processing to reduce feature space by using convenient data structures. One of
the most popular data structures to represent PE behaviour and extract pro-
gram structure is the control flow graph. This data structure allows compilers
to produce an optimized version of the program itself and model control flow re-
lationships [76]. Several works employ control flow graphs and their extensions
for sample analysis, in combination with other feature classes [18, 21, 69, 62, 35].
Network Activity. A huge number of key information can be obtained by ob-
serving how the PE interacts with the network. Contacted addresses and
generated traffic can unveil valuable aspects, e.g. regarding the communica-
tion with a command and control centre. Relevant features include statistics
11
on used protocols, TCP/UDP ports, HTTP requests, DNS-level interactions.
Many surveyed works require dynamic analysis to extract this kind of informa-
tion [42, 55, 56, 60, 50, 69, 32, 53, 40]. Other papers extract network-related
inputs by monitoring the network and analysing incoming and outgoing traf-
fic [66, 24, 41]. A complementary approach consists in analysing download pat-
terns of network users in a monitored network [22]. It does not require sample
execution and focuses on network features related to the download of a sample,
such as the website from which the file has been downloaded.
File System. What file operations are executed by samples is fundamental to
grasp evidence about the interaction with the environment and possibly detect
attempts to gain persistence. Features of interest mainly concern how many
files are read or modified, what types of files and in what directories, and which
files appear in not-infected/infected machines [42, 55, 14, 49, 69, 52, 33, 53].
Sandboxes and memory analysis toolkits include modules for monitoring inter-
actions with the file system, usually modelled by counting the number of files
created/deleted/modified by the PE. In [53], the size of these files is considered
as well, while Lin et al. leverage the number of created hidden files [52].
A particularly relevant type of file system features are those extracted from
the Windows Registry. The registry is one of the main sources of information
for a PE about the environment, and also represents a fundamental tool to
hook into the operating system, for example to gain persistence. Discovering
what keys are queried, created, deleted and modified can shed light on many
significant characteristics of a sample [42, 52, 33, 53]. Usually, works relying on
file system inputs monitor also the Windows Registry.
CPU Registers. The way CPU registers are used can also be a valuable indica-
tion, including whether any hidden register is used, and what values are stored
in the registers, especially in the FLAGS register [49, 31, 59, 30].
PE file characteristics. A static analysis of a PE can provide a large set of
valuable information such as 



Sections, imports, symbols, used compilers [42, 19,
12
77, 23, 70, 34].
Strings. A PE can be statically inspected to explicitly look for the strings it
contains, such as code fragments, author signatures, file names, system resource
information [11, 48, 34, 31].
3.3. Malware Analysis Algorithms
This sub



Section reports what machine learning algorithms are used in sur-
veyed works by organising them on the basis of whether the learning is super-
vised (§ 3.3.1), unsupervised (§ 3.3.2) or semi-supervised (§ 3.3.3).
3.3.1. Supervised Learning
Supervised learning is the task of gaining knowledge by providing statisti-
cal models with correct instance examples, during a preliminary phase called
training. The supervised algorithms used by reviewed papers are rule-based
classifier [11, 29, 30, 67, 40, 78, 60, 13], Bayes classifier [61, 20, 26, 51, 35],
Na¨ıve Bayes [11, 12, 15, 26, 51, 67, 35], Bayesian Network [21, 61, 20], Sup-
port Vector Machine (SVM) [12, 13, 15, 16, 65, 66, 48, 49, 61, 20, 24, 26, 31,
29, 51, 52, 53, 67, 35], Multiple Kernel Learning [18], Prototype-based Classi-
fication [57], Decision Tree [12, 13, 15, 48, 50, 61, 20, 23, 26, 51, 38, 53, 74],
Random Forest [72, 66, 48, 26, 31, 51, 38, 32, 33, 35], Gradient Boosting De-
cision Tree [65, 67], Logistic Model Tree [69, 46, 67, 58], k-Nearest Neighbors
(k-NN) [42, 49, 53, 36, 13, 15, 48, 51, 61], Artificial Neural Network [46, 34],
Multilayer Perceptron Neural Network [15].
3.3.2. Unsupervised Learning
Unsupervised approaches do not rely on any training phase and learn di-
rectly from unlabeled data. Reviewed papers use these unsupervised learning
algorithms: Clustering with locality sensitive hashing [56, 25, 39], Clustering with
Distance and Similarity Metrics (using either Euclidean [57, 53] or Hamming
distances [53], or cosine [53] or Jaccard similarities [53, 62]), Expectation Max-
imization [54], k-Means Clustering [43, 54], k-Medoids [45], Density-based Spa-
13
tial Clustering of Applications with Noise [41], Hierarchical Clustering [75, 53],
Prototype-based Clustering [57], Self-Organizing Maps [65].
3.3.3. Semi-supervised Learning
Semi-supervised learning combines both labeled and unlabeled data for feed-
ing statistical models to acquire knowledge. Learning with Local and Global
Consistency is used in [17] while Belief Propagation in [14, 25, 27].
4. Characterization of Surveyed Papers
In this 



Section we characterize each reviewed paper on the basis of analysis
objective, used machine learning algorithm and features. Several details are
also reported on the dataset used for the evaluation, including whether it is
publicly available (Public column), where samples have been collected from
(Source column) and whether the specific set of samples considered for the
experiment is available (Available column). Indeed, many works declare they do
not use all the executables in the dataset but they do not specify what samples
they choose, which prevents to reproduce their 

Results. The Label column states
how samples have been labelled. Finally, Benign, Malicious and Total columns
report benign executables count, malware count and their sum, respectively.
Malware detection. Table 1 lists all the reviewed works having malware
detection as objective. Most used features are byte sequences and API/system
call invocations, derived by executing the samples. Most of the works use more
than one algorithm to find out the one guaranteeing more accurate 

Results.
Malware similarity analysis. A table is provided for each version of this
objective (§ 3.1.2). Tables 2 and 3 describe the works dealing with variants
detection and families detection, respectively. For both, APIs and system calls
are largely used, as well as malware interactions with the environment, i.e.
memory, file system, and CPU registers. Tables 4 and 5 report the papers
on similarities and differences detection, respectively. All the analysed papers
but [61] rely on APIs and system calls collection. Works on differences detection,
14
in general, do not take into account the interactions with the hosting system,
while those on similarities detection do.
Malware category detection. These articles focus on the identification of
specific threats and, thus, on particular features such as byte sequences, opcodes,
function lengths and network activity. Table 6 reports the works whose objective
is the detection of malware category.
By reasoning on what algorithms and features have been used and what
have not for specific objectives, the provided characterisation allows to easily
identify gaps in the literature and, thus, possible research directions to inves-
tigate. For instance, all works on differences detection (see Table 5) but [61],
rely on dynamically extracted APIs and system calls for building their machine
learning models. Novel approaches can be explored by taking into account other
features that capture malware interactions with the environment (e.g., memory,
file system, CPU registers and Windows Registry).
15
T
a
b
le
1
:
C
h
a
ra
ct
er
iz
a
ti
o
n
o
f
su
rv
ey
ed
p
a
p
er
s
h
a
v
in
g
m
a
lw
a
re
d
et
ec
ti
o
n
a
s
o
b
je
ct
iv
e.
P
a
p
e
r
A
lg
o
r
it
h
m
s
F
e
a
t
u
r
e
s
L
im
it
a
t
io
n
s
D
a
t
a
s
e
t
s
a
m
p
le
s
P
u
b
li
c
S
o
u
r
c
e
A
v
a
il
a
b
le
L
a
b
e
li
n
g
B
e
n
ig
n
M
a
li
c
io
u
s
T
o
t
a
l
S
c
h
u
lt
z
e
t
a
l
[1
1
]
R
u
le
-b
a
s
e
d
c
la
s
s
if
ie
r
,
N
a¨
ıv
e
B
a
y
e
s
S
t
r
in
g
s
a
n
d
b
y
t
e
s
e
-
q
u
e
n
c
e
s
P
r
o
p
o
s
e
d
s
o
lu
t
io
n
s
a
r
e
n
o
t
e
ff
e
c
-
t
iv
e
a
g
a
in
s
t
e
n
c
r
y
p
t
e
d
e
x
e
c
u
t
a
-
b
le
s
a
n
d
t
h
e
d
a
t
a
s
e
t
u
s
e
d
in
t
h
e
e
v
a
lu
a
t
io
n
s
is
s
m
a
ll
.
−
F
T
P
s
it
e
s
X
A
u
t
o
m
a
t
e
d
1
,
0
0
1
3
,
2
6
5
4
,
2
6
6
K
o
lt
e
r
a
n
d
M
a
lo
o
f
[1
2
]
D
e
c
is
io
n
T
r
e
e
,
N
a¨
ıv
e
B
a
y
e
s
,
S
V
M
B
y
t
e
s
e
q
u
e
n
c
e
s
P
a
y
lo
a
d
c
la
s
s
if
ic
a
t
io
n
fa
il
s
in
p
r
e
s
e
n
c
e
o
f
b
in
a
r
y
o
b
fu
s
c
a
t
io
n
a
n
d
t
h
e
d
a
t
a
s
e
t
u
s
e
d
in
t
h
e
e
v
a
l-
u
a
t
io
n
s
is
v
e
r
y
s
m
a
ll
.
7
In
t
e
r
n
e
t
,
V
X
H
e
a
v
e
n
s
,
a
n
d
M
IT
R
E
7
A
u
t
o
m
a
t
e
d
1
,
9
7
1
1
,
6
5
1
3
,
6
2
2
A
h
m
e
d
e
t
a
l.
[1
3
]
D
e
c
is
io
n
T
r
e
e
,
N
a¨
ıv
e
B
a
y
e
s
,
S
V
M
A
P
Is
/
S
y
s
t
e
m
c
a
ll
s
T
h
e
d
a
t
a
s
e
t
u
s
e
d
in
t
h
e
e
x
p
e
r
i-
m
e
n
t
a
l
e
v
a
lu
a
t
io
n
s
is
v
e
r
y
s
m
a
ll
.
X
L
e
g
it
im
a
t
e
a
p
p
s
a
n
d
V
X
H
e
a
v
e
n
s
7
−
1
0
0
4
1
6
5
1
6
C
h
a
u
e
t
a
l.
[1
4
]
B
e
li
e
f
p
r
o
p
a
g
a
t
io
n
F
il
e
s
y
s
t
e
m
R
a
r
e
a
n
d
n
e
w
fi
le
s
c
a
n
n
o
t
b
e
a
c
-
c
u
r
a
t
e
ly
c
la
s
s
if
ie
d
a
s
b
e
n
ig
n
o
r
m
a
li
c
io
u
s
.
X
S
y
m
a
n
t
e
c
’s
N
o
r
t
o
n
C
o
m
m
u
n
it
y
W
a
t
c
h
7
−
?
?
9
0
3
·1
0
6
F
ir
d
a
u
s
i
e
t
a
l.
[1
5
]
D
e
c
is
io
n
T
r
e
e
,
N
a¨
ıv
e
B
a
y
e
s
,
S
V
M
,
k
-N
N
,
M
u
lt
il
a
y
e
r
P
e
r
c
e
p
t
r
o
n
N
e
u
r
a
l
N
e
t
w
o
r
k
A
P
Is
/
S
y
s
t
e
m
c
a
ll
s
,
fi
le
s
y
s
t
e
m
,
a
n
d
W
in
d
o
w
s
R
e
g
is
t
r
y
T
h
e
d
a
t
a
s
e
t
u
s
e
d
in
t
h
e
e
x
p
e
r
i-
m
e
n
t
a
l
e
v
a
lu
a
t
io
n
s
is
v
e
r
y
s
m
a
ll
.
X
W
in
d
o
w
s
X
P
S
P
2
7
−
2
5
0
2
2
0
4
7
0
A
n
d
e
r
s
o
n
e
t
a
l.
[1
6
]
S
V
M
B
y
t
e
s
e
q
u
e
n
c
e
s
a
n
d
A
P
Is
/
s
y
s
t
e
m
c
a
ll
s
T
h
e
d
a
t
a
s
e
t
u
s
e
d
in
t
h
e
e
v
a
lu
a
-
t
io
n
s
is
s
m
a
ll
.
−
−
7
−
6
1
5
1
,
6
1
5
2
,
2
3
0
S
a
n
t
o
s
e
t
a
l.
[1
7
]
L
e
a
r
n
in
g
w
it
h
L
o
c
a
l
a
n
d
G
lo
b
a
l
C
o
n
s
is
t
e
n
c
y
B
y
t
e
s
e
q
u
e
n
c
e
s
P
r
o
p
o
s
e
d
a
p
p
r
o
a
c
h
is
n
o
t
e
ff
e
c
-
t
iv
e
a
g
a
in
s
t
p
a
c
k
e
d
m
a
lw
a
r
e
a
n
d
r
e
q
u
ir
e
s
m
a
n
u
a
l
la
b
e
li
n
g
o
f
a
p
o
r
-
t
io
n
o
f
t
h
e
s
m
a
ll
d
a
t
a
s
e
t
.
In
p
a
r
-
t
ic
u
la
r
,
t
h
e
d
a
t
a
s
e
t
u
s
e
d
in
t
h
e
e
x
p
e
r
im
e
n
t
a
l
e
v
a
lu
a
t
io
n
s
is
s
m
a
ll
.
X
O
w
n
m
a
c
h
in
e
s
a
n
d
V
X
H
e
a
v
e
n
s
7
−
1
,
0
0
0
1
,
0
0
0
2
,
0
0
0
A
n
d
e
r
s
o
n
e
t
a
l.
[1
8
]
M
u
lt
ip
le
K
e
r
n
e
l
L
e
a
r
n
-
in
g
B
y
t
e
s
e
q
u
e
n
c
e
s
,
o
p
-
c
o
d
e
s
,
a
n
d
A
P
Is
/
s
y
s
t
e
m
c
a
ll
s
In
s
t
r
u
c
t
io
n
c
a
t
e
g
o
r
iz
a
t
io
n
is
n
o
t
o
p
t
im
a
l.
7
O
ff
e
n
s
iv
e
C
o
m
p
u
t
in
g
7
−
7
7
6
2
1
,
7
1
6
2
2
,
4
9
2
Y
o
n
t
s
[1
9
]
R
u
le
-b
a
s
e
d
c
la
s
s
if
ie
r
P
E
fi
le
c
h
a
r
a
c
t
e
r
is
t
ic
s
O
n
ly
a
s
u
b
s
e
t
o
f
a
ll
t
h
e
p
o
t
e
n
t
ia
l
lo
w
le
v
e
l
a
t
t
r
ib
u
t
e
s
is
c
o
n
s
id
e
r
e
d
.
7
S
A
N
S
In
s
t
it
u
t
e
7
−
6
5
,
0
0
0
2
5
·1
0
5
2
5
.6
5
·1
0
5
C
o
n
ti
n
u
e
o
n
th
e
n
e
x
t
p
a
g
e
16
T
a
b
le
1
:
C
h
a
ra
ct
er
iz
a
ti
o
n
o
f
su
rv
ey
ed
p
a
p
er
s
h
a
v
in
g
m
a
lw
a
re
d
et
ec
ti
o
n
a
s
o
b
je
ct
iv
e.
(C
o
n
ti
n
u
ed
)
P
a
p
e
r
A
lg
o
r
it
h
m
s
F
e
a
t
u
r
e
s
L
im
it
a
t
io
n
s
D
a
t
a
s
e
t
s
a
m
p
le
s
P
u
b
li
c
S
o
u
r
c
e
A
v
a
il
a
b
le
L
a
b
e
li
n
g
B
e
n
ig
n
M
a
li
c
io
u
s
T
o
t
a
l
E
s
k
a
n
d
a
r
i
e
t
a
l.
[2
1
]
B
a
y
e
s
ia
n
N
e
t
w
o
r
k
A
P
Is
/
S
y
s
t
e
m
c
a
ll
s
Ig
n
o
r
e
s
p
e
c
if
ic
in
s
t
r
u
c
t
io
n
s
.
E
v
a
-
s
io
n
/
o
b
fu
s
c
a
t
io
n
t
e
c
h
n
iq
u
e
s
a
n
d
s
a
m
p
le
s
r
e
q
u
ir
in
g
u
s
e
r
in
t
e
r
a
c
-
t
io
n
s
r
e
d
u
c
e
t
h
e
e
ff
e
c
t
iv
e
n
e
s
s
o
f
t
h
e
p
r
o
p
o
s
e
d
a
p
p
r
o
a
c
h
.
T
h
e
d
a
t
a
s
e
t
is
s
m
a
ll
.
7
R
e
s
e
a
r
c
h
L
a
b
o
r
a
t
o
r
y
a
t
S
h
ir
a
z
U
n
iv
e
r
s
it
y
7
−
1
,
0
0
0
2
,
0
0
0
3
,
0
0
0
S
a
n
t
o
s
e
t
a
l.
[2
0
]
B
a
y
e
s
ia
n
N
e
t
w
o
r
k
,
D
e
-
c
is
io
n
T
r
e
e
,
k
-N
N
,
S
V
M
O
p
c
o
d
e
s
,
A
P
Is
/
s
y
s
t
e
m
c
a
ll
s
,
a
n
d
r
a
is
e
d
e
x
c
e
p
-
t
io
n
s
P
a
c
k
e
d
m
a
lw
a
r
e
,
e
v
a
s
io
n
t
e
c
h
-
n
iq
u
e
s
,
a
n
d
s
a
m
p
le
s
r
e
q
u
ir
in
g
u
s
e
r
in
t
e
r
a
c
t
io
n
s
r
e
d
u
c
e
t
h
e
a
c
-
c
u
r
a
c
y
o
f
t
h
e
p
r
o
p
o
s
e
d
s
o
lu
t
io
n
.
T
h
e
d
a
t
a
s
e
t
is
s
m
a
ll
.
X
O
w
n
m
a
c
h
in
e
s
a
n
d
V
X
H
e
a
v
e
n
s
7
−
1
,
0
0
0
1
,
0
0
0
2
,
0
0
0
V
a
d
r
e
v
u
e
t
a
l.
[2
2
]
R
a
n
d
o
m
F
o
r
e
s
t
P
E
fi
le
c
h
a
r
a
c
t
e
r
is
t
ic
s
a
n
d
n
e
t
w
o
r
k
R
e
q
u
ir
e
s
a
h
u
g
e
n
u
m
b
e
r
o
f
s
a
m
-
p
le
s
la
b
e
le
d
e
it
h
e
r
a
s
m
a
li
c
io
u
s
o
r
b
e
n
ig
n
.
7
G
e
o
r
g
ia
In
s
t
it
u
t
e
o
f
T
e
c
h
n
o
lo
g
y
7
A
u
t
o
m
a
t
e
d
1
7
0
,
7
8
0
1
5
,
1
8
2
1
8
5
,
9
6
2
B
a
i
e
t
a
l.
[2
3
]
D
e
c
is
io
n
T
r
e
e
,
R
a
n
d
o
m
F
o
r
e
s
t
P
E
fi
le
c
h
a
r
a
c
t
e
r
is
t
ic
s
A
s
s
u
m
e
t
h
a
t
s
a
m
p
le
s
a
r
e
n
o
t
p
a
c
k
e
d
a
n
d
m
a
lw
a
r
e
a
u
t
h
o
r
s
c
a
n
p
r
o
p
e
r
ly
m
o
d
if
y
P
E
h
e
a
d
e
r
t
o
r
e
-
m
a
in
u
n
d
e
t
e
c
t
e
d
.
X
W
in
d
o
w
s
a
n
d
P
r
o
g
r
a
m
F
il
e
s
fo
ld
e
r
s
a
n
d
V
X
H
e
a
v
e
n
s
7
A
u
t
o
m
a
t
e
d
8
,
5
9
2
1
0
,
5
2
1
1
9
,
1
1
3
K
r
u
c
z
k
o
w
s
k
i
a
n
d
S
z
y
n
k
ie
w
ic
z
[2
4
]
S
V
M
N
e
t
w
o
r
k
T
h
e
d
a
t
a
s
e
t
u
s
e
d
in
t
h
e
e
x
p
e
r
i-
m
e
n
t
a
l
e
v
a
lu
a
t
io
n
s
is
s
m
a
ll
.
7
N
6
P
la
t
fo
r
m
7
−
?
?
1
,
0
1
5
T
a
m
e
r
s
o
y
e
t
a
l.
[2
5
]
C
lu
s
t
e
r
in
g
w
it
h
lo
c
a
li
t
y
s
e
n
s
it
iv
e
h
a
s
h
in
g
F
il
e
s
y
s
t
e
m
R
a
r
e
a
n
d
n
e
w
fi
le
s
c
a
n
n
o
t
b
e
a
c
-
c
u
r
a
t
e
ly
c
la
s
s
if
ie
d
a
s
b
e
n
ig
n
o
r
m
a
li
c
io
u
s
.
X
S
y
m
a
n
t
e
c
’s
N
o
r
t
o
n
C
o
m
m
u
n
it
y
W
a
t
c
h
7
−
1
,
6
6
3
,
5
0
6
4
7
,
9
5
6
4
,
9
7
0
,
8
6
5
U
p
p
a
l
e
t
a
l.
[2
6
]
D
e
c
is
io
n
T
r
e
e
,
R
a
n
d
o
m
F
o
r
e
s
t
,
N
a¨
ıv
e
B
a
y
e
s
,
S
V
M
B
y
t
e
s
e
q
u
e
n
c
e
s
a
n
d
A
P
Is
/
s
y
s
t
e
m
c
a
ll
s
T
h
e
d
a
t
a
s
e
t
u
s
e
d
in
t
h
e
e
x
p
e
r
i-
m
e
n
t
a
l
e
v
a
lu
a
t
io
n
s
is
v
e
r
y
s
m
a
ll
.
X
L
e
g
it
im
a
t
e
a
p
p
s
a
n
d
V
X
H
e
a
v
e
n
s
7
−
1
5
0
1
2
0
2
7
0
C
h
e
n
e
t
a
l.
[2
7
]
B
e
li
e
f
p
r
o
p
a
g
a
t
io
n
F
il
e
s
y
s
t
e
m
R
a
r
e
a
n
d
n
e
w
fi
le
s
c
a
n
n
o
t
b
e
a
c
-
c
u
r
a
t
e
ly
c
la
s
s
if
ie
d
a
s
b
e
n
ig
n
o
r
m
a
li
c
io
u
s
.
7
C
o
m
o
d
o
C
lo
u
d
S
e
c
u
r
it
y
C
e
n
t
e
r
7
−
1
9
,
1
4
2
2
,
8
8
3
6
9
,
1
6
5
E
lh
a
d
i
e
t
a
l.
[2
8
]
M
a
li
c
io
u
s
g
r
a
p
h
m
a
t
c
h
-
in
g
A
P
Is
/
S
y
s
t
e
m
c
a
ll
s
T
h
e
d
a
t
a
s
e
t
u
s
e
d
in
t
h
e
e
x
p
e
r
-
im
e
n
t
a
l
e
v
a
lu
a
t
io
n
s
is
e
x
t
r
e
m
e
ly
s
m
a
ll
.
X
V
X
H
e
a
v
e
n
s
X
−
1
0
7
5
8
5
17
T
a
b
le
1
:
C
h
a
ra
ct
er
iz
a
ti
o
n
o
f
su
rv
ey
ed
p
a
p
er
s
h
a
v
in
g
m
a
lw
a
re
d
et
ec
ti
o
n
a
s
o
b
je
ct
iv
e.
(C
o
n
ti
n
u
ed
)
P
a
p
e
r
A
lg
o
r
it
h
m
s
F
e
a
t
u
r
e
s
L
im
it
a
t
io
n
s
D
a
t
a
s
e
t
s
a
m
p
le
s
P
u
b
li
c
S
o
u
r
c
e
A
v
a
il
a
b
le
L
a
b
e
li
n
g
B
e
n
ig
n
M
a
li
c
io
u
s
T
o
t
a
l
F
e
n
g
e
t
a
l.
[2
9
]
R
u
le
-b
a
s
e
d
c
la
s
s
if
ie
r
,
S
V
M
B
y
t
e
s
e
q
u
e
n
c
e
s
O
n
ly
s
p
e
c
if
ic
m
a
lw
a
r
e
c
la
s
s
e
s
a
r
e
c
o
n
s
id
e
r
e
d
fo
r
t
h
e
a
p
p
r
o
a
c
h
e
v
a
l-
u
a
t
io
n
.
7
W
in
d
o
w
s
s
y
s
t
e
m
fi
le
s
a
n
d
o
w
n
A
V
p
la
t
fo
r
m
7
−
1
0
0
,
0
0
0
1
3
5
,
0
6
4
2
3
5
,
0
6
4
G
h
ia
s
i
e
t
a
l.
[3
0
]
R
u
le
-b
a
s
e
d
c
la
s
s
if
ie
r
A
P
Is
/
S
y
s
t
e
m
c
a
ll
s
a
n
d
C
P
U
r
e
g
is
t
e
r
s
A
P
Is
/
S
y
s
t
e
m
c
a
ll
s
c
a
t
e
g
o
r
iz
a
t
io
n
c
o
u
ld
b
e
n
o
t
o
p
t
im
a
l
a
n
d
t
h
e
d
a
t
a
s
e
t
s
iz
e
is
s
m
a
ll
.
X
W
in
d
o
w
s
X
P
s
y
s
t
e
m
a
n
d
P
r
o
g
r
a
m
F
il
e
s
fo
ld
e
r
s
a
n
d
p
r
iv
a
t
e
r
e
p
o
s
it
o
r
y
7
−
3
9
0
8
5
0
1
,
2
4
0
K
w
o
n
e
t
a
l.
[3
2
]
R
a
n
d
o
m
F
o
r
e
s
t
N
e
t
w
o
r
k
N
o
t
a
b
le
t
o
d
e
t
e
c
t
b
o
t
s
w
it
h
r
o
o
t
k
it
c
a
p
a
b
il
it
ie
s
.
X
S
y
m
a
n
t
e
c
’s
W
o
r
ld
w
id
e
In
t
e
ll
ig
e
n
c
e
N
e
t
w
o
r
k
E
n
v
ir
o
n
m
e
n
t
7
−
?
?
2
4
∗
1
0
6
M
a
o
e
t
a
l.
[3
3
]
R
a
n
d
o
m
F
o
r
e
s
t
A
P
Is
/
S
y
s
t
e
m
c
a
ll
s
,
fi
le
s
y
s
t
e
m
,
a
n
d
W
in
d
o
w
s
R
e
g
is
t
r
y
E
v
a
s
io
n
t
e
c
h
n
iq
u
e
s
a
n
d
s
a
m
p
le
s
r
e
q
u
ir
in
g
u
s
e
r
in
t
e
r
a
c
t
io
n
s
r
e
d
u
c
e
t
h
e
a
c
c
u
r
a
c
y
o
f
t
h
e
p
r
o
p
o
s
e
d
a
p
-
p
r
o
a
c
h
.
T
h
e
d
a
t
a
s
e
t
is
s
m
a
ll
.
X
W
in
d
o
w
s
X
P
S
P
3
a
n
d
V
X
H
e
a
v
e
n
s
7
−
5
3
4
7
,
2
5
7
7
,
7
9
1
S
a
x
e
a
n
d
B
e
r
li
n
[3
4
]
N
e
u
r
a
l
N
e
t
w
o
r
k
s
S
t
r
in
g
s
a
n
d
P
E
fi
le
c
h
a
r
a
c
t
e
r
is
t
ic
s
L
a
b
e
l
a
s
s
ig
n
e
d
t
o
t
r
a
in
in
g
s
e
t
m
a
y
b
e
in
a
c
c
u
r
a
t
e
a
n
d
t
h
e
a
c
c
u
-
r
a
c
y
o
f
t
h
e
p
r
o
p
o
s
e
d
a
p
p
r
o
a
c
h
d
e
-
c
r
e
a
s
e
s
s
u
b
s
t
a
n
t
ia
ll
y
w
h
e
n
s
a
m
-
p
le
s
a
r
e
o
b
fu
s
c
a
t
e
d
.
7
L
e
g
it
im
a
t
e
a
p
p
s
a
n
d
o
w
n
m
a
lw
a
r
e
d
a
t
a
b
a
s
e
7
A
u
t
o
m
a
t
e
d
8
1
,
9
1
0
3
5
0
,
0
1
6
4
3
1
,
9
2
6
S
r
a
k
a
e
w
e
t
a
l.
[7
4
]
D
e
c
is
io
n
T
r
e
e
B
y
t
e
s
e
q
u
e
n
c
e
s
a
n
d
o
p
-
c
o
d
e
s
O
b
fu
s
c
a
t
io
n
t
e
c
h
n
iq
u
e
s
r
e
d
u
c
e
d
e
t
e
c
t
io
n
a
c
c
u
r
a
c
y
.
7
L
e
g
it
im
a
t
e
fi
le
s
a
n
d
a
p
p
s
a
n
d
C
W
S
a
n
d
b
o
x
7
−
6
0
0
3
,
8
5
1
6
9
,
1
6
5
W
u¨
c
h
n
e
r
e
t
a
l.
[3
5
]
N
a¨
ıv
e
B
a
y
e
s
,
R
a
n
d
o
m
F
o
r
e
s
t
,
S
V
M
B
y
t
e
s
e
q
u
e
n
c
e
s
,
A
P
Is
/
s
y
s
t
e
m
c
a
ll
s
,
fi
le
s
y
s
t
e
m
,
a
n
d
W
in
-
d
o
w
s
R
e
g
is
t
r
y
O
b
fu
s
c
a
t
io
n
t
e
c
h
n
iq
u
e
s
a
p
p
li
e
d
b
y
t
h
e
a
u
t
h
o
r
s
m
a
y
n
o
t
r
e
fl
e
c
t
t
h
e
o
n
e
s
o
f
r
e
a
l-
w
o
r
ld
s
a
m
p
le
s
.
T
h
e
d
a
t
a
s
e
t
is
s
m
a
ll
.
7
L
e
g
it
im
a
t
e
a
p
p
d
o
w
n
lo
a
d
s
a
n
d
M
a
li
c
ia
7
−
5
1
3
6
,
9
9
4
7
,
5
0
7
R
a
ff
a
n
d
N
ic
h
o
la
s
[3
6
]
k
-N
N
w
it
h
L
e
m
p
e
l-
Z
iv
J
a
c
c
a
r
d
d
is
t
a
n
c
e
B
y
t
e
s
e
q
u
e
n
c
e
s
O
b
fu
s
c
a
t
io
n
t
e
c
h
n
iq
u
e
s
r
e
d
u
c
e
d
e
t
e
c
t
io
n
a
c
c
u
r
a
c
y
.
7
In
d
u
s
t
r
y
p
a
r
t
n
e
r
7
−
2
4
0
,
0
0
0
2
3
7
,
3
4
9
4
7
7
,
3
4
9
18
T
a
b
le
2
:
C
h
a
ra
ct
er
iz
a
ti
o
n
o
f
su
rv
ey
ed
p
a
p
er
s
h
a
v
in
g
m
a
lw
a
re
v
a
ri
a
n
ts
se
le
ct
io
n
a
s
o
b
je
ct
iv
e.
1
In
st
ea
d
o
f
u
si
n
g
m
a
ch
in
e
le
a
rn
in
g
te
ch
n
iq
u
es
,
G
h
a
ra
ch
eh
et
a
l.
re
ly
o
n
H
id
d
en
M
a
rk
o
v
M
o
d
el
s
to
d
et
ec
t
v
a
ri
a
n
ts
o
f
th
e
sa
m
e
m
a
li
ci
o
u
s
sa
m
p
le
[3
7
].
P
a
p
e
r
A
lg
o
ri
th
m
s
F
e
a
tu
re
s
L
im
it
a
ti
o
n
s
D
a
ta
se
t
sa
m
p
le
s
P
u
b
li
c
S
o
u
rc
e
A
v
a
il
a
b
le
L
a
b
e
li
n
g
B
e
n
ig
n
M
a
li
c
io
u
s
T
o
ta
l
G
h
a
ra
ch
e
h
e
t
a
l.
[3
7
]
-1
O
p
c
o
d
e
s
O
p
c
o
d
e
se
q
u
e
n
c
e
is
n
o
t
o
p
ti
m
a
l
a
n
d
th
e
d
a
ta
se
t
si
z
e
is
v
e
ry
sm
a
ll
.
X
C
y
g
w
in
a
n
d
V
X
H
e
a
v
e
n
s
7
−
?
?
7
4
0
G
h
ia
si
e
t
a
l.
[3
0
]
R
u
le
-b
a
se
d
c
la
ss
i-
fi
e
r
A
P
Is
/
S
y
st
e
m
c
a
ll
s
a
n
d
C
P
U
re
g
is
te
rs
A
P
Is
/
S
y
st
e
m
c
a
ll
s
c
a
te
-
g
o
ri
z
a
ti
o
n
c
o
u
ld
b
e
n
o
t
o
p
ti
m
a
l
a
n
d
th
e
d
a
ta
se
t
si
z
e
is
sm
a
ll
.
X
W
in
d
o
w
s
X
P
sy
st
e
m
a
n
d
P
ro
g
ra
m
F
il
e
s
fo
ld
e
rs
a
n
d
p
ri
v
a
te
re
p
o
si
to
ry
7
−
3
9
0
8
5
0
1
,
2
4
0
K
h
o
d
a
m
o
ra
d
i
e
t
a
l.
[3
8
]
D
e
c
is
io
n
T
re
e
,
R
a
n
d
o
m
F
o
re
st
O
p
c
o
d
e
s
O
p
c
o
d
e
se
q
u
e
n
c
e
is
n
o
t
o
p
ti
m
a
l
a
n
d
th
e
d
a
ta
se
t
si
z
e
is
v
e
ry
sm
a
ll
.
X
W
in
d
o
w
s
X
P
sy
st
e
m
a
n
d
P
ro
g
ra
m
F
il
e
s
fo
ld
e
rs
a
n
d
se
lf
-g
e
n
e
ra
te
d
m
e
ta
m
o
rp
h
ic
m
a
lw
a
re
7
−
5
5
0
2
8
0
8
3
0
U
p
ch
u
rc
h
a
n
d
Z
h
o
u
[3
9
]
C
lu
st
e
ri
n
g
w
it
h
lo
c
a
li
ty
se
n
si
ti
v
e
h
a
sh
in
g
B
y
te
se
q
u
e
n
c
e
s
T
h
e
d
a
ta
se
t
si
z
e
is
e
x
-
tr
e
m
e
ly
sm
a
ll
.
7
S
a
m
p
le
d
fr
o
m
se
c
u
ri
ty
in
c
id
e
n
ts
X
M
a
n
u
a
l
0
8
5
8
5
L
ia
n
g
e
t
a
l.
[4
0
]
R
u
le
-b
a
se
d
c
la
ss
i-
fi
e
r
A
P
Is
/
S
y
st
e
m
c
a
ll
s,
fi
le
sy
st
e
m
,
W
in
-
d
o
w
s
R
e
g
is
tr
y
,
a
n
d
n
e
tw
o
rk
M
o
n
it
o
re
d
A
P
I/
sy
st
e
m
c
a
ll
se
t
c
o
u
ld
b
e
n
o
t
o
p
-
ti
m
a
l
a
n
d
th
e
d
a
ta
se
t
si
z
e
is
sm
a
ll
.
7
A
n
u
b
is
w
e
b
si
te
7
−
0
3
3
0
,
2
4
8
3
3
0
,
2
4
8
C
o
n
ti
n
u
e
o
n
th
e
n
e
x
t
p
a
g
e
19
T
a
b
le
2
:
C
h
a
ra
ct
er
iz
a
ti
o
n
o
f
su
rv
ey
ed
p
a
p
er
s
h
a
v
in
g
m
a
lw
a
re
d
et
ec
ti
o
n
a
s
o
b
je
ct
iv
e.
(C
o
n
ti
n
u
ed
)
P
a
p
e
r
A
lg
o
ri
th
m
s
F
e
a
tu
re
s
L
im
it
a
ti
o
n
s
D
a
ta
se
t
sa
m
p
le
s
P
u
b
li
c
S
o
u
rc
e
A
v
a
il
a
b
le
L
a
b
e
li
n
g
B
e
n
ig
n
M
a
li
c
io
u
s
T
o
ta
l
V
a
d
re
v
u
a
n
d
P
e
rd
is
c
i
[4
1
]
D
B
S
C
A
N
c
lu
st
e
r-
in
g
A
P
Is
/
S
y
st
e
m
c
a
ll
s,
P
E
fi
le
ch
a
ra
c
te
ri
s-
ti
c
s,
a
n
d
n
e
tw
o
rk
E
v
a
si
o
n
te
ch
n
iq
u
e
s
a
n
d
sa
m
p
le
s
re
q
u
ir
in
g
u
se
r
in
te
ra
c
ti
o
n
s
re
d
u
c
e
th
e
a
c
c
u
ra
c
y
o
f
th
e
p
ro
p
o
se
d
a
p
p
ro
a
ch
.
7
S
e
c
u
ri
ty
c
o
m
p
a
n
y
a
n
d
la
rg
e
R
e
se
a
rc
h
In
st
it
u
te
7
−
0
1
,
6
5
1
,
9
0
6
1
,
6
5
1
,
9
0
6
T
a
b
le
3
:
C
h
a
ra
ct
er
iz
a
ti
o
n
o
f
su
rv
ey
ed
p
a
p
er
s
h
a
v
in
g
m
a
lw
a
re
fa
m
il
ie
s
se
le
ct
io
n
a
s
o
b
je
ct
iv
e.
2
A
sq
u
it
h
d
es
cr
ib
es
a
g
g
re
g
a
ti
o
n
o
v
er
la
y
g
ra
p
h
s
fo
r
st
o
ri
n
g
P
E
m
et
a
d
a
ta
,
w
it
h
o
u
t
fu
rt
h
er
d
is
cu
ss
in
g
a
n
y
m
a
ch
in
e
le
a
rn
in
g
te
ch
n
iq
u
e
th
a
t
co
u
ld
b
e
a
p
p
li
ed
o
n
to
p
o
f
th
es
e
n
ew
d
a
ta
st
ru
ct
u
re
s.
P
a
p
e
r
A
lg
o
r
it
h
m
s
F
e
a
t
u
r
e
s
L
im
it
a
t
io
n
s
D
a
t
a
s
e
t
s
a
m
p
le
s
P
u
b
li
c
S
o
u
r
c
e
A
v
a
il
a
b
le
L
a
b
e
li
n
g
B
e
n
ig
n
M
a
li
c
io
u
s
T
o
t
a
l
H
u
a
n
g
e
t
a
l.
[4
3
]
k
-M
e
a
n
s
-l
ik
e
a
lg
o
-
r
it
h
m
B
y
t
e
s
e
q
u
e
n
c
e
s
In
s
t
r
u
c
t
io
n
s
e
q
u
e
n
c
e
c
a
t
e
g
o
-
r
iz
a
t
io
n
c
o
u
ld
b
e
n
o
t
o
p
t
im
a
l
a
n
d
t
h
e
d
a
t
a
s
e
t
s
iz
e
is
s
m
a
ll
.
7
K
in
g
s
o
ft
C
o
r
p
o
r
a
t
io
n
7
−
0
2
,
0
2
9
2
,
0
2
9
P
a
r
k
e
t
a
l.
[4
4
]
M
a
li
c
io
u
s
g
r
a
p
h
m
a
t
c
h
in
g
A
P
Is
/
S
y
s
t
e
m
c
a
ll
s
A
p
p
r
o
a
c
h
v
u
ln
e
r
a
b
le
t
o
A
P
Is
/
s
y
s
t
e
m
c
a
ll
s
in
je
c
t
io
n
a
n
d
t
h
e
d
a
t
a
s
e
t
u
s
e
d
in
t
h
e
e
x
p
e
r
im
e
n
t
a
l
e
v
a
lu
a
t
io
n
s
is
v
e
r
y
s
m
a
ll
.
7
L
e
g
it
im
a
t
e
a
p
p
s
a
n
d
A
n
u
b
is
S
a
n
d
b
o
x
7
A
u
t
o
m
a
t
e
d
8
0
3
0
0
3
8
0
Y
e
e
t
a
l.
[4
5
]
k
-M
e
d
o
id
s
v
a
r
ia
n
t
s
O
p
c
o
d
e
s
In
s
t
r
u
c
t
io
n
c
a
t
e
g
o
r
iz
a
t
io
n
c
o
u
ld
b
e
n
o
t
o
p
t
im
a
l.
7
K
in
g
s
o
ft
C
o
r
p
o
r
a
t
io
n
7
−
0
1
1
,
7
1
3
1
1
,
7
1
3
D
a
h
l
e
t
a
l.
[4
6
]
L
o
g
is
t
ic
R
e
g
r
e
s
s
io
n
,
N
e
u
r
a
l
N
e
t
w
o
r
k
s
B
y
t
e
s
e
q
u
e
n
c
e
s
a
n
d
A
P
Is
/
s
y
s
t
e
m
c
a
ll
s
T
h
e
a
u
t
h
o
r
s
o
b
t
a
in
a
h
ig
h
t
w
o
-c
la
s
s
e
r
r
o
r
r
a
t
e
.
7
M
ic
r
o
s
o
ft
7
M
o
s
t
ly
m
a
n
u
a
l
8
1
7
,
4
8
5
1
,
8
4
3
,
3
5
9
3
,
7
6
0
,
8
4
4
H
u
e
t
a
l.
[4
7
]
P
r
o
t
o
t
y
p
e
-b
a
s
e
d
c
lu
s
t
e
r
in
g
O
p
c
o
d
e
s
O
b
fu
s
c
a
t
io
n
t
e
c
h
n
iq
u
e
s
r
e
-
d
u
c
e
t
h
e
e
ff
e
c
t
iv
e
n
e
s
s
o
f
t
h
e
ir
p
r
o
t
o
t
y
p
e
fo
r
m
a
lw
a
r
e
fa
m
il
y
s
e
le
c
t
io
n
.
7
−
7
M
a
n
u
a
l
a
n
d
a
u
t
o
m
a
t
e
d
0
1
3
7
,
0
5
5
1
3
7
,
0
5
5
C
o
n
ti
n
u
e
o
n
th
e
n
e
x
t
p
a
g
e
20
T
a
b
le
3
:
C
h
a
ra
ct
er
iz
a
ti
o
n
o
f
su
rv
ey
ed
p
a
p
er
s
h
a
v
in
g
m
a
lw
a
re
fa
m
il
ie
s
se
le
ct
io
n
a
s
o
b
je
ct
iv
e.
(C
o
n
ti
n
u
ed
)
P
a
p
e
r
A
lg
o
r
it
h
m
s
F
e
a
t
u
r
e
s
L
im
it
a
t
io
n
s
D
a
t
a
s
e
t
s
a
m
p
le
s
P
u
b
li
c
S
o
u
r
c
e
A
v
a
il
a
b
le
L
a
b
e
li
n
g
B
e
n
ig
n
M
a
li
c
io
u
s
T
o
t
a
l
Is
la
m
e
t
a
l.
[4
8
]
D
e
c
is
io
n
T
r
e
e
,
k
-N
N
,
R
a
n
d
o
m
F
o
r
e
s
t
,
S
V
M
S
t
r
in
g
s
,
b
y
t
e
s
e
q
u
e
n
c
e
s
a
n
d
A
P
Is
/
s
y
s
t
e
m
c
a
ll
s
T
h
e
p
r
o
p
o
s
e
d
a
p
p
r
o
a
c
h
is
le
s
s
e
ff
e
c
t
iv
e
n
o
v
e
l
s
a
m
p
le
s
.
T
h
e
d
a
t
a
s
e
t
is
s
m
a
ll
.
7
C
A
L
a
b
s
7
−
5
1
2
,
3
9
8
2
,
9
3
9
K
o
n
g
a
n
d
Y
a
n
[4
9
]
S
V
M
,
k
-N
N
O
p
c
o
d
e
s
,
m
e
m
o
r
y
,
fi
le
s
y
s
t
e
m
,
a
n
d
C
P
U
r
e
g
is
-
t
e
r
s
S
ig
n
if
ic
a
n
t
d
if
fe
r
e
n
c
e
s
in
s
a
m
p
le
s
b
e
lo
n
g
in
g
t
o
t
h
e
s
a
m
e
fa
m
il
y
r
e
d
u
c
e
t
h
e
p
r
o
p
o
s
e
d
a
p
p
r
o
a
c
h
a
c
c
u
r
a
c
y
.
7
O
ff
e
n
s
iv
e
C
o
m
p
u
t
in
g
7
A
u
t
o
m
a
t
e
d
0
5
2
6
,
1
7
9
5
2
6
,
1
7
9
N
a
r
i
a
n
d
G
h
o
r
b
a
n
i
[5
0
]
D
e
c
is
io
n
T
r
e
e
N
e
t
w
o
r
k
N
e
t
w
o
r
k
fe
a
t
u
r
e
s
a
r
e
e
x
-
t
r
a
c
t
e
d
b
y
a
c
o
m
m
e
r
c
ia
l
t
r
a
ff
ic
a
n
a
ly
z
e
r
.
T
h
e
d
a
t
a
s
e
t
u
s
e
d
in
t
h
e
e
x
p
e
r
im
e
n
t
a
l
e
v
a
lu
a
t
io
n
s
is
s
m
a
ll
.
7
C
o
m
m
u
n
ic
a
t
io
n
R
e
s
e
a
r
c
h
C
e
n
t
e
r
C
a
n
a
d
a
7
A
u
t
o
m
a
t
e
d
0
3
,
7
6
8
3
,
7
6
8
A
h
m
a
d
i
e
t
a
l.
[3
1
]
S
V
M
,
R
a
n
d
o
m
F
o
r
-
e
s
t
,
G
r
a
d
ie
n
t
B
o
o
s
t
-
in
g
D
e
c
is
io
n
T
r
e
e
B
y
t
e
s
e
q
u
e
n
c
e
s
,
o
p
-
c
o
d
e
s
,
A
P
Is
/
s
y
s
t
e
m
c
a
ll
s
,
W
in
d
o
w
s
R
e
g
-
is
t
r
y
,
C
P
U
r
e
g
is
t
e
r
s
,
a
n
d
P
E
fi
le
c
h
a
r
a
c
t
e
r
is
-
t
ic
s
S
e
le
c
t
e
d
fe
a
t
u
r
e
s
c
a
n
b
e
fu
r
t
h
e
r
r
e
d
u
c
e
d
t
o
h
a
v
e
a
c
le
a
r
e
r
v
ie
w
o
f
t
h
e
r
e
a
s
o
n
s
b
e
h
in
d
s
a
m
p
le
c
la
s
s
if
ic
a
t
io
n
.
X
M
ic
r
o
s
o
ft
’s
m
a
lw
a
r
e
c
la
s
s
if
ic
a
t
io
n
c
h
a
ll
e
n
g
e
7
−
0
2
1
,
7
4
1
2
1
,
7
4
1
A
s
q
u
it
h
[7
0
]
-2
A
P
Is
/
S
y
s
t
e
m
c
a
ll
s
,
m
e
m
o
r
y
,
fi
le
s
y
s
t
e
m
,
P
E
fi
le
c
h
a
r
a
c
t
e
r
is
t
ic
s
,
a
n
d
r
a
is
e
d
e
x
c
e
p
t
io
n
s
-5
−
−
−
−
−
−
−
L
in
e
t
a
l.
[5
2
]
S
V
M
B
y
t
e
s
e
q
u
e
n
c
e
s
,
A
P
Is
/
s
y
s
t
e
m
c
a
ll
s
,
fi
le
s
y
s
t
e
m
,
a
n
d
C
P
U
r
e
g
is
t
e
r
s
S
e
le
c
t
e
d
A
P
I/
s
y
s
t
e
m
c
a
ll
s
e
t
c
o
u
ld
b
e
n
o
t
o
p
t
im
a
l.
E
v
a
-
s
io
n
t
e
c
h
n
iq
u
e
s
a
n
d
s
a
m
-
p
le
s
r
e
q
u
ir
in
g
u
s
e
r
in
t
e
r
a
c
-
t
io
n
s
r
e
d
u
c
e
t
h
e
a
c
c
u
r
a
c
y
o
f
t
h
e
p
r
o
p
o
s
e
d
a
p
p
r
o
a
c
h
.
T
h
e
d
a
t
a
s
e
t
is
s
m
a
ll
.
7
O
w
n
s
a
n
d
b
o
x
7
−
3
8
9
3
,
8
9
9
4
,
2
8
8
C
o
n
ti
n
u
e
o
n
th
e
n
e
x
t
p
a
g
e
21
T
a
b
le
3
:
C
h
a
ra
ct
er
iz
a
ti
o
n
o
f
su
rv
ey
ed
p
a
p
er
s
h
a
v
in
g
m
a
lw
a
re
fa
m
il
ie
s
se
le
ct
io
n
a
s
o
b
je
ct
iv
e.
(C
o
n
ti
n
u
ed
)
P
a
p
e
r
A
lg
o
r
it
h
m
s
F
e
a
t
u
r
e
s
L
im
it
a
t
io
n
s
D
a
t
a
s
e
t
s
a
m
p
le
s
P
u
b
li
c
S
o
u
r
c
e
A
v
a
il
a
b
le
L
a
b
e
li
n
g
B
e
n
ig
n
M
a
li
c
io
u
s
T
o
t
a
l
K
a
w
a
g
u
c
h
i
a
n
d
O
m
o
t
e
[5
1
]
D
e
c
is
io
n
T
r
e
e
,
R
a
n
-
d
o
m
F
o
r
e
s
t
,
k
-N
N
,
N
a¨
ıv
e
B
a
y
e
s
A
P
Is
/
S
y
s
t
e
m
c
a
ll
s
T
h
is
c
la
s
s
if
ic
a
t
io
n
a
p
p
r
o
a
c
h
c
a
n
b
e
e
a
s
il
y
e
v
a
d
e
d
b
y
r
e
a
l-
w
o
r
ld
m
a
lw
a
r
e
.
T
h
e
d
a
t
a
s
e
t
u
s
e
d
in
t
h
e
e
x
p
e
r
im
e
n
t
a
l
e
v
a
lu
a
t
io
n
s
is
v
e
r
y
s
m
a
ll
.
7
F
F
R
I
In
c
.
7
−
2
3
6
4
0
8
6
4
4
M
o
h
a
is
e
n
e
t
a
l.
[5
3
]
D
e
c
is
io
n
T
r
e
e
,
k
-N
N
,
S
V
M
,
C
lu
s
t
e
r
in
g
w
it
h
w
it
h
d
if
fe
r
e
n
t
s
im
il
a
r
it
y
m
e
a
-
s
u
r
e
s
,
H
ie
r
a
r
c
h
ic
a
l
c
lu
s
t
e
r
in
g
F
il
e
s
y
s
t
e
m
,
W
in
d
o
w
s
R
e
g
is
t
r
y
,
C
P
U
r
e
g
is
-
t
e
r
s
,
a
n
d
n
e
t
w
o
r
k
E
v
a
s
io
n
t
e
c
h
n
iq
u
e
s
r
e
d
u
c
e
t
h
e
a
c
c
u
r
a
c
y
o
f
t
h
e
p
r
o
p
o
s
e
d
s
o
lu
t
io
n
.
7
A
M
A
L
s
y
s
t
e
m
7
M
a
n
u
a
l
a
n
d
a
u
t
o
m
a
t
e
d
0
1
1
5
,
1
5
7
1
1
5
,
1
5
7
P
a
i
e
t
a
l.
[5
4
]
k
-M
e
a
n
s
,
E
x
p
e
c
t
a
-
t
io
n
M
a
x
im
iz
a
t
io
n
O
p
c
o
d
e
s
O
b
fu
s
c
a
t
io
n
t
e
c
h
n
iq
u
e
s
r
e
-
d
u
c
e
t
h
e
e
ff
e
c
t
iv
e
n
e
s
s
o
f
t
h
e
e
m
p
lo
y
e
d
a
p
p
r
o
a
c
h
.
T
h
e
d
a
t
a
s
e
t
is
s
m
a
ll
.
7
C
y
g
w
in
u
t
il
it
y
fi
le
s
a
n
d
M
a
li
c
ia
7
−
2
1
3
8
,
0
5
2
8
,
2
6
5
R
a
ff
a
n
d
N
ic
h
o
la
s
[3
6
]
k
-N
N
w
it
h
L
e
m
p
e
l-
Z
iv
J
a
c
c
a
r
d
d
is
t
a
n
c
e
B
y
t
e
s
e
q
u
e
n
c
e
s
O
b
fu
s
c
a
t
io
n
t
e
c
h
n
iq
u
e
s
r
e
-
d
u
c
e
d
e
t
e
c
t
io
n
a
c
c
u
r
a
c
y
.
7
In
d
u
s
t
r
y
p
a
r
t
n
e
r
7
−
2
4
0
,
0
0
0
2
3
7
,
3
4
9
4
7
7
,
3
4
9
22
T
a
b
le
4
:
C
h
a
ra
ct
er
iz
a
ti
o
n
o
f
su
rv
ey
ed
p
a
p
er
s
h
a
v
in
g
m
a
lw
a
re
si
m
il
a
ri
ti
es
d
et
ec
ti
o
n
a
s
o
b
je
ct
iv
e.
3
S
V
M
is
u
se
d
o
n
ly
fo
r
co
m
p
u
ti
n
g
th
e
o
p
ti
m
a
l
v
a
lu
es
o
f
w
ei
g
h
t
fa
ct
o
rs
a
ss
o
ci
a
te
d
to
ea
ch
fe
a
tu
re
ch
o
se
n
to
d
et
ec
t
si
m
il
a
ri
ti
es
a
m
o
n
g
m
a
li
ci
o
u
s
sa
m
p
le
s.
P
a
p
e
r
A
lg
o
ri
th
m
s
F
e
a
tu
re
s
L
im
it
a
ti
o
n
s
D
a
ta
se
t
sa
m
p
le
s
P
u
b
li
c
S
o
u
rc
e
A
v
a
il
a
b
le
L
a
b
e
li
n
g
B
e
n
ig
n
M
a
li
c
io
u
s
T
o
ta
l
B
a
il
e
y
e
t
a
l.
[5
5
]
H
ie
ra
rc
h
ic
a
l
c
lu
st
e
r-
in
g
w
it
h
n
o
rm
a
li
z
e
d
c
o
m
p
re
ss
io
n
d
is
ta
n
c
e
A
P
Is
/
S
y
st
e
m
c
a
ll
s,
fi
le
sy
st
e
m
,
W
in
-
d
o
w
s
R
e
g
is
tr
y
,
a
n
d
n
e
tw
o
rk
E
v
a
si
o
n
te
ch
n
iq
u
e
s
a
n
d
sa
m
p
le
s
re
q
u
ir
in
g
u
se
r
in
te
ra
c
ti
o
n
s
re
d
u
c
e
th
e
a
c
c
u
ra
c
y
o
f
th
e
p
ro
p
o
se
d
c
la
ss
ifi
c
a
ti
o
n
m
e
th
o
d
.
T
h
e
d
a
ta
se
t
is
sm
a
ll
.
7
A
lb
o
r
M
a
lw
a
re
L
ib
ra
ry
a
n
d
p
u
b
li
c
re
p
o
si
to
ry
7
A
u
to
m
a
te
d
0
8
,
2
2
8
8
,
2
2
8
B
a
y
e
r
e
t
a
l.
[5
6
]
C
lu
st
e
ri
n
g
w
it
h
lo
c
a
l-
it
y
se
n
si
ti
v
e
h
a
sh
in
g
A
P
Is
/
S
y
st
e
m
c
a
ll
s
E
v
a
si
o
n
te
ch
n
iq
u
e
s
a
n
d
sa
m
p
le
s
re
q
u
ir
in
g
u
se
r
in
te
ra
c
ti
o
n
s
re
d
u
c
e
th
e
a
p
p
ro
a
ch
a
c
c
u
ra
c
y
.
7
A
n
u
b
is
w
e
b
si
te
7
M
a
n
u
a
l
a
n
d
a
u
to
m
a
te
d
0
7
5
,
6
9
2
7
5
,
6
9
2
R
ie
ck
e
t
a
l.
[5
7
]
P
ro
to
ty
p
e
-b
a
se
d
c
la
s-
si
fi
c
a
ti
o
n
a
n
d
c
lu
st
e
r-
in
g
w
it
h
E
u
c
li
d
e
a
n
d
is
ta
n
c
e
B
y
te
se
q
u
e
n
c
e
s
a
n
d
A
P
Is
/
sy
st
e
m
c
a
ll
s
E
v
a
si
o
n
te
ch
n
iq
u
e
s
a
n
d
sa
m
p
le
s
re
q
u
ir
in
g
u
se
r
in
te
ra
c
ti
o
n
s
re
d
u
c
e
th
e
a
c
c
u
ra
c
y
o
f
th
e
p
ro
-
p
o
se
d
fr
a
m
e
w
o
rk
.
7
C
W
S
a
n
d
b
o
x
a
n
d
S
u
n
b
e
lt
S
o
ft
w
a
re
7
A
u
to
m
a
te
d
0
3
6
,
8
3
1
3
6
,
8
3
1
C
o
n
ti
n
u
e
o
n
th
e
n
e
x
t
p
a
g
e
23
T
a
b
le
4
:
C
h
a
ra
ct
er
iz
a
ti
o
n
o
f
su
rv
ey
ed
p
a
p
er
s
h
a
v
in
g
m
a
lw
a
re
si
m
il
a
ri
ti
es
d
et
ec
ti
o
n
a
s
o
b
je
ct
iv
e.
(C
o
n
ti
n
u
ed
)
P
a
p
e
r
A
lg
o
ri
th
m
s
F
e
a
tu
re
s
L
im
it
a
ti
o
n
s
D
a
ta
se
t
sa
m
p
le
s
P
u
b
li
c
S
o
u
rc
e
A
v
a
il
a
b
le
L
a
b
e
li
n
g
B
e
n
ig
n
M
a
li
c
io
u
s
T
o
ta
l
P
a
la
h
a
n
e
t
a
l.
[5
8
]
L
o
g
is
ti
c
R
e
g
re
ss
io
n
A
P
Is
/
S
y
st
e
m
c
a
ll
s
E
v
a
si
o
n
te
ch
n
iq
u
e
s
a
n
d
sa
m
p
le
s
re
q
u
ir
in
g
u
se
r
in
te
ra
c
ti
o
n
s
re
d
u
c
e
th
e
a
c
c
u
ra
c
y
o
f
th
e
p
ro
-
p
o
se
d
fr
a
m
e
w
o
rk
,
w
h
il
e
u
n
k
n
o
w
n
o
b
se
rv
e
d
b
e
-
h
a
v
io
rs
a
re
c
la
ss
ifi
e
d
a
s
m
a
li
c
io
u
s.
T
h
e
d
a
ta
se
t
u
se
d
in
th
e
e
x
p
e
ri
m
e
n
-
ta
l
e
v
a
lu
a
ti
o
n
s
is
v
e
ry
sm
a
ll
.
7
O
w
n
h
o
n
e
y
p
o
t
7
−
4
9
9
1
2
9
6
1
E
g
e
le
e
t
a
l.
[5
9
]
S
V
M
3
A
P
Is
/
S
y
st
e
m
c
a
ll
s,
m
e
m
o
ry
,
a
n
d
C
P
U
re
g
is
te
rs
T
h
e
a
c
c
u
ra
c
y
o
f
c
o
m
-
p
u
te
d
P
E
fu
n
c
ti
o
n
si
m
il
a
ri
ti
e
s
d
ro
p
s
w
h
e
n
d
iff
e
re
n
t
c
o
m
p
il
e
r
to
o
lc
h
a
in
s
o
r
a
g
g
re
ss
iv
e
o
p
ti
m
iz
a
ti
o
n
le
v
e
ls
a
re
u
se
d
.
T
h
e
d
a
ta
se
t
is
sm
a
ll
.
X
c
o
r
e
u
t
i
l
s
-
8
.
1
3
p
ro
g
ra
m
su
it
e
7
−
1
,
1
4
0
0
1
,
1
4
0
24
T
a
b
le
5
:
C
h
a
ra
ct
er
iz
a
ti
o
n
o
f
su
rv
ey
ed
p
a
p
er
s
h
a
v
in
g
m
a
lw
a
re
d
iff
er
en
ce
s
d
et
ec
ti
o
n
a
s
o
b
je
ct
iv
e.
P
a
p
e
r
A
lg
o
ri
th
m
s
F
e
a
tu
re
s
L
im
it
a
ti
o
n
s
D
a
ta
se
t
sa
m
p
le
s
P
u
b
li
c
S
o
u
rc
e
A
v
a
il
a
b
le
L
a
b
e
li
n
g
B
e
n
ig
n
M
a
li
c
io
u
s
T
o
ta
l
B
a
y
e
r
e
t
a
l.
[5
6
]
C
lu
st
e
ri
n
g
w
it
h
lo
c
a
l-
it
y
se
n
si
ti
v
e
h
a
sh
in
g
A
P
Is
/
S
y
st
e
m
c
a
ll
s
E
v
a
si
o
n
te
ch
n
iq
u
e
s
a
n
d
sa
m
p
le
s
re
q
u
ir
in
g
u
se
r
in
te
ra
c
ti
o
n
s
re
d
u
c
e
th
e
a
p
p
ro
a
ch
a
c
c
u
ra
c
y
.
7
A
n
u
b
is
w
e
b
si
te
7
M
a
n
u
a
l
a
n
d
a
u
to
m
a
te
d
0
7
5
,
6
9
2
7
5
,
6
9
2
L
in
d
o
rf
e
r
e
t
a
l.
[6
0
]
R
u
le
-b
a
se
d
c
la
ss
ifi
e
r
A
P
Is
/
S
y
st
e
m
c
a
ll
s
a
n
d
n
e
tw
o
rk
S
o
p
h
is
ti
c
a
te
d
e
v
a
si
o
n
te
ch
n
iq
u
e
s
a
n
d
sa
m
p
le
s
re
q
u
ir
in
g
u
se
r
in
te
ra
c
-
ti
o
n
s
c
a
n
st
il
l
b
y
p
a
ss
d
e
te
c
ti
o
n
p
ro
c
e
ss
e
s.
T
h
e
d
a
ta
se
t
u
se
d
in
th
e
e
x
p
e
ri
m
e
n
ta
l
e
v
a
lu
a
ti
o
n
s
is
sm
a
ll
.
7
A
n
u
b
is
S
a
n
d
b
o
x
7
A
u
to
m
a
te
d
0
1
,
8
7
1
1
,
8
7
1
R
ie
ck
e
t
a
l.
[5
7
]
P
ro
to
ty
p
e
-b
a
se
d
c
la
s-
si
fi
c
a
ti
o
n
a
n
d
c
lu
st
e
r-
in
g
w
it
h
E
u
c
li
d
e
a
n
d
is
ta
n
c
e
B
y
te
se
q
u
e
n
c
e
s
a
n
d
A
P
Is
/
sy
st
e
m
c
a
ll
s
E
v
a
si
o
n
te
ch
n
iq
u
e
s
a
n
d
sa
m
p
le
s
re
q
u
ir
in
g
u
se
r
in
te
ra
c
ti
o
n
s
re
d
u
c
e
th
e
a
c
c
u
ra
c
y
o
f
th
e
p
ro
-
p
o
se
d
fr
a
m
e
w
o
rk
.
7
C
W
S
a
n
d
b
o
x
a
n
d
S
u
n
b
e
lt
S
o
ft
w
a
re
7
A
u
to
m
a
te
d
0
3
6
,
8
3
1
3
6
,
8
3
1
C
o
n
ti
n
u
e
o
n
th
e
n
e
x
t
p
a
g
e
25
T
a
b
le
5
:
C
h
a
ra
ct
er
iz
a
ti
o
n
o
f
su
rv
ey
ed
p
a
p
er
s
h
a
v
in
g
m
a
lw
a
re
d
iff
er
en
ce
s
d
et
ec
ti
o
n
a
s
o
b
je
ct
iv
e.
(C
o
n
ti
n
u
ed
)
P
a
p
e
r
A
lg
o
ri
th
m
s
F
e
a
tu
re
s
L
im
it
a
ti
o
n
s
D
a
ta
se
t
sa
m
p
le
s
P
u
b
li
c
S
o
u
rc
e
A
v
a
il
a
b
le
L
a
b
e
li
n
g
B
e
n
ig
n
M
a
li
c
io
u
s
T
o
ta
l
P
a
la
h
a
n
e
t
a
l.
[5
8
]
L
o
g
is
ti
c
R
e
g
re
ss
io
n
A
P
Is
/
S
y
st
e
m
c
a
ll
s
E
v
a
si
o
n
te
ch
n
iq
u
e
s
a
n
d
sa
m
p
le
s
re
q
u
ir
in
g
u
se
r
in
te
ra
c
ti
o
n
s
re
d
u
c
e
th
e
a
c
c
u
ra
c
y
o
f
th
e
p
ro
-
p
o
se
d
fr
a
m
e
w
o
rk
,
w
h
il
e
u
n
k
n
o
w
n
o
b
se
rv
e
d
b
e
-
h
a
v
io
rs
a
re
c
la
ss
ifi
e
d
a
s
m
a
li
c
io
u
s.
T
h
e
d
a
ta
se
t
u
se
d
in
th
e
e
x
p
e
ri
m
e
n
-
ta
l
e
v
a
lu
a
ti
o
n
s
is
sm
a
ll
.
7
O
w
n
h
o
n
e
y
p
o
t
7
−
4
9
9
1
2
9
6
1
S
a
n
to
s
e
t
a
l.
[6
1
]
D
e
c
is
io
n
T
re
e
,
k
-N
N
,
B
a
y
e
si
a
n
N
e
tw
o
rk
,
R
a
n
d
o
m
F
o
re
st
O
p
c
o
d
e
s
O
p
c
o
d
e
se
q
u
e
n
c
e
is
n
o
t
o
p
ti
m
a
l
a
n
d
th
e
d
a
ta
se
t
si
z
e
is
sm
a
ll
.
T
h
e
p
ro
-
p
o
se
d
m
e
th
o
d
is
n
o
t
e
f-
fe
c
ti
v
e
a
g
a
in
st
p
a
ck
e
d
m
a
lw
a
re
.
T
h
e
d
a
ta
se
t
is
sm
a
ll
.
X
O
w
n
m
a
ch
in
e
s
a
n
d
V
X
H
e
a
v
e
n
s
7
A
u
to
m
a
te
d
1
,
0
0
0
1
,
0
0
0
2
,
0
0
0
C
o
n
ti
n
u
e
o
n
th
e
n
e
x
t
p
a
g
e
26
T
a
b
le
5
:
C
h
a
ra
ct
er
iz
a
ti
o
n
o
f
su
rv
ey
ed
p
a
p
er
s
h
a
v
in
g
m
a
lw
a
re
d
iff
er
en
ce
s
d
et
ec
ti
o
n
a
s
o
b
je
ct
iv
e.
(C
o
n
ti
n
u
ed
)
P
a
p
e
r
A
lg
o
ri
th
m
s
F
e
a
tu
re
s
L
im
it
a
ti
o
n
s
D
a
ta
se
t
sa
m
p
le
s
P
u
b
li
c
S
o
u
rc
e
A
v
a
il
a
b
le
L
a
b
e
li
n
g
B
e
n
ig
n
M
a
li
c
io
u
s
T
o
ta
l
P
o
li
n
o
e
t
a
l.
[6
2
]
C
lu
st
e
ri
n
g
w
it
h
J
a
c
-
c
a
rd
si
m
il
a
ri
ty
A
P
Is
/
S
y
st
e
m
c
a
ll
s
E
v
a
si
o
n
te
ch
n
iq
u
e
s,
p
a
ck
e
d
m
a
lw
a
re
,
a
n
d
sa
m
p
le
s
re
q
u
ir
in
g
u
se
r
in
te
ra
c
ti
o
n
s
re
d
u
c
e
th
e
a
c
c
u
ra
c
y
o
f
th
e
p
ro
-
p
o
se
d
fr
a
m
e
w
o
rk
.
A
P
I
c
a
ll
s
se
q
u
e
n
c
e
u
se
d
to
id
e
n
ti
fy
sa
m
p
le
b
e
h
a
v
-
io
rs
is
n
o
t
o
p
ti
m
a
l.
T
h
e
d
a
ta
se
t
si
z
e
is
sm
a
ll
.
−
−
−
−
?
?
2
,
1
3
6
T
a
b
le
6
:
C
h
a
ra
ct
er
iz
a
ti
o
n
o
f
su
rv
ey
ed
p
a
p
er
s
h
a
v
in
g
m
a
lw
a
re
ca
te
g
o
ry
d
et
ec
ti
o
n
a
s
o
b
je
ct
iv
e.
4
In
st
ea
d
o
f
u
si
n
g
m
a
ch
in
e
le
a
rn
in
g
te
ch
n
iq
u
es
,
th
es
e
a
rt
ic
le
s
re
ly
o
n
H
id
d
en
M
a
rk
o
v
M
o
d
el
s
to
d
et
ec
t
m
et
a
m
o
rp
h
ic
v
ir
u
se
s
[6
3
,
6
4
].
P
a
p
e
r
A
lg
o
ri
th
m
s
F
e
a
tu
re
s
L
im
it
a
ti
o
n
s
D
a
ta
se
t
sa
m
p
le
s
P
u
b
li
c
S
o
u
rc
e
A
v
a
il
a
b
le
L
a
b
e
li
n
g
B
e
n
ig
n
M
a
li
c
io
u
s
T
o
ta
l
W
o
n
g
a
n
d
S
ta
m
p
[6
3
]
-4
O
p
c
o
d
e
s
D
e
te
c
ti
o
n
fa
il
s
if
m
e
ta
-
m
o
rp
h
ic
m
a
lw
a
re
a
re
si
m
il
a
r
to
b
e
n
ig
n
fi
le
s.
T
h
e
d
a
ta
se
t
is
e
x
tr
e
m
e
ly
sm
a
ll
.
7
C
y
g
w
in
a
n
d
V
X
H
e
a
v
e
n
s
g
e
n
e
ra
to
rs
7
−
4
0
2
5
6
5
27
T
a
b
le
6
:
C
h
a
ra
ct
er
iz
a
ti
o
n
o
f
su
rv
ey
ed
p
a
p
er
s
h
a
v
in
g
m
a
lw
a
re
ca
te
g
o
ry
d
et
ec
ti
o
n
a
s
o
b
je
ct
iv
e.
(C
o
n
ti
n
u
ed
)
P
a
p
e
r
A
lg
o
ri
th
m
s
F
e
a
tu
re
s
L
im
it
a
ti
o
n
s
D
a
ta
se
t
sa
m
p
le
s
P
u
b
li
c
S
o
u
rc
e
A
v
a
il
a
b
le
L
a
b
e
li
n
g
B
e
n
ig
n
M
a
li
c
io
u
s
T
o
ta
l
A
tt
a
lu
ri
e
t
a
l.
[6
4
]
-6
O
p
c
o
d
e
s
T
h
e
p
ro
p
o
se
d
a
p
p
ro
a
ch
is
n
o
t
e
ff
e
c
ti
v
e
a
g
a
in
st
a
ll
ty
p
e
s
o
f
m
e
ta
m
o
rp
h
ic
v
ir
u
se
s.
T
h
e
d
a
ta
se
t
si
z
e
is
v
e
ry
sm
a
ll
.
7
C
y
g
w
in
,
le
g
it
im
a
te
D
L
L
s
a
n
d
V
X
H
e
a
v
e
n
s
g
e
n
e
ra
to
rs
7
−
2
4
0
7
0
3
1
0
T
ia
n
e
t
a
l.
[7
8
]
R
u
le
-b
a
se
d
c
la
ss
i-
fi
e
r
F
u
n
c
ti
o
n
le
n
g
th
F
u
n
c
ti
o
n
le
n
g
th
s
a
lo
n
e
a
re
n
o
t
su
ffi
c
ie
n
t
to
d
e
-
te
c
t
T
ro
ja
n
s
a
n
d
th
e
d
a
ta
se
t
u
se
d
in
th
e
e
x
-
p
e
ri
m
e
n
ta
l
e
v
a
lu
a
ti
o
n
s
is
v
e
ry
sm
a
ll
.
−
−
−
−
0
7
2
1
7
2
1
S
id
d
iq
u
i
e
t
a
l.
[7
2
]
D
e
c
is
io
n
T
re
e
,
R
a
n
d
o
m
F
o
re
st
O
p
c
o
d
e
s
A
d
v
a
n
c
e
d
p
a
ck
in
g
te
ch
-
n
iq
u
e
s
c
o
u
ld
re
d
u
c
e
d
e
-
te
c
ti
o
n
a
c
c
u
ra
c
y
.
T
h
e
d
a
ta
se
t
u
se
d
in
th
e
e
x
-
p
e
ri
m
e
n
ta
l
e
v
a
lu
a
ti
o
n
s
is
sm
a
ll
.
X
W
in
d
o
w
s
X
P
a
n
d
V
X
H
e
a
v
e
n
s
7
−
1
,
4
4
4
1
,
3
3
0
2
,
7
7
4
C
h
e
n
e
t
a
l.
[6
5
]
R
a
n
d
o
m
F
o
re
st
,
S
V
M
B
y
te
se
q
u
e
n
c
e
s
T
h
e
p
ro
p
o
se
d
fr
a
m
e
w
o
rk
h
e
a
v
il
y
re
li
e
s
o
n
se
c
u
-
ri
ty
c
o
m
p
a
n
ie
s’
e
n
c
y
c
lo
-
p
e
d
ia
s.
7
T
re
n
d
M
ic
ro
7
−
0
3
3
0
,
2
4
8
3
3
0
,
2
4
8
C
o
n
ti
n
u
e
o
n
th
e
n
e
x
t
p
a
g
e
28
T
a
b
le
6
:
C
h
a
ra
ct
er
iz
a
ti
o
n
o
f
su
rv
ey
ed
p
a
p
er
s
h
a
v
in
g
m
a
lw
a
re
ca
te
g
o
ry
d
et
ec
ti
o
n
a
s
o
b
je
ct
iv
e.
(C
o
n
ti
n
u
ed
)
P
a
p
e
r
A
lg
o
ri
th
m
s
F
e
a
tu
re
s
L
im
it
a
ti
o
n
s
D
a
ta
se
t
sa
m
p
le
s
P
u
b
li
c
S
o
u
rc
e
A
v
a
il
a
b
le
L
a
b
e
li
n
g
B
e
n
ig
n
M
a
li
c
io
u
s
T
o
ta
l
C
o
m
a
r
e
t
a
l.
[6
6
]
R
a
n
d
o
m
F
o
re
st
,
S
V
M
N
e
tw
o
rk
N
e
tw
o
rk
fe
a
tu
re
s
a
re
e
x
-
tr
a
c
te
d
b
y
a
c
o
m
m
e
rc
ia
l
tr
a
ffi
c
a
n
a
ly
z
e
r.
7
In
te
rn
e
t
S
e
rv
ic
e
P
ro
v
id
e
r
7
M
a
n
u
a
l
a
n
d
a
u
to
m
a
te
d
2
1
2
,
5
0
5
4
,
3
9
4
2
1
6
,
8
9
9
K
w
o
n
e
t
a
l.
[3
2
]
R
a
n
d
o
m
F
o
re
st
N
e
tw
o
rk
N
o
t
a
b
le
to
d
e
te
c
t
b
o
ts
w
it
h
ro
o
tk
it
c
a
p
a
b
il
it
ie
s.
X
S
y
m
a
n
te
c
’s
W
o
rl
d
w
id
e
In
te
ll
ig
e
n
c
e
N
e
tw
o
rk
E
n
v
ir
o
n
m
e
n
t
7
−
?
?
2
4
∗1
0
6
S
e
x
to
n
e
t
a
l.
[6
7
]
R
u
le
-b
a
se
d
c
la
s-
si
fi
e
r,
L
o
g
is
ti
c
R
e
g
re
ss
io
n
,
N
a¨
ıv
e
B
a
y
e
s,
S
V
M
B
y
te
se
q
u
e
n
c
e
s
a
n
d
o
p
c
o
d
e
s
O
b
fu
sc
a
ti
o
n
te
ch
n
iq
u
e
s
re
d
u
c
e
d
e
te
c
ti
o
n
a
c
c
u
-
ra
c
y
.
T
h
e
d
a
ta
se
t
u
se
d
in
th
e
e
x
p
e
ri
m
e
n
ta
l
e
v
a
l-
u
a
ti
o
n
s
is
sm
a
ll
.
−
−
−
−
4
,
6
2
2
1
9
7
4
,
8
1
9
29
5. Issues and Challenges
Based on the characterization detailed in 



Section 4, this 



Section identifies
the main issues and challenges of surveyed papers. In the specific, the main
problems regard the usage of anti-analysis techniques by malware (§ 5.1), what
operation set to consider 5.2 and used dataset 5.3.
5.1. Anti-analysis Techniques
Malware developers want to avoid their samples to be analysed, so they
devise and refine several anti-analysis techniques that are effective in hindering
the reverse engineering of executables. Indeed many surveyed works claim that
the solution they propose does not work or loses in accuracy when samples using
such techniques are considered (§ 4).
Static analysis (§ 3.2.1) is commonly prevented by rendering sample binary
and resources unreadable through obfuscation, packing or encryption. Anyway,
at runtime, code and any other concealed data has to be either deobfuscated,
unpacked or decrypted to enable the correct execution of the payload. This
implies that such a kind of anti-analysis techniques can be overcome by using
dynamic analysis (§ 3.2.1) to make the sample unveil hidden information and
load them in memory, where they can then be extracted by creating a dump.
Refer to Ye et al. [1] for a detailed disquisition on how obfuscation, packing and
encryption are used by malware developers.
More advanced anti-analysis techniques exist to keep malware internals se-
cret even when dynamic analysis is used. One approach, commonly referred to
as environmental awareness, consists in the malware trying to detect whether
it is being executed in a controlled setting where an analyst is trying to dissect
it, for example by using a virtual machine or by running the sample in debug
mode. If any cue is found of possibly being under analysis, then the malware
does not execute its malicious payload. Miramirkhani et al. [79] show that a
malware can easily understand if it is running into an artificial environment.
Other approaches rely on timing-based evasion, i.e. they only show their ma-
licious behaviour at predetermined dates and times. Other malware instead
30
require or wait for some user interaction to start their intended activity, in
order to make any kind of automatic analysis infeasible.
Identifying and overcoming these anti-analysis techniques is an important
direction to investigate to improve the effectiveness of malware analysis. Re-
cent academic and not-academic literature are aligned on this aspect. Karpin
and Dorfman [80] highlight the need to address very current problems such
as discovering where malware configuration files are stored and whether stan-
dard or custom obfuscation/packing/encryption algorithms are employed. De-
obfuscation [81, 82] and other operations aimed at supporting binary reverse
engineering, such as function similarity identification [83], are still very active
research directions. Symbolic execution techniques [84] are promising means to
understand what execution paths trigger the launch of the malicious payload.
5.2. Operation Set
Opcodes, instructions, APIs and system calls (hereinafter, we refer to them
in general as operations) are the most used and powerful features employed for
malware analysis (§ 4), as they allow to directly and accurately model sample
behaviour. Normally, to reduce complexity and required computational power,
only a subset of all the available operations is considered. This choice of ignoring
part of the operations at disposal can reduce the accuracy of malware behaviour
model, which in turn reflects on the reliability of analysis outcomes. This issue
has been raised explicitly in some surveyed papers, including [18, 37, 38], while
others are anyway affected although they do not mention it, such as [30, 40, 43].
On one hand, this challenge can be addressed by either improving or us-
ing different machine learning techniques to achieve a more effective feature
selection. On the other hand, program analysis advances can be leveraged to
enhance the accuracy of disassemblers and decompilers, indeed these tools are
known to be error-prone [85, 86] and are thus likely to affect negatively the
whole analyses. Approaches that improve the quality of generated disassembly
and decompiled code, as in [87], can reduce the impact due to these errors.
31
5.3. Datasets
More than 72% of surveyed works use datasets with both malicious and
benign samples, while about 28% rely on datasets with malware only. Just
two works rely on benign datasets only [59, 73], because their objectives are
identifying sample similarities and attributing the ownership of some source
codes under analysis, respectively.
Figure 2 shows the dataset sources for malicious and benign samples. It is
worth noting that most of benign datasets consists of legitimate applications
(e.g. software contained in “Program Files” or “system” folders), while most
of malware have been obtained from public repositories, security vendors and
popular sandboxed analysis services. The most popular public repository in the
examined works is VX Heavens [88], followed by Offensive Computing [89] and
Malicia Project [90]. The first two repositories are still actively maintained at
the time of writing, while Malicia Project has been permanently shut down due
to dataset ageing and lack of maintainers.
0
5
10
15
20
25
30
Leg
itim
ate
 ap
pl i
cat
ion
s
Pu
bli
c r
ep
os
ito
rie
s
Se
cur
ity
 ve
nd
ors
San
db
oxe
s
AV
 co
mp
an
ies
Re
sea
rch
 Ce
nte
rs ISP
Wr
itte
n b
y a
uth
ors
Ho
ne
ypo
t
CE
RT
Un
kno
wn
Malicious Benign
Figure 2: Frequency histogram showing how many reviewed papers use each type of source
(e.g. public repositories, honeypot) to collect their datasets, and whether it is used to gather
malware or benign samples.
32
Security vendors, popular sandboxed analysis services, and AV companies
have access to a huge number of samples. Surveyed works rely on CWSandbox,
developed by ThreatTrack Security [91], and Anubis [92]. As can be observed
from Figure 2, these sandboxes are mainly used for obtaining malicious sam-
ples. Internet Service Providers (ISPs), honeypots and Computer Emergency
Response Teams (CERTs) share with researchers both benign and malicious
datasets. A few works use malware developed by the authors [37, 38], created
using malware toolkits [63] such as Next Generation Virus Constrution Kit,
Virus Creation Lab, Mass Code Generator and Second Generation Virus Gen-
erator, all available on VX Heavens [88]. A minority of analysed papers do not
mention the source of their datasets.
Among surveyed papers, a recurring issue is the size of used dataset. Many
works, including [12, 13, 15], carry out evaluations on less than 1, 000 samples.
Just 39% of reviewed studies test their approaches on a population greater than
10, 000 samples.
When both malicious and benign samples are used for the evaluation, it is
crucial to reflect their real distribution [11, 12, 13, 72, 15, 44, 16, 17, 18, 93,
19, 46, 21, 48, 77, 58, 61, 20, 23, 26, 28, 29, 30, 51, 52, 33, 54, 34, 74, 35, 36].
Indeed, there needs to be a huge imbalance because non-malware executables
are the overwhelming majority. 48% of surveyed works do not take care of
this aspect and use datasets that either are balanced between malware and non
malicious software or, even, have more of the former than the latter. In [19],
Yonts supports his choice of using a smaller benign dataset by pointing out
that changes in standard system files and legitimate applications are little. 38%
of examined papers employ instead datasets having a proper distribution of
malware and non-malware, indeed they are either unbalanced towards benign
samples or use exclusively benign or malicious software. As an example, the
majority of surveyed papers having malware similarities detection as objective
(see Table 4) contains exclusively either malware or legitimate applications [55,
56, 57, 59]. The remaining 14% does not describe how datasets are composed.
Differently from other research fields, no reference benchmark is available for
33
malware analysis to compare accuracy and performance with other works. Fur-
thermore, published 

Results are known to be biased towards good 

Results [94].
In addition, since the datasets used for evaluations are rarely shared, it is
nearly impossible to compare works. Only two surveyed works have shared
their dataset [11, 39], while a third one plans to share it in the future [53]. It
is worth mentioning that one of the shared dataset is from 2001, hence almost
useless today. Indeed, temporal information is crucial to evaluate malware anal-
ysis 

Results [95] and determine whether machine learning models have become
obsolete [96, 97].
Given such lack of reference datasets, we propose three desiderata for mal-
ware analysis benchmarks.
1. Benchmarks should be labeled accordingly to the specific objectives to
achieve. As an example, benchmarks for families selection should be la-
beled with samples’ families.
2. Benchmarks should model realistically the sample distributions of real-
world 



Scenarios, considering the objectives to attain. For example, bench-
marks for malware detection should contain a set of legitimate applications
orders of magnitude greater than the number of malware samples.
3. Benchmarks should be actively maintained and updated over time with
new samples, trying to keep pace with the malware industry. Samples
should also be provided with temporal information, e.g., when they have
been spotted first.
Datasets used in [11] and [39] are correctly labeled according to malware de-
tection and malware variants selection objectives, respectively. Both datasets
are not balanced. In Shultz et al. [11], the described dataset is biased towards
malicious programs, while in [39] diverse groups of variants contain a different
number of samples, ranging from 3 to 20. Finally, analysed datasets are not
actively maintained and do not contain any temporal information (in [11], the
authors do not mention if such information has been included into the dataset).
34
6. Topical Trends
This 



Section outlines a list of topical trends in malware analysis, i.e. topics
that are currently being investigated but have not reached the same level of
maturity of the other areas described in previous 



Sections.
6.1. Malware Development Detection
Malware developers can use online public services like VirusTotal [98] and
Malwr [99] to test the effectiveness of their samples in evading most common
antiviruses. Malware analysts can leverage such behaviour by querying these
online services to obtain additional information useful for the analysis, such as
submission time and how many online antiviruses classify a sample as malicious.
Graziano et al. [69] leverage submissions to an online sandbox for identifying
cases where new samples are being tested, with the final aim to detect novel
malware during their development process. Surprisingly, it turned out that
samples used in infamous targeted campaigns had been submitted to public
sandboxes months or years before.
With reference to the proposed taxonomy, advances in the state of the art in
malware analysis could be obtained by analysing submissions to online malware
analysis services, to extract additional machine learning features and gather
intelligence on what next malware are likely to be.
6.2. Malware Attribution
Another aspect of interest for malware analysts is the identification of who
developed a given sample, i.e. the attribution of a malware to a specific mali-
cious actor. There are a number of features in a binary to support this process:
used programming language, included IP addresses and URLs, and the language
of comments and resources. Additional, recently proposed features which can
be used for attribution are the time slot when the malware communicates with
a command and control centre and what digital certificates are used [100]. Fea-
tures related to the coding style can also reveal important details on developer’s
identity, at least for arguing whether different malware have been developed
35
by the same person or group. In [73], the author’s coding style of a generic
software (i.e. not necessarily malicious) is accurately profiled through syntactic,
lexical, and layout features. Unfortunately, this approach requires the availabil-
ity of source code, which happens only occasionally, e.g. in case of leaks and/or
public disclosures.
Malware attribution can be seen as an additional analysis objective, accord-
ing to the proposed taxonomy. Progresses in this direction through machine
learning techniques are currently hindered by the lack of ground truth on mal-
ware authors, which proves to be really hard to provision. Recent approaches
leverage on public reports referring to APT groups and detailing what mal-
ware they are supposed to have developed: those reports are parsed to mine
the relationships between malicious samples and corresponding APT group au-
thors [101]. The state of the art in malware attribution through machine learn-
ing can be advanced by researching alternative methods to generate reliable
ground truth on malware developers, or on what malware have been developed
by the same actor.
6.3. Malware Triage
Given the huge amount of new malware that need to be analysed, a fast and
accurate prioritisation is required to identify what samples deserve more in depth
analyses. This can be decided on the basis of the level of similarity with already
known samples. If a new malware resembles very closely other binaries that
have been analysed before, then its examination is not a priority. Otherwise,
further analyses can be advised if a new malware really looks differently from
everything else observed so far. This process is referred to as malware triage
and shares some aspects with malware similarity analysis, as they both provide
key information to support malware analysis prioritisation. Anyway, they are
different because triage requires faster 

Results at the cost of worse accuracy,
hence different techniques are usually employed [75, 77, 101, 86].
Likewise attribution, triage can be considered as another malware analysis
objective. One important challenge of malware triage is finding the proper
36
trade-off between accuracy and performance, which fits with the problems we
address in the context of malware analysis economics (see 



Section 7).
6.4. Prediction of Future Variants
Compared to malware analysts, malware developers have the advantage of
knowing current anti-malware measures and thus novel variants can be designed
accordingly. A novel trend in malware analysis is investigating the feasibility to
fill that gap by predicting how future malware will look like, so as to allow ana-
lysts to update anti-malware measures ahead. Howard et al. [102] use machine
learning techniques to model patterns in malware family evolutions and predict
future variants.
This problem can be seen as yet another objective in the malware analysis
taxonomy. It has not been investigated much yet, only a couple of works seem
to address that topic [103, 102]. Given its great potential to proactively identify
novel malware, and considering the opportunity to exploit existing malware
families datasets, we claim the worthiness to boost the research on malware
evolution prediction through machine learning techniques.
6.5. Other Features
This 



Section describes features different from those analysed in 



Section 3.2.2
and that have been used by just a few papers so far. In view of advancing
the state of the art in malware analysis, additional research is required on the
effectiveness of using such features to improve the accuracy of machine learning
techniques.
6.5.1. Memory Accesses
Any data of interest, such as user generated content, is temporary stored
in main memory, hence analysing how memory is accessed can reveal impor-
tant information about the behaviour of an executable [104]. Kong et al. rely
on statically trace reads and writes in main memory [49], while Egele et al.
dynamically trace values read from and written to stack and heap [59].
37
6.5.2. Function Length
Another characterising feature is the function length, measured as the num-
ber of bytes contained in a function. This input alone is not sufficient to discrim-
inate malicious executables from benign software, indeed it is usually combined
with other features. This idea, formulated in [78], is adopted in [48], where
function length frequencies, extracted through static analysis, are used together
with other static and dynamic features.
6.5.3. Raised Exceptions
The analysis of the exceptions raised during the execution can help under-
standing what strategies a malware adopts to evade analysis systems [20, 70].
A common trick to deceive analysts is throwing an exception to run a mali-
cious handler, registered at the beginning of malware execution. In this way,
examining the control flow becomes much more complex.
7. Malware Analysis Economics
Analysing samples through machine learning techniques requires complex
computations for extracting desired features and running chosen algorithms.
The time complexity of these computations has to be carefully taken into ac-
count to ensure they complete fast enough to keep pace with the speed new
malware are developed. Space complexity has to be considered as well, indeed
feature space can easily become excessively large (e.g., using n-grams), and also
the memory required by machine learning algorithms can grow to the point of
saturating available resources.
Time and space complexities can be either reduced to adapt to processing
and storage capacity at disposal, or they can be accommodated by supplying
more resources. In the former case, the analysis accuracy is likely to worsen,
while, in the latter, accuracy levels can be preserved at the cost of providing
more computing machines, storage and network. There exist therefore trade-
offs between maintaining high accuracy and performance of malware analysis
38
on one hand, and supplying the required equipment on the other. We refer to
the study of these trade-offs as malware analysis economics, and in this 



Section
we provide some initial qualitative 



Discussions on this novel topic.
The time needed to analyse a sample through machine learning is mainly
spent in feature extraction and algorithm execution. While time complexity
of machine learning algorithms is widely discussed in literature, the same does
not apply for the study of feature extraction execution time. The main aspect
to take into account is whether desired features come from static or dynamic
analysis, which considerably affects execution time because the former does not
require to run the samples, while the latter does.
To deepen even further this point, Table 7 reports for each feature type
whether it can be extracted through static or dynamic analysis. It is interesting
to note that certain types of features can be extracted both statically and dy-
namically, with significant differences on execution time as well as on malware
analysis accuracy. Indeed, while certainly more time-consuming, dynamic anal-
ysis enables to gather features that contribute relevantly to the overall analysis
effectiveness [105]. As an example, we can consider the features derived from
API calls (see Table 7), which can be obtained both statically and dynamically.
Tools like IDA provide the list of imports used by a sample and can statically
trace what API calls are present in the sample code. Malware authors usually
hide their suspicious API calls by inserting in the source code a huge number of
legitimate APIs. By means of dynamic analysis, it is possible to obtain the list
Table 7: Type of analysis required for extracting the inputs presented in 



Sections 3.2.2 and 6.5:
strings, byte sequences, opcodes, APIs/system calls, file system, CPU registers, PE file char-
acteristics, network, AV/Sandbox submissions, code stylometry, memory accesses, function
length, and raised exceptions.
Analysis Str.
Byte
seq.
Ops
APIs
Sys.
calls
File
sys.
CPU
reg.
PE
file
char.
Net.
Sub-
mis.
Code
stylo.
Mem.
Func.
len.
Exc.
Static X X X X X X X X X
Dynamic X X X X X X X
39
of the APIs that the sample has actually invoked, thus simplifying the identifi-
cation of those suspicious APIs. By consequences, in this case dynamic analysis
is likely to generate more valuable features compared to static analysis. Maze-
Walker [106] is a typical example of how dynamic information can integrate
static analysis.
Although choosing dynamic analysis over, or in addition to, static seems ob-
vious, its inherently higher time complexity constitutes a potential performance
bottleneck for the whole malware analysis process, which can undermine the
possibility to keep pace with malware evolution speed. The natural solution is
to provision more computational resources to parallelise analysis tasks and thus
remove bottlenecks. In turn, such solution has a cost to be taken into account
when designing a malware analysis environment, such as the one presented by
Laurenza et al. [107].
The qualitative trade-offs we have identified are between accuracy and time
complexity (i.e., higher accuracy requires larger times), between time complexity
and analysis pace (i.e., larger times implies slower pace), between analysis pace
and computational resources (faster analysis demands using more resources),
and between computational resources and economic cost (obviously, additional
equipment has a cost). Similar trade-offs also hold for space complexity. As an
example, when using n-grams as features, it has been shown that larger values
of n lead to more accurate analysis, at cost of having the feature space grow
exponentially with n [26, 52]. As another example, using larger datasets in gen-
eral enables more accurate machine learning models and thus better accuracy,
provided the availability of enough space to store all the samples of the dataset
and the related analysis reports.
Table 8: Relationship between n and number of features.
n feature count
1 187
2 6740
3 46216
4 130671
5 342663
40
80
81
82
83
84
85
86
87
88
89
90
10
100
1000
10000
100000
1000000
1 2 3 4 5
ac
cu
ra
cy
 (%
)
ex
ec
ut
io
n 
tim
e 
(m
s)
n-grams size
execution time
accuracy
target accuracy
Figure 3: Relationship between execution time (in logarithmic scale) and detection accuracy
as n varies. The target accuracy of 86% is also reported.
We present a qualitative, simplified example of analysis that leverages on the
trade-offs just introduced. The scenario we target regards detecting malware
families of new malicious samples (§ 3.1.2) using as features n-grams computed
over invoked APIs (§ 3.2.2), recorded through dynamic analysis (§ 3.2.1). We
want here to explore the trade-offs between family detection accuracy, execution
time, analysis pace and cost, in terms of required computational resources. For
what concerns the scenario and qualitative numbers on the relationships between
n, the number of features, accuracy and execution time, we take inspiration
from the experimental evaluation presented by Lin et al. [52]. Table 8 shows
the relationship between n and feature count. We introduce a few simplifying




Assumptions and constraints to make this qualitative example as consistent as
possible. We assume that the algorithm used to detect families is parallelisable
and ideally scalable, meaning that by doubling available machines we also double
the throughput, i.e. the number of malware analysed per second. We want to
process one million malware per day with an accuracy of at least 86%.
Figure 3 

Highlights the trade-off between execution time (in logarithmic
scale) and detection accuracy as n is varied. As n grows, the accuracy in-
41
100
1000
10000
100000
1000000
10000000
1 2 3 4 5
m
al
w
ar
e 
th
ro
ug
hp
ut
 (m
al
w
ar
e 
pe
r d
ay
)
machine count
1-grams 2-grams 3-grams
4-grams 5-grams malware load
Figure 4: Relationship between machine count and malware throughput (in logarithmic scale)
for different n-grams sizes. The one million malware per day to sustain is also reported.
creases almost linearly while the execution time has an exponential rise, which
translates to an exponential decrease of how many malware per second can be
processed. It can be noted that the minimum n-grams size to meet the accuracy
requirement of 86% is 3. The trade-off between analysis pace and cost can be
observed in Figure 4 where, by leveraging on the assumption of ideal scalability
of the detection algorithm, it is shown that sustainable malware throughput (in
logarithmic scale) increases linearly as the algorithm is parallelised on more ma-
chines. 4-grams and 5-grams cannot be used to cope with the expected malware
load of one million per day, at least when considering up to five machines. On
the other hand, by using four machines and 3-grams, we can sustain the target
load and at the same time meet the constraint on detection accuracy.
The presented toy example is just meant to better explain how malware
analysis economics can be used in practical 



Scenarios. We claim the significance
of investigating these trade-offs more in detail, with the aim of outlining proper
guidelines and strategies to design a malware analysis environment in compli-
ance with requirements on analysis accuracy and pace, while respecting budget
42
constraints.
8. 

Conclusion
We presented a survey on existing literature on malware analysis through
machine learning techniques. There are five main contributions of our work.
First, we proposed an organization of reviewed works according to three or-
thogonal dimensions: the objective of the analysis, the type of features extracted
from samples, the machine learning algorithms used to process these features.
Such characterization provides an 

Overview on how machine learning algorithms
can be employed in malware analysis, emphasising which specific feature classes
allow to achieve the objective(s) of interest. Second, we have arranged existing
literature on PE malware analysis through machine learning according the pro-
posed taxonomy, providing a detailed comparative analysis of surveyed works.
Third, we highlighted the current issues of machine learning for malware anal-
ysis: anti-analysis techniques used by malware, what operation set to consider
for the features and used datasets. Fourth, we identified topical trends on inter-
esting objectives and features, such as malware attribution and triage. Fifth, we
introduced the novel concept of malware analysis economics, concerning the in-
vestigation and exploitation of existing trade-offs between performance metrics
of malware analysis (e.g., analysis accuracy and execution time) and economical
costs.
Noteworthy research directions to investigate can be linked to those con-
tributions. Novel combinations of objectives, features and algorithms can be
investigated to achieve better accuracy compared to the state of the art. More-
over, observing that some classes of algorithms have never been used for a cer-
tain objective may suggest novel directions to examine further. The 



Discussion
on malware analysis issues can provide further ideas worth to be explored. In
particular, defining appropriate benchmarks for malware analysis is a priority
of the whole research area. The novel concept of malware analysis economics
can encourage further research directions, where appropriate tuning strategies
43
can be provided to balance competing metrics (e.g. accuracy and cost) when
designing a malware analysis environment.
Acknowledgment
This work has been partially supported by a grant of the Italian Presidency
of Ministry Council and by the Laboratorio Nazionale of Cyber Security of the
CINI (Consorzio Interuniversitario Nazionale Informatica).




References
[1] Y. Ye, T. Li, D. Adjeroh, S. S. Iyengar, A survey on malware detection
using data mining techniques, ACM Computing Surveys (CSUR) 50 (3)
(2017) 41.
[2] AV-TEST, Security Report 2016/17, https://www.av-test.org/
fileadmin/pdf/security_report/AV-TEST_Security_Report_
2016-2017.pdf (2017).
[3] A. Shabtai, R. Moskovitch, Y. Elovici, C. Glezer, Detection of malicious
code by applying machine learning classifiers on static features: A state-
of-the-art survey, Inf. Secur. Tech. Rep. 14 (1) (2009) 16–29.
[4] M. K. Sahu, M. Ahirwar, A. Hemlata, A review of malware detection
based on pattern matching technique, Int. J. of Computer Science and
Information Technologies (IJCSIT) 5 (1) (2014) 944–947.
[5] A. Souri, R. Hosseini, A state-of-the-art survey of malware detection ap-
proaches using data mining techniques, Human-centric Computing and
Information Sciences 8 (1) (2018) 3.
[6] C. LeDoux, A. Lakhotia, Malware and machine learning, in: Intelligent
Methods for Cyber Warfare, Springer, 2015, pp. 1–42.
44
[7] Z. Bazrafshan, H. Hashemi, S. M. H. Fard, A. Hamzeh, A survey on
heuristic malware detection techniques, in: Information and Knowledge
Technology (IKT), 2013 5th Conference on, IEEE, 2013, pp. 113–120.
[8] I. Basu, Malware detection based on source data using data mining: A
survey, American Journal Of Advanced Computing 3 (1).
[9] J. J. Barriga, S. G. Yoo, Malware detection and evasion with machine
learning techniques: A survey, International Journal of Applied Engineer-
ing Research 12 (318).
[10] J. Gardiner, S. Nagaraja, On the security of machine learning in malware
c&c detection: A survey, ACM Comput. Surv. 49 (3) (2016) 59:1–59:39.
[11] M. G. Schultz, E. Eskin, F. Zadok, S. J. Stolfo, Data mining methods for
detection of new malicious executables, in: Security and Privacy, 2001. S
P 2001. Proceedings. 2001 IEEE Symposium on, 2001, pp. 38–49.
[12] J. Z. Kolter, M. A. Maloof, Learning to detect and classify malicious
executables in the wild, J. Mach. Learn. Res. 7 (2006) 2721–2744.
[13] F. Ahmed, H. Hameed, M. Z. Shafiq, M. Farooq, Using spatio-temporal
information in api calls with machine learning algorithms for malware
detection, in: Proceedings of the 2nd ACM workshop on Security and
artificial intelligence, ACM, 2009, pp. 55–62.
[14] D. H. Chau, C. Nachenberg, J. Wilhelm, A. Wright, C. Faloutsos, Polo-
nium: Tera-scale graph mining for malware detection, in: ACM SIGKDD
Conference on Knowledge Discovery and Data Mining, 2010, pp. 131–142.
[15] I. Firdausi, C. Lim, A. Erwin, A. S. Nugroho, Analysis of machine learning
techniques used in behavior-based malware detection, in: ACT ’10, IEEE,
2010, pp. 201–203.
[16] B. Anderson, D. Quist, J. Neil, C. Storlie, T. Lane, Graph-based malware
detection using dynamic analysis, Journal in Computer Virology 7 (4)
(2011) 247–258.
45
[17] I. Santos, J. Nieves, P. G. Bringas, International Symposium on Dis-
tributed Computing and Artificial Intelligence, Springer Berlin Heidel-
berg, Berlin, Heidelberg, 2011, Ch. Semi-supervised Learning for Un-
known Malware Detection, pp. 415–422.
[18] B. Anderson, C. Storlie, T. Lane, Improving malware classification: bridg-
ing the static/dynamic gap, in: Proceedings of the 5th ACM workshop on
Security and artificial intelligence, ACM, 2012, pp. 3–14.
[19] J. Yonts, Attributes of malicious files, Tech. rep., The SANS Institute
(2012).
[20] I. Santos, J. Devesa, F. Brezo, J. Nieves, P. G. Bringas, Opem: A static-
dynamic approach for machine-learning-based malware detection, in: CI-
SIS ’12-ICEUTE´ 12-SOCO´, Springer, 2013, pp. 271–280.
[21] M. Eskandari, Z. Khorshidpour, S. Hashemi, Hdm-analyser: a hybrid
analysis approach based on data mining techniques for malware detection,
Journal of Computer Virology and Hacking Techniques 9 (2) (2013) 77–93.
[22] P. Vadrevu, B. Rahbarinia, R. Perdisci, K. Li, M. Antonakakis, Measur-
ing and detecting malware downloads in live network traffic, in: Com-
puter Security – ESORICS 2013: 18th European Symposium on Research
in Computer Security, Egham, UK, September 9-13, 2013. Proceedings,
Springer Berlin Heidelberg, Berlin, Heidelberg, 2013, pp. 556–573.
[23] J. Bai, J. Wang, G. Zou, A malware detection scheme based on mining
format information, The Scientific World Journal.
[24] M. Kruczkowski, E. N. Szynkiewicz, Support vector machine for malware
analysis and classification, in: Web Intelligence (WI) and Intelligent Agent
Technologies (IAT), IEEE Computer Society, 2014, pp. 415–420.
[25] A. Tamersoy, K. Roundy, D. H. Chau, Guilt by association: large scale
malware detection by mining file-relation graphs, in: Proceedings of the
20th ACM SIGKDD, ACM, 2014, pp. 1524–1533.
46
[26] D. Uppal, R. Sinha, V. Mehra, V. Jain, Malware detection and classifica-
tion based on extraction of api sequences, in: ICACCI, IEEE, 2014, pp.
2337–2342.
[27] L. Chen, T. Li, M. Abdulhayoglu, Y. Ye, Intelligent malware detection
based on file relation graphs, in: Semantic Computing (ICSC), 2015 IEEE
International Conference on, 2015, pp. 85–92.
[28] E. Elhadi, M. A. Maarof, B. Barry, Improving the detection of malware
behaviour using simplified data dependent api call graph, Journal of Se-
curity and Its Applications.
[29] Z. Feng, S. Xiong, D. Cao, X. Deng, X. Wang, Y. Yang, X. Zhou,
Y. Huang, G. Wu, Hrs: A hybrid framework for malware detection, in:
Proceedings of the 2015 ACM International Workshop on Security and
Privacy Analytics, ACM, 2015, pp. 19–26.
[30] M. Ghiasi, A. Sami, Z. Salehi, Dynamic VSA: a framework for malware de-
tection based on register contents , Engineering Applications of Artificial
Intelligence 44 (2015) 111 – 122.
[31] M. Ahmadi, G. Giacinto, D. Ulyanov, S. Semenov, M. Trofimov, Novel
feature extraction, selection and fusion for effective malware family clas-
sification, CoRR abs/1511.04317.
[32] B. J. Kwon, J. Mondal, J. Jang, L. Bilge, T. Dumitras, The dropper effect:
Insights into malware distribution with downloader graph analytics, in:
Proceedings of the 22nd ACM SIGSAC Conference on Computer and
Communications Security, ACM, 2015, pp. 1118–1129.
[33] W. Mao, Z. Cai, D. Towsley, X. Guan, Probabilistic inference on integrity
for access behavior based malware detection, in: International Workshop
on Recent Advances in Intrusion Detection, Springer, 2015, pp. 155–176.
[34] J. Saxe, K. Berlin, Deep neural network based malware detection using
two dimensional binary program features, in: Malicious and Unwanted
47
Software (MALWARE), 2015 10th International Conference on, IEEE,
2015, pp. 11–20.
[35] T. Wu¨chner, M. Ochoa, A. Pretschner, Robust and effective malware
detection through quantitative data flow graph metrics, in: Detection of
Intrusions and Malware, and Vulnerability Assessment, Springer, 2015,
pp. 98–118.
[36] E. Raff, C. Nicholas, An alternative to ncd for large sequences, lempel-ziv
jaccard distance, in: Proceedings of the 23rd ACM SIGKDD International
Conference on Knowledge Discovery and Data Mining, ACM, 2017, pp.
1007–1015.
[37] M. Gharacheh, V. Derhami, S. Hashemi, S. M. H. Fard, Proposing an
hmm-based approach to detect metamorphic malware, in: Fuzzy and In-
telligent Systems (CFIS), 2015, pp. 1–5.
[38] P. Khodamoradi, M. Fazlali, F. Mardukhi, M. Nosrati, Heuristic metamor-
phic malware detection based on statistics of assembly instructions using
classification algorithms, in: Computer Architecture and Digital Systems
(CADS), 2015 18th CSI International Symposium on, IEEE, 2015, pp.
1–6.
[39] J. Upchurch, X. Zhou, Variant: a malware similarity testing framework,
in: 2015 10th International Conference on Malicious and Unwanted Soft-
ware (MALWARE), IEEE, 2015, pp. 31–39.
[40] G. Liang, J. Pang, C. Dai, A behavior-based malware variant classification
technique, International Journal of Information and Education Technol-
ogy 6 (4) (2016) 291.
[41] P. Vadrevu, R. Perdisci, MAXS: Scaling Malware Execution with Sequen-
tial Multi-Hypothesis Testing, in: ASIA CCS ’16, ASIA CCS ’16, ACM,
New York, NY, USA, 2016, pp. 771–782.
48
[42] T. Lee, J. J. Mody, Behavioral classification, in: EICAR Conference, 2006,
pp. 1–17.
[43] K. Huang, Y. Ye, Q. Jiang, Ismcs: an intelligent instruction sequence
based malware categorization system, in: Anti-counterfeiting, Security,
and Identification in Communication, 2009, IEEE, 2009, pp. 509–512.
[44] Y. Park, D. Reeves, V. Mulukutla, B. Sundaravel, Fast malware classifi-
cation by automated behavioral graph matching, in: Workshop on Cyber
Security and Information Intelligence Research, ACM, 2010, p. 45.
[45] Y. Ye, T. Li, Y. Chen, Q. Jiang, Automatic malware categorization using
cluster ensemble, in: Proceedings of the 16th ACM SIGKDD international
conference on Knowledge discovery and data mining, ACM, 2010, pp. 95–
104.
[46] G. E. Dahl, J. W. Stokes, L. Deng, D. Yu, Large-scale malware classifica-
tion using random projections and neural networks, in: Acoustics, Speech
and Signal Processing (ICASSP), IEEE, 2013, pp. 3422–3426.
[47] X. Hu, K. G. Shin, S. Bhatkar, K. Griffin, Mutantx-s: Scalable malware
clustering based on static features, in: USENIX Annual Technical Con-
ference, 2013, pp. 187–198.
[48] R. Islam, R. Tian, L. M. Batten, S. Versteeg, Classification of malware
based on integrated static and dynamic features, Journal of Network and
Computer Applications 36 (2) (2013) 646–656.
[49] D. Kong, G. Yan, Discriminant malware distance learning on structural
information for automated malware classification, in: ACM SIGKDD ’13,
KDD ’13, ACM, New York, NY, USA, 2013, pp. 1357–1365.
[50] S. Nari, A. A. Ghorbani, Automated malware classification based on net-
work behavior, in: Computing, Networking and Communications (ICNC),
2013 International Conference on, IEEE, 2013, pp. 642–647.
49
[51] N. Kawaguchi, K. Omote, Malware function classification using apis in
initial behavior, in: Information Security (AsiaJCIS), 2015 10th Asia Joint
Conference on, IEEE, 2015, pp. 138–144.
[52] C.-T. Lin, N.-J. Wang, H. Xiao, C. Eckert, Feature selection and ex-
traction for malware classification, Journal of Information Science and
Engineering 31 (3) (2015) 965–992.
[53] A. Mohaisen, O. Alrawi, M. Mohaisen, Amal: High-fidelity, behavior-
based automated malware analysis and classification, computers & secu-
rity 52 (2015) 251–266.
[54] S. Pai, F. Di Troia, C. A. Visaggio, T. H. Austin, M. Stamp, Clustering
for malware classification, J Comput Virol Hack Tech.
[55] M. Bailey, J. Oberheide, J. Andersen, Z. M. Mao, F. Jahanian, J. Nazario,
Automated classification and analysis of internet malware, in: Recent
advances in intrusion detection, Springer, 2007, pp. 178–197.
[56] U. Bayer, P. M. Comparetti, C. Hlauschek, C. Kruegel, E. Kirda, Scalable,
behavior-based malware clustering, in: NDSS, Vol. 9, 2009, pp. 8–11.
[57] K. Rieck, P. Trinius, C. Willems, T. Holz, Automatic analysis of malware
behavior using machine learning, Journal of Computer Security 19 (4)
(2011) 639–668.
[58] S. Palahan, D. Babic´, S. Chaudhuri, D. Kifer, Extraction of statistically
significant malware behaviors, in: Computer Security Applications Con-
ference, ACM, 2013, pp. 69–78.
[59] M. Egele, M. Woo, P. Chapman, D. Brumley, Blanket execution: Dynamic
similarity testing for program binaries and components, in: USENIX Se-
curity ’14, USENIX Association, San Diego, CA, 2014, pp. 303–317.
[60] M. Lindorfer, C. Kolbitsch, P. M. Comparetti, Detecting environment-
sensitive malware, in: Recent Advances in Intrusion Detection, Springer,
2011, pp. 338–357.
50
[61] I. Santos, F. Brezo, X. Ugarte-Pedrero, P. G. Bringas, Opcode sequences
as representation of executables for data-mining-based unknown malware
detection, Information Sciences 231 (2013) 64–82.
[62] M. Polino, A. Scorti, F. Maggi, S. Zanero, Jackdaw: Towards Automatic
Reverse Engineering of Large Datasets of Binaries, in: Detection of In-
trusions and Malware, and Vulnerability Assessment, Lecture 

Notes in
Computer Science, Springer International Publishing, 2015, pp. 121–143.
[63] W. Wong, M. Stamp, Hunting for metamorphic engines, Journal in Com-
puter Virology 2 (3) (2006) 211–229.
[64] S. Attaluri, S. McGhee, M. Stamp, Profile hidden markov models and
metamorphic virus detection, Journal in Computer Virology 5 (2) (2009)
151–169.
[65] Z. Chen, M. Roussopoulos, Z. Liang, Y. Zhang, Z. Chen, A. Delis, Malware
characteristics and threats on the internet ecosystem, Journal of Systems
and Software 85 (7) (2012) 1650–1672.
[66] P. M. Comar, L. Liu, S. Saha, P. N. Tan, A. Nucci, Combining supervised
and unsupervised learning for zero-day malware detection, in: INFOCOM,
2013 Proceedings IEEE, 2013, pp. 2022–2030.
[67] J. Sexton, C. Storlie, B. Anderson, Subroutine based detection of APT
malware, Journal of Computer Virology and Hacking Techniques (2015)
1–9.
[68] H.-S. Park, C.-H. Jun, A simple and fast algorithm for k-medoids cluster-
ing, Expert Systems with Applications 36 (2009) 3336 – 3341.
[69] M. Graziano, D. Canali, L. Bilge, A. Lanzi, D. Balzarotti, Needles in a
haystack: Mining information from public dynamic analysis sandboxes for
malware intelligence, in: USENIX Security ’15, 2015, pp. 1057–1072.
51
[70] M. Asquith, Extremely scalable storage and clustering of malware meta-
data, Journal of Computer Virology and Hacking Techniques (2015) 1–10.
[71] M. Egele, T. Scholte, E. Kirda, C. Kruegel, A survey on automated dy-
namic malware-analysis techniques and tools, ACM computing surveys
(CSUR) 44 (2) (2012) 6.
[72] M. Siddiqui, M. C. Wang, J. Lee, Detecting internet worms using data
mining techniques, Journal of Systemics, Cybernetics and Informatics
(2009) 48–53.
[73] A. Caliskan-Islam, R. Harang, A. Liu, A. Narayanan, C. Voss, F. Yam-
aguchi, R. Greenstadt, De-anonymizing programmers via code stylometry,
in: USENIX Security ’15, USENIX Association, 2015, pp. 255–270.
[74] S. Srakaew, W. Piyanuntcharatsr, S. Adulkasem, On the comparison of
malware detection methods using data mining with two feature sets, Jour-
nal of Security and Its Applications 9 (2015) 293–318.
[75] J. Jang, D. Brumley, S. Venkataraman, Bitshred: feature hashing malware
for scalable triage and semantic analysis, in: Computer and communica-
tions security, ACM, 2011, pp. 309–320.
[76] F. E. Allen, Control flow analysis, in: Proceedings of a Symposium on
Compiler Optimization, ACM, New York, NY, USA, 1970, pp. 1–19.
[77] D. Kirat, L. Nataraj, G. Vigna, B. Manjunath, Sigmal: A static sig-
nal processing based malware triage, in: Proceedings of the 29th Annual
Computer Security Applications Conference, ACM, 2013, pp. 89–98.
[78] R. Tian, L. M. Batten, S. C. Versteeg, Function length as a tool for mal-
ware classification, in: Malicious and Unwanted Software, 2008. MAL-
WARE 2008. 3rd International Conference on, 2008, pp. 69–76.
[79] N. Miramirkhani, M. P. Appini, N. Nikiforakis, M. Polychronakis, Spot-
less sandboxes: Evading malware analysis systems using wear-and-tear
52
artifacts, in: 2017 IEEE Symposium on Security and Privacy (SP), 2017,
pp. 1009–1024.
[80] J. Karpin, A. Dorfman, Crypton - Exposing Malware’s Deep-
est Secrets, https://recon.cx/2017/montreal/resources/slides/
RECON-MTL-2017-crypton.pdf, last accessed: 2018-10-18 (2017).
[81] T. Blazytko, M. Contag, C. Aschermann, T. Holz, Syntia: Synthesizing
the semantics of obfuscated code, in: 26th USENIX Security Symposium
(USENIX Security 17), USENIX Association, 2017, pp. 643–659.
[82] V. Kotov, M. Wojnowicz, Towards generic deobfuscation of windows API
calls, CoRR abs/1802.04466.
[83] Y. Liao, R. Cai, G. Zhu, Y. Yin, K. Li, Mobilefindr: Function similarity
identification for reversing mobile binaries, in: ESORICS (1), Vol. 11098
of Lecture 

Notes in Computer Science, Springer, 2018, pp. 66–83.
[84] R. Baldoni, E. Coppa, D. C. D’Elia, C. Demetrescu, I. Finocchi, A survey
of symbolic execution techniques, ACM Comput. Surv. 51 (3).
[85] I. Guilfanov, Decompilers and beyond, Black Hat USA.
[86] A. Rosseau, R. Seymour, Finding Xori: Malware Analysis Triage with Au-
tomated Disassembly, https://i.blackhat.com/us-18/Wed-August-8/
us-18-Rousseau-Finding-Xori-Malware-Analysis-Triage-With-Automated-Disassembly.
pdf, last accessed: 2018-10-14 (2018).
[87] E. Schulte, J. Ruchti, M. Noonan, D. Ciarletta, A. Loginov, Evolving
exact decompilation, in: Binary Analysis Research (BAR), 2018, 2018.
[88] Vxheaven, https://github.com/opsxcq/mirror-vxheaven.org, ac-
cessed: 2018-06-03.
[89] Offensive Computing, http://www.offensivecomputing.net, accessed:
2018-06-03.
53
[90] Malicia Project, http://malicia-project.com, accessed: 2018-06-03.
[91] ThreatTrack, https://www.threattrack.com/malware-analysis.
aspx, accessed: 2018-06-03.
[92] Anubis, https://seclab.cs.ucsb.edu/academic/projects/projects/
anubis/, accessed: 2018-06-03.
[93] L. Bilge, D. Balzarotti, W. Robertson, E. Kirda, C. Kruegel, Disclosure:
detecting botnet command and control servers through large-scale netflow
analysis, in: ACSAC ’12, ACM, 2012, pp. 129–138.
[94] H. Sanders, Garbage In, Garbage Out - How pur-
portedly great ML models can be screwed up by bad
data , https://www.blackhat.com/docs/us-17/wednesday/
us-17-Sanders-Garbage-In-Garbage-Out-How-Purportedly-Great-ML-Models-Can-Be-Screwed-Up-By-Bad-Data.
pdf, last accessed: 2018-10-18 (2017).
[95] B. Miller, A. Kantchelian, S. Afroz, R. Bachwani, R. Faizullabhoy,
L. Huang, V. Shankar, M. Tschantz, T. Wu, G. Yiu, et al., Back to the
future: Malware detection with temporally consistent labels, CORR.
[96] R. Jordaney, K. Sharad, S. K. Dash, Z. Wang, D. Papini, I. Nouretdinov,
L. Cavallaro, Transcend: Detecting concept drift in malware classification
models, in: 26th USENIX Security Symposium (USENIX Security 17),
USENIX Association, Vancouver, BC, 2017, pp. 625–642.
URL https://www.usenix.org/conference/usenixsecurity17/
technical-sessions/presentation/jordaney
[97] R. Harang, F. Ducau, Measuring the Speed of the Red
Queens Race, https://i.blackhat.com/us-18/Wed-August-8/
us-18-Harang-Measuring-the-Speed-of-the-Red-Queens-Race.pdf,
last accessed: 2018-10-18 (2018).
[98] VirusTotal, https://www.virustotal.com, accessed: 2018-06-03.
54
[99] Malwr, https://malwr.com, accessed: 2018-06-03.
[100] M. Ruthven, A. Blaich, Fighting targeted malware in the mobile
ecosystem, https://www.blackhat.com/docs/us-17/wednesday/
us-17-Ruthven-Fighting-Targeted-Malware-In-The-Mobile-Ecosystem.
pdf, last accessed: 2018-10-16 (2017).
[101] G. Laurenza, L. Aniello, R. Lazzeretti, R. Baldoni, Malware triage based
on static features and public apt reports, in: S. Dolev, S. Lodha (Eds.),
Cyber Security Cryptography and Machine Learning, Springer Interna-
tional Publishing, Cham, 2017, pp. 288–305.
[102] M. Howard, A. Pfeffer, M. Dalai, M. Reposa, Predicting signatures of
future malware variants, in: 2017 12th International Conference on Mali-
cious and Unwanted Software (MALWARE), 2017, pp. 126–132.
[103] V. Juzonis, N. Goranin, A. Cenys, D. Olifer, Specialized genetic algorithm
based simulation tool designed for malware evolution forecasting, Annales
Universitatis Mariae Curie-Sklodowska, sectio AI–Informatica 12 (4).
[104] H. Pomeranz, Detecting malware with memory forensics, http://www.
deer-run.com/~hal/Detect_Malware_w_Memory_Forensics.pdf, last
accessed: 2018-05-14 (2012).
[105] A. Damodaran, F. Di Troia, C. A. Visaggio, T. H. Austin, M. Stamp, A
comparison of static, dynamic, and hybrid analysis for malware detection,
Journal of Computer Virology and Hacking Techniques (2015) 1–12.
[106] Y. Kulakov, Mazewalker, https://recon.cx/2017/montreal/
resources/slides/RECON-MTL-2017-MazeWalker.pdf (2017).
[107] G. Laurenza, D. Ucci, L. Aniello, R. Baldoni, An architecture for semi-
automatic collaborative malware analysis for cis, in: Dependable Sys-
tems and Networks Workshop, 2016 46th Annual IEEE/IFIP International
Conference on, IEEE, 2016, pp. 137–142.
55

