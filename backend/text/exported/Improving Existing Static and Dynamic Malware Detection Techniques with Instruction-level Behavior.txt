
Improving Existing Static and Dynamic Malware Detection Techniques with Instruction-level Behavior (2019) by Kim, Danny
Abstract:
My Ph.D. focuses on detecting malware by leveraging the information obtained at an instruction-level. Instruction-level information is obtained by looking at the instructions or disassembly that make up an executable. My initial work focused on using a dynamic binary instrumentation (DBI) tool. A DBI tool enables the study of instruction-level behavior while the malware is executing, which I show proves to be valuable in detecting malware. To expand on my work with dynamic instruction-level information, I integrated it with machine learning to increase the scalability and robustness of my detection tool. To further increase the scalability of the dynamic detection of malware, I created a two stage static-dynamic malware detection scheme aimed at achieving the accuracy of a fully-dynamic detection scheme without the high computational resources and time required. Lastly, I show the improvement of static analysis-based detection of malware by automatically generated machine learning features based on opcode sequences with the help of convolutional neural networks.

The first part of my research focused on obfuscated malware. Obfuscation is the process in which malware tries to hide itself from static analysis and trick disassemblers. I found that by using a DBI tool, I was able to not only detect obfuscation, but detect the differences in how it occurred in malware versus goodware. Through dynamic program-level analysis, I was able to detect specific obfuscations and use the varying methods in which it was used by programs to differentiate malware and goodware. I found that by using the mere presence of obfuscation as a method of detecting malware, I was able to detect previously undetected malware.

I then focused on using my knowledge of dynamic program-level features to build a highly accurate machine learning-based malware detection tool. Machine learning is useful in malware detection because it can process a large amount of data to determine meaningful relationships to distinguish malware from benign programs. Through the integration of machine learning, I was able to expand my obfuscation detection schemes to address a broader class of malware, which ultimately led to a malware detection tool that can detect 98.45% of malware with a 1% false positive rate.

Understanding the pitfalls of dynamic analysis of malware, I focused on creating a more efficient method of detecting malware. Malware detection comes in three methods: static analysis, dynamic analysis, and hybrids. Static analysis is fast and effective for detecting previously seen malware where as dynamic analysis can be more accurate and robust against zero-day or polymorphic malware, but at the cost of a high computational load. Most modern defenses today use a hybrid approach, which uses both static and dynamic analysis, but are suboptimal. I created a two-phase malware detection tool that approaches the accuracy of the dynamic-only system with only a small fraction of its computational cost, while maintaining a real-time malware detection timeliness similar to a static-only system, thus achieving the best of both approaches.

Lastly, my Ph.D. focused on reducing the need for manual feature generation by utilizing Convolutional Neural Networks (CNNs) to automatically generate feature vectors from raw input data. My work shows that using a raw sequence of opcode sequences from static disassembly with a CNN model can automatically produce feature vectors that are useful for detecting malware. Because this process is automated, it presents as a scalable method of consistently producing useful features without human intervention or labor that can be used to detect malware

FullText:




Abstract



Title of dissertation: Improving Existing Static and DynamicMalware Detection Techniqueswith Instruction-level BehaviorDanny KimDoctor of Philosophy, 2019Dissertation directed by: Professor Rajeev BaruaDepartment of Electricaland Computer EngineeringMy Ph.D. focuses on detecting malware by leveraging the information obtainedat an instruction-level. Instruction-level information is obtained by looking at theinstructions or disassembly that make up an executable. My initial work focused onusing a dynamic binary instrumentation (DBI) tool. A DBI tool enables the studyof instruction-level behavior while the malware is executing, which I show proves tobe valuable in detecting malware. To expand on my work with dynamic instruction-level information, I integrated it with machine learning to increase the scalability androbustness of my detection tool. To further increase the scalability of the dynamicdetection of malware, I created a two stage static-dynamic malware detection schemeaimed at achieving the accuracy of a fully-dynamic detection scheme without thehigh computational resources and time required. Lastly, I show the improvementof static analysis-based detection of malware by automatically generated machinelearning features based on opcode sequences with the help of convolutional neuralnetworks.The first part of my research focused on obfuscated malware. Obfuscation isthe process in which malware tries to hide itself from static analysis and trick disas-semblers. I found that by using a DBI tool, I was able to not only detect obfuscation,but detect the differences in how it occurred in malware versus goodware. Throughdynamic program-level analysis, I was able to detect specific obfuscations and usethe varying methods in which it was used by programs to differentiate malware andgoodware. I found that by using the mere presence of obfuscation as a method ofdetecting malware, I was able to detect previously undetected malware.I then focused on using my knowledge of dynamic program-level features tobuild a highly accurate machine learning-based malware detection tool. Machinelearning is useful in malware detection because it can process a large amount of datato determine meaningful relationships to distinguish malware from benign programs.Through the integration of machine learning, I was able to expand my obfuscationdetection schemes to address a broader class of malware, which ultimately led to amalware detection tool that can detect 98.45% of malware with a 1% false positiverate.Understanding the pitfalls of dynamic analysis of malware, I focused on cre-ating a more efficient method of detecting malware. Malware detection comes inthree methods: static analysis, dynamic analysis, and hybrids. Static analysis isfast and effective for detecting previously seen malware where as dynamic anal-ysis can be more accurate and robust against zero-day or polymorphic malware,but at the cost of a high computational load. Most modern defenses today use ahybrid approach, which uses both static and dynamic analysis, but are subopti-mal. I created a two-phase malware detection tool that approaches the accuracyof the dynamic-only system with only a small fraction of its computational cost,while maintaining a real-time malware detection timeliness similar to a static-onlysystem, thus achieving the best of both approaches.Lastly, my Ph.D. focused on reducing the need for manual feature genera-tion by utilizing Convolutional Neural Networks (CNNs) to automatically generatefeature vectors from raw input data. My work shows that using a raw sequenceof opcode sequences from static disassembly with a CNN model can automaticallyproduce feature vectors that are useful for detecting malware. Because this pro-cess is automated, it presents as a scalable method of consistently producing usefulfeatures without human intervention or labor that can be used to detect malware.Improving Existing Static and Dynamic Malware DetectionTechniques with Instruction-level BehaviorbyDanny KimDissertation submitted to the Faculty of the Graduate School of theUniversity of Maryland, College Park in partial fulfillmentof the requirements for the degree ofDoctor of Philosophy2019Advisory Committee:Professor Rajeev Barua, Chair/AdvisorProfessor Tudor DumitrasProfessor Charalampos (Babis) PapamanthouProfessor Michael HicksProfessor Dana Dachman-Soledc© Copyright byDanny Kim2019



DedicationI dedicate this work to Jesus Christ and my wife, Rebekah Kim. God first andforemost has always been foundational in my life and will continue to be the sourceof my motivation. My wife has been supporting me through the seeemingly endlessyears of getting underpaid, overworked, and denied from too many conferences. Itwas a grueling process filled with many doubts and failures, but she never lost faithin me. She has supported me with the unconditional love I needed to make itthrough. Though she did not contribute any research-related ideas, she providedlaughs, love, and a balance in my life that I needed. She is the best wife and theperfect mate. This work and everything that comes of it is for you.ii

AcknowledgmentsI would first like to thank my advisor, Professor Rajeev Barua, for his unwa-vering guidance and timely advice in helping me complete this work. He taughtvaluable lessons in being detail-oriented, goal-minded, and 

Results driven. I havelearned an incredible amount from him as a teacher and a researcher that made myPh.D. what it is.Second, I would like to thank Professor Ankur Srivastava for pushing me topursue my Ph.D. I would not be the same student or engineer without his relentlesspassion or guidance.Third, I would like to thank Daniel Mirsky for his valuable help in the comple-tion of my work. He was my constant sounding board for new ideas and thoughts.His ability to transform ideas into concrete code was unmatched and I could nothave completed my work as quickly as I did without him.Fourth, I would like to thank my friends through this process: Kevin Merchant,Michael Zuzak, Shang Li, and Amir Majlesi Kupaei. They have been with methrough the entire process and were vital in keeping me sane and on track. I onlyhope that I am as helpful to them as they were to me.Fifth, I would like to thank the Laboratory of Telecommunication Sciencesand the ARCS foundation for funding parts of my research.Lastly, I would like to thank Nikhil Kandpa, Vamsi Kovuru, Matthew Gilboy,Aaron Kramer, and Julien Roy for their individual contributions to my work. Allof you played a part in the creation and development of the projects that made upiiimy Ph.D.iv



Table of Contents



Dedication ii



Acknowledgements iii



Table of Contents v



List of Tables ix



List of Figures x



List of Abbreviations xi1 



Introduction 12 Detecting Dynamic Obfuscation in Malware 112.1 



Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 112.2 Detecting Dynamic Obfuscation . . . . . . . . . . . . . . . . . . . . . 132.3 Self-Modification . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 152.3.1 Definition . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 152.3.2 Presence in Benign Applications . . . . . . . . . . . . . . . . . 152.3.3 Detection Scheme . . . . . . . . . . . . . . . . . . . . . . . . . 162.3.4 Related Work . . . . . . . . . . . . . . . . . . . . . . . . . . . 172.4 



Section Mislabel Obfuscation . . . . . . . . . . . . . . . . . . . . . . 182.4.1 Definition . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 182.4.2 Presence in Benign Applications . . . . . . . . . . . . . . . . . 202.4.3 Detection scheme . . . . . . . . . . . . . . . . . . . . . . . . . 202.4.4 Related Work . . . . . . . . . . . . . . . . . . . . . . . . . . . 202.5 Dynamically Generated Code . . . . . . . . . . . . . . . . . . . . . . 212.5.1 Definition . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 212.5.2 Presence in Benign Applications . . . . . . . . . . . . . . . . . 222.5.3 Detection Scheme . . . . . . . . . . . . . . . . . . . . . . . . . 232.5.4 Related Work . . . . . . . . . . . . . . . . . . . . . . . . . . . 252.6 Unconditional To Conditional Branch Obfuscation . . . . . . . . . . . 262.6.1 Definition . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 262.6.2 Presence in Benign Applications . . . . . . . . . . . . . . . . . 272.6.3 Detection Scheme . . . . . . . . . . . . . . . . . . . . . . . . . 272.6.4 Related Work . . . . . . . . . . . . . . . . . . . . . . . . . . . 28v2.7 Exception-Based Obfuscation . . . . . . . . . . . . . . . . . . . . . . 282.7.1 Definition . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 282.7.2 Presence in Benign Applications . . . . . . . . . . . . . . . . . 292.7.3 Detection Scheme . . . . . . . . . . . . . . . . . . . . . . . . . 292.7.4 Related Work . . . . . . . . . . . . . . . . . . . . . . . . . . . 312.8 Overlapping Code Sequences . . . . . . . . . . . . . . . . . . . . . . . 312.8.1 Definition . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 312.8.2 Presence in Benign Applications . . . . . . . . . . . . . . . . . 322.8.3 Detection Scheme . . . . . . . . . . . . . . . . . . . . . . . . . 322.8.4 Related Work . . . . . . . . . . . . . . . . . . . . . . . . . . . 332.9 DynODet Capabilities and 

Limitations . . . . . . . . . . . . . . . . . 332.9.1 Capabilities . . . . . . . . . . . . . . . . . . . . . . . . . . . . 332.9.1.1 Multithreaded Applications . . . . . . . . . . . . . . 332.9.1.2 Spawned Child Processes . . . . . . . . . . . . . . . 342.9.2 

Limitations and 



Assumptions . . . . . . . . . . . . . . . . . . 342.10 

Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 342.10.1 Test Set up . . . . . . . . . . . . . . . . . . . . . . . . . . . . 342.10.2 Benign Applications . . . . . . . . . . . . . . . . . . . . . . . 352.10.2.1 NSRL Set . . . . . . . . . . . . . . . . . . . . . . . . 372.10.2.2 Standard Installed Applications . . . . . . . . . . . . 382.10.2.3 Interpreters and JIT-platform Programs . . . . . . . 392.10.3 Malware . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 402.10.4 

Limitations with Evasion . . . . . . . . . . . . . . . . . . . . . 412.11 

Conclusion and 



Future Work . . . . . . . . . . . . . . . . . . . . . . . 433 Enhancing Dynamic Analysis-based Malware Detection with Dynamic Program-level Features 473.1 



Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 473.2 

Background of Machine Learning in Malware Detection . . . . . . . . 543.3 Existing Works’ Feature Sets . . . . . . . . . . . . . . . . . . . . . . . 553.3.1 Static analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . 553.3.2 Dynamic Analysis . . . . . . . . . . . . . . . . . . . . . . . . . 563.4 My Feature Set . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 593.4.1 Incorporation of Existing Features . . . . . . . . . . . . . . . . 593.4.1.1 Static Features . . . . . . . . . . . . . . . . . . . . . 593.4.1.2 Dynamic Features- OS Features . . . . . . . . . . . . 603.4.2 Novel Dynamic Program-level Features: Potentially Evasive . 613.4.2.1 Self-modification . . . . . . . . . . . . . . . . . . . . 623.4.2.2 Dynamically generated code . . . . . . . . . . . . . . 643.4.2.3 



Section-related obfuscation . . . . . . . . . . . . . . 663.4.2.4 Unconditional to conditional branch conversion . . . 673.4.2.5 Overlapping code sequences . . . . . . . . . . . . . . 683.4.2.6 Hidden functions . . . . . . . . . . . . . . . . . . . . 693.4.2.7 Dynamic IAT . . . . . . . . . . . . . . . . . . . . . . 713.4.2.8 Call-return obfuscation . . . . . . . . . . . . . . . . . 72vi3.4.3 Novel Dynamic Program-level Features: General DPL Execution 733.4.3.1 Function analysis . . . . . . . . . . . . . . . . . . . . 743.4.3.2 Control flow analysis . . . . . . . . . . . . . . . . . . 743.4.3.3 Instruction execution . . . . . . . . . . . . . . . . . . 753.5 My Implementation . . . . . . . . . . . . . . . . . . . . . . . . . . . . 763.5.1 Analysis 

Overview . . . . . . . . . . . . . . . . . . . . . . . . 763.5.2 Machine Learning . . . . . . . . . . . . . . . . . . . . . . . . . 773.5.3 Malware Detection Tool Implementation . . . . . . . . . . . . 793.5.4 My Dataset . . . . . . . . . . . . . . . . . . . . . . . . . . . . 793.6 

Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 823.6.1 MLP-based Malware Detection Tool 

Results . . . . . . . . . . 823.6.2 Generalization Test . . . . . . . . . . . . . . . . . . . . . . . . 853.6.3 Zero-day Test . . . . . . . . . . . . . . . . . . . . . . . . . . . 873.6.4 Performance on Malware with Few Dynamic Signatures . . . . 883.7 

Limitations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 893.8 

Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 914 A Hybrid Static Tool to Increase the Usability and Scalability of DynamicDetection of Malware 924.1 



Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 924.2 Related Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 984.3 My Two-phase System . . . . . . . . . . . . . . . . . . . . . . . . . . 1014.3.1 Architectural Comparison VS Existing Hybrid Tools . . . . . 1014.3.2 My Design . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1034.3.3 Computational Resources Reduction . . . . . . . . . . . . . . 1054.3.4 Timeliness Improvement . . . . . . . . . . . . . . . . . . . . . 1064.3.5 Hard-to-Classify Programs . . . . . . . . . . . . . . . . . . . . 1064.4 Implementation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1084.4.1 Dataset . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1084.4.2 Machine Learning . . . . . . . . . . . . . . . . . . . . . . . . . 1094.4.3 Feature Set and Testing . . . . . . . . . . . . . . . . . . . . . 1104.5 

Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1114.5.1 Static VS Dynamic IDS . . . . . . . . . . . . . . . . . . . . . 1114.5.2 Definitions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1134.5.2.1 Computational Requirements Reduction . . . . . . . 1144.5.2.2 Timeliness Reduction . . . . . . . . . . . . . . . . . 1144.5.2.3 Alert Generation . . . . . . . . . . . . . . . . . . . . 1154.5.3 Static-Hybrid Tool: Minimizing BBR . . . . . . . . . . . . . . 1164.5.3.1 Bucket 2 Analysis . . . . . . . . . . . . . . . . . . . 1194.6 

Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1205 Enhancing the Static Detection of Malware with CNNs 1225.1 



Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1225.2 Static Program Structure Feature Set . . . . . . . . . . . . . . . . . . 1265.2.1 PE32 Program Structure . . . . . . . . . . . . . . . . . . . . . 126vii5.2.2 Base Static Features . . . . . . . . . . . . . . . . . . . . . . . 1275.2.3 Exact or Near-exact Pattern Matching Features . . . . . . . . 1285.2.4 Opcode-Based Feature Generation and Training . . . . . . . . 1295.3 Implementation Details . . . . . . . . . . . . . . . . . . . . . . . . . . 1325.3.1 Dataset . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1325.3.2 Disassembly . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1345.3.3 Machine Learning . . . . . . . . . . . . . . . . . . . . . . . . . 1345.4 

Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1375.4.1 The Addition of Opcode Sequence-based CNN Features . . . . 1375.4.2 Zero-day Malware Detection . . . . . . . . . . . . . . . . . . . 1395.4.3 CNN Robustness Test . . . . . . . . . . . . . . . . . . . . . . 1415.4.4 Similarity Analysis and 



Future Work . . . . . . . . . . . . . . 1435.5 Related Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1445.6 

Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1476 

Conclusion 148Bibliography 149viii



List of Tables2.1 Benign Application 

Results . . . . . . . . . . . . . . . . . . . . . . . 442.2 Benign Interpreter 

Results . . . . . . . . . . . . . . . . . . . . . . . . 452.3 Obfuscation in Malware 

Results . . . . . . . . . . . . . . . . . . . . . 462.4 Malware Detection Improvement . . . . . . . . . . . . . . . . . . . . 463.1 MLP 

Results with a 1% FPR . . . . . . . . . . . . . . . . . . . . . . 833.2 Generalization Test 

Results . . . . . . . . . . . . . . . . . . . . . . . 863.3 Zero-day Test 

Results . . . . . . . . . . . . . . . . . . . . . . . . . . . 874.1 Static analysis VS. Dynamic analysis Detection 

Results . . . . . . . . 1124.2 Static-dynamic-analysis 

Results for T1=0.2, T2=0.999999 . . . . . . . 1164.3 Static-dynamic-analysis 

Results for T1=0.2, T2=0.999999 . . . . . . . 1174.4 Bucket 2 Correctness 

Results for T1=0.2, T2=0.999999 . . . . . . . . 1195.1 Ensemble 

Results with Various Base Classifiers at a 1% FPR . . . . . 1385.2 Simulated Zero-day Test: Ensemble 

Results with Various Base Clas-sifiers at a 1.5% FPR . . . . . . . . . . . . . . . . . . . . . . . . . . . 140ix



List of Figures2.1 Example of Self-modification . . . . . . . . . . . . . . . . . . . . . . . 152.2 Example of Permission Change . . . . . . . . . . . . . . . . . . . . . 192.3 Example of Dynamically Generated Code . . . . . . . . . . . . . . . . 222.4 Example of Unconditional to Conditional Obfuscation . . . . . . . . . 262.5 Example of Exception-based obfuscation . . . . . . . . . . . . . . . . 282.6 Example of Overlapping Code Sequences . . . . . . . . . . . . . . . . 323.1 ROC plot for MLP with 0% ≤ FPR ≤ 5% . . . . . . . . . . . . . . . 843.2 False Negative Rates of OS VS OS+DPL on Malware with Few Sig-natures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 884.1 Advantages: Maximum accuracy; Disadvantages: High computa-tional costs, decreased timeliness . . . . . . . . . . . . . . . . . . . . 1024.2 Advantages: Fast detection, some computational benefits; Disadvan-tages: Limited to static-only accuracy . . . . . . . . . . . . . . . . . . 1024.3 Advantages: Bandwidth and timeliness improvements, near maxi-mum accuracy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1034.4 Static-hybrid Categorization . . . . . . . . . . . . . . . . . . . . . . . 1044.5 Static-only VS. Static-hybrid Comparison . . . . . . . . . . . . . . . 1075.1 ROC plot for Ensemble with 0% ≤ FPR ≤ 10% . . . . . . . . . . . . 1395.2 Robustness Test 

Results . . . . . . . . . . . . . . . . . . . . . . . . . 142x



List of AbbreviationsAG Alert GenerationAPI Application Programming InterfaceAR Acrobat ReaderAUC Area Under the CurveAV Anti-VirusBBR Blocked Benign RateBMR Blocked Malicious RateCISC Complex Instruction Set ComputingCNN Convolutional Neural NetworkCR Computational ResourcesCTI Control Transfer InstructionCV Cross ValidationDEP Data Execution PreventionDBI Dynamic Binary InstrumentationDLL Dynamically Linked LibraryDPL Dynamic Program-levelDR Detection RateESN Echo State NetworkFN False NegativeFPR False Positive RateIAT Import Address TableIDS Intrusion Detection SystemIOC Indicator of CompromiseJVM Java Virtual MachineJIT Just In TimeMLP Multi-layer PerceptronNLP Natural Language ProcessingNIST National Institute of Science and TechnologyNSRL National Software Resource LibraryxiOS Operating SystemPCA Principle Component AnalysisPyInt Python InterpreterROC Receiver Operating CharacteristicRNN Recurrent Neural NetworkSOC Security Operation CenterTIB Thread Information BlockVM Virtual Machinexii



Chapter 1: 



IntroductionMalicious software, better known as malware, is a problem in today’s growingcyber community. Malware has continued to grow at an increasingly rapid rate,which brings the need for advanced and innovative defenses to an all-time high.Symantec reported discovering more than 430 million unique pieces of malware in2015 alone [1]. The sheer number of malware with their growing complexities makedetecting them a difficult task. Malware has been a cornerstone for cyberthievesand attackers to steal money, compromise information and undermine the securityof all people.Malware is decidedly a hard problem to solve. In order to combat advancedmalware today, security companies use a combination of static and dynamic tech-niques for extracting unique indicators of maliciousness (IOM) from malware. Statictechniques refer to analyzing a program without execution whereas dynamic tech-niques involve executing the program. These techniques are used typically in com-plementary fashions to extract malicious indicators that can be employed to differ-entiate malware from benign programs.However, both current static and dynamic analysis methods fail to defeat ad-vanced, obfuscated malware. Obfuscation is a technique malware writers use to1thwart the extraction of IOM during analysis and evade static detection. Examplesof obfuscation are self-modifying code, and dynamically generated code. Obfusca-tion is effective against both static and dynamic analysis because it can hide the truecontrol flow paths of a program. A control flow path of a program is the sequenceof instructions or actions executed by the program when it executes. Often times,obfuscation is performed at an instruction level and thus can be difficult to detector reverse engineer by using static analysis methods or OS-level dynamic analysismethods alone.In order to detect and defeat obfuscation, a more exact tool is needed. In thefirst part of my work, I used a dynamic binary instrumentation (DBI) tool to analyzea program’s instructions in real-time during its execution. With an instruction-levelview of the program, obfuscations can be detected and analyzed. Understandingthat malware employs different methods of obfuscation as a method of defeatingboth static and OS-level dynamic analysis, I used the presence of obfuscation as amethod of detecting malware.During my work, however, I found that obfuscation is not unique to malware.Benign programs (goodware) also used obfuscations for a variety of reasons. Forexample, I found that self-modification of instruction operands occurs in goodwarebecause goodware populates jump tables dynamically at run-time. Thus, simplyusing the presence of obfuscation in a program as a method of detecting malwaregenerated a high number of false positives. Related work that studied dynamicobfuscation detection in the past made no attempts to distinguish between maliciousand benign obfuscations. To improve upon existing work, I had to create a set2of discriminating features that distinguished malicious obfuscations from benignones. From literature, I implemented six different types of obfuscations, three withdiscriminating features, to prove that using the presence of malicious obfuscation isa viable method of detecting malware.The first part of my work, detailed in 



Section 2, focuses on detecting obfusca-tions only in malware and describes in detail each detection technique. The work isculminated in a tool called DynODet. The 



Section details DynODet’s 

Results whentested on a set of over 100K malware and over 6K goodware. It proves two keypoints. First, it shows that using the discriminating features for detecting maliciousobfuscations is invaluable in maintaining a low false positive rate, making the tooldeployable. Second, it shows that by analyzing these program-level behaviors, itwas able to detect 25% of the malware that five prominent antivirus tools missed.This shows that particularly hard to detect malware may be employing advancedprogram-level obfuscations, which DynODet is capable of detecting.Although DynODet showed promise in detecting previously undetected mal-ware with obfuscation, it had two 

Limitations. First, the discriminating featuresused to distinguish malicious obfuscations from benign ones was manually deter-mined by analyzing the dynamic 

Results of both malware and goodware. This isnot a scalable method of discovering which obfuscations are specific to malware.Furthermore, manual analysis inhibits the usefulness of program-level behavior suchas the frequency of specific opcodes because features such as these are less intuitivefor humans to understand why they would occur more in malware versus goodware.Second, only 33% of the malware tested previously had one or more of the mali-3cious types of obfuscations studied. DynODet alone is not good enough to generallydetect all types of malware.To improve upon DynODet, I did two things. First, I integrated machinelearning to produce a more scalable and accurate tool. This allowed me to enhanceand expand my dynamic program-level feature set to include more obfuscations,more targeted behaviors, and general program-level behavior. Because I was nolonger using ad-hoc discriminating features to identify obfuscations specific to mal-ware, I was able to expand my dynamic program-level feature set to include morebehaviors, which led to more detections.This work specifically targeted two deficiencies I saw in modern dynamicanalysis-based detection schemes. First, dynamic analysis is usually only run onceper sample, which means dynamic analysis is based on the behaviors of a singleexecution path, which is often an underapproximation of a sample’s total possiblebehaviors. This problem is exacerbated because current dynamic technologies thatdetect malware only focus on detecting how a program interacts with the OS as amethod of monitoring behavior. This means they detect OS-level behavior, suchas system calls or Windows library calls made by a program during its execution,and derive their IOCs based on the sequence of OS calls seen at run-time. I callthese external behaviors. These external behaviors dismiss internal behavior, behav-ior that occurs in the program without the interacting with the OS, which I haveshown is valuable in enhancing a tool’s ability to reliably and robustly detect mal-ware. Additionally, existing tools solely rely on OS calls or sequences of OS calls todetermine malicious behavior. Existing dynamic analysis is adversely affected when4these specific malicious sequences of OS calls are not present in the single instanceof behavior analysis. Second, dynamic analysis has been heralded to defeat obfus-cation and packing because executing the program can reveal the OS calls made bythe program. However, current tools cannot actually detect the methods of obfus-cation or unpacking. They simply bypass the malware’s defenses to try to uncoverthe OS calls made by the program. They miss the methods of how the malware hidtheir code and thus sacrifice a potential way of further differentiating malware fromgoodware.I formally introduce Dynamic Program-level (DPL) information in 



Section3. It covers how I use a DBI tool to detect more DPL information that provesto be both valuable and orthogonal to existing dynamic analysis information. Toshowcase the work, I built a malware detection tool that utilizes machine learningwith a comprehensive feature set including my novel DPL features. To prove thatDPL features are capable of improving existing dynamic analysis technologies, Idetected two classes of DPL information: potentially evasive and general programexecution. I define DPL potentially evasive actions as any dynamic program-levelbehavior that a program, malicious or benign, uses to hide the true code that isexecuted. I also detect three classes of general DPL information, which I define tobe features that, although collected at an instruction-level, can quantify a program’sdynamic execution characteristics.My work shows that DPL features complement dynamic OS-level features inthe following ways. First, it is gathered from monitoring the instruction sequencesexecuted within the program. The use of DPL analysis gives access to wealth of5information that has not been used in previous literature for the purpose of malwaredetection. I show and explain in my work how DPL information is orthogonaland distinct from OS-level features. Second, examining DPL information enhancesdynamic analysis’s ability to correctly detect malware when the monitoring of OS-level calls produces little to no behavioral signatures. DPL features can be morefundamental to the nature of the program and my work shows that the informationobtained, when combined with machine learning, can provably increase the detectionrate of a OS-based tool.After focusing on the dynamic analysis and detection of malware, I saw thatexisting detection architectures were not optimal in terms of performance and ef-ficiency. Most modern malware defense systems rely on hybrid approaches, whichcombine both static and dynamic analysis in order to defend against malware. How-ever, I found from a 



Literature Review that the way in which static and dynamicanalysis have been combined is suboptimal. Most hybrid approaches work one oftwo ways. The first is a system which performs both static and dynamic analysison all incoming traffic to obtain static and dynamic information in order to maxi-mize a system’s accuracy. The problem with this method is that although both setsof static and dynamic information are obtained, the computational and timelinesscosts are prohibitively high because all programs are dynamically analyzed. Theother primary hybrid approach is using a static analysis-based tool to detect anyincoming threats. The detected threats, based on static analysis alone, are sentto a Security Operations Center (SOC) to be analyzed further by other methodssuch as dynamic analysis. This method is problematic because it relies solely on6the capability of static analysis to detect threats. Any active system maintains anextremely low false positive rate (to remain usable in the real world) by sacrificingits detection rate. Thus by only relying on static analysis, the malware detectionsystem is incapable of defending robustly against all types of threats.In 



Section 4, I present a new hybrid malware detection configuration that runsat the network entry point to an enterprise that strategically leverages the strengthsof both static and dynamic analysis while minimizing their weaknesses.I propose a detection system that contains a two-step process. First, a toolwhich I call a static-hybrid tool analyzes all incoming programs statically and cat-egorizes them into one of three buckets: very benign, very malicious, and needsfurther analysis. It is thus named to distinguish it from usual static tools, whichcategorize incoming programs into only two buckets: malicious or benign. The verybenign bucket contains programs that the static-hybrid is highly confident are be-nign. This bucket contains near zero false negatives (i.e., missed malware). Thevery malicious bucket contains programs that the static-hybrid tool is highly con-fident are malicious. This bucket contains near zero false positives (i.e., benignprograms falsely detected as malware). The needs further analysis bucket containsprograms the static-hybrid tool is unable to make a strong determination on andthus is passed to the dynamic analysis tool, which is the second step of the process.The programs located in each bucket provide unique improvements to existingIDSs. The programs in the benign bucket can directly bypass the dynamic analysisportion of my tool, reducing the computational resources needed for dynamic anal-ysis. The programs in the malicious bucket can be blocked immediately, improving7timeliness and reducing the need to conduct damage control after a program isidentified as malicious in a passive IDS. The programs in the needs further analysisbucket are the only programs passed to the dynamic analysis tool. These programs,as my 

Results will show, have a lower chance of being categorized correctly by astatic analysis tool compared to a dynamic analysis tool. Thus by utilizing dynamicanalysis on this subset of programs only, my tool’s overall accuracy is higher thana strictly static IDS. In addition, because only the programs located in the verymalicious bucket are immediately blocked, my static-hybrid tool is able to operateat a much lower false positive rate than a comparably built static-only tool, as my

Results will show.In the process of building a static analysis-based malware detection tool, Ifound a few areas that despite the advancements in static analysis-based machinelearning malware detection techniques still needed work. The first is the effortrequired to generate features that are useful for machine learning. Feature gen-eration is vital in producing a highly accurate machine learning malware detectiontool. This in some ways limits machine learning’s capabilities to detect malware andgoodware. Manual feature generation is a time-consuming process that still requiresdomain expertise and analysis to build effective features. Additionally, new featuresmay have to be continually developed to deal with new malware. The second is-sue relates to the prominence of using features such as N-grams or other strictlypresence-absence features that can cause overfitting resulting in less generalizable

Results [2]. Malware detection has largely moved away from traditional hash-basedsignatures, but using features such as N-gram combinations of Windows APIs can8be seen as a similar variant to hash-based signatures. They are only more effectivebecause of the computing power of machine learning. More advances have to bemade in order to reduce the time and knowledge necessary to create quality featuresand help improve a malware detection tool’s ability to generalize and detect newmalware.To address the issues outlined above, I propose the use of static program disas-sembly and Convolutional Neural Networks (CNNs) in order to automatically gener-ate machine learning features that are effective at differentiating between goodwareand malware. I apply Natural Language Processing (NLP) methods to the staticdisassembly of both malware and goodware with the hypothesis that the opcode se-quences found in programs can be treated as sentences would be in natural languageprocessing. With the use of CNNs, I show that my tool is able to automatically gen-erate features that embed raw opcode sequences without any manual intervention,and improve the accuracy of a tool based on existing static analysis features.My work with CNNs and opcode sequences is distinct from related work be-cause it strategically balances human knowledge of a Windows PE32 executable,knowing that opcode sequences are fundamental to the function and behavior ofa program, with the power of automation of CNNs. The approaches found in thelimited previous work that has looked at CNNs for the purpose of malware detectionwere suboptimal in this regard. Work such as [3] chose to train their CNN model onthe first 2 million bytes of the input program as the input sequence, not taking intoregard any understanding of inherit program structure. Although they producedreasonable accuracies, their model took over 1 month to train whereas our model9took hours with similar accuracies. Other works such as [4] relied too heavily ondomain expertise on malware to produce an input sequence that proved to be useful,but required heavy manual analysis and development. My approach balances bothunderstanding of program structure while minimizing the need for domain expertise.The rest of the thesis is organized as follows. 



Section 2 covers the first partof my work into obfuscation detection. 



Section 3 covers the integration of machinelearning and the expansion of my obfuscation detection, which 

Results in a generalmalware detection tool. 



Section 4 focuses on improving the deficiencies of modernmalware defense architectures. 



Section 5 looks into my work related to automaticfeature generation based on opcode sequences.10



Chapter 2: Detecting Dynamic Obfuscation in Malware2.1 



IntroductionMalware writers have used a technique called obfuscation [5] to thwart ex-traction of such indicators of maliciousness (IOM) from malware and evade staticdetection [6]. Examples of obfuscation techniques are self-modifying code, and dy-namic code generation. Although dynamic analysis tools have detected most typesof obfuscation, obfuscation successfully thwarts static techniques such as [7] whenanalyzing malware. Obfuscated malware is a heavily studied subset within the fieldof malware [8]. The tools mentioned here [9–17] are capable of detecting and, insome cases, reversing obfuscation in malware. However, such tools are largely foren-sic tools and cannot be used for automatically distinguishing malware from benignprograms because their schemes would detect obfuscation in both.In this 



Section, I study obfuscations present in programs with a goal of auto-matically distinguishing malware and benign programs. First, I present my studyof the presence of six different obfuscation types in 6,192 benign applications. Thisstudy is the first that looks at which obfuscations (or code patterns that appear in-distinguishable from obfuscation) are present in benign programs. Next, obfuscationis classified in two ways – allowed obfuscations (present in benign applications) vs.11disallowed obfuscations (usually only in malware). Through the study, I find thatthree of the six obfuscations I analyze are regularly present in benign applications.For these three, I create a set of discriminating features that reduce false positives.The remaining three obfuscation types are found to be largely restricted to mal-ware. With my set of six obfuscations with discriminating features, I produce amalware detection technique, which is able to detect malware with high confidence.This includes the ability to detect previously missed malware using the presence ofdisallowed obfuscations as an IOM.I present DynODet, a dynamic obfuscation detection tool built as an Intel PinDLL [18] that detects binary-level obfuscations, and uses discriminating featuresto filter out benign application behaviors. When configured with discriminators,DynODet is not a general obfuscation detection tool and is not meant to genericallydetect obfuscation in all programs. Rather, DynODet is the first tool of its kindthat can detect advanced malware, and hence is meant to be used in addition toexisting detection tools. DynODet is meant for use in a sandbox [19], such asthose in widely used sandbox based malware detectors. Enhancing the sandboxwith DynODet increases malware detection without significantly increasing falsepositives. I present the following contributions:• A unique study into the prevalence of obfuscations in benign applications• Methods, implemented in my tool DynODet, to classify obfuscation types intotwo types - allowed obfuscations that are prevalent in benign programs anddisallowed obfuscations that are present in malware• 

Results showing that 33% of malware in a set of 100,208 have at least one of12the six disallowed obfuscations DynODet detects• 

Results showing a false positive rate of below 2.5% in a test of 6,192 real worldbenign applications• 

Results showing a decrease of 24.5% in malware missed by five market-leadingAV tools by using DynODet’s disallowed obfuscationsThe 



Section is structured as follows: 



Section 2.2 discusses the theoretical ideabehind detecting obfuscation in malware. 



Sections 2.3 through 2.8 give an in-depthexplanation of each of the six obfuscation types, including related work. 



Section 2.9discusses DynODet’s capabilities. 



Section 2.10 discusses current findings.2.2 Detecting Dynamic ObfuscationObfuscation is defined as the deliberate attempt of programs to mislead a staticanalysis tool. Obfuscation works by thwarting or misleading static disassembly thatis used in static analysis tools to understand the instruction-level structure of theprogram. Obfuscation has become a widespread tool in malware given its ability todefeat static analysis [6]. DynODet leverages the strength of dynamic analysis inorder to improve static analysis efforts against obfuscated programs.Although static analysis has been shown to be ineffective against obfucsa-tion, it is still useful in determining a program’s expected path. Using just-in-timerecurisive-traversal disassembly is advantageous because it allows DynODet to pro-duce a limited expected path of the program prior to its execution. Then duringexecution, for some of the obfuscations, DynODet can compare the expected path to13the actual path to detect if any obfuscation is present. DynODet implements just-in-time disassembly at run-time, which is the process of performing disassemblyrecursively during execution. It uses this in order to disassemble portions of theprogram just before they are executed in groups of code called frontiers. A frontieris the set of instructions reachable from the current instruction using direct control-transfer instructions (CTIs) only1. Hence frontiers terminate at a set of indirectCTIs. Frontiers are disassembled when execution reaches the current instruction atits beginning. Because indirect branch targets cannot be always determined untiljust before the instruction executes, just-in-time disassembly stops at all indirectbranches. When an indirect branch target at the end of a frontier becomes knownbecause the execution reaches that point, DynODet then restarts recursive traversaldisassembly at its target.DynODet chose to detect the following six obfuscations because these wereamong the obfuscations studied in academic papers, as shown through the relatedwork 



Sections below, and were discovered through my program-analysis of malware.The six chosen obfuscations are not an exhaustive list, but do show the potential ofusing the presence of obfuscations as IOMs. Also, by detecting these obfuscations,DynODet limits the ability of malware to escape static analysis.1A CTI is called direct where the CTI’s target is a constant; otherwise it is called indirect.142.3 Self-Modification2.3.1 DefinitionSelf-modifying code is when a program overwrites existing instructions withnew instructions at run time. Self-modification defeats static analysis by producinginstructions at run time that were not present during static analysis.Figure 2.1: Example of Self-modificationMalware can implement this behavior by first changing the write permission ona region of existing code. Then the malware can overwrite the existing instructionswith new instructions as seen in the example in figure 2.1. The malware can thenre-execute the same region with the new instructions in place.2.3.2 Presence in Benign ApplicationsWhen detecting self-modification by comparing an initial snapshot of a pro-gram with a current one after some execution time, I found that self-modificationoccurs in benign applications, in part because of dynamic address relocation. Dy-namic address relocation is the process of updating a program with the runtimeaddresses for functions that exist in other DLLs or binary images. Static linkingdoes not cause self-modification. In order to perform this relocation, the operating15system loader overwrites instruction operands that are dependent on the addressesof other DLL functions because the addresses is unknown statically. By naivelyimplementing self-modification detection, this dynamic address relocation behaviorwould be flagged. DynODet uses the comparison of two snapshots of the program’scode from different points of execution as its overall detection scheme, but also incor-porates two discriminating features to distinguish malware from benign programs.2.3.3 Detection SchemeFirst, DynODet detects self-modification by comparing only the opcodes ofinstructions rather than the instructions along with their operands. I found that thedynamic linking process described above only modifies operands, whereas malwaremay modify both the operands and opcodes. Detecting only opcode modificationreduces the detection of self-modification in benign programs while still detectingit in malware. By not being able to change the opcodes, malware is limited in itsability to perform malicious actions.Second, DynODet does not flag a dynamic optimization found in a small per-centage of benign programs as malicious. The dynamic optimization allows pro-grams to overwrite the first instruction of a function with a JMP instruction. Atrun-time, a program may decide that it can reduce the runtime of the programby simply jumping to some other location every time this particular function iscalled [20]. A program can also overwrite a JMP instruction in order to enablea function to execute based on a runtime decision. Thus, DynODet allows a sin-16gle instruction per frontier of code to be replaced by a JMP instruction or have aJMP instruction replaced without it being considered malicious. DynODet’s goal isnot to generally detect self-modification, but to only distinguish self-modification inmalware vs. benign applications.DynODet does not detect self-modification in any dynamically allocated mem-ory outside of the program’s main image because it found this behavior in bothbenign applications and malware without a clear discriminating feature. Dur-ing the course of execution, a program in Windows can allocate memory withread/write/execute permissions, which allows a program to use the region as a codecache where it can write code, execute it, and repeat. Benign interpreter programswill do this as confirmed in 



Section 2.10.2.3.At first, it may seem like malware can simply mimic benign programs in or-der to evade detection. However, it has been shown in studies such as [21] thatstatic analysis of opcode sequences can be used to detect malware. Thus, malwarecan either only modify its instructions’ operands and be detected by their opcodesequences, or it can overwrite its instructions and be caught by DynODet.2.3.4 Related WorkPrevious work, as explained below, detecting self-modification has largely fo-cused on detecting it in a forensic setting, rather than using it as an IOM. Previousschemes would not be a viable detection tool because their methods of detectingself-modification would also detect it in benign applications.17PolyUnpack [22] detects self-modification by performing static analysis on aprogram, then comparing the dynamically executed instructions to those in thestatic disassembly. If they do not match, then PolyUnpack outputs the code. Mmm-Bop [23] is a dynamic binary instrumentation scheme that uses a code cache tohelp unpack a program and determine the original entry point. It detects self-modification by checking the write target of every write instruction to determine ifthe program wrote to a code cached instruction. However, both of these tools donot use the detection of self-modification as a method of catching malware, sincetheir goals were malware understanding, not malware detection.The following works [24–26] also detect self-modifying code, but do not proposetheir techniques as a method of detecting malware. [24, 26] in particular did notbuild their tools with the intention to use it on malware. [25] is a forensic tool andnot meant for live detection. Work from the University of Virginia [27] provides away, such as using a dynamically generated check-sum, to protect binaries againstself-modification to preserve software integrity, but do not use the presence of self-modification as an IOM.2.4 



Section Mislabel Obfuscation2.4.1 Definition



Section mislabel obfuscation is the process of dynamically changing the per-missions of a 



Section within the binary to execute a non-code region. By markingsome 



Sections of its binary as a non-code 



Section, a static analyzer may not analyze18it for instructions, thus missing potentially malicious code.Figure 2.2: Example of Permission ChangeAs an example of 



Section mislabel obfuscation, figure 2.2 shows a malwarethat first changes the permissions on a data 



Section to executable, then it executesfrom the data region. This type of obfuscation allows malware to avoid staticallymarking 



Sections of code in their binary, which can help evade static detection. Italso allows the malware to possibly make changes to the non-code regions prior tochanging the permissions on the 



Section to further its obfuscation.Self-modification, explained in 



Section 2.3, can include the changing of permis-sions on a memory region. However, 



Section mislabel obfuscation is distinct becauseit tracks when a malware intentionally mislabels a 



Section or 



Sections of a binaryas a non-code region, only to later modify the permissions to execute the 



Section.Self-modification, per my definition, only occurs in code 



Sections.192.4.2 Presence in Benign ApplicationsFrom my study of benign applications, 



Section mislabel obfuscation does notoccur in most benign programs. This is most likely due to the use of standardcompilers when compiling benign applications. Thus, DynODet does not employ adiscriminating feature for this obfuscation.2.4.3 Detection schemeDynODet detects 



Section mislabel obfuscation by using Pin’s API to deter-mine a program’s 



Sections when first loaded into memory. Each binary has several



Sections such as code, and data. DynODet stores which address ranges are markedas code regions and which are not. It then monitors the execution of the programand if the PC lies within a non-code region then 



Section mislabel obfuscation hasoccurred. DynODet does not detect the actual request of the program to change thepermissions on its 



Section, but is still able to determine if such an event did occurby watching the execution of the program.Because DynODet does not employ a specific discriminating feature in orderto detect this obfuscation, there is no way for malware to hide this obfuscation.2.4.4 Related WorkI am not aware of any tool that explicitly detects 



Section mislabel obfuscationin the manner that DynODet does, but there are existing schemes that try to preventthe execution of non-code 



Sections.20Windows and other OSs have implemented a protection called data executionprevention (DEP) [28]. DEP prevents programs from executing code from non-executable memory regions such as data 



Sections. Although it seems DEP employsa similar goal to my method, the goals are not identical – DEP is primarily meant toprevent hijacking of control of critical Windows system files using data execution, forexample in a stack smashing attack. DynODet aims to detect malware payload files.Consequent to its goals, most DEP implementations do not prevent adding executepermissions to segments. DynODet will detect such permission changes. Anotherdrawback of DEP with regard to DynODet’s goals is that with DEP, if a pieceof malware on an end point performs some malicious actions prior to attemptingto execute data, then those prior will be allowed. In contrast, DynODet is meantto be an integral part of a sandbox mechanism, which means detection of 



Sectionmislabeling will imply that the malware will be prevented from reaching the endpoint in its entirety.2.5 Dynamically Generated Code2.5.1 DefinitionDynamically generated code is the process of creating code in a dynamicallyallocated memory region. Malware dynamically generates code because it wantsto hides its malicious instructions from static analysis. As in figure 2.3, malwarecan first allocate a new region of memory with read/write/execute permissions.It can then copy over instructions to the new memory region and then execute21Figure 2.3: Example of Dynamically Generated Codeit. To add a level of obfuscation, malware could also decrypt a data 



Section thatholds malicious instructions prior to copying over the instructions. Static analysisis defeated here because it cannot reliably decrypt the data 



Section to reveal theinstructions in addition to its inability to know with high confidence that the data



Section is encrypted.Dynamically generated code differs from self-modification because dynamicallygenerated code is the action of allocating new memory, copying code to it, then exe-cuting that region. Self-modification refers to overwriting existing instructions (i.e.instructions that have already executed) with new instructions and then executingthe new instructions.2.5.2 Presence in Benign ApplicationsIn my experiments, I found that benign applications also dynamically generatecode for a variety of reasons. For example, I found that some benign programs gen-erate jump tables that can only be built after the linking of other DLLs at runtimebecause the addresses of DLL functions are not known statically. Benign appli-cations may also copy a function to a new region of memory to create a wrapper22function. In the cases where a benign program dynamically generates code, I foundthat the code that is copied to new memory is in an existing code 



Section of the bi-nary image loaded at run time. This is because the dynamically generated code thatis copied to new memory is often generated by a compiler, which naturally placescode in a code 



Section. Understanding that dynamically generated code occurs inbenign applications, discriminating features are needed in order to eliminate falsepositives.2.5.3 Detection SchemeDynODet detects dynamically generated code in a three-step manner. Firstit hooks into Windows systems calls that are related to the allocation and changingof permissions of memory. DynODet begins to track any region that is marked asexecutable and is not a part of any loaded binary image. Second, it instrumentsany write instructions to tracked memory regions from the program so that rightbefore it executes, DynODet can determine if such a memory region is written to.If such a write occurs, DynODet checks to see if the source address of the writeinstruction is from one of the program’s non-code regions. If so, DynODet watchesfor the newly copied code to execute at which point DynODet detects dynamicallygenerated code.With DynODet’s unique method of detecting dynamically generated code,malware cannot simply try to mimic the behavior of benign applications in order toevade detection. If the malware tried to specifically evade DynODet’s detection, it23would only be allowed to copy code into the newly allocated region of memory fromstatically-declared code 



Sections. If the code is copied from a code 



Section, thenthe code is discoverable statically and thus defeats the purpose of dynamic codegeneration. In regards to self-modification in external memory regions, if the codethat is replacing existing code is from a data 



Section inside of the main image of thebinary, then DynODet will detect it. If the code is from a code 



Section, then staticanalysis can discover it.Just-in-time (JIT) compilation and interpretation of code are two types ofprograms that are closely tied to dynamically generated code. JIT compilationand interpretation of code are present in platforms that take an input of data orbytecode and translate it into machine code. Unfortunately, interpretation of codeis a powerful tool that malware can misuse. For example, malware can use toolssuch as Themida and VMProtect to obfuscate attacks [16]. Further research isneeded to mitigate this risk. The current implementation of my detection scheme fordynamically generated code with discriminating features does not flag interpretationor JIT compilation as malicious. However, one potential solution to this problem isto whitelist benign interpreter and JIT-platform programs, which is feasible giventheir small number and well-known nature- this has the added benefit of preventingthe malicious use of interepreters unknown to the user.242.5.4 Related WorkAs noted above, detecting and tracking dynamically generated code is a solvedproblem. However, none of the following tools are able to use their detection ofdynamically generated code to catch malware.OllyBonE [15], a plug-in to OllyDbg [29] is a kernel driver which reports whenpages are written to then executed. However, OllyBonE was only tested on commonpacker code and not on benign applications. OmniUnpack [30] is a similar tool thattracks memory page writes and then analyzes the contents when a dangerous systemcall is made. When such a call is made another malware analysis tool is invoked toanalyze the written pages. ReconBin [31] also analyzes dynamically generated code.Renovo [32] attempts to extract hidden code from packed executables by watchingall memory writes, and determining if any instructions executed are generated. Itdoes not check the source of the writes and was not tested on benign applications.None of these tools use the presence of dynamically generated code as an IOM,since, lacking my discriminant, they would have found such code in several benignapplications as well. These tools are also limited in their malware analysis only todynamically generated code.252.6 Unconditional To Conditional Branch Obfuscation2.6.1 DefinitionUnconditional to conditional branch obfuscation is the process of converting anunconditional branch to a conditional branch by the use of an opaque predicate [33].An opaque predicate is an expression that always evaluates to true or false andthus can be used in a conditional branch to always transfer control one way. Thisobfuscation can be used to thwart static analysis by adding more control-paths thatstatic analysis has to analyze.Figure 2.4: Example of Unconditional to Conditional ObfuscationFor example, in figure 2.4, malware can take an unconditional branch andconvert into a conditional branch. The malware can set the R1 and R2 registerssuch that they are never equal thus always jumping to the target address of 0x10A.Now the malware can insert junk code or invalid opcodes at the always not-takendirection of the conditional branch in order to confuse the static disassembler.This type of obfuscation is generally defeated by any dynamic analysis tool bywatching the actual execution of the program, and seeing which paths were takenand never taken. However, merely having one outcome of a conditional branch neverexecute is not indicative of the presence of this obfuscation, since benign program26may have branches outcomes which never happen (for example error checks thatnever trigger in a particular run). In order to detect this obfuscation specifically,some additional analysis has to be done.2.6.2 Presence in Benign ApplicationsAlthough benign programs rarely use this obfuscation, having one side of abranch in a benign program never execute is common. Thus, I need a discriminatingfeature to distinguish this behavior in malware vs. benign applications.2.6.3 Detection SchemeTo distinguish malware from benign applications, DynODet uses the observa-tion that if malware uses this obfuscation, then the untaken path is likely not code,and can be detected as such by just-in-time disassembly. DynODet disassemblesboth the target and fall through address of each conditional branch until an indirectbranch is reached. If either control flow path contains an invalid instruction prior toreaching an indirect branch, this obfuscation is detected. DynODet stops inspectingthe control flow paths at indirect branches because the targets of indirect branchesare unknown statically.This is as far as DynODet is able to detect unconditional to conditional branchobfuscation because it is hard to determine whether code is doing useful work ornot. However, it does eliminate the malware’s ability to place junk code at eitherthe target or fallthrough address of a conditional branch, which can thwart some27static disassemblers.2.6.4 Related WorkDynODet is not aware of any work that explicitly detects this obfuscation. Inmost dynamic analysis tools, this obfuscation is partially detected as a by-product,but is not documented as being used to distinguish malware from benign programs.2.7 Exception-Based Obfuscation2.7.1 DefinitionException-based obfuscation is the process of registering an exception handlerwith the OS then causing an exception intentionally. Static analyzers fail to see thisbecause exceptions can occur in programs in ways that are not statically deducible.For example, a divide instruction, which usually take registers as operands, canhave the divisor equal to zero. It is very difficult for static analysis tools to reliablyconfirm that the divisor register will be set to zero.Figure 2.5: Example of Exception-based obfuscationAn example is shown in figure 2.5. The malware first registers an exceptionhandler that jumps to harmful code. Then, the malware causes an intentional28exception such as division by zero. In figure 2.5, R6 would be equal to zero. Theregistered exception handler will then execute and the program will jump to theharmful code. This instruction execution sequence would not have been predictedor analyzed by static analyzers due to the dynamic nature of exceptions.2.7.2 Presence in Benign ApplicationsException-based obfuscation has been studied in the past as the related work



Section below shows, but I am not aware of any work that uses this as an IOM formalware. Unsurprisingly, handled exceptions do occur inside of benign applications.Legitimate exception handlers may execute because of an invalid input from the useror bad input from a file. Because of this, simply classifying any exception handlerexecution as exception-based obfuscation is not a viable detection technique.2.7.3 Detection SchemeBenign applications do not intentionally cause exceptions, such as divide byzero, in their programs because these would cause a system error. Malware, however,to ensure that its malicious exception handler executes, will cause an intentionalexception. Using this, DynODet incorporates the following discriminating featuresto catch exception-based obfuscation in malware.DynODet detects exception-based obfuscation by monitoring exception han-dler registration followed by an exception occurring. During execution, DynODetmonitors two methods of registering an exception handler. One is the standard29Windows API SetUnhandledExceptionFilter. The other method is directly writingto the thread information block (TIB). In order to detect this method, DynODetwatches all writes to the TIB and detects any changes to the current exception han-dler. Once an exception handler is registered, DynODet instruments the beginningof it and is notified when it runs. Next, DynODet strengthens the probability ofdetecting a malicious exception by catching an unexpected control flow exception.DynODet defines an unexpected control flow exception as when the control-flow ofthe program does not follow the expected path. In order to detect an unexpectedcontrol flow exception, DynODet instruments every Pin basic block and keeps trackof the first and last instruction addresses. Prior to the dynamic execution of eachbasic block, DynODet checks if the entire prior basic block executed. A basic blockis a sequence of instructions that should execute from top to the bottom, unlessan exception occurred. If DynODet determines that a previous basic block did notexecute in its entirety, it turns an internal flag on. If the next basic block executed isin a registered exception handler and the internal flag is on, exception-based obfus-cation has occurred. The internal flag is used because DynODet is only concernedwith exceptions that occur within the application because malware, when employingthis obfuscation, triggers the exception in its code to ensure that the exception willoccur.This type of obfuscation is rare, as will be seen in the 

Results below. The pointof this obfuscation is to hide a malware’s true path of execution from a static anal-ysis tool. If malware chose to implement exception-based obfuscation in a mannerthat deliberately evades DynODet’s detection scheme, such as by using an explicit30interrupt instruction, the interrupt could be discovered through static analysis, thusmaking the obfuscation less useful. DynODet’s detection scheme allows it to broadlydetect most exception-based obfuscation 



Scenarios such as divide by zero or writesto address zero.2.7.4 Related WorkThere have been a few works that looked at how exception-based obfuscationmay be present in malware, but none have created a general solution and used it asan IOM. Prakash [34] introduced an x86 emulator that attempts to detect exception-based obfuscation in attempts to generically unpack malware. The emulator onlydetects common exception-based obfuscations, such as using the x86 interrupt in-struction or a divide by zero, to ensure that the emulator continues running. It doesnot use exception-based obfuscation as a detection mechanism and did not studyit in benign programs. Work from the University of Arizona [35] proposes usingexception handlers as a method of obfuscation, but does not propose or deliver amechanism of detecting it.2.8 Overlapping Code Sequences2.8.1 DefinitionOverlapping code sequences occur when jumping into the middle of an ex-isting instruction. This method allows malware to hide instructions within otherinstructions, which can trick static disassemblers. In the complex instruction set31computing (CISC) x86 architecture, instructions have variable length so the samerange of addresses can have several different instruction sequences.Figure 2.6: Example of Overlapping Code SequencesAs shown in figure 2.6, to implement this behavior, a malware can use aninstruction with an immediate value that is an encoding of an instruction. A staticdisassembler will not be able to see the hidden instruction because it is not located ata natural instruction address and could miss malicious behavior. A push instructionis represented in the immediate value of a MOV instruction as a proof-of-concept infigure 2.6.2.8.2 Presence in Benign ApplicationsDuring benign testing, DynODet found a very small number of benign pro-grams with this behavior. To the best of my knowledge, there are no high-levelconstruct that would produce this behavior when compiled by a standard compiler.Thus, no discriminating feature is needed to use this as an IOM.2.8.3 Detection SchemeDuring disassembly, DynODet checks if the current PC is in the middle of anexisting instruction in the disassembly map produced by recursive traversal. If it32is, DynODet checks if all bytes of the current instruction match the original code.If they do not match, self-modification has occurred. If they do, overlapping codesequences are present.2.8.4 Related WorkWork at the University of Louisiana at Lafayette [36] implements segmentationto produce a collection of potentially overlapping segments, where each segment de-fines a unique sequence of instructions. Their tool attempts to uncover all potentialsequences of instructions. Their tool does not provide much insight into which se-quence of instructions actually ran, and provides superfluous instructions that maynever be executed dynamically. Their scheme also does not try to detect overlappingcode sequences as an IOM.2.9 DynODet Capabilities and 

Limitations2.9.1 Capabilities2.9.1.1 Multithreaded Applications: DynODet can handle multithreaded applications so long as the underlyingdynamic binary instrumentation (DBI) tool it uses (such as Pin) handles multi-threading. Pin assigns each created thread a thread ID that is used to distinguishwhich thread is executing and being instrumented. DynODet analyzes each thread’sdynamic execution separately, and combines all detections found in all threads.332.9.1.2 Spawned Child Processes: DynODet is able to handle programs that spawn other processes. This is acommon behavior for many programs so DynODet is injected by Pin into each childprocess and each process gets its own unique analysis, but ultimately gets groupedinto the parent process’s analysis.2.9.2 

Limitations and 



AssumptionsMalware detection is a constant arms race between the malware writers andcybersecurity companies. As with any new scheme, malware can specifically targetto defeat my scheme and bypass my detections. However, my detection schemes domake it considerably more difficult for malware to bypass both conventional staticdetection and my tool’s detections. I address these 

Limitations at the end of this



Section.2.10 

Results2.10.1 Test Set upMy tool is currently built as an Intel Pin [18] dynamically linked library (DLL).Pin is a DBI tool that provides all of the necessary capabilities described above. Al-though the current implementation of DynODet is tied to Pin, my detection mech-anisms are universal and can be implemented using other dynamic binary rewriters.As a Pin DLL, DynODet gets injected into the program being monitored in a sand-34box environment. After the program is finished running or killed by my timeout,the 

Results are collected and sent back to the host computer.The Cuckoo Sandbox [37] is a popular malware analysis environment that pro-vides an infrastructure for dynamic malware testing. I perform all of my malwaretesting in duplicated Cuckoo sandboxes, one sandbox per malware, which are re-verted to a clean environment prior to each execution. I give my Cuckoo Sandboxprocess 32 KVM [38] instances, which are running Windows 7 with 1GB of RAMeach. I also set up INetSim [39] in order to give the KVM machines a fake Internetconnection to trick malware into thinking it has access to Internet. INetSim is usedhere to get better code coverage in malware. DynODet has an internal timeout ofone minute per malware.2.10.2 Benign ApplicationsI performed benign application testing for 6,192 Windows programs. In orderto ensure that my testing was comprehensive, I tested two sets of benign programs.First were 119 programs that had to be installed prior to executing (referred to asthe installed benign set). Second was a set of 6,073 benign programs from a listproduced by the National Institute of Standards and Technology (NIST) [40].For the installed benign set, some of the installed programs tested were AdobeAcrobat, Mozilla Firefox, QuickTime Player, Notepad++, Google Chrome, WinScp,Open Office, 7zip, and Java Virtual Machine (JVM). The other installed programswere a mix of media players, music players, text editors, IDEs, mail clients, digital35recorders, and standard system tools. When testing these installed benign applica-tions, there was no easy method of interaction automation because these programsrequire a complex level of input. A generic interaction script cannot be created to ro-bustly test all of the benign applications. In my best attempt, I modified human.py,Cuckoo’s python script that is responsible for simulating human interaction, to clickin a grid pattern, left to right, top to bottom, in fixed intervals across the window ofthe benign application in order to click as many buttons as possible. Human.py alsoinput random text in order to give input into text fields of applications. Althoughthis was a simple method of interaction, the purpose of this was to increase codecoverage in each application.For the second part of my dataset, I obtained a list of Windows executablesfrom the National Software Reference Library (NSRL) produced by NIST. TheNSRL set contains millions of hashes of benign software. From the initial list, Iextracted the unique hashes of Windows 7 compatible executables and queried VirusTotal in order to download the binaries. This resulted in 6,073 benign applicationsthat I was able to test. The NSRL Set is largely considered to be a set of knownbenign software as noted in [41, 42]. However, there is a small subset of knownhacker tools and other unknown software that are considered to be malicious [43].For testing purposes, I removed these programs to ensure that my benign datasetwas truly benign in order to evaluate my tool properly. Ground truth is important,thus I felt that the preceding precautions were justified. Additionally, due to thesheer number of samples, it was not feasible to test and install each by hand. Theability to thoroughly test benign applications that arrive as standalone executables36is outside of the scope of DynODet.2.10.2.1 NSRL SetThe 

Results for the 6,073 programs from the NSRL set are listed below in table2.1. In table 2.1, the second column shows the obfuscation types that were detectedin benign applications when no discriminating features were implemented. Withoutdiscriminating features, 8.35% of benign programs tested contain at least one type ofobfuscation. The third column shows the obfuscations present with discriminatingfeatures. With discriminating features, the false positive rate is reduced by nearly70% for programs with one or more obfuscations to 2.45% and 75% for programswith two or more obfuscations to .13%. As with any detection tool, the false positiverate is important and using these obfuscation types without discriminating featuresas IOM of malware is not viable.The 149 programs falsely flagged, from manual inspection, seem to have nosingle attribute that explain their false detection. Using PeID, a popular packeridentifier, I was able to determine that 58 of the 149 programs were packed witha variety of packers and compressors. My conjecture is that these programs arevery uncommon and do not follow standard compilation tools as supported by mytesting 

Results. These programs, rather than intentionally implementing unallowedobfuscations, are most likely flagged due to some extreme corner cases that mycurrent implementation does not allow.The subset of programs tested from the NSRL set were obtained from Virus37Total. This leads me to believe that the programs tested in this dataset are morerepresentative of the types of executables that would be tested in an intrusion de-tection system. Thus, the 

Results here show the versatility of DynODet in that itcan work for both large, installed programs as well as standalone executables suchas those arriving at a network’s firewall.2.10.2.2 Standard Installed ApplicationsThe 

Results for 117 out of the 119 applications are also listed in table 2.1. Only117 were tested here because two of the programs, JVM and Python interpreter,cannot be run without input. These are tested and explained in the next sub-



Section.Out of the 117 benign applications tested, only one program had a false positivein any of my obfuscation detectors, namely a 



Section mislabel obfuscation. Theprogram with the false positive was a graphical viewer called i view.exe. This falsepositive is caused by Pin’s inability to detect a code region along with the program’spossible use of a non-standard compiler that may have produced an irregular header.As shown in Table 2.1, none of the indicators outside of the one explained above,were detected in 117 benign applications. This shows that the modifications thatwere made in DynODet reduce false positives for three of the indicators to nearly0%.382.10.2.3 Interpreters and JIT-platform ProgramsI also studied interpreter programs, which are programs take in data containingexecutable code. For example, Adobe Acrobat Reader (AR) takes in a PDF as input,which can contain executable code. DynODet’s goal is not to detect malicious PDFs.Rather, I aimed to find out whether DynODet detects behaviors such as dynamicallygenerated code in the interpreter program.Each interpreter program was tested with a small set of inputs. AR was testedwith 12 PDFs that included scripts, such as a template form. The Python interpreter(PyInt) was tested with a set of nine python scripts that performed small tasks suchas analyzing a directory for mp3s or printing the date and time. Firefox was testedwith eight websites running javascript such as www.cnn.com, www.youtube.com, andwww.amazon.com. JVM was tested with 11 benchmarks out of Decapo Benchmarks,a Java open-source benchmark suite [44].As table 2.2 shows, when my tool did not use discriminating features, it de-tected dynamically generated code in AR, Firefox and JVM. With my discriminatingfeatures incorporated, there were no detections. This proves that my discriminatingfeatures are valuable in not detecting obfuscation in benign applications.As noted in 



Section 2.3.2, I did not test for self-modification in dynamicallyallocated memory. I found that Firefox and JVM allocate memory outside of theirmain images to use as a code cache when executing chunks of interpreted code. Asmentioned in 



Section 2.5.3, there are other methods of detecting malicious interpreterand JIT-platform programs.392.10.3 MalwareThe malware samples were collected by my group from Virus Total, a databaseof malware maintained by Google. I tested in total of 100,208 malware selectedrandomly from 2011 to 2016. The malware test set used is a comprehensive setincluding viruses, backdoors, trojans, adware, infostealers, ransomware, spyware,downloaders, and bots. It is worth noting that Virus Total does contain somebenign applications as well; hence I only tested samples that had at least threedetections in their corresponding Virus Total report to filter out false positives.As seen in Table 2.3, DynODet found examples of each obfuscation in malware.The table shows the number of detections in the 100,208 malware tested whendiscriminating features are used. With discriminating features enabled, 32.7% ofmalware are detected. DynODet here is not claiming that the 

Results below show thetrue number of malware that have these characteristics. Rather, DynODet is showingthe number of malware that can be detected despite having made modifications tosome of the dynamic obfuscation detection schemes.Although some of the detections such as overlapping code sequences andexception-based obfuscation were not that common in malware, it is still usefulto include them as malware detectors for two reasons. The first is that these arerarely found in benign programs so adding to the list of distinguishable character-istics between malware and benign applications will always be useful. Second, anadvantage of DynODet is that it uses all of these detections in combination in orderto catch malware. Thus, although the detections of individual obfuscations may be40small, when combined, they can be substantial.As seen in Table 2.3, DynODet found that 32.74% of malware tested had atleast one disallowed obfuscation. When compared to benign programs, in which lessthan 2.5% had at least one indicator, there is a clear distinction between malwareand benign programs. This allows DynODet to be employed as a detection tool,rather than just an analysis tool. If a use case of DynODet could not tolerate anyfalse positives, then it can be altered to only classify programs with 2 obfuscationsas malware, which still 

Results in a 5.74% detection rate.Another indication of the capability and novelty of DynODet is shown in Table2.4. I analyzed the detections of the following five market-leading AV tools: Kasper-sky, ClamAV, McAfee, Symantec, and Microsoft Security Essentials and gatheredthe subset of malware that were not detected by any of the tools. The set resulted in12,833 malware. I was able to show that DynODet is able to detect 4,445 (34.63%)without discriminating features and 3,141 (24.48%) with discriminating features outof the previously missed malware. This also shows the efficacy in using obfuscationdetection in order to detect malware that was previously hard to catch. The detec-tion rate of each tool listed below was obtained through Virus Total’s reports foreach malware.2.10.4 

Limitations with EvasionAs with any detection scheme, there are ways for malware to evade my toolspecifically. I have listed below possible evasion techniques for three of the obfusca-41tions detected in DynODet.• 



Section mislabel obfuscation: In order to evade 



Section mislabel detection,malware can mark all 



Sections in their program executable so that regardless ofwhich 



Section it executes from, it will not be caught by my detection. However,this becomes problematic for the malware for two reasons. First, from myanalysis of benign programs, I found that almost no program had all executable



Sections. If malware, in order to evade my detection scheme, started to markall 



Sections executable, this would be an easy sign for analysis tools to pickup on. Second, if malware marks all 



Sections as code, every analysis tool willanalyze all of its 



Sections expecting code. This leads to two 



Scenarios. Eitherthe malware’s malicious code will be revealed, or in attempts to hide its code,the malware’s code 



Sections will have high entropy due to encryption or novalid code at all, which is suspicious and will also be caught by detectionschemes.• Exception-based obfuscation: My tool currently detects all hardware excep-tions that lead to the execution of a registered exception handler as a poten-tially malicious indicator. Although hardware exceptions can occur in benignprograms, through my study, I found that the frequency of occurrences in be-nign programs differ from those in malware. As supported by my data, thisoccurs about three times more often in malware than in benign applications.Although this is not a great indicator, I conjecture that it might be useful ina machine-learning framework as one feature among many used to weigh thelikelihood of a program being malicious.42• Unconditional to conditional obfuscation: Malware can evade this detection byputting legitimate code at every conditional branch in the program. As men-tioned in 



Section 2.6.3, DynODet is unable to prevent this evasion. However,it does constrain the malware writer’s flexibility in placing data in the code



Section, since not all data values also represent valid instructions. Moreover,it increases the work of the malware writer.2.11 

Conclusion and 



Future WorkDynODet has exemplified that there is a way to use dynamic program-levelanalysis a method of detecting and differentiating benign and malicious obfuscations.DynODet also showed that dynamic program-level analysis can be key in detectingpreviously unseen malware, as shown by the 25% detection rate of unknown malware.However, DynODet has two major 

Limitations. First, the discriminating fea-tures used were determined through manual analysis of benign programs and mal-ware. This is not a scalable or robust method of differentiating obfuscations inmalware and benign programs. Furthermore, using the presence of a single disal-lowed obfuscation as an indicator of malware is not realistic. Second, DynODetcould only detect disallowed obfuscations in 33% of malware. Although DynODetis not a standalone tool, it still does not detect a large number of malware, makingit less useful in the real world. To address these shortcomings, the next 



Section ofmy proposal addresses how to integrate machine learning and expanding the featureset to build a highly accurate, robust detection tool.43Detection W/O discriminating fea-turesW/ discriminating featuresNSRL Installed NSRL InstalledSelf-modification135 5 2 0



Section Misla-bel51 1 51 1DynamicallyGeneratedCode296 29 86 0Unconditionalto Conditional12 0 12 0Exception-based27 1 5 0OverlappingCode Sequences5 0 5 0Had 1 or moreobfuscations507/6,073(8.35%)34/117(29.05%)149/6,073(2.45%)1/117(.85%)Had 2 or moreobfuscations33/6,073(.54%)2/117(1.71%)8/6,073(.13%)0/117(0%)Table 2.1: Benign Application 

Results44Detection W/O discriminating fea-turesW/ discriminating featuresAR PyInt Firefox JVM AR PyInt Firefox JVMSelf-modification0/12 0/9 0/8 0/11 0/12 0/9 0/8 0/11



Section Mis-label0/12 0/9 0/8 0/11 0/12 0/9 0/8 0/11DynamicallyGeneratedCode12/12 0/9 8/8 11/11 0/12 0/9 0/8 0/11Unconditionalto Condi-tional0/12 0/9 0/8 0/11 0/12 0/9 0/8 0/11Exception-based0/12 0/9 0/8 0/11 0/12 0/9 0/8 0/11OverlappingCode Se-quences0/12 0/9 0/8 0/11 0/12 0/9 0/8 0/11Had 1 ormore obfus-cations12/12(100%)0/9(0%)8/8(100%)11/11(100%)0/12(0%)0/9(0%)0/8(0%)0/11(0%)Table 2.2: Benign Interpreter 

Results45Detection for 100,208 MalwareDetection W/ discriminating featuresSelf-modification 10,264 10.24%



Section Mislabel 19,051 19.01%Dynamically Generated Code 7,106 7.09%Unconditional to Conditional 7,889 7.87%Exception-based 334 0.33%Overlapping Code Sequences 1,710 1.71%Had 1 or more obfuscations 32,811 32.74%Had 2 or more obfuscations 5,750 5.74%Table 2.3: Obfuscation in Malware 

ResultsDetection of 12,833 Missed MalwareW/O discriminating features W/ discriminating features4,445 34.64% 3,141 24.48%Table 2.4: Malware Detection Improvement46



Chapter 3: Enhancing Dynamic Analysis-based Malware Detectionwith Dynamic Program-level Features3.1 



IntroductionAs I look to build upon DynODet and expand my work, I looked at howdynamic analysis and detection is done today in order to improve upon the statusquo.There are two primary methods of malware detection. The first is sandbox-based detection, also known as dynamic analysis. Sandbox-based analysis aims toreveal malicious behavior by executing a program within a protected environment.Sandbox-based analysis is effective because some malware are packed or obfuscatedin some way that make static analysis harder to reliably perform. Static analysisis the process of analyzing a program without execution and has been shown to bedefeated by packing or obfuscation [6]. Dynamic analysis executes the program andcan monitor its actual behavior, but is computationally intensive and slow (operateson the order of minutes). Both analysis types have their strengths and weaknessesand I make no claim as to which is better. Rather they are used for different purposes– static analysis is usually used for large-scale rapid detection of malware, whereas47dynamic analysis is typically used for in-depth examination of malware. My goal isto improve dynamic malware analysis by offering a new set of features that aid thedetection of malware.Dynamic analysis is valuable in today’s modern defenses against malware be-cause it can provide information about malware behaviors that are complementaryto static analysis. Dynamic analysis is used widely for producing sandbox reports,which detail actions executed by the program at run-time. Dynamic analysis uses theactions executed by the program, observed typically at an Operating System (OS)-level such as system calls, to build behavioral Indicators of Compromise (IOCs).These reports can be used by human analysts to understand what the malware isdoing.Although the current advances in dynamic analysis are helpful in moderndefenses, there are still two problems that the current dynamic technologies fail toaddress. First, dynamic analysis is usually only run once per sample, which meansdynamic analysis is based on the behaviors of a single execution path, which isoften an underapproximation of a sample’s total possible behaviors. This problem isexacerbated because current dynamic technologies that detect malware only focus ondetecting how a program interacts with the OS as a method of monitoring behavior.This means they detect OS-level behavior, such as system calls or Windows librarycalls made by a program during its execution, and derive their IOCs based on thesequence of OS calls seen at run-time. I call these external behaviors. These externalbehaviors dismiss internal behavior, behavior that occurs in the program withoutthe interacting with the OS, which I prove is valuable in enhancing a tool’s ability48to reliably and robustly detect malware. Additionally, existing tools solely rely onOS calls or sequences of OS calls to determine malicious behavior. Existing dynamicanalysis is adversely affected when these specific malicious sequences of OS calls arenot present in the single instance of behavior analysis. Second, dynamic analysis hasbeen heralded to defeat obfuscation and packing because executing the program canreveal the OS calls made by the program. However, current tools cannot actuallydetect the methods of obfuscation or unpacking. They simply bypass the malware’sdefenses to try to uncover the OS calls made by the program. They miss themethods of how the malware hid their code and thus sacrifice a potential way offurther differentiating malware from goodware.In order to increase existing dynamic malware detection tools’ abilities to de-tect malware and address some of its deficiencies outlined above, I propose utilizingdynamic program-level (DPL) information to complement OS-level detection. DPLanalysis is the study of a program’s internal behavior at an instruction-level duringexecution. DPL analysis is fundamentally different from OS-level analysis in that itfocuses on how the program is behaving within itself, rather than how it interactswith its environment. This leads to a class of behaviors that are orthogonal to OSbehavior and thus complementary to existing dynamic analysis. I show that DPLinformation, when added to dynamic OS-level analysis, has the ability to increasethe detection of malware and analyze a class of behaviors that OS-level analysiscannot.I have built a malware detection tool that utilizes machine learning with acomprehensive feature set including my novel DPL features. To prove that DPL49features are capable of improving existing dynamic analysis technologies, I detectedtwo classes of DPL information: potentially evasive and general program execution.I define DPL potentially evasive actions as any dynamic program-level behavior thata program, malicious or benign, uses to hide the true code that is executed. I detectthe following eight DPL potentially evasive classes of behavior: self-modification,dynamically-generated code, 



Section-related obfuscation, unconditional to conditionalbranch conversion, overlapping code sequences, hidden functions, dynamic importaddress tables (IATs), and call-return obfuscations. I also detect three classes ofgeneral DPL information, which I define to be features that, although collected atan instruction-level, can quantify a program’s dynamic execution characteristics.The three general DPL classes I detect are: function analysis, control flow analysis,and instruction execution.DPL features complement dynamic OS-level features in the following ways.First, it is gathered from monitoring the instruction sequences executed within theprogram. The use of DPL analysis gives access to wealth of information that has notbeen used in previous literature for the purpose of malware detection. I show andexplain in this 



Section how DPL information is orthogonal and distinct from OS-levelfeatures. Second, examining DPL information enhances dynamic analysis’s abilityto correctly detect malware when the monitoring of OS-level calls produces littleto no behavioral signatures. DPL features can be more fundamental to the natureof the program and my work shows that the information obtained, when combinedwith machine learning, can provably increase the detection rate of a OS-based tool.Some of the DPL features above are known to the security community as be-50ing more associated with malware than with benign programs. However my workis the first to identify a set of automatically detectable DPL features that can beused to improve dynamic malware detection. My contribution is unique for thefollowing two reasons. First, I prove that I can extract and quantify DPL-relatedmethods that malware uses to specifically hide code to avoid detection. The classof DPL potentially evasive behaviors I detect specifically targets methods in whichmalware tries to avoid existing analysis techniques. The alternative for malware tonot using these methods would be to be caught by other simpler detection tech-niques. Though my list of these behaviors is not exhaustive, it is substantial enoughto prove that these class of behaviors are quantifiable and useful for the purposeof malware detection. Second, I show that with my addition of general DPL infor-mation, irrespective of first classifying these DPL features as malicious or benign,that machine learning can learn the differences in the way malware versus goodwareexecute at an instruction level, leading to a higher accuracy rate.Additionally, my DPL features have a significant advantage over previousworks that used features sets such as strings to detect malware. Malware can al-ter their bytes or strings arbitrarily to match those of benign programs, which cancause a tool to generate a benign-looking feature set for a malware sample. Thisinevitably will cause it to be classified falsely as benign. My potentially evasive DPLfeatures are unique because they detect how malware tries to hide code. Statisti-cally speaking, my testing shows that benign programs perform potentially evasiveactions significantly less than malware. Thus, if malware tried to bypass my DPLfeature detection, they would lose the ability to hide its malicious code and could be51caught by other analysis tools. This is a significant upgrade in comparison to otherfeature sets because the alternative to avoiding my detection is to be caught moreeasily by other standard methods. My general DPL information features provideadditional value because they measure at an instruction-level how malware execute.In order to avoid detection from my general DPL information features, malwarewould have to start behaving at an instruction level like benign programs, whichsignificantly limits malware writers.My DPL analysis differs from other previous work for the following reasons.First, works such as [45, 46] focused on instruction-level analysis, but in a staticdeployment. Their technologies did not execute the program and thus could notobserve the types of behaviors my tool collects. Second, works such as [22, 25]have analyzed program-level behaviors dynamically, but only in a forensic setting.Some of my behaviors, better explained in 



Section 3.4.2, have been studied for thepurpose of better understanding malware behaviors. However, my contribution andnovelty stems from my insight that these behaviors that occur at a program-level canprovide a non-redundant set of information to improve existing dynamic malwaredetection tools. My work here shows a comprehensive evaluation of my feature setand shows that it is capable of reducing the percentage of malware missed by adynamic detection tool. Third, although it is well known that dynamic analysiscan defeat some obfuscations and packed malware, existing works such as [47] thatclaim to defeat these malware techniques to avoid static detection only use dynamicanalysis to bypass them. These works do not use the presence of these behaviors orcategorize them in any useful way for the purpose of malware detection.52I show in my 

Results the following findings. First, I show that adding my DPLfeature set to a dynamic OS-based machine learning malware detection tool reducesthe percentage of missed malware, also known as the false negative rate, by 39.45%.Second, I show that my DPL features when added to a dynamic OS-based malwaredetection tool detect more zero-day malware than the latter by itself. Third, I showthat in deployment 



Scenarios, where the testing set is obtained independently of thetraining set, my feature set improves a malware detection tool’s robustness. Last, Ishow that my DPL information is critical in improving the performance of an OS-based malware detection tool in cases where a malware’s execution produces littleto no OS behavioral signatures.I show the impact of the program-level features on my tool’s detection rate ona dataset of over 400,000 real-world programs, distributed roughly equally betweenmalware and goodware. I tested a neural network multi-layer perceptron (MLP)machine learning model and show that the model’s performance improvements whenthe DPL features are added. Overall, with my DPL features incorporated, mymalware detection system can correctly detect 98.45% of malware while maintaininga false positive rate of 1%. My contributions in this 



Section are as follows:• Prove the addition of DPL features reduces the false negative rate of OS-basedmalware detection tool by 39.45%.• Provide comprehensive analysis of my DPL features, showing that they areboth complementary and orthogonal to OS behavioral signatures.• Show that with DPL features, I can produce a malware detection tool thatcan correctly detect 98.45% of malware while falsely detecting only 1% of53goodware.• Produce a publicly shared dataset comprised of over 400,000 Windows executa-bles with 223,417 malware and 195,255 goodware that are unique accordingto their SHA256 hash.The rest of the 



Section is organized as follows. 



Section 3.2 gives a 

Backgroundinto malware detection using machine learning. 



Section 3.3 covers prior works’ fea-ture sets. 



Section 3.4 covers my feature set in detail. 



Section 3.5 covers my dataset,specific implementation, and tools used to build my system. 



Section 3.6 shows myfindings. 



Section 3.7 discusses this work’s 

Limitations and possible remedies.3.2 

Background of Machine Learning in Malware DetectionMachine learning is critical in a scalable malware detection tool. I believe thereare three core components needed. First, a large, diverse dataset must be used in de-veloping an accurate and reliable machine learning malware detection tool. Second,the detection tool must be able to handle all types of malware, including obfuscatedand packed malware. Third, a comprehensive, robust feature set including multiplesources of information must be used. My aim is to meet each of these requirementsto produce a highly accurate, robust detection tool.A machine learning-based malware detection tool is built in the following way.First, a labeled training set is obtained to train the classifier on what previouslyknown goodware and malware looks like. After the training phase, a testing phaseoccurs where new unlabeled data is sent to the machine learning classifier for it54to classify as benign or malicious. These predictions are compared against thetrue labels of the test set to measure accuracy. Typically, a classifier is measuredaccording to various metrics, the two most important ones being the false positiverate, and the true positive rate. In the malware detection field, a true positiveis when a malicious program is correctly classified as malicious. A false positive iswhen a benign programs is detected as malicious. The false positive rate is supremelyimportant because a majority of real-world network traffic is benign. Thus, my goalwill be to minimize the false positive rate, while maximizing the detection rate.3.3 Existing Works’ Feature SetsFeature selection is crucial to a machine learning algorithm’s efficacy in de-tecting malware. The features chosen quantify a sample into something a machinelearning algorithm can understand. Thus, choosing how to quantify a program, inmy case, into a set of features is vital in producing a good detection tool. The goalof a good feature set is to accurately quantify a program, ideally with features thatdiffer in value between malware and goodware.3.3.1 Static analysisPrior work has largely leaned on static analysis to detect malware. However,as [6] showed, static analysis has drawbacks that can be mitigated by dynamicanalysis. Neither static or dynamic analysis is a substitute for the other; ratherthey have different strengths and are used for different purposes. My goal is to55improve dynamic analysis given that it is also widely used in sandboxes to producedynamic reports on malware behavior. Below, I cover prior work that used staticprogram-level information to detect malware. However, my work is fundamentallydifferent from these because my work is focused on complementing existing dynamicmalware detection technologies by incorporating DPL information.These papers [21, 45–63] focused on using n-grams, opcodes, or strings indi-vidually or in some combination as a feature set for machine learning and malwaredetection. Although these features can be extracted from instruction or byte level,they do not quantify program behavior like my feature set. The dynamic informa-tion I collect from program-level features has no overlap with the features typicallyused by static tools to detect malware.My DPL features differ from any static analysis tool because my featuresare discovered through the actual execution of the program. Although some ofmy features explained below, such as self-modification, combine a version of staticanalysis with dynamic analysis to detect the behavior, my detection schemes cannot be replicated with static analysis alone. Runtime behavior is key in accuratelyand reliably detecting DPL behavior that aids the detection of malware.3.3.2 Dynamic AnalysisDynamic analysis of malware has been heavily studied in the past. However,I show below why existing dynamic analysis of malware has focused on goals ormethods that are distinct from ours.56These works [15, 30, 64–66] utilized dynamic OS-level behavioral analysis todetect malware. Dynamic OS-level behavioral detection focuses on monitoring theWindows Application Programming Interface (API) calls and system calls made bythe program during execution. This type of dynamic analysis solely focuses on aprogram’s external actions. Previous work has shown success in detecting malwarewith using this type of dynamic analysis because the external actions often signifysome action or request a program is making to possibly inflict harm. However, thisclass of dynamic analysis differs from my work because my DPL feature set focuseson internal actions and behaviors that an OS-level dynamic tool cannot detect ormonitor. I show in my 

Results that DPL information is indeed complementary anddistinct from OS-level information, which is ultimately proved in my feature set’sability to boost the performance of a malware detection tool.The following works [22,23,25,67] looked into dynamically analyzing malwareat a instruction-level, but only for malware understanding – not malware detection.Work like [25, 67] only studied obfuscations in malware such as self-modification ordynamically generated code. Other works such as [22, 23] used dynamic analysisto detect unpacking to uncover potentially malicious code to analyze further. Al-though these works focus on utilizing DPL analysis similar to ours, their goals areentirely different. First, their goal is to detect obfuscations or unpacking for thepurpose of understanding malware better. Theirs works did not study the presenceof obfuscations or unpacking in goodware, which limits their work to understandingmalware and not being a general malware detection tool. My DPL analysis, on theother hand, uses the presence of obfuscation or unpacking at a program-level to57differentiate malware from goodware.[68] is unique in that the authors focus on automatically synthesizing discrim-inative significant behaviors to detect malware. However, their tool still focuses onOS-level calls. Although their work proved to be useful in automatically generateddiscriminative dynamic OS behaviors, I believe that my work would still benefittheirs because my tool focuses on internal behaviors that are orthogonal to theirexternal behavior analysis.[69] generates behavioral models that represent families of malware. Thesemodels are generated by analyzing which dynamic OS calls are made as well as aninstruction-level dynamic taint analysis. Although their tool does incorporate somelevel of DPL information, my work is still distinct from theirs for the following rea-sons. First, their DPL analysis did not focus on detecting obfuscations in malwareas a method of detecting malware. Rather, they use DPL analysis to build a be-havioral graph, which was used to represent the malware. Second, the authors onlygenerate behavioral models for six distinct malware families. Their testing, whichinvolves less than 500 samples total, only proves that their method could work asa way to classify unknown programs as one of these 6 malware families with a 93%success rate. Thus, their method is unproven for benign behavioral models and it isunknown whether their tool would work as a general malware detection tool.The only work that has looked at DPL obfuscations as a method of detectingmalware is [70], where six obfuscations were detected in a 100K malware and 6Kgoodware. [70] had to manually determine discriminating features so that the ob-fuscations detected were not found in benign programs. Moreover they did not use58machine learning in their method, and used a series of ad-hoc heuristics. Their workshowed it is possible to use the presence of obfuscation as a method of detectingmalware, but only in a limited, non-scalable way.3.4 My Feature SetIn total, I have 1,168 unique features, of which 454 were the number of timeseach opcode found in my dataset executed dynamically. However, I found thattraining with all the opcode features in my machine learning algorithm took signif-icantly more time and decreased my overall accuracy slightly. Thus, I use PrincipleComponent Analysis (PCA) to reduce the opcode feature subset. This left 714 fea-tures collected plus the 250 components from the PCA of the opcode subset, whichI found to be an optimal choice. The general DPL information along with the dy-namic opcode counts are referred to as DPL statistical features. All of my featureswere either boolean features or value features. Boolean features had values of one, ifthe detection was present, or zero, if it was not. Value features were detections thatcould not be represented in a binary value such as the number of total instructionsthat were executed.3.4.1 Incorporation of Existing Features3.4.1.1 Static FeaturesI collect static information such as PE header information and 



Section-relatedinformation like 



Section entropy. These features are input into my feature set as59either boolean features or value features (those which take a range of float or integervalues). For features such as language, I use a boolean feature per language to showwhich language the program is in. For features such as entropy, I use the entropyvalue as my feature.The following sets of static information were incorporated in my static featureset as boolean features (present/absent): YARA rules, language, and packer type(using PEiD). The following sets of static information were incorporated in my staticfeature set as value features: number of static imports, static size of program, andnumber of 



Sections.3.4.1.2 Dynamic Features- OS FeaturesI collect OS-level dynamic information such as when a HTTP request is madeor a file is created. I utilize an OS-level tool to monitor the program’s interactionswith the OS, then use the calls made to generate dynamic behavioral signatures.These dynamic signatures are generated based on a single or series of OS-level actionsmade by the program. An example of an OS-level feature based on a single action is aHTTP request signature which is generated when a program makes a HTTP request.An example of an OS-level feature based on a series of actions is a API spammingsignature which is generated when a program repeatedly makes the same API call inorder to delay analysis. These signatures are used as binary features in my featureset. I do not manually assign any feature weights to my features. The complete OSfeature set can be found in the Cuckoo Sandbox Monitor Repository [37].603.4.2 Novel Dynamic Program-level Features: Potentially EvasiveThe novelty in my work comes from my use of DPL information for the pur-pose of malware detection. I collect two different sets of DPL features. First, Icollect DPL potentially evasive behavior (referenced as EV in 



Section 3.6) features.Second, I collect general DPL execution behavior (referenced as STAT in 



Section3.6) features. I collect DPL features using a dynamic binary instrumentation (DBI)tool. A DBI tool can monitor and collect information about each instruction in aprogram during its execution.The premise of using DPL features is that these features can help provide amore complete picture of a program’s execution and give a fine-grained look intothe program’s behavior. Specifically in the case of malware, traditional OS-leveldetections have relied on the presence of specific OS calls. However, OS calls alonetypically only capture malicious behaviors such as installing a keylogger. My poten-tially evasive DPL features focus on capturing how the program internally arrivedat executing its code. All of my potentially evasive DPL features focus on detectingwhen a program obfuscates or attempts to hide the code that is executed at run-timefrom static analysis methods.In the case of my DPL potentially evasive detections, I detect DPL behaviorthat I believe is more prevalent in malware than in goodware. After analysis ofmalware at a program-level, I can leverage the fact that malware actively attempts toavoid detection of static and OS-level tools. Goodware typically does not. My DPLpotentially evasive detection schemes focus on how malware tries to avoid triggering61static and OS-level tools’ alerts. Using this distinction, I are able to create a tool thatdetects a wide variety of potentially evasive DPL behaviors that are fundamentallydifferent in malware than in goodware. Some of these DPL behaviors can occur inboth malware and goodware, but it is my belief, as justified by my 

Results, thatthey occur more often in malware. Additionally, these DPL features cannot bedetected by existing OS-based dynamic tools. Thus, my DPL detections provide anorthogonal set of information that is more prevalent in malware than in goodware,ultimately increasing an OS-based dynamic malware detection tool’s accuracy.My tool detects self-modification, dynamically-generated code, 



Section-relatedobfuscation, unconditional to conditional branch conversion, overlapping code se-quences, hidden functions, dynamic IATs, and call-return obfuscations. In total, Idetect eight mechanisms that malware I studied uses to avoid detection from staticand OS-level tools. Below, I describe in detail how each of these obfuscations aredetected.3.4.2.1 Self-modificationDescription: Self-modification is the process in which a program modifies itsexisting code during its runtime and then executes the new code. Self-modificationoccurs dynamically, which means the code that replaces the existing code maynot be discoverable statically. Self-modification can occur through changing theread/write/execute permissions on a 



Section of code, to later overwrite and executeit. Malware often use self-modification to hide malicious segments of code from62analysis tools.Implementation: Self-modification detection is not novel, but the use ofits presence and its varying levels of implementation for the purpose of detectingmalware versus goodware is. I not only built my tool to generically detect self-modification (like most prior work), but to also detect the self-modification of op-codes, operands, and self-modification in dynamically generated code individually.I did this for two reasons. Previous work [70] showed that there are differences be-tween obfuscations that occur in malware and obfuscations that occur in goodware.By detecting self-modification in varying degrees, my analysis tool helps the machinelearning algorithm learn these patterns. Additionally, I found that the more datapoints I gave to machine learning to quantify programs, the better it performed.Thus, I leverage a DBI tool’s ability to obtain specific DPL behavior that otherwisecould not be obtained to enhance my DPL feature set.I detect self-modification as follows. I maintain a dynamic disassembly as theprogram executes. A dynamic disassembly, as I define it, is built by using recursivetraversal to build a limited static disassembly. Recursive traversal is a disassemblytechnique which starts at a target of an indirect Control Transfer Instruction (CTI),continues to the targets of direct CTIs and ends at a set of indirect CTIs. Thedisassembly process is continued when the target of the indirect branch is deter-mined (right before it executes). While monitoring the execution of the program,my tool checks to see if the current address matches a previously disassembled ad-dress. If the current address has been seen before, my tool compares the currentinstruction bytes to the previously disassembled bytes. If they do not match, my63tool logs which portion of the bytes do not match (opcodes, operands) and outputsthe corresponding boolean feature.Robustness: This detection is hard to evade if the malware tries to use self-modification. Since I detect the self-modification of both opcodes and operands, mycomprehensive analysis disallows self-modifying malware from going undetected. Mytool constantly analyzes the code executed at an instruction level, the only way toavoid detection would be to not self-modify.My detection implementation does detect some self-modification instances ingoodware tested. However, my testing shows the number of occurrences is signifi-cantly lower in goodware versus malware. Additionally, because my tool does not usethe sole presence of self-modification as an indication of malware, but rather relieson machine learning to use statistically significant trends, having a small number ofself-modification detections in goodware does not greatly diminish this detection’sefficacy.3.4.2.2 Dynamically generated codeDescription: I define dynamically generated code as the process of allocatingnew memory, writing code to that memory, and then executing that code. Malwarecan use dynamically generated code to create and run code at runtime that may notbe discoverable statically. My definition of dynamically generated code differs frommy self-modification detection because dynamically generated code occurs whennewly allocated memory is written to then executed. Self-modification occurs when64existing code in the program’s code image is overwritten then executed.Implementation: Although the detection of dynamically generated code isnot novel, the use of its presence as a method of detecting malware is somethingthat has not been studied outside of [70]. Similar to my self-modification detectionscheme, my tool detects varying ways dynamically generated code occurs in malwareI studied in practice.My detection scheme for dynamically generated code detects the followingas boolean features. The first feature is a boolean value detecting whether anydynamically generated code is executed. The second feature is whether virtualmemory is written to without the use of standard Windows API calls like memcpyand then is executed. This feature specifically targets malware that try to avoidusing standard Windows APIs to write to memory and instead use, for example,the x86 mov instruction to write to memory. The third feature is whether data iscopied from a data 



Section in the program to virtual memory then executed. Thisfeature targets malware that may hide its malicious code in its data 



Sections, whichcan be encrypted to harden its defenses against static analysis tools. Only duringits execution is the malicious code unpacked and executed. The last feature is usedto signify code cache behavior. Code cache behavior is when a program repeatedlywrites and executes code in allocated memory. This is another way malware canunpack itself or hide its code from being statically discoverable.Robustness: Because these detections occur at the program-level, malwarehas a significantly harder time evading these detections. Malware can choose notto dynamically generate code, but then loses one major method of evading static65detection and creating code at run-time. Previous OS-level approaches can onlymonitor memory writes that occur if the program uses a Windows API call orOS call. However, programs can directly write to memory locations using a movassembly instruction. My DPL tool has the capability to detect these memory writesensuring accurate and reliable detection.Goodware can also dynamically generate code for benign reasons. My anal-ysis shows that varying degrees of dynamically generated code did occur in bothgoodware and malware. However, the prevalence in malware was much higher thanin goodware, especially for the last three features described in the previous 



Section.3.4.2.3 



Section-related obfuscationDescription: 



Section-related obfuscation involves misusing 



Section labels orpermissions in order to hide code or confuse disassemblers. Malware can initiallymark 



Sections of its program as read/write to make it look like data. However, itcan later change the permissions of specific address regions within that data 



Sectionto read/execute so that it can execute code. This obfuscation allows malware tohide code in 



Sections initially marked non-executable, which may not be analyzedby static analysis tools.Implementation: My tool detects the following 



Section-related obfuscationfeatures. The first boolean feature 

Notes whether any of the 



Sections have read,write, and execute permissions. This set of permissions allows programs to writeand execute arbitrary code within its 



Sections. This can be used for malware to self-66modify and dynamically generate code. My tool uses DynamoRio’s internal APIto determine the permissions of each 



Section in the program when it is loaded intomemory. The second boolean feature is output true if an instruction executes froma 



Section of the program that was initially marked as non-executable. When theprogram is loaded into memory, my tool saves the address ranges of each 



Section ofthe program to later determine if an instruction is executing from a non-executablesub



Section.Robustness: My constant instruction-level analysis makes it nearly impossi-ble for malware to use this obfuscation without being detected because my tool isable to track all executed instructions. My tool does not detect the changing of per-missions explicitly, but can guarantee that if malware tries to execute an instructionfrom a region initially marked as non-executable, it will be detected.3.4.2.4 Unconditional to conditional branch conversionDescription: Unconditional to conditional branch conversion occurs whena program converts an unconditional branch to a conditional branch that alwaysevaluates to only one of the fallthrough or target address. This conversion is usedby malware to introduce more control flow paths or place junk code on the unusedpath to confuse a disassembler. By creating more code paths or invalid disassemblyat the unused path, malware can hope to either create more work for a reverseengineer or potentially cause errors in the disassembly process.Implementation: My tool detects this DPL behavior with a boolean feature67as follows. At every new conditional branch found, my tool disassembles the nextbasic block at both the target and fallthrough address. If either basic block has aninvalid instruction, this boolean feature is output true.Robustness: It is nearly impossible to determine if a conditional branchalways evaluates one direction. Thus, although this is not a guaranteed methodof detecting all instances of this conversion, I felt that it was a good compromisebetween a more complicated implementation, which would determine whether theo-retically a conditional branch will always evaluate in one direction, and a simplisticimplementation, which marked every conditional branch that only evaluated in onedirection during a program’s execution as malicious. My implementation does notdetect if malware only uses this obfuscation to introduce more code paths, but doesdetect if malware places invalid instructions at either code path with high reliability.This detection can only be done at an instruction level.3.4.2.5 Overlapping code sequencesDescription: Overlapping code sequences are unique code sequences existingwithin the same set of code bytes. Because the x86 architecture is a complex in-struction set computer (CISC) architecture with variable length instructions, uniqueinstruction sequences can exist at different offsets within the same set of bytes. Mal-ware can use this obfuscation as a method of hiding code within sequences of othercode to avoid static and OS-level detection.Implementation: My tool detects this behavior by maintaining a dynamic68disassembly of the program, as described above, and dynamically checking to seeif the program is executing an instruction that begins in the middle of an alreadydisassembled instruction. To differentiate my self-modification detection and over-lapping code sequences, my tool checks to ensure that the current instruction’s bytesexactly match the previously disassembled bytes, with the only difference being theaddress at which the new instruction sequence begins. If my tool detects that theprogram is executing an instruction at an address that is in the middle of an al-ready disassembled instruction and the current instruction bytes match the bytes ofa previously disassembled region, my tool outputs this feature.Robustness: This DPL feature cannot be monitored using only OS-levelanalysis because a disassembly of previously seen instructions as well as the currentinstruction executing must be kept. My use of a DBI tool ensures my tool willdetect this behavior if it occurs dynamically and makes it impossible for malware touse overlapping code sequences to hide code without being detected. The only waymalware could avoid my detection is to not use this obfuscation. The only way astatic tool could detect this obfuscation is to disassemble the code of the program atevery byte offset, which will produce a high number of incorrect disassembly tracesand a high number of unexecuted code paths.3.4.2.6 Hidden functionsDescription: Hidden functions are functions in a program that are not calledby the traditional call instruction. In x86, a call instruction combines the function-69ality of a push and jump instruction. However, in order to avoid or deter analysisschemes, malware will use a manual push and jump instruction in place of a call in-struction. This can help the malware hide functions from analysis tools that targetthe presence of call instructions to identify functions.Implementation: My tool detects this behavior through two features, aboolean and value feature. The boolean feature de

Notes when at runtime, a re-turn instruction goes to the instruction immediately after a jump instruction. Thistells my tool that most likely, this jump instruction was used in place of a call in-struction. The value feature detects how many times this occurs. My tool doesnot actively track push then jump instruction combinations because malware canplace an arbitrary number of instructions in between a push and jump to evade thisdetection.Robustness: Although my method of detecting hidden functions is not aguaranteed method of finding all hidden functions in a program, I felt that this was agood compromise that detected instances of this obfuscation without implementing acomplicated, heavy detection scheme. My scheme resulted in a non-trivial number ofdetections in my malware dataset and disallows malware from utilizing a push/jmpinstruction in place of a call instruction to avoid function-based detection schemes.The use of a DBI tool allows the detection of this obfuscation that otherwise wouldnot be possible.703.4.2.7 Dynamic IATDescription: The import address table (IAT) is a list of functions that aprogram imports during run-time. Static analysis methods have been shown tobe able to detect malware based on its imports [71]. To counter this detection,malware can bypass the IAT entirely at run-time to avoid prepopulating it duringcompilation. At runtime, malware can dynamically calculate the address of functionsit needs in order to call them directly without having to use the offset located inits IAT. This allows malware to avoid giving up information statically about whatfunctions it may use during its execution.Implementation: My tool detects this obfuscation by measuring how manyof the program’s function calls were located in the IAT. After studying malwareand goodware, I determined that having a feature that noted whether or not morethan half the function calls made by a program bypass the static IAT was a goodmethod of finding this obfuscation. My tool monitors all function calls made by theprogram dynamically, and compares them to the initially loaded IAT.Robustness: Because my tool analyzes the initially loaded IAT and thencontinuously monitors the function call made by the program, my tool is able todetect all instances of malware trying to call functions that were not listed in the IATstatically. Additionally, since my tool also detects hidden function calls as outlinedabove, malware has two significant obstacles in the way of hiding dynamic functioncalls. The only way to avoid this DPL feature is to statically list all functions calledin the IAT. My determination to use 50% as the benchmark to determine if this71obfuscation was present was based on data from goodware and malware’s behavior.I saw that some instances of goodware may call functions not listed in the IAT, butit was very rare for goodware to have more than 50% of its function calls made notin the IAT. Goodware has no clear reasoning to do this, while malware has moremotivation to use this obfuscation, which my tool leverages.3.4.2.8 Call-return obfuscationDescription: Call-return obfuscations involve misusing the call and returninstructions to confuse analysis tools on what the real control flow paths are. Inparticular, the return instruction is effective because it is an indirect control transferinstruction (CTI). Static tools cannot decipher the control flow of a program afteran indirect CTI because the target of the CTI is typically only known at run-time.Malware often times abuse the return instruction because it can conceal the controlflow of its execution.Implementation: My tool detects call-return obfuscations by several meth-ods. First, it keeps track of all calls and returns made by the program and makessure that returns match up with calls. If they do not, my tools outputs that asa boolean feature. My tool also outputs as a value feature the number of times areturn instruction goes to an invalid location (i.e. a location that did not have acorresponding call instruction immediately before it).Robustness: My tool’s detection here is based on the correct usage of a returninstruction (meaning all returns go to the instruction after the corresponding call72instruction). My testing and analysis shows that return instructions do not alwaysgo to a corresponding call instructions in either goodware or malware. However,my testing also showed that this occurred a significantly higher number of times inmalware than in goodware. Thus, my detection is simple as explained above, whichdisallows malware from abusing the return instruction. The only way malware couldavoid my detection or behave similarly to goodware is to very rarely use the returninstruction to obfuscate control flow, which greatly diminishes the utility of thisobfuscation, or not use it at all, which again eliminates one method of avoidingdetection from other tools. OS-level tools miss this behavior because they cannotmonitor call or return instructions.3.4.3 Novel Dynamic Program-level Features: General DPL Execu-tionIn addition to the possibly evasive detections, I collect general DPL executionstatistics. Although these detections are not as targeted as my obfuscation DPLfeatures, my belief, which is later confirmed with my 

Results, is that these sets of datadiffer between malware and goodware. With the level of specificity a program-leveltool is able to provide, I show the addition of this set of features helps my machinelearning detection tool differentiate malware and goodware more accurately. I foundthat earlier works had success incorporating features that were not clear indicatorsof maliciousness such as the opcodes found or a program’s bytes. Thus, I incorporatethe following sets of DPL data as value features that help quantify how a program73behaved at an instruction level that existing OS-based behavioral detection tools donot capture.3.4.3.1 Function analysisIn addition to detecting hidden function and call-return obfuscations as de-scribed above, my tool also tracks generic function execution details. My tool out-puts as features the number of external functions found (functions that are locatedoutside of the program code), number of internal functions found (functions thatare located inside of the program), and the number of times internal and externalfunctions are called dynamically.I hypothesize that this set of DPL information can give a higher-level view ofthe control flow and call graphs of the programs studied. I found that malware Ianalyzed typically relies less on external dlls and dependencies in order to ensurethat it can execute regardless of its environment. This is backed up by my highersuccessful run rate in the dynamic testing malware versus goodware. Thus, malwaremay call more internal functions than goodware, which this set of information aimsto quantify.3.4.3.2 Control flow analysisI use DPL analysis to quantify the control flow of a program. I detect thenumber of edges between basic blocks in the program’s execution. I gather as valuefeatures the number of outgoing edges from basic blocks that end in an indirect74branch (such as returns), and the number of times indirect branches execute. Ialso output the number of times the indirect branches go inside or outside of theprogram’s code 



Sections. These metrics can be useful in detecting code flattening,which is a process in which a malware jumps to a majority of its code from a singlebasic block so that its control flow graph is essentially flat. Malware employ this toprevent static tools from building full control flow graphs.3.4.3.3 Instruction executionMy tool monitors and quantifies the overall execution the program under anal-ysis. It measures the following statistics: the average number of times a basic blockexecutes, the max number of times a basic block executes, the number of unique op-codes that execute, and how often each opcode is executed dynamically. All of theseare output as value features. I saw in previous works that using opcodes as a featureset performed well; thus I felt that analyzing the opcodes that executed dynamicallywould be useful. My 

Results show that by monitoring the general execution trends ofgoodware and malware, machine learning is able to decipher statistically significantpatterns that ultimately improve its accuracy by a non-trivial amount.My 

Results show that my highest accuracy was obtained when all of my DPLfeatures were incorporated into my model. My primary goal was to show that theDPL information, whether it measured obfuscation-related behavior or statisticalinformation, provides a non-redundant set of information that is orthogonal to ex-isting dynamic detection tools. By leveraging machine learning, similarly to previous75works before me, I was able to incorporate these statistical features that were ableto quantifiably boost the performance of my tool because it provided additionalinstruction-level insight that further differentiated malware from goodware.Ultimately, the novelty and usefulness of my work comes from these DPL fea-tures. I show in my 

Results that these features are able to provide an non-redundantset of information to existing dynamic OS-level tools that helps differentiate mal-ware from goodware. My 

Results prove that not only are my DPL features useful forbetter understanding malware’s behavior, but also critical in reducing the numberof malware missed by OS-based tools.3.5 My ImplementationThe specifics of the tools used for my implementation and experimental setupare described below.3.5.1 Analysis 

OverviewCuckoo: I utilized Cuckoo Sandbox [37], which is an open-source sandboxmanager for automated dynamic program analysis. After a program is submittedto Cuckoo through its API, it is uploaded to a virtual machine (VM) and executed.During the program’s execution, it is monitored using Cuckoo Monitor, which isCuckoo’s OS-level monitoring tool. It captures all OS-level behavior and then gen-erates behavioral signatures that are output into a Cuckoo report. The Cuckooreport also contains static information that is used in my feature set as well.76I used a Windows 7 environment for my VM. Each VM is given 1/2 GB ofRAM and 1 virtual CPU. Each sample was run in its own VM for one minute. I feltthat one minute was enough time to allow the program to run, while keeping mytesting time within reason. Cuckoo also has a module that mimics human interactionto simulate an endpoint. My VMs use a Tor gateway to give the program accessto the Internet while obscuring where the request is coming from. Although thereare safety and ethical concerns with allowing malware to connect to the Internet,because all the malware under study have been detected by antivirus tools and havebeen in existence for more than a year, I felt that it was an acceptable decision.In addition, [72] calls for real Internet connection for malware when analyzing it toensure more substantial execution. I loaded the VM with common DLLs such asmsvc.dll in order to maximize the number of applications that ran.DynamoRio: I used a DBI tool called DynamoRio to perform DPL analysis[73]. DynamoRio is an open-source tool used to instrument binaries at run-timeand monitor all of the instructions it executes. Using DynamoRio, I build customDPL detections and statistics collectors that are added to the Cuckoo report at theend of its execution. These detections and statistics are used as a part of my DPLfeature set.3.5.2 Machine LearningI utilized a neural networks-based approach due to number of features andsamples I had. Specifically, I used a multilayer perceptron (MLP) neural network to77produce my malware detection tool. I saw that from preliminary testing, MLP wasrobust and generalized the best on all of my test sets. I also tested random forestand Support Vector Machine with various kernels, but chose MLP because of itsperformance. I are not claiming MLP is the best choice for malware detection. Mygoal here is not to extensively test different machine learning models, but rather, Iaim to show how my DPL features can positively impact a high performing machinelearning-based malware detection tool.In my MLP configuration, I used one hidden layer with a size equal to the inputlayer with dropout set to 0.5 between each. I used a learning rate of 0.01, learningrate decay of 1e-6, and Nesterov momentum set to 0.9. For my first two layers, Iused a rectified linear unit activation function. I used these parameters in order tohelp the model train quickly and learn efficiently. These are standard parametersand practices when it comes to using an MLP model. For the third layer, I used asoftmax activation function to output the probability of maliciousness. In total, mylargest feature set produced a model with 1.8 million trainable parameters. I trainedmy model and used a separate validation set to measure the learning progress. Thetest set was not used until all the model’s parameters were set. I trained the MLPfor 100 epochs because I observed that after 100 epochs, my tool’s accuracy on myvalidation set leveled off at 98.7%.To implement my machine learning detection tool, I used Scikit Learn [74] andTensorflow with Keras [75]. I used Scikit to generate my feature matrix and usedTensorflow with Keras to implement my neural networks. I scaled my features torange from -1 to 1. Scaling my features ensured that all the value-based features78did not outweigh another. Normalization scaled the features to have unit variance.These are standard practices.I trained and tested my MLP on a server that had a NVIDIA GeForce GTX745 GPU.3.5.3 Malware Detection Tool ImplementationIn order to improve the implementation of my malware detection tool, I pairedmy MLP tool with ClamAV- a popular open-source AV tool [76]. I used ClamAV inparallel with my MLP malware detection tool to simulate a real-world deployment.My system worked as follows. If either ClamAV or my tool flagged the program asmalicious, I considered it malicious. If neither considered the program malicious, Icategorized the program as benign. I did this because ClamAV has an extremelylow false positive rate (0.005% on my goodware dataset). Thus, the detection rateof my system improves without hurting the false positive rate.This likely emulates how a real-world system works; they often pair all typesof tools to build a comprehensive, high performing tool. More importantly, I showthat my DPL features can still aid the detection of such a real-world tool and thusproves the importance of my tool to any malware detection tool.3.5.4 My DatasetI first collected a set of over 400,000 programs consisting of 223,417 malwareand 195,255 goodware. These are programs that execute dynamically in a Windows797 environment.As with any dynamic analysis scheme, not all the samples tested executed inmy test environment. Thus my 400K dataset was obtained after filtering out theones that did not run successfully within my VMs. This was an inherent downsideto using dynamic analysis, but I felt that by having a dataset with more than 400Kthat did run sufficed. I discuss possible remediations in 



Section 3.7.Malware: My malware dataset was obtained from VirusTotal, who grantedme a private key so that I could download these programs. Virus Total is a onlinedatabase of programs maintained by Google that are queried against 50+ antivirustools to determine maliciousness. I chose 5,000 randomly selected malware per yearfrom 2001 to 2008. I then used 20,000 randomly selected malware per year from 2009to 2017. Lastly, I used 40,000 randomly selected malware that had a PE timestampthat was before 2001 or after 2017. I assumed for these samples, the timestamphad been tampered with and thus categorized all of them together as unknown. Ichose this distribution to ensure a diverse malware set, while weighting my datasetto more recent samples.I chose to download PE32 programs that had at least 15 or more detections onVirusTotal to ensure that the malware being testing was indeed malicious. I chose15 or more detections because it means that more than 25% of the queried anti-virus tools determined the program to be malicious. One of the main issues withother malware datasets, as [72] points out, is that some publicly available malwaresets have no guarantees of being malicious. Rather, they may simply be samples ofunknown programs. This is problematic because if the ground truth of the machine80learning dataset is unreliable, then the 

Results may be unreliable. Thus I felt thatonly taking programs with at least 15 detections was a necessary step. Similarmeasures were taken in related works [77,78].Goodware: In order to obtain a goodware dataset that was large and diverse,I downloaded programs with zero detections on Virus Total. I felt that if a programhas been in VirusTotal’s database for more than a year with zero detections, thenit was most likely a benign program. I saw the same filtering being used in relatedworks such as [77, 78]. I downloaded all PE32 programs that had zero detectionsfrom 2005 to 2016.Defining a benign program is a difficult problem. Simply put, a benign pro-gram can be seen as a program that does not perform any unwanted action. If 50+antivirus tools deemed that a program did not execute any malicious actions, thenI believe that this program is most likely benign. In addition, most other datasetsused in prior work are dominated by installing a clean version of Windows and ex-tracting all the system executables. However, this taints the benign set because itis coming from one source. Furthermore, there is no guarantee that the programsthere will provide diverse examples of benign programs that may act suspicious.Including these types of programs in my benign set are important to ensure mytool’s false positive rate is one that will generalize well even when deployed in thewild. Programs could be submitted to VirusTotal because the community wantedto check if it was benign or malicious. Thus, I believe that the programs that weresubmitted to VirusTotal and cleared by 50+ antivirus tools provide better exam-ples of suspicious benign programs and ultimately provide a more robust, diverse81dataset.3.6 

ResultsI used a standard ten-fold cross validation (CV) in order to obtain my 

Results.This means I used ten folds (each fold consisting of 90% of the dataset for training,and 10% for testing) such that each sample was in the test set once. This is astandard practice in machine learning to ensure that the validity of the 

Results.3.6.1 MLP-based Malware Detection Tool 

ResultsTable 3.1 below shows how my MLP-based malware detection tool performswhen set at a 1% false positive rate (FPR). I show the improvements in the detectionrate (DR) as I add to the feature set. The first feature set consists of all static andOS-level features obtained from the Cuckoo report (this set is labeled OS). The sec-ond feature set includes everything in the OS feature set along with the potentiallyevasive (EV) DPL features (this is labeled OS+EV). The third feature set includesthe OS+EV features along with the DPL features that quantify general executionstatistics (this is labeled OS+EV+STAT). I also show the F1 score, and area un-der the receiver operating characteristic (ROC) curve (AUC) for each configuration.The 

Results shown below are for my ten-fold CV test on my dataset described in



Section 3.5.4 in conjunction with ClamAV.From Table 3.1, it is clear that MLP’s best DR, F1 score, and AUC are achievedwhen the DPL features are incorporated. Since the false negative rate decreases from82Feature Set DR w/ ClamAV F1 score AUCOS 97.44% .9829 .9974OS+EV 98.00% .9855 .9980OS+EV+STAT 98.45% .9879 .9981Table 3.1: MLP 

Results with a 1% FPR100 - 97.44 = 2.56% to 100 - 98.45 = 1.55%, that is a decrease of 39.45% when usedthe DPL features versus just the OS feature set. The false negative rate is thepercentage of malware missed by a classifier and is calculated by subtracting theDR from 100%. The DPL features here add clear value in helping detect moremalware. In addition, the F1 score is 29.24% closer to a perfect score and the AUCis 26.92% closer to a perfect score when using the DPL features are incorporated.The increase in AUC is important because it shows that MLP is able to obtain ahigher DR across a range of FPRs, not just when operating with a 1% FPR. This isshown in the ROC plot in Figure 3.1, which shows the detection rate or true positiverate for when the FPR ranges from 0% to 5%.To further study my DPL features’ impact on the MLP-based malware de-tection tool, I analyzed the false negatives of the OS feature set versus the falsenegatives of the OS+EV+STAT feature set without the aid of ClamAV. A falsenegative is when a malware is incorrectly classified as goodware. When the MLPtool used the OS feature set, it missed 5,359 malware out of 223,417 (2.40%) whennormalized to a 1% FPR. When the MLP tool used the feature set with my DPLfeatures included, it missed 3,454 malware out of 223,417 (1.55%) when normalized83Figure 3.1: ROC plot for MLP with 0% ≤ FPR ≤ 5%to a 1% FPR. I analyzed the subset of 2,462 malware that the MLP tool was able todetect because of my DPL feature set. For these malware, I measured the averageprobability of maliciousness output by the MLP tool when using the OS feature setvs the OS+DPL feature set. On average, the MLP tool categorized the likelihoodof this subset of 2,462 malware as 28.84% maliciousness. After the addition of myDPL feature set, the average likelihood of maliciousness was increased to 86.81%(an increase of 57.97%). This boost in probability of maliciousness shows that notonly are my DPL features helpful in detecting more malware, but that they alsoprovide information that significantly increases a MLP model’s predictive power.For samples that my MLP model was more than 86.81% confident it was malicious,84it was 99.57% accurate. This demonstrates that my DPL features’ impact on myMLP tool’s accuracy is not a trivial improvement.Analyzing feature importance when using a MLP model is an unsolved problembecause MLP does not give feature importances. However, I did filter out a fewDPL-feature sets by training and testing my MLP model with a four-fold CV andexcluded one set of DPL-feature sets at a time. Although this is also an imperfecttest of feature importance, I was able to eliminate DPL features that were not usefulfor increasing the accuracy of my tool.3.6.2 Generalization TestI conducted a small experiment to approximate how my DLP features affect amore realistic deployment scenario where the training set is collected independentlyof the testing set. I trained two MLP models, one based on the OS feature set andone with the OS+DPL feature set, on my entire dataset. I tested on two different setscollected from two reputable cybersecurity companies (unnamed for confidentialitypurposes). The companies mentioned that both datasets were of advanced malwarethat were particularly hard to classify, that they used for comparative testing oftools. Malware set one (from company one) contained 340 samples and malwareset two (from company two) contained 720 samples. Both sets were confirmedto be malicious by the respective companies. Each set of malware were collectedcompletely independently and had no overlap from my training set. I used the samesetup and threshold of maliciousness as my experiment above (covered in 



Section853.6.1). The 

Results are shown below in Table 3.2.Test Set Feature Set DR w/ ClamAVSet 1OS 85.59%OS+DPL 91.18%Set 2OS 80.14%OS+DPL 84.44%Table 3.2: Generalization Test 

ResultsThe 

Results above show that my DPL features are useful in increasing theMLP-based malware detection tool’s ability to detect more malware in a challeng-ing deployment scenario. For set one and two, my DPL features decrease the falsenegative rate by 38.79% and 21.65%, respectively. This is important because itproves that my proposed feature set is able to increase an OS-based malware de-tection tool’s robustness in the real-world where the samples coming into a networkcould be different than what the original machine learning model was trained on.I expect the 

Results from my tool are lower than my expected detection ratesbecause both of these companies’ sets are used by the companies to test othermalware detection tools. In order to do so, the companies intentionally chose hard-to-detect malware, which is presumably why the detection rates are lower than formy full dataset of randomly selected diverse malware. Additionally, these sets aresmall and thus have limited value in adequately evaluating my system, but I feltthat showing the 

Results was still important for completeness.863.6.3 Zero-day TestI tested the effect of my DPL feature set on a simulated zero-day test. I trainedtwo MLP models, one with the OS feature set and one with the OS+DPL featureset, on samples in my dataset that had a PE timestamp of 2015 or earlier. I thentested on goodware and malware from 2016 and 2017. This resulted in a test set of27,402 goodware and 36,578 malware. The purpose of this experiment is to showmy DPL features help a dynamic OS-based malware detection tool more accuratelydetect zero-day malware. The detection rate shown is for when the FPR is set to1%.Feature Set DR w/ ClamAV F1 Score AUCOS 82.83% .9097 .9835OS+DPL 87.50% .9424 .9853Table 3.3: Zero-day Test 

ResultsTable 3.3 shows that the addition of my DPL features reduces the false neg-ative rate by 27.20%. This experiment approximating a zero-day detection showsthat my DPL features again prove to be useful for an OS-based tool to more accu-rately detect malware. This additionally motivates the usage of my DPL features inany deployment scenario to aid existing dynamic OS-based malware detection toolsperform better.The time-analysis 

Results above are likely worse than expected because pro-gram behavior changes over time. Thus, training on an older set of programs and87testing on new ones often produces a worse result than expected. This is partiallywhy zero-day malware are hard to detect. However, the goal of using DPL fea-tures is not to solve the problems associated with zero-day malware; rather, I showin the 

Results that my DPL feature set increases existing malware detection tool’sperformance against zero-day malware.3.6.4 Performance on Malware with Few Dynamic SignaturesFigure 3.2: False Negative Rates of OS VS OS+DPL on Malware with Few Signa-turesOften when dynamic OS-level tools are used, the dynamic signatures used todetect malicious behavior is reliant on a sequence of specific API calls being made.88For example, Cuckoo’s keylogger OS behavioral signature relies on the executionof an API that registers an interrupt for every key pressed, then another API towrite each keystroke to a file on disk. Malware detection tools that use OS-basedbehavioral detections rely heavily on these signatures in order to detect malware.As shown in Figure 3.2, I see that the false negative rate rises for as the number ofdynamic signatures found decreases. In the cases where there are little to no dynamicOS-level signatures, existing dynamic tools have no other method of detecting thesemalware. The DPL features are able to decrease the percentage of missed malwareby upwards of 43%. The use of DPL features is pivotal to detecting the malwarethat OS-level tools cannot because it captures a set of information orthogonal toOS-level malicious behavior.With further analysis, I found that for the malware samples which the OS-based MLP model correctly classified, they had on average 8.88 dynamic OS sig-natures. For the malware samples which it got wrong, they had on average 5.05dynamic OS signatures. Despite the reduced number of dynamic OS signatures, myDPL features are consistently able to reduce the false negative rate and maximizedynamic analysis’ capability to detect malware.3.7 

LimitationsWhen performing dynamic analysis, having programs that do not execute dueto dependency issues or are evasive are always concerns. In order to combat thedependency issue, I first downloaded standard libraries such as Microsoft Visual89Studio. Unfortunately, there is no feasible way to obtain all programs’ dependenciesto ensure execution. However, in typical real-world deployments this may not bean issue because a sandbox placed at a network’s firewall will likely imitate theenvironment of the endpoints of the network. Thus, if the unknown program canexecute on the endpoint, it will most likely be capable of executing in the sandbox.Malware with anti-sandbox evasion is a harder, but orthogonal problem. Mal-ware with anti-sandbox evasion is malware that uses techniques such as sleepingto avoid executing any significant behaviors unless specific requirements are met.Although I detect potentially evasive actions, I do not claim to defeat all evasivemalware. The current advances in defeating it could be added to my tool in thefuture. However I collected my datasets without regard to anti-sandbox evasivemalware, so I expect some of these malware deploy anti-sandbox evasion. Hence,all 

Results in the 



Section are valid for a collection of real-world malware, includingevasive malware.Adversarial machine learning is the practice of creating samples that are specif-ically crafted to trick machine learning models. In my case, adversarial machinelearning could be used to create malware samples that have similar feature valuesto my goodware set, thus tricking my model into thinking malware are goodware.Although this is outside of the scope of my paper, I believe that adversarial machinelearning would be more difficult to do when using my DPL features versus OS-levelfeatures only because my DPL features capture another class of behaviors. Malwarewould have to not only perform OS calls in a seemingly benign manner, but alsoexecute their instructions in ways that are restricted to actions a typical benign90program would perform. Thus, my DPL features reduces a dimension of freedommalware has in terms of hiding its malicious code.3.8 

ConclusionDynamic program-level features provide a new frontier of information thatis capable of aiding existing dynamic OS-level malware detection tools. Withoutit, dynamic OS-level tools miss internal behaviors that not only detail potentiallyevasive actions, but also provide additional useful information that can be used todetect malware despite the lack of OS-level behavioral signatures. My work showsthat DPL features are key in producing a tool that can reduce the false negativerate of dynamic OS-level tools by nearly 40%, which can reduce an enterprise’s costof dealing with malware by 40%. My DPL features also qualitatively changes theway malware can behave because my tool detects and uses internal behavior as amethod of detecting malware. My 

Results show that in a variety of test cases, DPLfeatures can further reduce the adverse impact of malware and present a future areaof research in hopes to better defend against malware.91



Chapter 4: A Hybrid Static Tool to Increase the Usability and Scal-ability of Dynamic Detection of Malware4.1 



IntroductionModern intrusion detection systems (IDSs) are responsible for stopping un-wanted software from entering an enterprise’s network, while ensuring that benignprograms are not falsely flagged. IDSs that rely on static analysis can be deployedas active defense systems because static analysis is fast and can handle at scalethe thousands of programs coming into the network. An active defense system isone that can stop programs in real time from coming into the network if flagged asmalicious. However, active systems must maintain an extremely low false positiverate to ensure that benign programs are not falsely flagged. This is done by settingthe threshold very high for how confident the IDS is in order to classify somethingas malicious, allowing some malware to slip through the detection system. Thus inorder to deploy an active static IDS, the detection rate of malware is sacrificed at acost of reducing false positives.IDSs that analyze every file dynamically present a different strengths andweaknesses. Dynamic analysis is based on the behavior rather than the static at-92tributes of malware, which can make it more robust against packed, obfuscated,and previously unseen malware. Work such as [70] show that dynamic analysis canobtain useful information, which often leads to higher accuracies of detection, thatstatic analysis cannot. IDSs that use dynamic analysis on every incoming file aretypically deployed as passive systems, meaning that programs that arrive at the net-work are not blocked in real time. Because dynamic analysis requires the executionof the program in a protected environment, also known as a sandbox, analysis takesminutes to complete. Because malware is not blocked in real time, it is allowed to gopast a network’s defenses during analysis and wreak havoc before being potentiallydetected by the dynamic IDS a few minutes later. At this point, remedial actionis taken at the infected endpoint to remove the malware and perhaps re-image theendpoint if the malware has run. I define the time elapsed between when a malwareenters the network and is stopped as timeliness.Most modern malware defense systems rely on hybrid approaches, which com-bine both static and dynamic analysis in order to defend against malware. However,I found from a literature and industry review that the way in which static and dy-namic analysis have been combined is suboptimal. Most hybrid approaches workone of two ways. The first is a system which performs both static and dynamicanalysis on all incoming traffic to obtain static and dynamic information in orderto maximize a system’s accuracy. The problem with this method is that althoughboth sets of static and dynamic information are obtained, the computational andtimeliness costs are prohibitively high because all programs are dynamically ana-lyzed. The other primary hybrid approach is using a static analysis-based tool to93detect any incoming threats. The detected threats, based on static analysis alone,are sent to a Security Operations Center (SOC) to be analyzed further by othermethods such as dynamic analysis. This method is problematic because it reliessolely on the capability of static analysis to detect threats. As mentioned above,any active system maintains an extremely low false positive rate (to remain usablein the real world) by sacrificing its detection rate. Thus by only relying on staticanalysis, the malware detection system is incapable of defending robustly againstall types of threats.I present a new hybrid malware detection configuration that runs at the net-work entry point to an enterprise that strategically leverages the strengths of bothstatic and dynamic analysis while minimizing their weaknesses.My proposed detection system contains a two-step process. First, a tool whichI call a static-hybrid tool analyzes all incoming programs statically and categorizesthem into one of three buckets: very benign, very malicious, and needs further anal-ysis. It is thus named to distinguish it from usual static tools, which categorizeincoming programs into only two buckets: malicious or benign. The very benignbucket contains programs that the static-hybrid is highly confident are benign. Thisbucket contains near zero false negatives (i.e., missed malware). The very maliciousbucket contains programs that the static-hybrid tool is highly confident are mali-cious. This bucket contains near zero false positives (i.e., benign programs falselydetected as malware). The needs further analysis bucket contains programs thestatic-hybrid tool is unable to make a strong determination on and thus is passedto the dynamic analysis tool, which is the second step of the process.94The programs located in each bucket provide unique improvements to existingIDSs. The programs in the benign bucket can directly bypass the dynamic analysisportion of my tool, reducing the computational resources needed for dynamic anal-ysis. The programs in the malicious bucket can be blocked immediately, improvingtimeliness and reducing the need to conduct damage control after a program isidentified as malicious in a passive IDS. The programs in the needs further analysisbucket are the only programs passed to the dynamic analysis tool. These programs,as my 

Results will show, have a lower chance of being categorized correctly by astatic analysis tool compared to a dynamic analysis tool. Thus by utilizing dynamicanalysis on this subset of programs only, my tool’s overall accuracy is higher thana strictly static IDS. In addition, because only the programs located in the verymalicious bucket are immediately blocked, my static-hybrid tool is able to operateat a much lower false positive rate than a comparably built static-only tool, as my

Results will show.My scheme reduces the computational resources by 27.5X in my salient con-figuration. This reduction is important for the practicality of a dynamic scheme.For example, a system that analyzes every file dynamically using a sandbox thatencounters 200,000 files/day at an organization’s network entry point (a typical filevolume for a mid-size organization), I estimate would cost $24,000/year in cloudcomputing costs alone to run the full sandbox load, based on commercial cloudcosts today. By reducing the computational load by 27.5X, the cost of protectionwould also drop by 27.5X with a very small loss in accuracy of protection.In practice, any active system must maintain a near-zero false positive rate to95avoid adversely affecting an enterprise’s users. Typical active IDSs block 100% ofthe programs flagged as malicious. However, my tool’s two-step process allows it toonly block a subset of programs flagged malicious. This is unique to my tool and Idefine it as the Blocked Benign Rate or BBR. The BBR is the percentage of benignprograms stopped in real-time, which is distinct from the overall false positive ratethat measures the total percentage of benign programs flagged as malicious. Mygoal is to produce a practical, scalable malware detection tool that strategicallycombines the benefits of both static and dynamic analysis. Thus, in order to ensurethe practicality of my system, I chose my salient configuration to have a BBRof 0.08%. My 

Results show that my salient configuration can still block 88.98%of malware immediately. Additionally, in practice I believe that the BBR can befurther reduced by combining my system with other AV tools or file reputationwebsites.My work differs from previous work because I are the first to use a static-analysis based tool to generate three answers instead of two. This allows my workto utilize the strengths of static analysis to quickly and correctly detect a subset ofmalware and goodware for which it is very confident, while using dynamic analy-sis to more accurately classify the remaining programs. I are the first to proposesuch a system to improve existing hybrid malware defense systems’ scalability andperformance. Because of my two-phase design, I can reduce computational resourcerequirements and improve timeliness of schemes that use dynamic analysis on allincoming traffic by much larger factors in comparison to previous work. I introducea system that combines both static and dynamic analysis in an innovative way that96takes maximizes the strengths of both while minimizing their weaknesses.My contributions are as follows:• Propose a two-phase malware detection tool that uses a static-hybrid-basedmachine learning tool to reduce the computational resources needed, improvethe timeliness, and reduce the alerts generated by dynamic analysis.• Prove that on programs a static analysis tool has difficulty classifying, dynamicanalysis can provide a dimension of information which enables it to moreaccurately classify them, ultimately improving my system’s overall accuracycompared to static-only based methods.• Show that my resulting hybrid system is able to reduce computational re-quirements of typical dynamic analysis by 27.5X, block 88.98% of malware inreal-time with a 0.08% BBR (detecting 98.73% of malware eventually), andreduce the number of alerts generated by 9.5X.• Obtain the 

Results on my system by training its machine learning componenton a set of over half a million programs, equally split between malware andbenign programs (also known as goodware).The rest of the 



Section is organized as follows. 



Section 4.2 covers the relatedwork in the field along with my distinctions. 



Section 4.3 covers my design andexplains in detail the technology behind my scheme. 



Section 4.4 covers the specificsof my machine learning implementation, feature set, dataset, and testing setup.



Section 4.5 covers my 

Results.974.2 Related WorkMy goal has two main components. In comparison to dynamic analysis-basedIDSs, my technology aims to reduce the computational load, while improving thetimeliness of dealing with a malware. In comparison to static IDSs, my technologyaims to perform more accurately. On these fronts, there are several related worksthat are explained below.[79] had the most similar goal to ours of improving the efficiency of dynamicmalware analysis, but tackles the problem through reducing the number of polymor-phic samples tested. Polymorphic malware are malware that contain different bytesas to avoid signature-based detection, but perform the same actions. [79] states thatdue the high number of polymorphic samples, dynamic analysis is often unnecessary,thus it only dynamically analyzes each malware sample for a short period of time,then compares the dynamic analysis 

Results with that of previous malware. If itmatches, then analysis is stopped, thus saving time and resources. However, theirwork was only able to forgo 25% of analysis, while my work reduces the computa-tional requirements by 27X. Additionally, spawning a sandbox takes a non-trivialamount of time meaning that their scheme cannot in real time stop malware (i.e.,there is no improvement in timeliness).Another class of related works are papers that aim to detect malware similarity[80–87]. These works use static or dynamic analysis in order to cluster malware intofamilies or find similarities between them. However, these works do this to tryto aid forensic malware analysis, rather than trying to reduce the computational98load of dynamic IDSs. All these works were only tested on malware. My goal andimplementation of my static-hybrid is fundamentally different in that it is used todistinguish malware from goodware.[88–90] specifically aim to reduce the time dynamic analysis takes to ana-lyze each sample. [88] uses static features to try to predict how long it will takefor dynamic analysis to uncover malicious behaviors. [89] uses network analysis tospecifically detect if dynamic analysis should be suspended. Both works still requirethe use of a sandbox, which means their tools cannot stop malware in real-timeor reduce the number of programs analyzed dynamically. [90] proposed using cloudcomputing features to support and enhance malware analysis with the goal of reduc-ing analysis response time, but only could improve it by 23%. Additionally, theirtool is strictly a malware analysis tool, not a malware detection tool like ours.[91] aims to maximize the value of the information obtained from dynamicanalysis by using static analysis to cluster malware behavior. Their goal is to re-duce duplicative runs of dynamic analysis for malware to maximize the efficiency ofsandboxing. Although they do improve the efficiency of dynamic analysis, they donot aim to produce a malware detection tool such as ours.[92] built an endpoint tool to detect maliciousness within the first five sec-onds of analysis. Their work is similar to ours in that the authors try to quicklydetect maliciousness, but is unrelated because their tool is an endpoint tool, ratherthan a network IDS like ours. My work aims to prevent malware from reachingthe endpoint all together. [69] similarly built an endpoint tool, but uses a set ofmalicious dynamic models of behavior generated during dynamic analysis to detect99malware on an endpoint. Their technology enables fast detection of malware on anendpoint, but again does not try to stop malware from reaching the endpoint alltogether. Endpoint tools have an entirely different set of trade offs from network-entry-point tools. In practice, the two types of tools are not in competition, withmany enterprises using both types simultaneously to achieve a multi-layered defense.[21, 22, 93, 94] all use a combination of static and dynamic analysis to eitherdetect or forensically analyze malware. Although these works use a combinationof static and dynamic analysis likes ours, they combine the analysis into one setof information with the goal of maximizing accuracy. My work uses the analysistypes separately to reduce computational requirements and timeliness of dynamicanalysis.[95] proposes a two-phase classification system for detecting android malware.In the first phase, they use two separate bloom filters, one for malware and one forgoodware, to classify incoming programs as malicious or benign. If their initial-phase classifiers produce conflicting 

Results, then the android program is passed tothe second, more accurate classifier. Their work differs from ours for the followingreasons. First, their work is specific to android software. Second, their initialphase uses two classification tools, whereas I rely on one and use the probability ofmaliciousness as a method of determining which samples are passed to my dynamiccomponent. Third, their work was only tested on 190 samples and obtained anaccuracy of less than 90%. My tool was trained and tested on over 500,000 samplesand obtained an overall accuracy over 99%. Further, the first phase of their toolstill passed nearly 50% of the incoming programs to the second phase whereas my100tool passed less than 10%.The following works are tangentially related to ours, but differ significantlyas explained below. [96] uses static analysis to fingerprint binary code for the pur-pose of speeding up forensic analysis and not malware detection. [97] uses dynamicanalysis to enhance static analysis for Internet malware binaries, but their tech-nology cannot be used to reduce computational resources like ours. [98] introducesof method of smartly storing signatures on an endpoint because of the enormousamount of signatures needed to detect all malware today using a signature-basedapproach. [99] uses a two-phase classification tool to detect malicious obfuscationcode, but performs poorly when used to detect malware.4.3 My Two-phase System4.3.1 Architectural Comparison VS Existing Hybrid ToolsTo understand the novelty behind my work, I must first look at how exist-ing hybrid tools operate. Figure 4.1 shows a hybrid configuration that utilizesboth static and dynamic analysis to detect malware and generate behavioral re-ports. 100% of the the network traffic is analyzed both statically and dynamically.Although this configuration offers the best accuracy, its costs in terms of computa-tional resources and timeliness are prohibitively high because of the use of dynamicanalysis on all incoming programs.Figure 4.2 shows a hybrid configuration that uses static analysis to filter in-coming programs into two categories: benign and malicious. The traffic classified101Figure 4.1: Advantages: Maximum accuracy; Disadvantages: High computationalcosts, decreased timelinessas malicious generates an alert, and then is sent to the SOC to be analyzed dynam-ically. This model is problematic because it relies solely on static analysis to detectmalware. As mentioned previously, static analysis alone can struggle to detect heav-ily obfuscated or packed malware, limiting its overall accuracy [6]. In addition, thealerts generated all have to be analyzed dynamically, which increases the amount ofwork the SOC has to perform.Figure 4.2: Advantages: Fast detection, some computational benefits; Disadvan-tages: Limited to static-only accuracyFigure 4.3 shows my configuration and its stark improvement over existinghybrid designs. My configuration utilizes a static analysis tool to filter incomingprograms into three categories: very benign, very malicious, and needs further anal-ysis. Because of this innovative three bucket design, my tool can strategically deploy102the use of dynamic analysis only when it truly is necessary to gain an accuracy ben-efit.Figure 4.3: Advantages: Bandwidth and timeliness improvements, near maximumaccuracy4.3.2 My DesignThe novelty in my work comes from my use of my static-hybrid-based machinelearning tool. As shown in Figure 4.4, this static-hybrid tool divides incomingprograms in real time into the following three categories based on thresholds T1and T2. For the programs that the static-hybrid tool is confident is benign, thetool places them in the definitely benign bucket, bucket 1. The programs in thebenign bucket bypass dynamic analysis entirely. For the programs that the tool isconfident are malicious, it places them in the definitely malicious bucket, bucket 3.The programs in the malicious bucket are blocked in real-time, preventing malwarefrom reaching the endpoint. For the programs that the tool is unsure about, itplaces them in the needs further analysis bucket, bucket 2. The programs in bucket2 are passed to the dynamic analysis tool.103Figure 4.4: Static-hybrid CategorizationThe key to my system is my static-hybrid tool. This tool has two main benefitsthat help my system approach the accuracy of the configuration shown in figure 4.1with a fraction of the computational resource usage and timeliness. First, on theprograms the static-hybrid tool has a confident prediction for, it is very accurate.This helps my system maintain an overall accuracy similar to hybrid systems that usedynamic analysis on all incoming programs because a large percentage of programsare correctly categorized with very low error rates. Second, the static-hybrid toolcan classify a large percentage of goodware and malware into the definitely benignand definitely malicious buckets, respectively. By classifying a large percentageof goodware and malware into buckets 1 and 3 respectively, the static-hybrid toolmaximizes the computational resource reduction and improvement in timeliness.Because it categorize both malware and goodware into their respective buckets,my configuration gains more computational benefits as compared to the hybridconfiguration shown in figure 4.2.For the subset of programs that the static-hybrid tool is unable to make aconfident prediction for, my system’s uses dynamic analysis because it can obtainbehavioral information that static analysis cannot. This dynamic information can104be helpful in more accurately detecting malware because it is based on what themalware does rather than static attributes that can modified by processes like pack-ing. In the second phase of my tool, the dynamic information obtained is combinedwith the static information to give my machine learning classifier the best chanceat accurately detecting the remaining malware and goodware.Static and dynamic analysis are equipped to detect malware in fundamentallydifferent ways. This observation is key in how and why my system is built. My

Results show that a large portion of malware can be detected using static analysis.However, the percentage of malware that remain undetected still have massive fi-nancial and safety implications. Thus, dynamic analysis is key in modern defensesas well because it provides an additional source of information complementary tostatic analysis.4.3.3 Computational Resources ReductionThe benign bucket is correlated to the amount of computational resourcessaved by not having to run dynamic analysis. As explained above, dynamic analysisis resource and computationally intensive. Especially since typically more than99% of programs coming into a enterprise network are benign, dynamic analysis iswasteful and creates prohibitively high cost for relatively small benefits. By firstlearning to categorize goodware into bucket 1, my static-hybrid tool can save atremendous amount of resources. This equates to reducing the cost of an accurateIDS for an enterprise.1054.3.4 Timeliness ImprovementThe malicious bucket is correlated to the timeliness improvement by blockingmalware in real time. In typical passive IDSs that utilize a configuration such as fig-ure 4.1, malware is allowed through to the endpoint because dynamic analysis takeson the order of minutes to process per sample. In practice, since the percentage ofprograms that are indeed malicious is small, this is a compromise that is acceptableto users. However, in the cases that the program is malicious, the endpoint has tobe quarantined and potentially restored from a previous backup to ensure that anyinfected files are not still on the machine. This is an ineffective and costly methodof dealing with malware. My tool relies on static analysis, but is coupled with thepower of machine learning to detect a high percentage of malware. Its ability todetect a large percentage of malware with high confidence, as shown in my 

Results,gives it the ability to stop most malware prior to it reaching the endpoint. Thissaves an enterprise the time and cost of quarantining and performing damage controlafter a typical passive IDS would have let malware pass through.4.3.5 Hard-to-Classify ProgramsThe needs further analysis bucket has the programs that the static-hybrid toolwas unable to make a strong classification prediction for and thus are passed to thedynamic analysis tool. I refer to these programs has hard to classify. My beliefis that the dynamic portion of my tool is able obtain information that can help itmore reliably determine the correct classification for this subset of programs. My106Figure 4.5: Static-only VS. Static-hybrid Comparisonconjecture is that the programs located in this bucket are harder to classify than theprograms in buckets 1 and 3 and thus would benefit from dynamic analysis. Thegoal of my tool is to minimize the this subset of programs to maximize my system’sbenefits.My 

Results will show that on the subset of programs located in bucket 2,information from dynamic analysis is indeed valuable for more accurately classifyingthese programs compared to static analysis. In many cases, the increase in accuracyis dramatic, which quantifies the benefit of utilizing dynamic analysis versus staticanalysis. Figure 4.5 shows the overlap of my static-hybrid tool versus a tool basedon static analysis alone, such as the configuration shown in figure 4.2. In a typicalstatic-only-based tool, the programs with probabilities of maliciousness between T1and Ts would be categorized as benign and the programs with probabilities betweenTs and T2 would be categorized as malware. However, my work shows that static-only-based tools are ill equipped to reliably categorize these and thus passing themto dynamic analysis maximizes the chances of being classified correctly.1074.4 Implementation4.4.1 DatasetMy total dataset contained 264,769 goodware and 259,356 malware WindowsPE32 executables. I obtained my malware and goodware datasets through a com-bination of Virus Total and Virus Share [100, 101]. Both graciously allowed me todownload a large number of malware and goodware. Although I cannot guaranteethat my dataset is perfectly representative of all programs in the wild, I took everyprecaution I feasibly could while trying to amass a large, diverse set.For my malware, I collected programs that had at least 15+ detections on VirusTotal. Virus Total queries nearly 60 Anti-Virus (AV) tools to determine a program’smaliciousness. I chose 15+ as an acceptable threshold to ensure the ground truthin my dataset because it meant that at least 25% of the AV tools believed thisprogram is malicious. I ensured that my malware dataset was temporally diverseby choosing a specific number of malware per year. My malware dataset had 5,000samples per year from the years 2001 to 2008. For the years 2009 to 2017, I chose20,000 per year. Lastly, I chose 40,000 malware from my total dataset that had aPE timestamp that was prior to 2001 or after 2017, as these timestamps were clearlytampered with. This distribution was chosen based on distribution of a malwaretest set I received from a private malware analysis company. The malware chosenper year were chosen randomly.For my goodware, I collected all of my programs from the years 2005 to 2016108and ensured that each had zero detections on Virus Total. I chose to downloadprograms from Virus Total with zero detections because I believed that if a programwas not flagged by any AV tools for more than a year, then it was most likely benign.A similar method was taken in these works [77,92]. Additionally, this was the onlyway of obtaining a dataset that was large enough to effectively train and test mymachine learning algorithm.4.4.2 Machine LearningMy machine learning-based detection tools were trained and tested using aMulti-Layer Perceptron (MLP) neural network implemented with Tensorflow withKeras [75]. My MLP configuration, I used one hidden layer with a size equal to theinput layer with dropout set to 0.5 between each. I used a learning rate of 0.01,learning rate decay of 1e-6, and Nesterov momentum set to 0.9. For my first twolayers, I used a rectified linear unit activation function. I trained the MLP for 100epochs as I observed in my training that my tool’s accuracy on the validation setleveled off after 100 epochs. The final layer of my tool was a Softmax layer usedto output a probability of maliciousness. I trained and tested my machine learningalgorithm using a 4-fold cross validation.The goal of my system was not to extensively test machine learning algorithms,but to show that my tool is capable of utilizing the unique strengths of both staticand dynamic analysis in a previously unseen way.1094.4.3 Feature Set and TestingFor the static portion of my test, I generated static reports for each sample withthe following class of features. My static features comprised of header data suchas imported APIs, and dynamically linked libraries (DLLs), 



Section entropy, andYARA rules. I chose to analyze APIs and DLLs based on previous work’s successesusing them as features. I also used YARA rules to detect signatures that wereobtained from the open-source YARA-Rules project [102]. Due to the high numberof unique imported APIs and DLLs found across over half a million programs, Ifiltered out the ones that did not occur at least 10,000 times in either the goodwareor malware set. I chose 10,000 because it produced a feasible number of featuresthat my machines could process and train on given my large dataset. This resultedin a set of 4,002 static features. The number of static features is large because eachclass of static features I collected, such as imported APIs, produced a large numberof individual features.For the dynamic portion of my tool, I executed each sample in a CuckooSandbox for 2 minutes. Cuckoo Sandbox is an open-source sandbox manager builtto dynamically analyze programs [37]. Each sandbox was run with Windows 7, 1/2GB of ram, and 1 core. Each sandbox was given Internet access using the Whonixgateway to obscure where the HTTP requests were originating from [103].My dynamic feature set was a superset of all the static features in addition tooperating system (OS)-level and program-level behavioral signatures. The OS-levelbehavioral signatures were obtained using Cuckoo Monitor, Cuckoo’s dynamic anal-110ysis tool that monitors the interaction between a program and the OS to build dy-namic signatures. For example, Cuckoo Monitor will generate an HTTP REQUESTsignature if the program attempted to connect to the Internet. The program-levelbehavior was obtained from a dynamic binary instrumentation (DBI) tool based onthe technologies found in [70]. The program-level features detected instruction-levelobfuscations and collected instruction-level statistics. I used DynamoRio, an open-sourced DBI tool, in my implementation [73]. My dynamic feature set was 4,594features in total.It should be noted that my hybrid configuration, which is my main contri-bution, can be used by any existing static and dynamic analysis hybrid malwaredetection system that utilizes machine learning. Although untested, my conjectureis that my configuration’s benefits are not unique to my system’s feature set orimplementation.4.5 

Results4.5.1 Static VS Dynamic IDSHere, I cover the performance of the static phase versus the dynamic phaseof my two-phase system on my total dataset to prove the usefulness of dynamicanalysis as a complementary addition to static analysis.Table 4.1 below shows the following information for using a strictly staticanalysis-based MLP tool, and a combination of static and dynamic analysis-basedMLP tool. First, it gives the detection rate, which is the percentage of malware111detected out of the malware test set. Second, it shows the false positive rate, whichis the percentage of goodware that are falsely flagged as malicious. Third, it showsthe area under curve (AUC), which corresponds to a machine learning classifier’sreceiver operating characteristic that shows the detection rate across a range of falsepositive rates. Lastly, it shows the F1 score, which is common machine learningmetric used in practice.Tool DetectionRateFalse PositiveRateF1 Score AUCStatic-based MLP tool 97.71% 0.75% .9850 .9974Dynamic-based MLPtool99.02% 0.75% .9919 .9980Table 4.1: Static analysis VS. Dynamic analysis Detection 

ResultsI used the same dataset for my dynamic tool as my static tool: 264,769 good-ware and 259,356 malware. However, not all the samples executed dynamically dueto issues such as dependencies not being met. As a result, I generated dynamic re-ports for only 195,255 goodware (70.95% of my original goodware set) and 223,352malware (86.27% of my original malware set). When training and testing my dy-namic tool, I used the same training and test set as for my static tool during the4-fold cross validation, but only included the ones that ran. Thus, the 

Results shownabove for the dynamic-based MLP tool is based on this subset of programs that ran.Table 4.1 shows that the false negative rate (% of missed malware) for mydynamic tool is 0.98%, compared to 2.29% for my static tool. This is a decrease112of 57.2% for the dynamic tool. These 

Results show that dynamic analysis providesbehavioral information that help a malware detection tool be more accurate thanstatic analysis, which is why dynamic analysis is necessary in real-world tools. Iobserve similar increases in the F1 score and AUC compared to my static tool.Although dynamic analysis has benefits in terms of accuracy, there are draw-backs related to the resources needed and timeliness as explained in 



Section 4.3.First, spawning a sandbox per sample is unscalable for many enterprise networksdue to the number of programs coming in daily. Second, dynamic analysis takeson the order of minutes meaning that malware cannot be stopped in real time,and instead are allowed to pass through to the endpoint. Only after the dynamictool determines that the program tested is malicious is it stopped and the endpointfixed. Additionally, not all programs execute dynamically, as I experienced in myexperiments.4.5.2 DefinitionsThis sub



Section defines the metrics used to quantify my improvements and

Results of my two-phase detection tool. G1 and M1 are the number of goodware andmalware located in bucket 1, respectively. The same notation is used for buckets 2and 3. In my notation, NG and NM are the total number of goodware and malwarerespectively.1134.5.2.1 Computational Requirements ReductionI define the computational requirements (CR) of traditional dynamic IDSs asthe amount of resources needed to spawn a single sandbox per sample arriving atthe network. Using a typical dynamic IDS, the CR would be equal to 100%. Icalculate the computational requirements of my system by Equation 4.1.CR =G2 + M2NG + NM(4.1)To calculate the CR in my system, I have to find the percentage of goodwareand malware located in bucket 2 (the bucket of programs that will be passed todynamic analysis) and divide by the total number of goodware and malware. How-ever, I know that in the real-world, a majority of programs that arrive at a typicalenterprise firewall are benign, thus the number of goodware greatly outweighs thenumber of malware. I can then approximate the CR of my system to be simply:CR ≈ G2NG(4.2)4.5.2.2 Timeliness ReductionI define timeliness as the amount of time elapsed from the malware reachingthe IDS to being stopped at the endpoint. I quantify it by calculating the BMR,which is how many malware are blocked and thus stopped in real time, shown inEquation 4.3. In a strictly dynamic IDS, live network traffic cannot be blocked, thusall malware that comes into the network is run on the endpoint for minutes prior114to being detected and removed. Because my static filter is fast enough for it to beused with stopping live network traffic, it can block a percentage of malware fromreaching the endpoint as seen in the 

Results below.BMR =M3NM(4.3)4.5.2.3 Alert GenerationIn typical dynamic IDSs, an alert is generated for every program flagged asmalicious, which is then analyzed by a network administrator. In a dynamic scheme,the number of alerts generated are typically overwhelming and cause only a smallpercentage to be analyzed. In my scheme, because only a small portion of programsare dynamically analyzed, my system dramatically reduces the number of alerts sentto the network administrator.My alert generation (AG) metric is determined by the percentage of alerts thatmy dynamic portion generates compared to the number of alerts a fully dynamicscheme would produce. An alert is generated only when a dynamic tool flags aprogram as malicious (i.e., a true positive, or false positive). The formal equationis defined in Equation 4.4. First, I calculate the percentage of malware that are inbucket 2 that are detected as malicious, or my detection rate (DR) on the portionof malware in bucket 2. I then account for the percentage of goodware that are inbucket 2 that are falsely flagged, or my false positive rate (FPR) on the goodwarein bucket 2.115AG = (DRM2 ∗M2NM) + (FPRG2 ∗G2NG) (4.4)4.5.3 Static-Hybrid Tool: Minimizing BBRThe following 

Results are for my salient configuration, where I chose thresholdsT1=0.2 and T2=0.999999 to minimize the BBR. I show this configuration to explainmy scheme’s improvements in comparison to static-only and dynamic-only analysis.Static-only analysis refers to using a strictly static IDS while dynamic-only refers tousing a strictly dynamic IDS.In Tables 4.2 and 4.3, I show the overall detection rate (DR), overall falsepositive rate (FPR), CR, AG, percentage of malware blocked in real-time (BMR),and percentage of benign programs wrongly blocked in real-time (BBR). The overallDR is the percentage of total malware detected as malicious; in my tool, this is byeither the static and dynamic phase. The overall FPR is what percentage of totalgoodware were falsely detected as malicious; in my tool, this is by either the staticor dynamic phase.Tool DR FPR CR AGStatic-only 97.71% 0.75% 0% 0%Dynamic-only 99.02% 0.75% 100% 100%Static-dynamic 98.73% 0.75% 3.63% 10.68%Table 4.2: Static-dynamic-analysis 

Results for T1=0.2, T2=0.999999Tables 4.2 and 4.3 shows the followings 



Conclusions about my scheme com-116Tool BMR BBRStatic-only 97.71% 0.75%Dynamic-only 0% 0%Static-dynamic 88.98% 0.08%Table 4.3: Static-dynamic-analysis 

Results for T1=0.2, T2=0.999999pared to a scheme that relies solely on static analysis to detect malware. First, myhybrid scheme reduces the overall false negative rate, or the percentage of missedmalware, by 44.54%. Additionally, because my tool only blocks programs in realtime that are located in bucket 3, my tool only blocks 0.08% of goodware (10.7%the goodware that the static-only tool blocks). A static-only tool stops any programflagged as malicious in real time. The static-only tool does stop more malware inreal time compared to my tool (97.71% versus 88.98%), but ultimately does not de-tect as many malware as my tool because of my use of dynamic analysis. Static-onlyschemes only have one chance to stop malware and if it does not, the malware ispassed into the network to be executed for an indeterminate amount of time. Myscheme also holds a significant advantage over static-only based detection tools be-cause my tool can operate at almost 1/10 of the false positive rate, while ultimatelydetecting more malware. This greatly increases the usability and practicality of mysystem over existing static technologies today.Tables 4.2 and 4.3 also shows the following 



Conclusions about my scheme com-pared to a scheme that analyzes every file dynamically. The dynamic-only schemeis the most accurate, but has the costs of high computational resources, alert gen-117eration, and the inability to stop malware in real-time (as evidenced by BMR equalto 0%). My 

Results show that my tool, for the nearly the same DR as dynamic-only,is able to use only 3.63% of the computational resources (a near 27.5X reduction),generate only 10.68% of the alerts (a 9.5X reduction), and block 88.98% of malwarefrom entering the network (a 9X reduction). My scheme produces nearly the sameoverall DR as a dynamic-only scheme with a small fraction of the costs.The reductions in computational resources and alert generation are related toincreasing the scalability of dynamic analysis. By reducing computational resourcesby 27.5X, dynamic analysis’s cost in terms of servers, virtual machines, and totalanalysis times is similarly reduced to ensure it can still be used even as the amountof network traffic continues to grow. Additionally, I argue that the alerts that aregenerated by my tool on the hard-to-classify programs are potentially more valuablethan the alerts that would be generated by a dynamic-only scheme on every predictedmalicious file. The alerts generated for a large percentage of malware I expect doesnot need human analysis because it is clearly malicious. My tool automaticallyproduces a set of alerts for programs that were hard-to-classify and thus may needhuman analysis to truly understand.My tool’s BMR is an invaluable part of my system as compared to a dynamic-only scheme because a dynamic-only scheme cannot stop any malware in real-time.My scheme’s ability to block 89% of malware immediately saves an immense amountof post-infection damage control and removal. This ultimately leads to reduction incost for an enterprise to maintain a secured network.The dynamic-only metrics shown in Tables 4.2 and 4.3 were only on the pro-118grams that executed within the sandbox (approximately 78% of programs tested).This is a detriment to using a strictly dynamic IDS because not all programs executewithin a sandbox. In those cases, my static-hybrid tool proves to be invaluable inmaintaining a high detection rate, while still utilizing dynamic analysis’s informationwhen available.4.5.3.1 Bucket 2 AnalysisIn my scheme, my hypothesis is that current hybrid schemes do not optimallydeploy dynamic analysis- meaning using dynamic information to boost confidenceof prediction when static analysis alone is incapable of doing so. To prove that mysystem more optimally combines static and dynamic analysis, I tested the programsin bucket 2, the hard-to-classify programs, with static analysis and dynamic analysisand show the correctness of classification of goodware and malware. Correctness formalware is calculated by the DR of malware on the set of malware in bucket 2, whilecorrectness for goodware is calculated by the FPR on the set of goodware in bucket2. For the programs located in bucket 2 that did not able to execute dynamically,my scheme relied on static analysis for a classification.ToolBucket 2G (FPR) M (DR)Static 37.85% 6.90%Dynamic 18.83% 96.72%Table 4.4: Bucket 2 Correctness 

Results for T1=0.2, T2=0.999999119Table 4.4 shows that on this subset of programs, each tool’s correctness is sig-nificantly lower than their accuracies overall on goodware and malware. However,this table shows important 



Conclusions. First, it proves that this subset of pro-grams is hard-to-classify as evidenced by the worse accuracies. This means that theprograms located in bucket 2 cannot be reliably classified by static analysis alone.Second, it shows dynamic analysis is the most capable of distinguishing these hard-to-classify programs. The dynamic analysis tool is able to nearly increase the DR ofmalware in bucket 2 by more than 14X while reducing the FPR by half as comparedto the static-only scheme. This result shows that by utilizing my system, dynamicanalysis can still be used strategically (maximizing its complementary informationto boost accuracy), while incurring minimal costs as shown in the 



Section 4.5.3.4.6 

ConclusionMalware detection is a fundamental tool necessary to prevent attacks on in-formation and security. IDSs play a pivotal role in preventing malware attacks, butthe way that current IDSs use both static and dynamic analysis are suboptimal.My two-phase system is a stark improvement over existing hybrid schemes. By un-derstanding the unique strengths of static and dynamic analysis, my system is ableto obtain an overall DR near that of a system that analyzes every file dynamicallywith a 27.5X reduction in computational resources, 10.5X reduction in alert gener-ation, and a 9X reduction of malware entering a system’s network. Additionally,my system can operate at a much lower FPR than a system that only relies on120static analysis, greatly increasing its practicality. Existing hybrid technologies arecorrect in utilizing both static and dynamic analysis when detecting malware asthey are complementary to one another. However, they fail to strategically deploythese technologies to maximize efficiency and usability. My work introduces a novelmethod of accomplishing both.121



Chapter 5: Enhancing the Static Detection of Malware with CNNs5.1 



IntroductionMalware detection is at the forefront of cybersecurity research. Due to therapid growth of malicious programs and threats, the diversity and number of mal-ware in the world has outpaced human’s ability to manually analyze and detectthem. Machine learning has become intertwined with malware detection in themodern era because of its ability to decipher patterns in large amounts of data thatwould not be possible otherwise.The static detection of malware initially started with static signature matchingin order to detect malware. A static signature is an exact byte-for-byte matchthat is unique to malware that detection tools can use to confidently find malware.Recent advances with the use of machine learning have helped static analysis moveaway from strictly static signatures. Instead, information such as the ApplicationProgramming Interfaces (APIs) found in the program header or N-grams of opcodeshas been proven to be useful for malware detection [77, 104]. Because of machinelearning, large amounts of data can be analyzed for patterns indicating maliciousnesswithin a program. Machine learning provides a probabilistic method of detectingmore malware versus a static signature that typically only detects a single malware.122Amidst the recent advances in static detection of malware with machine learn-ing, there are still areas that need improvement. The first is the often manual effortrequired to generate features that are useful for machine learning. Feature gener-ation is vital in producing a highly accurate machine learning malware detectiontool. This is a nontrivial task because it often times requires domain expertiseand manual investigation [105]. Poor feature generation can in some ways limitmachine learning’s capabilities of detecting malware and goodware. Additionally,new features may have to be continually developed to deal with new malware cre-ating a constant need to study in-depth the latest malware trends. The secondissue relates to the prominence of using features such as N-grams or other strictlypresence-absence features that can cause overfitting resulting in less generalizable

Results [2]. Malware detection has largely moved away from traditional hash-basedsignatures, but using features such as N-gram combinations of Windows APIs canbe seen as a similar variant to hash-based signatures. They are only more effectivebecause of the computing power of machine learning. More advances have to bemade in order to reduce the time and knowledge necessary to create quality featuresand help improve a malware detection tool’s ability to generalize and detect newmalware.To address the issues outlined above, I propose the use of static program disas-sembly and Convolutional Neural Networks (CNNs) in order to automatically gener-ate machine learning features that are effective at differentiating between goodwareand malware. I apply Natural Language Processing (NLP) methods to the staticdisassembly of both malware and goodware with the hypothesis that the opcode se-123quences found in programs can be treated as sentences would be in natural languageprocessing. With the use of CNNs, I show that my tool is able to automatically gen-erate features that embed raw opcode sequences without any manual intervention,and improve the accuracy of a tool based on existing static analysis features.My work has four main advantages. First, the use of CNNs to automaticallygenerate useful features reduces the time and effort required compared to manually-generated features. As the number and diversity of malware continue to grow,the need for more scalable feature generation is evident. My method is completelyautomatic, which presents a scalable and useful method of future malware detection.My tool requires no human expertise in identifying which opcode sequences aremalicious or benign. In addition, because the feature vectors based on opcodesequences are generated by the model itself, the features are optimized to improvethe performance of the detection tool. Second, I show that when my generatedfeatures are added to an existing static analysis tool’s feature set, the percentageof missed malware decreases by about 40%. This is a significant finding becauseit shows that the CNN is capable of reducing the work necessary to produce high-quality features. Additionally, my tool does not prefilter the dataset in any way,meaning that both packed and obfuscated malware are included in my set. Previousmethods that relied on the reliable uncovering a malware’s API sequences or trueopcodes can be defeated by packing or obfuscation techniques. My tool shows theability to perform well despite such malware. Third, my work shows in a simulatedzero-day malware test that the addition of my features to a typical static analysis-based set of features decrease the number of missed malware by more than 50%.124This is significant because other simple exact-pattern matching features have shownto be prone to overfitting and thus perform poorly on unseen malware [2]. Lastly,analysis into the 

Results show that malware that have the same generated featurefrom the CNN model are indeed similar. This is a somewhat expected, but excitingfinding because it shows that there is promise in using CNNs for automaticallyidentifying similar malware and their malicious code.My approach works as follows. I first obtain the static disassembly of a Win-dows PE32’s executable 



Sections. I then extract only the opcodes in program orderbecause it is my belief that the opcodes are more important to the behavior ofthe malware versus the operands, which may change arbitrarily. I then feed in theopcode sequences into my CNN, which produces a feature vector representation ofthe input sequence. The feature vector representation of the input opcode sequenceencodes the relationship between opcodes found in the sequence. This feature vectorrepresentation is then fed into a back-end machine learning algorithm for classifica-tion between goodware and malware.The rest of the paper is structured as follows. 



Section 5.2 gives an 

Overview ofPE32 executable as well as the 



Methodology behind my tool. 



Section 5.3 details theimplementation of my work, while 



Section 5.4 covers the 

Results. 



Section 5.5 coversthe related work.1255.2 Static Program Structure Feature Set5.2.1 PE32 Program StructureA Windows PE32 executable is structured in the following way. First, there isa header, which contains information such as where the code and data 



Sections residealong with imported Application Programming Interfaces (APIs) and DynamicallyLinked Libraries (DLLs). The remaining portions of the executable are its individual



Sections, which can be code or some form of data.Code 



Sections are typically marked as read/execute in the header, while data



Sections are typically read-only or read/write. In x86, the code 



Sections sometimescan contain data as well, which makes the process of disassembly difficult. In addi-tion, because x86 is a complex instruction computing set architecture with variablelength instructions, there may be multiple legitimate instruction sequences withinthe same set of bytes. These two facts make static disassembly of x86 code hard todo reliably. Especially in the case of malware, static disassembly can be tricked orfooled by packing or obfuscation.As my proposed method below relies on static disassembly, the problems withit mentioned above are concerning. However, my research and 

Results show thefollowing. I found in practice that although malware can be heavily packed andobfuscated in order to trick static disassemblers, I was still able to obtain codetraces from over 93% of malware tested. This could be improved by choosing amore robust static disassembly tool. Also, because the extracted code is simply a126basis for the CNN’s generated features, my tool’s performance supports the claimthat it can find effective feature vectors that are able to differentiate malware andgoodware despite the presence obfuscated or packed programs.5.2.2 Base Static FeaturesThe first set of static features I obtain are what I call my base features. Thisset of features contains header information and Cuckoo static information. Mystatic header-related features included imported APIs and DLLs, 



Section entropy,and language. Features such as the presence or absence of specific APIs or languagewere boolean features whereas features such as 



Section entropy were value features.Cuckoo Sandbox is a commonly used open-source sandbox tool used to analyzemalware [37]. It also contains a static module for detecting static attributes of theprogram under study. I chose to include those as features as well to make my basefeature set as robust as possible. These were standard static features I found inprevious work.As shown in my related work 



Section, a majority of the static analysis-basedmalware detection papers relied on PE header information and some variant of thepresence or absence of Windows APIs and DLLs similar to my base static features.Although machine learning has greatly enhanced the ability to detect all typesof malware accurately and at scale, these types of features are not a significantimprovement in comparison to the traditional hash-based signatures because thesetypes of features can still require domain expertise (to filter out which APIs/DLLs127are relevant) and some manual analysis to be used effectively to detect malware.Machine learning has automated some of the process, but my work shows thatfurther automation can take place to build accurate detection tools without anymanual analysis or expertise.5.2.3 Exact or Near-exact Pattern Matching FeaturesThe second portion to my static feature set are exact or near-exact patternmatching rules. I chose to use the Python library PEID and YARA rules in practiceas examples of these rules [102]. Both of these tools use exact or near-exact byte-level matches in order to detect specific attributes of programs such as which typeof packer or compiler was used. The byte-level matches can occur in code, theheader, or the data 



Section. Although my opcode sequence CNN model also looksfor similarities in the code, these methods are still distinct for reasons explainedin sub



Section 5.2.4. These tools are targeted at identifying specific attributes ofmalware that can be useful to an analyst. Because many of these rules are specific tomalware, they have been shown to be effective as boolean features for differentiatingmalware and goodware [70]. Thus, I included them in my feature set to increase theperformance of my static analysis detection tool.In order to properly validate the value of my automatically generated featuresfrom opcode sequences, I felt that it was necessary to include this set of features toprove two things. First, I want to show that my generated features still add value interms of accuracy despite some overlap in 



Methodology between the opcode sequence128CNN model and strict pattern matching. In order to test this, I had to include aset of strict rule-based features to show improvement. Second, I wanted to furtherdemonstrate that quality features can be generated despite the lack of knowledgeabout which opcode sequences were malicious versus benign. By including the PEIDand YARA rules as features that were developed by experts with specific knowledge,the improvement in accuracy in my 

Results better reinforces this idea.As the number of malware and goodware continue to grow, hard-coded rulesto detect attributes of malware will become harder to maintain and develop. Evennow, out of the nearly 2,000 YARA and PEID signatures I found in my malwareset, more than 80% had a hit rate of less than 0.1%. As malware detection andanalysis continue to try to scale with the rapid growth of malware, a more scalable,automatic, and efficient method of feature generation that does not require theexpertise of the ever-changing attributes of malware is paramount.5.2.4 Opcode-Based Feature Generation and TrainingA natural way to view a program is as a sequence of instructions. In this



Section, I discuss how machine learning, specifically CNNs, can be used to extractfeatures from the sequence of instructions that make up an executable program.The process of feature extraction begins with static disassembly of the exe-cutable. Disassembly is the process of turning machine language code into human-readable assembly language. Since this process occurs statically, the returned se-quences of assembly language opcodes are in program order. Our process only129extracts the opcodes out of the disassembly because operands, such as registers, canbe changed arbitrarily and are less important to the core operation of the program.By extracting only the opcodes, the storage space necessary and computing timealso decreases because of the smaller amount of raw data extracted.Once each program is represented as a program order sequence of opcodes, anysequence-based ML model, such as CNNs using one-dimensional convolution, canbe trained to recognize sequences of opcodes that occur frequently in either malwareor goodware. This allows these sequence-based models to discern between the twoclasses of programs using only an input sequence of opcodes.CNNs have classically been applied to sequential data mainly in Natural Lan-guage Processing (NLP) for tasks like sentence classification and sentiment anal-ysis [106]. From a high-level this application of CNNs to malware detection canbe viewed as a similar task to sentence classification where the input tokens are asequence of opcodes rather than words and the output classes are malicious andbenign rather than sentence topics.CNNs, like most ML models, are designed as a composition of non-linear func-tions, called layers, that allow for each layer to create a representation of the inputbased on the output of the previous layer. In the case of CNNs, an embedding layerinitially assigns each opcode a random real-valued vector. Following the initial em-bedding layer is a series of convolutional layers. These convolutional layers generatefilters, short sequences of vectors, and convolve these filters with the output of theprevious layer. Each layer ends by applying a non-linear element-wise activationfunction to the output of the convolution. Intuitively, this procedure can be seen130as a fuzzy matching operation between the layer’s filters and the layer’s input. If afilter’s sequence of vectors are similar to a subsequence in the layer’s input, then theconvolution operation creates a larger output than if the sequences are dissimilar.Succinctly, each filter can be described by the following input-output rule:yi = f(W ·Xi:i+h + b) (5.1)where yi is the ith output of the convolution, W is the filter, Xi:i+h is the sequenceof embeddings for opcodes i through i+ h, and f(·) is an activation function. Afterapplying a series of convolutional layers, CNN classifiers typically create a set ofoutput class probabilities by first performing a pooling operation across the finalconvolutional layer’s filter outputs and then applying fully-connected layers as seenin regular feedforward neural networks.The training procedure for CNNs uses the backpropagation algorithm with anyvariant of stochastic gradient descent. This algorithm runs a batch of samples fromthe training dataset through the model, producing output classifications. Theseoutputs are compared to the known class labels associated with each sample and aloss function, usually cross entropy for classification tasks, measuring the model’sdeviation from the ground truth labels is evaluated. The model parameters arethen updated by taking the gradient of the loss function with respect to all of theparameters so that each parameter can be adjusted in the direction that locallyminimizes the loss function.Superficially, this idea of using a CNN for opcode-level analysis is reminiscentof N-gram opcode analysis or other code-based pattern matching. However, as seen131by previous research, N-gram analysis at the byte level tends to overfit to trainingdata and CNNs operating on the byte-level were shown to be more robust to minorchanges to the input bytes seen in polymorphic malware [2]. Since N-gram analysisat the byte level is also sensitive to single byte changes, it is reasonable to hypothesizethat similar 

Results would be seen at the opcode level.Additionally, the high-level interpretation of what a CNN does matches wellwith human intuition of how programs work. Unlike other sequence-based ML mod-els such as Recurrent Neural Networks, a CNN layer only considers a small, spatiallyrelevant number of input tokens when generating an output value. This is seen inequation 5.1 where the ith output of a filter is a function of input tokens Xi:i+h.This matches with the intuition that only short sequences of contiguous opcodesare actually relevant to one another, especially when dealing with a program-orderdisassembly.5.3 Implementation Details5.3.1 DatasetMy total dataset contained 101,847 goodware and 96,753 malware WindowsPE32 executables. I obtained my malware and goodware datasets through a com-bination of Virus Total and Virus Share [100, 101]. Both graciously allowed me todownload a large number of malware and goodware. Although I cannot guaranteethat my dataset is perfectly representative of all programs in the wild, I took everyprecaution I feasibly could while trying to amass a large, diverse set. This includes132not prefiltering my dataset in any other way than ensuring I had a temporally di-verse dataset. Analysis on my malware and goodware set showed that 52% and 25%were packed, respectively.For my malware, I collected programs that had at least 15+ detections on VirusTotal. Virus Total queries nearly 60 Anti-Virus (AV) tools to determine a program’smaliciousness. I chose 15+ as an acceptable threshold to ensure the ground truth inmy dataset because it meant that at least 25% of the AV tools believed this programis malicious. I ensured that my malware dataset was temporally diverse by choosinga specific number of malware per year. My malware dataset had 2,000 samples peryear from the years 2001 to 2008. For the years 2009 to 2017, I chose 8,000 per year.Lastly, I chose 16,000 malware from my total dataset that had a PE timestamp thatwas prior to 2001 or after 2017, as these timestamps were clearly tampered with.This distribution was chosen based on distribution of a malware test set I receivedfrom a private malware analysis company. The malware samples for each year werechosen randomly.For my goodware, I collected all of my programs from the years 2005 to 2016and ensured that each had zero detections on Virus Total. I chose to downloadprograms from Virus Total with zero detections because I believed that if a programwas not flagged by any AV tools for more than a year, then it was most likelybenign. A similar method was taken in these works [77, 92]. Additionally, this wasthe only way of obtaining a dataset that was large enough to effectively train andtest my machine learning algorithm. I chose the goodware dataset based on a similardistribution as the malware.1335.3.2 DisassemblyThe first step in my process is producing the static disassembly of each pro-gram in my dataset. I chose to use the Linux utility ObjDump to produce thestatic disassembly of the executable 



Sections found in each program. ObjDump useslinear sweep to disassemble a program. Linear sweep disassembles the code regionssequentially assuming there is no interleaved data. Although linear sweep can beprone to errors, I chose to use ObjDump because of its ability to obtain sizablesequences of opcodes. In practice I saw that ObjDump was successful in uncoveringopcode sequences more than 93% of the time. By choosing a more robust tool, thisnumber may be improved upon.My 

Results and work shows that despite the pitfalls of linear sweep disassembly,my model is able to produce opcode sequence feature vectors that are still capable ofdifferentiating malware from goodware. Additionally, packed or obfuscated malwarethat produce erroneous disassembly may be somewhat beneficial because it couldproduce uncommon opcode sequences that my tool is able to attribute to malware.5.3.3 Machine LearningI implemented my entire tool with Python3 and Tensorflow with Keras. I useda basic ensemble configuration to test and compare my different feature sets. Myensemble is two layers, a set of base classifiers that feed into a second-level classifierthat takes the output probabilities of the base classifiers as input. I chose to use anensemble configuration due to its success in previous works. Each base classifier is134described below.The first base classifier is trained on a set of static features I call my basestatic features. This set of features is described in 5.2.2. This set of features totaled1,302 features in total. I chose to train an Multi-Layer Perceptron (MLP) neuralnetwork to train on the base static features. I found that through testing the MLPwas able to handle the large number of features well in a reasonable amount of time.For my MLP configuration, I used one hidden layer with a size equal to the inputlayer with dropout set to 0.5 between each. I used a learning rate of 0.01, learningrate decay of 1e-6, and Nesterov momentum set to 0.9. For my first two layers, Iused a rectified linear unit activation function. I trained the MLP for 45 epochsas I observed in my training that my tool’s accuracy on the validation set leveledoff after 45 epochs. The final layer of my tool was a Softmax layer used to outputa probability of maliciousness. I trained and tested the MLP using a 4-fold crossvalidation.The second base classifier is trained on the set features described in 5.2.3, whichI call the rule-based features. These features were all boolean features and generatedfrom the YARA open-source project as well as the Python library PEID [102].My dataset had 2,002 collective features from these tools. I used the same MLPconfiguration as above to train and test the accuracy of this feature set. This modelwas also trained for 45 epochs as the validation accuracy leveled off. A 4-fold crossvalidation was used here as well.The third base classifier was my opcode sequence CNN model described in5.2.4. I chose to feed in sequences of length 10,000 opcodes after testing various135sequence lengths because it performed the best by a slight margin with reasonabletraining times. During the training phase, I found that in practice training on arandomly selected contiguous chunk of 10K opcode sequences from within a programin a given class was more efficient versus training on the every 10K contiguous chunkof each program. Due to the large number of samples in my dataset, there were asubset of programs with extremely long disassemblies, which made training timeshighly impractical. Thus, the CNN model was trained with contiguous chunks of10K opcode sequences from within the malware or goodware training samples. Irandomly chose 10K opcode sequences within each binary versus choosing the first10K opcode sequence to prevent bias and overfitting on the code located at theentry point. During the testing phase, I feed each 10K opcode sequence chunk fromthe entire testing sample into the CNN and backend MLP to get a set of predictionprobabilities. To get a final determination for a given sample, I average the outputprobabilities. I originally tried taking the max, but found that it caused a highnumber of false positives. In practice, I found that this configuration of trainingand testing performed best while maintaining practical training times.For configuration of the CNN itself, it uses a set of two gated convolutionallayers followed by the max pooling layer along the opcode dimension. Each gatedconvolutional layer uses two sets of convolutional filters. The output of the first setof filters is passed through a sigmoid activation function that maps the output valuesto the interval ¡0,1¿. These values are then element-wise multiplied by the outputs ofthe second set of convolutional filters. This gated convolution configuration followsthe approach in [107]. The intermediate output from the max pooling layer is an136automatically generated feature vector with a 1x100 dimension. This generatedfeature vector was then fed into the same MLP configuration as the other basemodels mentioned above to get a final prediction. For programs that did not haveat least 10K opcodes, I padded the opcode sequence with a null opcode reservedspecifically to pad my sequence vectors. I used a 4-fold cross validation here.The 2nd-layer classifier I chose to use to train on the output probabilitiesof the base classifiers was the Random Forest algorithm. I found that throughexperimentation that Random Forest was the best performing 2nd-level classifierfor my testing scenario. I built the Random Forest classifier with 300 estimatorsfrom the SkLearn Python library.5.4 

Results5.4.1 The Addition of Opcode Sequence-based CNN FeaturesThe first test 

Results I collected shown in table 5.1 shows the accuracy of twoensemble configurations. The second row shows the first (labeled base+pattern)configuration where the base classifiers include the MLP trained on the base staticfeatures and the MLP trained on the pattern-matching features. The second con-figuration (labeled base+pattern+opcode) is when the base models include the twopreviously mentioned models plus my opcode sequence CNN model. The secondcolumn abbreviated DR stands for detection rate. The third column has the F1score, which is a common machine learning accuracy metric. The fourth columnhas the AUC, which is short for Area Under the Curve, of the Receiver Operating137Characteristic (ROC) curve. The last column has the False Negative (FN) reductionor the reduction in the number of malware missed.Base Models DR F1 score AUC FN ReductionBase+Pattern 90.91% 0.959 0.988 –Base+Pattern+Opcode 94.56% 0.971 0.994 40.2%Table 5.1: Ensemble 

Results with Various Base Classifiers at a 1% FPRThe table of 

Results showcase the following 



Conclusions. First, it shows therelatively good performance of using the base static features and the pattern-basedfeature set. The AUC is nearly 99%, which is inline with we saw in other priorworks on similar sized datasets using static analysis. The more significant findingis the 40% reduction in the false negative rate or the number of missed malwarewhen adding the automatically generated opcode sequence features into the firstensemble configuration. The false negative reduction is calculated by subtractingthe false negative rate of the second model (5.44%) from the false negative rate ofthe first model (9.09%) and then dividing the resulting number (9.09% - 5.44% =3.65%) by the false negative rate of the first model (3.65% / 9.09% = 40.2%). TheAUC and F1 score similarly have gains of 50% and 29.3%. The value added to theexisting static detection tool is evident.Looking closer at the 

Results, my hypothesis that adding this set of automati-cally generated opcode sequence-based features adds value in the context of malwaredetection is confirmed. Furthermore, after the analysis of my malware dataset andgoodware dataset revealed that 52.4% and 24.92%, respectively, were packed, the138fact that the CNN model was still capable of producing quality features based ondisassembly produced by linear sweep that helped differentiate more malware andgoodware than using other standard static features alone is significant. This showsthe promise of using CNNs to automatically produce features that are valuable forbettering malware detection while reducing the manual labor involved in generatingfeatures specific to malware.Figure 5.1 shows the ROC curve for both ensemble configurations. As shown,the second model with the CNN-generated features outperforms the other configu-ration across a multitude of false positive rates.Figure 5.1: ROC plot for Ensemble with 0% ≤ FPR ≤ 10%5.4.2 Zero-day Malware DetectionIn order to further test the value of my opcode sequence-based CNN features,I ran a simulated zero-day malware detection test. I trained my base models only on139goodware and malware from before 2014 within my dataset and tested on goodwareand malware that were compiled after 2015. This 

Results in 73,475 malware and83,988 goodware in the training set and 23,946 malware and 17,993 goodware in thetest set. The 

Results are shown in table 5.2.Base Models DR F1 score AUC FN ReductionBase+Pattern 72.25% 0.923 0.966 –Base+Pattern+Opcode 87.04% 0.951 0.986 53.3%Table 5.2: Simulated Zero-day Test: Ensemble 

Results with Various Base Classifiersat a 1.5% FPRThe purpose of this test was to confirm prior work’s claims that features suchas exact pattern matching or other boolean features such as the presence or absenceof specific APIs were prone to overfitting while showing that CNN-based featuresare less prone. Overfitting would cause superficially high accuracies on datasets thatcontained similar samples in the test set and training set (as seen in most malwaredatasets) and significantly lower accuracies on samples unseen before. As shownin the second row, the detection rate, F1 score, and AUC of the model withoutthe opcode sequence-based features drop off dramatically. The detection rate onthis test shows a decrease of 22.1% when compared to its detection rate of 92.75%with a 1.5% FPR on the standard 4-fold CV test. Although the model with theopcode sequence-based features also has a dip in performance, it is only a loss of9.0% compared to its detection rate of 96.71% with a 1.5% FPR on the standard4-fold CV test. In other related work studied, I saw a similar dip in performance140when testing across time because malware is constantly changing to adapt to recentupdates, platforms, vulnerabilities, and detection techniques.When compared head to head, the model with the additional opcode sequence-based features reduces the false negative rate of the model without it by over 50%.This helps confirm that the opcode sequence features generated by the CNN areuseful in reducing the inability of other feature sets, which are solely based onboolean features or exact matches, to generalize better.This time test overall shows that there is still significant work to be done tobe able to build malware detection tools that can reliably detect zero-day malware.As the landscape of malware continues to change rapidly, the information malwaredetection tools draw upon has to change and be updated equally rapidly. The onlyway to do this is through automation. Although the opcode sequence-based featurevectors are not the complete answer, the promise they showed in improving theaccuracy without needing prior knowledge on what the latest malware trends wereis significant and interesting area of future research.5.4.3 CNN Robustness TestTo further confirm that the CNN is capable of robustly handling minor changesin the raw input sequence and performing some form of fuzzy matching, I conductedan experiment on a randomly chosen test set of 24,213 malware. I changed a varyingpercentage of the opcodes in the input sequence and measured the change in theoutput probability of maliciousness. I randomly chose the opcodes to alter within141each input sequence using a random number generator for the location and ensuredthat there was no repeats in locations chosen. I also used a random number gen-erator to come up with the opcode that replaced the existing opcode. I varied thepercentage of opcodes randomly replaced in the following increments: 5%, 10%,20%, 30%, 40%, 50%. The 

Results in the change of the output probability are shownin Figure 5.2.Figure 5.2: Robustness Test 

ResultsThe 

Results confirm that CNNs are indeed more than capable at handlingsmall to fairly large changes in the input sequence without the changes having alarge effect on the output probability. Despite up to 50% of the input opcodes inthe input sequence being changed, the CNN model’s probability of maliciousnessonly decreased by an average of 9.32% compared to its original probability of ma-liciousness on the original unchanged input sequence. This is a desirable quality in142malware detection because malware can have arbitrary changes in its code 



Sectionsthat may not directly affect the overall function of the malware. In these 



Scenarios,it is beneficial to still classify these similar, but not identical opcode sequences assequences originating in malware. This robustness gives our CNN model a signifi-cant advantage over exact-pattern matching feature sets. Exact-pattern matchingfeature sets are more strict and thus could be more heavily affected by small arbi-trary changes in the malware, resulting in a higher likelihood of overfitting and poorgeneralization 

Results.5.4.4 Similarity Analysis and 



Future WorkAt an intuitive level, the CNN model is performing a fuzzy match of opcodesequences found in goodware and malware automatically. Using this information andby analyzing the resulting generated feature vectors, a simple similarity test can beperformed. By storing all of the generated feature vectors by the CNN model formalware and goodware, I ran a test to see how similar two different programs wereif their respective input opcode sequences mapped to the same feature vector. Ichose to focus on the generated feature based on the first 10K opcode sequences ofeach program as I found that it was the most reliable in delivering the most qualitymatches.I first found out the most commonly generated features that were element-wise equal and near equal. The most commonly generated feature was found 1,023times, all occurring from malware. Taking a closer look, I found that all 1,023143of these malware had the same list of 41 imported APIs, giving high confidencethat these malware had very similar if not the same opcode sequences. This issomewhat of an expected finding as intuitively the CNN was finding similar opcodesequences that were specific to goodware or malware. I further investigated thenext ten most common embeddings and their associated occurrences from goodwareor malware. Each set of programs that had the same generated feature were allexclusively malware and imported the same set of Windows APIs respectively. Inthe small 

Case Studies done, the confirmation that the CNN model is finding similarprograms based solely on opcode sequences without the use of any prior humanexpertise is significant because it opens up the prospect of potentially using thissystem not only as a malware detection engine, but as a malware analysis tool. Thebiggest benefit here is that this was done automatically.I am not proposing this work as a general malware classification tool, as thereare many other works that focus exclusively on that area. However, I do think thereis potential for this framework to be used in the future to automatically find malwarethat have very similar code. Although this tool is not as general as other classifi-cation tools, based on my limited analysis, there is potential for future research tolook more heavily into this technique.5.5 Related Work[4] used Echo State Networks (ESNs) and Recurrent Neural Networks (RNNs)in order to automatically generate features for the purpose of malware detection.144However, their schemes relied on the dynamic sequence of specific Windows APIscalled whereas my tool only requires the static disassembly of the program, which isfaster and easier to obtain. Additionally, the authors had to first condense the low-level APIs into distinct, high-level events to consolidate behaviors such as openinga file since there is more than one API to do so. My approach does not require thesame level effort in terms of preprocessing or prior knowledge.[3] used a CNN to produce features from a raw sequence of bytes from aprogram. Their approach consisted of feeding in the whole binary (up to 2 millionbytes), disregarding the inherent structure of the binary, into the CNN in order togenerate a feature and ultimately provide a classification between goodware andmalware. Their work on a comparably sized dataset achieved less than 90% overallaccuracy whereas my CNN model alone is able to achieve 93% overall. Becausetheir work treats each byte as a sequence unit, their work could be less resilient toarbitrary changes made such as changes in the data 



Section. The data 



Section ofa program, especially if it is packed or encrypted in some way will be significantlydifferent from compilation to compilation, which can cause issues in their scheme.My model takes into account the inherent structure of the binary and recognizesthat the opcode sequence is a better representation of a program, which is backedup by my 

Results.[108] introduces an automatic string signature generation system in order todetect specific strings in malware with near-zero detections in goodware. Althoughtheir goal of malware detection is similar to ours, their programs need to be unpackedprior to being fed into their system. This is a significant disadvantage because of the145time and effort required to accurately unpack programs. Their paper reveals thatless than 55% of their original malware dataset were successfully unpacked. Also,their system uses exact matches, which has a low false positive rate, but can causeoverfitting.Many works such as [109, 110] have used various types of neural networks inorder to generate features for the purpose of malware classification, not malwaredetection. [109] uses CNNs and RNNs with the dynamic system call trace as inputto identify which family of malware a sample belonged to. [110] uses an unsuperviseddeep belief network that takes as input dynamic behavior from malware and outputsa malware family classification. My work is different from this class of work becausemy automatic feature generation is for the purpose of malware detection.Other works such as [45, 49, 50, 71, 77, 104] propose machine learning-basedmalware detection tool based on static features such as PE imports, strings, andother metadata. As previously mentioned, these types of features are more proneto overfitting than perhaps a CNN model would be and thus when run in a timesplit experiment, their performance drops off rapidly. This is also supported by ourfindings in our 

Results.Work such as [105, 111] use similar natural language processing methods formalware detection goals, but differ from my work because [111] focuses on capturingmalicious payloads and [105] focuses solely on android malware.1465.6 

ConclusionThe need for further advancements in the static detection of malware withmachine learning is necessary to handle the ever-growing cyber threats. The useof CNNs and raw opcode sequences is innovative because it reduces the need formalware and malicious code expertise and manual analysis. Instead, it relies onthe CNN’s ability to generate quality features that are helpful to existing staticdetection tools. My 

Results show that with the added CNN model’s automaticallygenerated features, it can reduce the false negative rate of a tool trained on existingfeatures by over 40% and by over 50% on a simulated zero-day test. Additionally, ourCNN model is capable of robustly handling minor changes in the input sequencesof opcodes, resulting in a fuzzy matching of opcode sequences from malware orgoodware. This is an advantage over previous work that relied on exact or near-exact matches and proves to be more robust in practice. Although the featuresgenerated from the CNN model are not the complete solution to malware detection,it shows promise is finding opcode sequences specific to goodware or malware whilemaintaining the flexibility needed to handle modern malware.147



Chapter 6: 

ConclusionMalware is a decidedly hard problem to solve. Windows PE32 executables areonly a small slice of the total problem that malware presents. My Ph.D. research hasshown that both properly understanding malware and the ways in which it is oftendetected leads to useful research. By targeting fundamental behaviors, such as theways that malware attempts to hide from static detection tools, my work shows thatmalware can be identified by their attempts using dynamic program-level analysis.With the understanding of how malware detection tools are developed and the timeit takes to find malicious indicators, my CNN work is able to reduce the time andknowledge necessary to produce high-quality features indicative of malware. Lastly,by properly understanding how current malware detection tools are setup, my workcombining static and dynamic analysis methods shows that the tradeoff is not linearand improves upon existing hybrid detection schemes.148Bibliography[1] Symantec Corporation. Internet security threat report. 21:5, apr 2016.[2] Richard Zak, Edward Raff, and Charles Nicholas. What can n-grams learn formalware detection? In 2017 12th International Conference on Malicious andUnwanted Software (MALWARE), pages 109–118. IEEE, 2017.[3] Edward Raff, Jon Barker, Jared Sylvester, Robert Brandon, Bryan Catan-zaro, and Charles K Nicholas. Malware detection by eating a whole exe. InWorkshops at the Thirty-Second AAAI Conference on Artificial Intelligence,2018.[4] Razvan Pascanu, Jack W Stokes, Hermineh Sanossian, Mady Marinescu, andAnil Thomas. Malware classification with recurrent networks. In Acoustics,Speech and Signal Processing (ICASSP), 2015 IEEE International Conferenceon, pages 1916–1920. IEEE, 2015.[5] Philip O’Kane, Sakir Sezer, and Keiran McLaughlin. Obfuscation: The hiddenmalware. Security & Privacy, IEEE, 9(5):41–47, 2011.[6] Andreas Moser, Christopher Kruegel, and Engin Kirda. Limits of static analy-sis for malware detection. In Computer security applications conference, 2007.ACSAC 2007. Twenty-third annual, pages 421–430. IEEE, 2007.[7] Xinran Wang, Yoon-Chan Jhi, Sencun Zhu, and Peng Liu. Still: Exploit codedetection via static taint and initialization analyses. In Computer SecurityApplications Conference, 2008. ACSAC 2008. Annual, pages 289–298. IEEE,2008.[8] Kevin A Roundy and Barton P Miller. Binary-code obfuscations in prevalentpacker tools. ACM Journal Name, 1:21, 2012.[9] Daniel A Quist and Lorie M Liebrock. Visualizing compiled executables formalware analysis. In Visualization for Cyber Security, 2009. VizSec 2009. 6thInternational Workshop on, pages 27–32. IEEE, 2009.149[10] Artem Dinaburg, Paul Royal, Monirul Sharif, and Wenke Lee. Ether: mal-ware analysis via hardware virtualization extensions. In Proceedings of the15th ACM conference on Computer and communications security, pages 51–62. ACM, 2008.[11] Danny Quist and V Smith. Covert debugging circumventing software armoringtechniques. Black hat briefings USA, 2007.[12] Ulrich Bayer, Andreas Moser, Christopher Kruegel, and Engin Kirda. Dy-namic analysis of malicious code. Journal in Computer Virology, 2(1):67–77,2006.[13] Matias Madou, Ludo Van Put, and Koen De Bosschere. Understanding ob-fuscated code. In Program Comprehension, 2006. ICPC 2006. 14th IEEEInternational Conference on, pages 268–274. IEEE, 2006.[14] Jesse C Rabek, Roger I Khazan, Scott M Lewandowski, and Robert K Cun-ningham. Detection of injected, dynamically generated, and obfuscated ma-licious code. In Proceedings of the 2003 ACM workshop on Rapid malcode,pages 76–82. ACM, 2003.[15] Joe Stewart. Ollybone: Semi-automatic unpacking on ia-32. In Proceedingsof the 14th DEF CON Hacking Conference, 2006.[16] Monirul Sharif, Andrea Lanzi, Jonathon Giffin, and Wenke Lee. Automaticreverse engineering of malware emulators. In Security and Privacy, 2009 30thIEEE Symposium on, pages 94–109. IEEE, 2009.[17] Dawn Song, David Brumley, Heng Yin, Juan Caballero, Ivan Jager,Min Gyung Kang, Zhenkai Liang, James Newsome, Pongsin Poosankam, andPrateek Saxena. Bitblaze: A new approach to computer security via binaryanalysis. In Information systems security, pages 1–25. Springer, 2008.[18] Chi-Keung Luk, Robert Cohn, Robert Muth, Harish Patil, Artur Klauser,Geoff Lowney, Steven Wallace, Vijay Janapa Reddi, and Kim Hazelwood. Pin:building customized program analysis tools with dynamic instrumentation. InAcm sigplan notices, volume 40, pages 190–200. ACM, 2005.[19] Carsten Willems, Thorsten Holz, and Felix Freiling. Toward automated dy-namic malware analysis using cwsandbox. IEEE Security & Privacy, (2):32–39, 2007.[20] Rob Pike, Bart Locanthi, and John Reiser. Hardware/software trade-offs forbitmap graphics on the blit. Softw., Pract. Exper., 15(2):131–151, 1985.[21] Igor Santos, Jaime Devesa, Felix Brezo, Javier Nieves, and Pablo GarciaBringas. Opem: A static-dynamic approach for machine-learning-based mal-ware detection. In International Joint Conference CISIS12-ICEUTE 12-SOCO 12 Special Sessions, pages 271–280. Springer, 2013.150[22] Paul Royal, Mitch Halpin, David Dagon, Robert Edmonds, and Wenke Lee.Polyunpack: Automating the hidden-code extraction of unpack-executing mal-ware. In Computer Security Applications Conference, 2006. ACSAC’06. 22ndAnnual, pages 289–300. IEEE, 2006.[23] Piotr Bania. Generic unpacking of self-modifying, aggressive, packed binaryprograms. arXiv preprint arXiv:0905.4581, 2009.[24] Bertrand Anckaert, Matias Madou, and Koen De Bosschere. A model forself-modifying code. In Information Hiding, pages 232–248. Springer, 2006.[25] Saumya Debray and Jay Patel. Reverse engineering self-modifying code: Un-packer extraction. In Reverse Engineering (WCRE), 2010 17th Working Con-ference on, pages 131–140. IEEE, 2010.[26] Jonas Maebe and Koen De Bosschere. Instrumenting self-modifying code.arXiv preprint cs/0309029, 2003.[27] Sudeep Ghosh, Jason Hiser, and Jack W Davidson. Software protection fordynamically-generated code. In Proceedings of the 2nd ACM SIGPLAN Pro-gram Protection and Reverse Engineering Workshop, page 1. ACM, 2013.[28] Microsoft Coporation. What is data execution prevention? may 2016.[29] Oleh Yuschuk. Ollydbg, 2007.[30] Lorenzo Martignoni, Mihai Christodorescu, and Somesh Jha. Omniunpack:Fast, generic, and safe unpacking of malware. In Computer Security Applica-tions Conference, 2007. ACSAC 2007. Twenty-Third Annual, pages 431–441.IEEE, 2007.[31] Lingyun Ying, Purui Su, Dengguo Feng, Xianggen Wang, Yi Yang, and Yu Liu.Reconbin: Reconstructing binary file from execution for software analysis. InSecure Software Integration and Reliability Improvement, 2009. SSIRI 2009.Third IEEE International Conference on, pages 222–229. IEEE, 2009.[32] Min Gyung Kang, Pongsin Poosankam, and Heng Yin. Renovo: A hidden codeextractor for packed executables. In Proceedings of the 2007 ACM workshopon Recurring malcode, pages 46–53. ACM, 2007.[33] Christian Collberg, Clark Thomborson, and Douglas Low. A taxonomy of ob-fuscating transformations. Technical report, Department of Computer Science,The University of Auckland, New Zealand, 1997.[34] Chandra Prakash. Design of x86 emulator for generic unpacking. In Assocationof Anti-Virus Asia Researchers International Conference. Seoul, South Korea,2007.151[35] Igor V Popov, Saumya K Debray, and Gregory R Andrews. Binary obfuscationusing signals. In Usenix Security, 2007.[36] Aditya Kapoor. An approach towards disassembly of malicious binary exe-cutables. PhD thesis, University of Louisiana at Lafayette, 2004.[37] Claudio Guarnieri, Allessandro Tanasi, Jurriaan Bremer, and Mark Schloesser.The cuckoo sandbox, 2012.[38] Avi Kivity, Yaniv Kamay, Dor Laor, Uri Lublin, and Anthony Liguori. kvm:the linux virtual machine monitor. In Proceedings of the Linux symposium,volume 1, pages 225–230, 2007.[39] Thomas Hungenberg and Matthias Eckert. Inetsim: Internet services simula-tion suite, 2013.[40] National Institute of Standards and Technology. National software referencelibrary. Online.[41] Bum Jun Kwon, Jayanta Mondal, Jiyong Jang, Leyla Bilge, and Tudor Dumi-tras. The dropper effect: Insights into malware distribution with downloadergraph analytics. In Proceedings of the 22nd ACM SIGSAC Conference onComputer and Communications Security, pages 1118–1129. ACM, 2015.[42] Yi-Min Wang, Binh Vo, Roussi Roussev, Chad Verbowski, and Aaron Johnson.Strider ghostbuster: Why itsa bad idea for stealth software to hide files. Tech-nical report, Technical Report MSR-TR-2004-71, Microsoft Research, 2004.[43] Tony Rodrigues. Extracting known bad hash set from nsrl, feb 2010.[44] Stephen M Blackburn, Robin Garner, Chris Hoffmann, Asjad M Khang,Kathryn S McKinley, Rotem Bentzur, Amer Diwan, Daniel Feinberg, DanielFrampton, Samuel Z Guyer, et al. The dacapo benchmarks: Java benchmark-ing development and analysis. In ACM Sigplan Notices, volume 41, pages169–190. ACM, 2006.[45] Igor Santos, Felix Brezo, Xabier Ugarte-Pedrero, and Pablo G Bringas. Op-code sequences as representation of executables for data-mining-based un-known malware detection. Information Sciences, 231:64–82, 2013.[46] P Vinod, Vijay Laxmi, and Manoj Singh Gaur. Scattered feature space formalware analysis. Advances in Computing and Communications, pages 562–571, 2011.[47] Gil Tahan, Lior Rokach, and Yuval Shahar. Mal-id: Automatic malware detec-tion using common segment analysis and meta-features. Journal of MachineLearning Research, 13(Apr):949–979, 2012.152[48] J Zico Kolter and Marcus A Maloof. Learning to detect and classify maliciousexecutables in the wild. Journal of Machine Learning Research, 7(Dec):2721–2744, 2006.[49] Matthew G Schultz, Eleazar Eskin, F Zadok, and Salvatore J Stolfo. Datamining methods for detection of new malicious executables. In Security andPrivacy, 2001. S&P 2001. Proceedings. 2001 IEEE Symposium on, pages 38–49. IEEE, 2001.[50] Igor Santos, Javier Nieves, and Pablo Garcia Bringas. Semi-supervised learn-ing for unknown malware detection. In DCAI, pages 415–422. Springer, 2011.[51] Eitan Menahem, Asaf Shabtai, Lior Rokach, and Yuval Elovici. Improvingmalware detection by applying multi-inducer ensemble. Computational Statis-tics & Data Analysis, 53(4):1483–1494, 2009.[52] Jeremy Z Kolter and Marcus A Maloof. Learning to detect malicious exe-cutables in the wild. In Proceedings of the tenth ACM SIGKDD internationalconference on Knowledge discovery and data mining, pages 470–478. ACM,2004.[53] Roberto Perdisci, Andrea Lanzi, and Wenke Lee. Mcboost: Boosting scala-bility in malware collection and analysis using statistical classification of exe-cutables. In Computer Security Applications Conference, 2008. ACSAC 2008.Annual, pages 301–310. IEEE, 2008.[54] Yanfang Ye, Lifei Chen, Dingding Wang, Tao Li, Qingshan Jiang, and MinZhao. Sbmds: an interpretable string based malware detection system usingsvm ensemble with bagging. Journal in computer virology, 5(4):283–293, 2009.[55] Igor Santos, Yoseba K Penya, Jaime Devesa, and Pablo Garcia Bringas. N-grams-based file signatures for malware detection. ICEIS (2), 9:317–320, 2009.[56] S Momina Tabish, M Zubair Shafiq, and Muddassar Farooq. Malware de-tection using statistical analysis of byte-level file content. In Proceedings ofthe ACM SIGKDD Workshop on CyberSecurity and Intelligence Informatics,pages 23–31. ACM, 2009.[57] Tony Abou-Assaleh, Nick Cercone, Vlado Keselj, and Ray Sweidan. N-gram-based detection of new malicious code. In Computer Software and ApplicationsConference, 2004. COMPSAC 2004. Proceedings of the 28th Annual Interna-tional, volume 2, pages 41–42. IEEE, 2004.[58] Robert Moskovitch, Dima Stopel, Clint Feher, Nir Nissim, and Yuval Elovici.Unknown malcode detection via text categorization and the imbalance prob-lem. In Intelligence and Security Informatics, 2008. ISI 2008. IEEE Interna-tional Conference on, pages 156–161. IEEE, 2008.153[59] Robert Moskovitch, Clint Feher, Nir Tzachar, Eugene Berger, Marina Gitel-man, Shlomi Dolev, and Yuval Elovici. Unknown malcode detection usingopcode representation. Intelligence and Security Informatics, pages 204–215,2008.[60] Robert Moskovitch, Clint Feher, and Yuval Elovici. Unknown malcode detec-tiona chronological evaluation. In Intelligence and Security Informatics, 2008.ISI 2008. IEEE International Conference on, pages 267–268. IEEE, 2008.[61] Olivier Henchiri and Nathalie Japkowicz. A feature selection and evaluationscheme for computer virus detection. In Data Mining, 2006. ICDM’06. SixthInternational Conference on, pages 891–895. IEEE, 2006.[62] Boyun Zhang, Jianping Yin, Jingbo Hao, Dingxing Zhang, and Shulin Wang.Malicious codes detection based on ensemble learning. Autonomic and trustedcomputing, pages 468–477, 2007.[63] Yuval Elovici, Asaf Shabtai, Robert Moskovitch, Gil Tahan, and ChananGlezer. Applying machine learning techniques for detection of malicious codein network traffic. In Annual Conference on Artificial Intelligence, pages 44–50. Springer, 2007.[64] Yi-Bin Lu, Shu-Chang Din, Chao-Fu Zheng, and Bai-Jian Gao. Using multi-feature and classifier ensembles to improve malware detection. Journal ofCCIT, 39(2):57–72, 2010.[65] Konrad Rieck, Philipp Trinius, Carsten Willems, and Thorsten Holz. Auto-matic analysis of malware behavior using machine learning. Journal of Com-puter Security, 19(4):639–668, 2011.[66] Swapna Vemparala. Malware detection using dynamic analysis. 2015.[67] MG Kang, P Poosankam, and H Yin Renovo. A hidden code extractor forpacked executables [c]. In Workshop on Recurring Malcode (WORM 2007),2007.[68] Matt Fredrikson, Somesh Jha, Mihai Christodorescu, Reiner Sailer, and XifengYan. Synthesizing near-optimal malware specifications from suspicious behav-iors. In Security and Privacy (SP), 2010 IEEE Symposium on, pages 45–60.IEEE, 2010.[69] Clemens Kolbitsch, Paolo Milani Comparetti, Christopher Kruegel, EnginKirda, Xiao-yong Zhou, and XiaoFeng Wang. Effective and efficient malwaredetection at the end host. In USENIX security symposium, volume 4, pages351–366, 2009.[70] Danny Kim, Amir Majlesi-Kupaei, Julien Roy, Kapil Anand, Khaled El-Wazeer, Daniel Buettner, and Rajeev Barua. Dynodet: Detecting dynamic154obfuscation in malware. In International Conference on Detection of Intru-sions and Malware, and Vulnerability Assessment, pages 97–118. Springer,2017.[71] Yanfang Ye, Dingding Wang, Tao Li, Dongyi Ye, and Qingshan Jiang. Anintelligent pe-malware detection system based on association mining. Journalin computer virology, 4(4):323–334, 2008.[72] Christian Rossow, Christian J Dietrich, Chris Grier, Christian Kreibich, VernPaxson, Norbert Pohlmann, Herbert Bos, and Maarten Van Steen. Prudentpractices for designing malware experiments: Status quo and outlook. InSecurity and Privacy (SP), 2012 IEEE Symposium on, pages 65–79. IEEE,2012.[73] Derek Bruening and Saman Amarasinghe. Efficient, transparent, and com-prehensive runtime code manipulation. PhD thesis, Massachusetts Instituteof Technology, Department of Electrical Engineering and Computer Science,2004.[74] Fabian Pedregosa, Gael Varoquaux, Alexandre Gramfort, Vincent Michel,Bertrand Thirion, Olivier Grisel, Mathieu Blondel, Peter Prettenhofer, RonWeiss, Vincent Dubourg, et al. Scikit-learn: Machine learning in python.Journal of Machine Learning Research, 12(Oct):2825–2830, 2011.[75] Francois Chollet. Keras: deep learning library for theano and tensorflow. 2015.[76] Tomasz Kojm. Clamav, 2004.[77] Joshua Saxe and Konstantin Berlin. Deep neural network based malware de-tection using two dimensional binary program features. In Malicious and Un-wanted Software (MALWARE), 2015 10th International Conference on, pages11–20. IEEE, 2015.[78] Konstantin Berlin, David Slater, and Joshua Saxe. Malicious behavior detec-tion using windows audit logs. In Proceedings of the 8th ACM Workshop onArtificial Intelligence and Security, pages 35–44. ACM, 2015.[79] Ulrich Bayer, Engin Kirda, and Christopher Kruegel. Improving the efficiencyof dynamic malware analysis. In Proceedings of the 2010 ACM Symposium onApplied Computing, pages 1871–1878. ACM, 2010.[80] Grégoire Jacob, Paolo Milani Comparetti, Matthias Neugschwandtner,Christopher Kruegel, and Giovanni Vigna. A static, packer-agnostic filterto detect similar malware samples. In International Conference on Detec-tion of Intrusions and Malware, and Vulnerability Assessment, pages 102–122.Springer, 2012.[81] Georg Wicherski. pehash: A novel approach to fast malware clustering. LEET,9:8, 2009.155[82] Engin Kirda and C Kruegel. Large-Scale Dynamic Malware Analysis. PhDthesis, PhD Dissertation, Technical University of Vienna, 2009.[83] Ulrich Bayer, Paolo Milani Comparetti, Clemens Hlauschek, ChristopherKruegel, and Engin Kirda. Scalable, behavior-based malware clustering. InNDSS, volume 9, pages 8–11. Citeseer, 2009.[84] Joris Kinable and Orestis Kostakis. Malware classification based on call graphclustering. Journal in computer virology, 7(4):233–245, 2011.[85] Silvio Cesare and Yang Xiang. A fast flowgraph based classification system forpacked and polymorphic malware on the endhost. In Advanced InformationNetworking and Applications (AINA), 2010 24th IEEE International Confer-ence on, pages 721–728. IEEE, 2010.[86] Igor Santos, Felix Brezo, Javier Nieves, Yoseba K Penya, Borja Sanz, Car-los Laorden, and Pablo G Bringas. Idea: Opcode-sequence-based malwaredetection. In International Symposium on Engineering Secure Software andSystems, pages 35–43. Springer, 2010.[87] Vinod P Nair, Harshit Jain, Yashwant K Golecha, Manoj Singh Gaur, andVijay Laxmi. Medusa: Metamorphic malware dynamic analysis usingsignaturefrom api. In Proceedings of the 3rd International Conference on Security ofInformation and Networks, pages 263–269. ACM, 2010.[88] Sean Kilgallon, Leonardo De La Rosa, and John Cavazos. Improving the ef-fectiveness and efficiency of dynamic malware analysis with machine learning.In Resilience Week (RWS), 2017, pages 30–36. IEEE, 2017.[89] Toshiki Shibahara, Takeshi Yagi, Mitsuaki Akiyama, Daiki Chiba, and TakeshiYada. Efficient dynamic malware analysis based on network behavior usingdeep learning. In Global Communications Conference (GLOBECOM), 2016IEEE, pages 1–7. IEEE, 2016.[90] Osamah L Barakat, Shaiful J Hashim, Raja Syamsul Azmir B Raja Abdul-lah, Abdul Rahman Ramli, Fazirulhisyam Hashim, Khairulmizam Samsudin,and Mahmud Ab Rahman. Malware analysis performance enhancement us-ing cloud computing. Journal of Computer Virology and Hacking Techniques,10(1):1–10, 2014.[91] Matthias Neugschwandtner, Paolo Milani Comparetti, Gregoire Jacob, andChristopher Kruegel. Forecast: skimming off the malware cream. In Proceed-ings of the 27th Annual Computer Security Applications Conference, pages11–20. ACM, 2011.[92] Matilda Rhode, Pete Burnap, and Kevin Jones. Early stage malware predic-tion using recurrent neural networks. arXiv preprint arXiv:1708.03513, 2017.156[93] James B Fraley. Improved Detection for Advanced Polymorphic Malware. PhDthesis, Nova Southeastern University, 2017.[94] PV Shijo and A Salim. Integrated static and dynamic analysis for malwaredetection. Procedia Computer Science, 46:804–811, 2015.[95] Priyadarshani M Kate and Sunita V Dhavale. Two phase static analysis tech-nique for android malware detection. In Proceedings of the Third InternationalSymposium on Women in Computing and Informatics, pages 650–655. ACM,2015.[96] Lina Nouh, Ashkan Rahimian, Djedjiga Mouheb, Mourad Debbabi, andAiman Hanna. Binsign: fingerprinting binary functions to support automatedanalysis of code executables. In IFIP International Conference on ICT Sys-tems Security and Privacy Protection, pages 341–355. Springer, 2017.[97] Monirul Sharif, Vinod Yegneswaran, Hassen Saidi, Phillip Porras, and WenkeLee. Eureka: A framework for enabling static malware analysis. In EuropeanSymposium on Research in Computer Security, pages 481–500. Springer, 2008.[98] Sang Kil Cha, Iulian Moraru, Jiyong Jang, John Truelove, David Brumley,and David G Andersen. Splitscreen: Enabling efficient, distributed malwaredetection. Journal of Communications and Networks, 13(2):187–200, 2011.[99] D Swathigavaishnave and R Sarala. Detection of malicious code-injectionattack using two phase analysis technique. Pondicherry Engineering CollegePuducherry, India, 2012.[100] Virus Total. Virustotal-free online virus, malware and url scanner. Online:https://www. virustotal. com/en, 2012.[101] J-Michael Roberts. Virus share.(2011). URL https://virusshare. com, 2011.[102] Yara-rules. https://github.com/Yara-Rules/rules, 2017.[103][104] Zane Markel and Michael Bilzor. Building a machine learning classifier formalware detection. In Anti-malware Testing Research (WATeR), 2014 SecondWorkshop on, pages 1–4. IEEE, 2014.[105] Ziyun Zhu and Tudor Dumitras. Featuresmith: Automatically engineeringfeatures for malware detection by mining the security literature. In Proceedingsof the 2016 ACM SIGSAC Conference on Computer and CommunicationsSecurity, pages 767–778. ACM, 2016.[106] Cicero dos Santos and Maira Gatti. Deep convolutional neural networks forsentiment analysis of short texts. In Proceedings of COLING 2014, the 25th In-ternational Conference on Computational Linguistics: Technical Papers, pages69–78, 2014.157[107] Yann N Dauphin, Angela Fan, Michael Auli, and David Grangier. Languagemodeling with gated convolutional networks. In Proceedings of the 34th Inter-national Conference on Machine Learning-Volume 70, pages 933–941. JMLR.org, 2017.[108] Kent Griffin, Scott Schneider, Xin Hu, and Tzi-Cker Chiueh. Automatic gen-eration of string signatures for malware detection. In International workshopon recent advances in intrusion detection, pages 101–120. Springer, 2009.[109] Bojan Kolosnjaji, Apostolis Zarras, George Webster, and Claudia Eckert.Deep learning for classification of malware system call sequences. In Aus-tralasian Joint Conference on Artificial Intelligence, pages 137–149. Springer,2016.[110] Omid E David and Nathan S Netanyahu. Deepsign: Deep learning for au-tomatic malware signature generation and classification. In Neural Networks(IJCNN), 2015 International Joint Conference on, pages 1–8. IEEE, 2015.[111] Sam Small, Joshua Mason, Fabian Monrose, Niels Provos, and Adam Stubble-field. To catch a predator: A natural language approach for eliciting maliciouspayloads. In USENIX Security Symposium, pages 171–184, 2008.158
