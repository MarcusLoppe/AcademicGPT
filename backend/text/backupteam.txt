from communication.ClientUpdate import ClientUpdate  
import openai 
from agent_request import get_research_informatio2n
from autogen import config_list_from_json,Agent,oai 
from ExtenedAgents import ChatMixin,ExtendedAssistantAgent,ExtendedUserGroupChat,ExtendedUserGroupChatManager,ExtendedUserProxyAgent
 
config_list = config_list_from_json(env_or_file="OAI_CONFIG_LIST")
api_key = "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"
openai.api_key= api_key   

# What is the limit of data compress?
class AgentTeam: 
    ClientUpdator : ClientUpdate 
    Objective: str
 
    def __init__(self, updater: ClientUpdate):
        self.ClientUpdator = updater 

    def start_agents(self, message): 
        self.Objective = message
        llm_config_content_assistant = {
            "functions": [
                    {
                    "name": "get_research_information",
                    "description": "search for recent academic information",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "search_keywords": {
                                "type": "string",
                                "description": "search keyword for academic research titles",
                            },
                            "search_text": {
                                "type": "string",
                                "description": "phrase to be used to search in acedemic paper for information",
                            } 
                        },
                        "required": ["search_keywords","search_text"],
                    }
                }, 
                
                {
                    "name": "write_content",
                    "description": "Write content based on the given research material & topic",
                    "parameters": {
                            "type": "object",
                            "properties": {
                                "research_material": {
                                    "type": "string",
                                    "description": "research material of a given topic, including reference links when available",
                                },
                                "topic": {
                                    "type": "string",
                                    "description": "The topic of the content",
                                }
                            },
                        "required": ["research_material", "topic"],
                    },
                },
            ],
            "config_list": config_list}    
        
        writing_assistant = ExtendedAssistantAgent(
            updater = self.ClientUpdator,
            name="writing_assistant",
            system_message="You are a writing assistant, you can use research function to collect latest information about a given topic, and then use write_content function to write a very well written content; Reply TERMINATE when your task is done",
            llm_config=llm_config_content_assistant, 
        )

        user_proxy = ExtendedUserProxyAgent(
            updater = self.ClientUpdator,
            name="User_proxy",
            human_input_mode="TERMINATE",
            function_map={
                "write_content": self.write_content,
                "get_research_information" : lambda **kwargs:  self.get_research_information(**kwargs), 
            }
        )  
        result = user_proxy.initiate_chat(
            writing_assistant, message= message)#"explain how 3d mesh can be compressed")
        
        self.ClientUpdator.ConversationChatResponse("Final response:", result)
        
    
    def get_research_information(self, search_keywords, search_text):    
        #data = get_research_informatio2n(self.ClientUpdator, self.Objective, search_keywords, search_text)
        with open('sum_short.txt', 'r', encoding='utf-8') as file: 
            data = file.read()
        print(data)
        return self.write_content(data, search_text)

    def research(self, topic):
        llm_config_researcher = {
            "functions": [
                {
                    "name": "get_research_information",
                    "description": "search for recent academic information",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "search_keywords": {
                                "type": "string",
                                "description": "search keyword for academic research titles",
                            },
                            "search_text": {
                                "type": "string",
                                "description": "phrase to be used to search in acedemic paper for information",
                            } 
                        },
                        "required": ["search_keywords","search_text"],
                    }
                } 
            ],
            "config_list": config_list
        }
        print("research called")
        print(topic)

        researcher = ExtendedAssistantAgent(
            updater = self.ClientUpdator,
            name="researcher",
            system_message="Research about a given query, search to find as much academic information as possible, and generate detailed research article with all reference links attached; Add TERMINATE to the end of the research report;",
            #"Research about a given query by using the get_research_information function then generate a thorough and comprehensive research report. Ensure to include all citations and sources from the research; Add TERMINATE to the end of the research report;",
            llm_config=llm_config_researcher,
        )

        user_proxy = ExtendedUserProxyAgent(
            updater = self.ClientUpdator,
            name="User_proxy",
            code_execution_config={"last_n_messages": 2, "work_dir": "coding"},
            is_termination_msg=lambda x: x.get("content", "") and x.get(
                "content", "").rstrip().endswith("TERMINATE"), 
            human_input_mode="TERMINATE",
            function_map={ 
                "get_research_information" : lambda **kwargs:  self.get_research_information(self.ClientUpdator, self.Objective, **kwargs), 
            }
        )
     
        user_proxy.initiate_chat(researcher, message=topic)
    
        user_proxy.stop_reply_at_receive(researcher) 
        print("RETURNING ")
        print(user_proxy.last_message()["content"])
        return user_proxy.last_message()["content"]
     
    def write_content(self, research_material, topic):   
        self.ClientUpdator.ConversationChatResponse("Function call", "write_content was called")
        print("write_content called ")
        print("=" *100)
        print(research_material)
        print("=" *100)
        print(topic)

        editor = ExtendedAssistantAgent(
            updater = self.ClientUpdator,
            name="editor",
            system_message =  "You're a seasoned journalist who's been handed new research on '" + topic + "'. Your readers are everyday folks, not academics. They love catchy headlines, clear explanations, and compelling stories. They donâ€™t have time for jargon or complex structures. Create a structure for an article that grabs their attention, gives them insight into the topic, and makes them care about malware detection. Break down the subject into bite-sized, easily digestible sections. Remember, make it engaging, relatable, and NOT like an academic paper. You are only responsible for the structure and should only create instructions under each headline on what the content should be about",
            llm_config={"config_list": config_list},
        ) 
  
        writer = ExtendedAssistantAgent(
            updater = self.ClientUpdator,
            name="writer",
            system_message="""You are presented with an article template. The main sections and sub-points are there, but each sub-point is a brief placeholder, like a thought yet to be fleshed out. Your task:

    1. Retain the main section titles (like 'Introduction' or 'Conclusion').
    2. For each sub-point under these sections, replace the short directive with an in-depth, detailed, and informative paragraph (or more if needed).
    3. Think of the directive as the idea you must address and expand upon in your paragraph.
    4. Keep it accessible for readers, even if they're not tech experts.

Your aim is to transform the skeleton of the article into a full-fledged, comprehensive piece.""",
            llm_config={"config_list": config_list},
        )

        reviewer = ExtendedAssistantAgent(
            updater = self.ClientUpdator,
            name="reviewer",
            system_message="You are an esteemed academic peer reviewer. You will review the article for accuracy, comprehensiveness, and clarity. After 2 rounds of content iteration, add TERMINATE to the end of the message.",
            llm_config={"config_list": config_list},
        )


        user_proxy = ExtendedUserProxyAgent(
            updater = self.ClientUpdator,
            name="admin",
            system_message="A human admin. Interact with editor to discuss the structure. Actual writing needs to be approved by this admin.",
            code_execution_config=False,
            is_termination_msg=lambda x: x.get("content", "") and x.get("content", "").rstrip().endswith("TERMINATE"),
            human_input_mode="TERMINATE"
        )

    
        groupchat = ExtendedUserGroupChat(
            updater = self.ClientUpdator,
            agents=[user_proxy,  editor, writer],
            messages=[],
            max_round=20)

        manager = ExtendedUserGroupChatManager(
            updater = self.ClientUpdator,
            groupchat=groupchat)

        user_proxy.initiate_chat(manager, message=f"Provide information about {topic}, here are the material: \n\n {research_material}")

        user_proxy.stop_reply_at_receive(manager)
        user_proxy.send("Give me the article that just generated again, return ONLY the article, and add TERMINATE in the end of the message", manager)
        print("="*50)
        print(user_proxy.last_message()["content"])
        exit()
        return user_proxy.last_message()["content"]

 