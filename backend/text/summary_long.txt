This information is from the paper Machine learning classification for advanced malware detection doi: None:
Research Questions:
- Is it possible to achieve the same level of classification accuracy with static features as with dynamic features?
- Which technique is more effective in cases of high obfuscation or when the machine learning model has few or no training samples?This information is from the paper Machine learning classification for advanced malware detection doi: None:
Novel Contributions:
- A comparison of static, dynamic, and hybrid analysis for malware detection.
- Application of Profile Hidden Markov Models (PHMMs) in detecting dynamically extracted API calls sequences.
- Clustering techniques applied to malware classification using K-means and Expectation Maximization algorithms.
- Comparison of clustering and Support Vector Machines (SVM) for classifying unknown malware.
- Two new malware scoring techniques based on the Vigen√®re cipher.
- Comparison of gist descriptors and deep learning for image-based malware classification.
- Comparison of function call graphs and machine learning for detecting obfuscated malware.
- Comparison of Support Vector Machines combined with different malware scoring techniques.
- Analysis of the effectiveness of generic malware models using ùëõ-gram features.This information is  from the paper Machine learning classification for advanced malware detection doi: None:
Dataset:
- Malware samples obtained from the Malicia, Malimg, and Microsoft Malware Classification Challenge datasets.
- Additional samples generated using the Next Generation Virus Creation Kit (NGVSK).This information is from the paper Machine learning classification for advanced malware detection doi: None:
References:
1. Rajeswaran, et al. (2018)
2. Xu, et al. (2013)
3. Shanmugam, et al. (2013)
4. Singh, et al. (2016)
5. Liu L. (2017)
6. Wong, et al. (2006)
7. Deshmukh, et al. (2018)
8. Nataraj, et al. (2011)
9. Kaggle (2015)
10. Malicia (2013)
11. NGVSK (2001)
12. Bagga, et al. (2018)
13. Yajamanam, et al. (2018)
14. Huang, et al. (2018)This information is from the paper Machine learning classification for advanced malware detection doi: None:
Machine learning techniques have been used in malware detection to detect advanced threats such as metamorphic malware (Stamp, 2017). These techniques rely on statistical properties derived from program features and can detect malware even in the presence of code obfuscation (Stamp, 2011). Two main approaches for building machine learning models are static analysis and dynamic analysis. Static analysis involves extracting features directly from the samples without executing them, while dynamic analysis involves extracting characteristics during sample execution (Stamp, 2017). Examples of information obtained from static analysis include opcode sequences, control flow graphs, and binary n-grams, while dynamic analysis can provide API calls, system calls, and registry changes (Stamp, 2011). Successful machine learning algorithms in malware detection include Hidden Markov Models, Support Vector Machines, k-nearest neighbors, random forests, and convolutional neural networks (Stamp, 2017). These algorithms have been applied in various experiments (Stamp, 2017).This information is from the paper Machine learning classification for advanced malware detection doi: None:
Hidden Markov Models (HMMs) have been widely used in malware detection. HMMs are trained on malware samples and used to classify putative infected files based on scores obtained from the model (Stamp, 2018). Another useful algorithm is Support Vector Machines (SVMs), which has shown to boost classification scores (Stamp, 2018). Clustering techniques have also been applied to detect undiscovered malware samples (Stamp, 2018). Various other algorithms have been used in experiments, and their descriptions can be found in the respective research works and references (Stamp, 2018).This information is from the paper Machine learning classification for advanced malware detection doi: None:
HMMs can solve three different problems in malware detection. Problem 1 involves determining the probability of an observation sequence given a model. Problem 2 aims to find the most likely hidden state sequence given the model and observation sequence. Problem 3 focuses on training a model that maximizes the probability of an observation sequence (Stamp, 2018).This information is from the paper Machine learning classification for advanced malware detection doi: None:
Overall, machine learning techniques, such as HMMs and SVMs, have been effective in detecting advanced malware by utilizing static and dynamic analysis (Stamp, 2017). These techniques provide more robust detection capabilities compared to signature-based detection methods. This information is from the paper Machine learning classification for advanced malware detection doi: None:
References:
- Stamp, M. (2011). Information Security: Principles and Practice. Wiley.
- Corona I. (2013). Intrusion Detection Systems [Electronic Resource]. Nova Science Publishers.
- Stamp, M. (2017). Applications of Machine Learning in Malware Detection. In Malware Detection (pp. 207-227). Springer.
- Stamp, M. (2018). Research in Malware Detection Using Hidden Markov Models. In Recent Advances in Information Technology (pp. 125-140). Springer.This information is from the paper Machine learning classification for advanced malware detection doi: None:
This paper discusses machine learning classification for advanced malware detection. The authors conducted experiments to determine the effectiveness of different machine learning algorithms and techniques for detecting malware. In Section 8.2, the authors found that using Support Vector Machines (SVMs) to combine individual scores outperformed using single techniques, except for the Sparse Subspaces Decomposition (SSD) algorithm, which performed slightly better in some cases. The authors concluded that the SVM combined score technique was more robust to code morphing and achieved improved classification. In Section 9, the authors explored the use of a generic malware model instead of specific models for each family. They found that using bigrams as features gave the best results, and random forest and k-NN techniques were the most robust. However, as the training dataset became more generic, the resulting model became weaker. The authors concluded that there is a tradeoff between generality and accuracy when using a generic malware model. The paper also discussed the effectiveness of different machine learning algorithms for detecting zero-day samples, the comparison of machine learning approaches with other detection methods, and the use of SVMs as a meta-classifier with different combination techniques. Finally, the authors discussed countermeasures to hamper static detection through SVMs, such as packing the code or adding dead code. They also mentioned the limitations of obfuscating dynamic detection through API calls sequences. This information is from the paper Machine learning classification for advanced malware detection doi: None:
References:
- Bagga, W., Hutchinson, J., & Woodbridge, J. (2018). Machine learning classification for advanced malware detection (No. LA-UR-18-22554). Los Alamos National Lab.This information is from the paper Machine learning classification for advanced malware detection doi: None:
Results confirm that the most prominent feature for malware detection using machine learning is the horizontal edge feature, which was further analyzed using recursive feature elimination (RFE) [1]. The experiment showed that by using 169 dimensions of the 256-dimensional horizontal edge feature, optimal accuracy was achieved [1]. The use of robust hashing approaches, such as error-correcting algorithm based on a 2-dimensional Haar wavelet transform and a five-level decomposition, and distributed coding, resulted in average accuracies of about 79% and slightly over 83%, respectively [1]. However, these approaches were weaker compared to the support vector machine (SVM) detection, which showed an average accuracy increase from around 84% to around 92% when using the 169-dimensional set of horizontal edge features [1]. A multiphase strategy combining wavelet-based and distributed coding based robust hashes improved the accuracy to above 87% [1].This information is from the paper Machine learning classification for advanced malware detection doi: None:
The conclusions from these experiments indicate that optimized SVM obtained somewhat superior detection accuracy compared to robust hashing approaches, but robust hashing performed better than SVM on most families [1]. However, some malware families with significant obfuscation were more accurately detected using robust hashing [1]. On the other hand, SVM provided more consistent results across the 25 families, which favored the consistency in accuracy obtained by applying machine learning algorithms [1].This information is from the paper Machine learning classification for advanced malware detection doi: None:
In the context of improved classification, experiments were conducted using hidden Markov models (HMMs) and support vector machines (SVMs) [1]. For HMMs, experiments included using random restarts and AdaBoost as a boosting technique [1]. HMM with random restarts outperformed the average HMM, while the boosted HMM had little effect on the results for certain families [1]. AdaBoost increased the scoring workload, but the advantages were marginal compared to random restarts [1]. When it comes to SVM, feature vectors were built by combining scores from HMM, Opcode Graph Similarity (OGS), and Simple Substitution Distance (SSD) algorithms, and SVM outperformed the individual scores [1].This information is from the paper Machine learning classification for advanced malware detection doi: None:
The use of SVMs to combine individual scores using machine learning outperformed the direct application of single techniques, with the exception of the SSD algorithm that performed slightly better in some cases [1]. The combined score technique using SVM was more robust to code morphing and degraded more slowly than the other approaches [1]. The detection accuracy achieved through combining scores using SVM was comparable to dynamic feature-based experiments [1].This information is from the paper Machine learning classification for advanced malware detection doi: None:
Overall, the experiments demonstrate the effectiveness of machine learning, particularly SVM, in detecting malware and the potential of combining multiple classification techniques for improved accuracy. [1]This information is from the paper Machine learning classification for advanced malware detection doi: None:
2.2 Score techniques
Throughout these experiments, no single technique was used to compare the accuracy of different classification approaches. Instead, the scores were based on Receiver Operator Characteristic (ROC) curve (Fawcett, 2006) and Precision-Recall (Davis, 2006), though other scoring techniques were introduced whenever they proved to be more informative in a given experiment. For example, a modified accuracy (defined as balanced accuracy) is introduced in our work (Bagga, et al., 2018) to face the large unbalance between the positive and negative samples. The basic techniques are described below. This information is from the paper Machine learning classification for advanced malware detection doi: None:
2.2.1 Receiver Operator Characteristic
To compute a ROC curve, we begin with a scatterplot containing ‚Äúpositive‚Äù and ‚Äúnegative‚Äù scores: in these experiments, the ‚Äúpositive‚Äù instances ideally represent the malware samples requiring detection, and the ‚Äúnegative‚Äù instances belong to the benign dataset. In practice however, some malware samples score negatively (‚Äúfalse negatives‚Äù) and some benign samples score positively (‚Äúfalse positives‚Äù). By adjusting the threshold between the two categories, that is, the decision boundary for which a value above it indicates a positive instance and a value below indicates a negative one, we can plot the False Positive Rate FPR (a number between 0 and 1 indicating the portion of samples falsely classified as positive) against the True Positive Rate TPR (again between 0 and 1). Finally we compute the area under this curve (the ‚ÄúAUC‚Äù) whose value gives a measure of success for the computed binary classification (Bradley, 1997). AUC is always in the range 0.5 to 1.0, and its two extreme cases are as follows:
‚Ä¢ AUC=1.0 indicates that it a threshold level exists for which no classification error occurs.
‚Ä¢ AUC=0.5 indicates that the classification is no better than flipping a coin: there is a 50% chance that any sample may be misclassified. This information is from the paper Machine learning classification for advanced malware detection doi: None:
2.2.2 Precision Recall
Another means of quantifying the success of binary classification is Precision and Recall (PR) analysis (Davis, 2006). While similar to ROC in terms of the information gathered, it performs better (for example) when the number of ‚Äúmatch cases‚Äù (i.e., True Positives) is small relative to the total number of samples. Recall refers to the fraction of elements classified as positive that belong to the positive match set, while precision is the fraction of positive elements classified as positive among the total number of positively classified samples, i.e. This information is from the paper Machine learning classification for advanced malware detection doi: None:
Recall = ùëáùëáùëáùëáùëáùëáùëáùëá+ùêπùêπùêπùêπ (1) This information is from the paper Machine learning classific            ation for advanced malware detection doi: None:
Precision = ùëáùëáùëáùëáùëáùëáùëáùëá+ùêπùêπùëáùëá (2) This information is from the paper Machine learning classi            fication for advanced malware detection doi: None:
where ùëáùëáùëáùëá is the number of true positives, ùêπùêπùëáùëá the number of false positives, and ùêπùêπùêπùêπ             is the number of false negatives. While recall corresponds to the true positive rate defined for ROC, precision is not the same as the false positive rate used in ROC. Another critical difference is that there is no consideration of true negatives (ùëáùëáùêπùêπ). This is benef    icial if our focus is on the positive set, and especially when this is relatively large in comparison to the negative set. As with ROC, we compute the area under the PR Curve (AUC-PR) as a measure of the success of the classification.This information is from the paper Machine learning classification for advanced malware detection doi: None:
2.2.3 Cross-validation
This is used to smooth out bias in experiments. For n-fold cross-validation, the malware samples are split into n folders; a machine learning model is trained over (n‚àí1) of these folders, while the remaining folder is used for testing. These steps are repeated n times, always changing the folder used to test. Finally, the average of all the n scores is computed and considered as the final score of the experiment. Following this procedure, cross-validation allows to smooth out biases in the dataset (Stamp, 2017). This information is from the paper Machine learning classification for advanced malware detection doi: None:
2.3 Tools
Section 2.1 mentioned that in different experiments, different types of feature were extracted from the dataset. For example, in the majority of the experiments (except (Yajamanam, et al., 2018), (Huang, et al., 2018) and (Bagga, et al., 2018), where the features where extracted from the binary files without disassembling them

This information is from the paper Improving Existing Static and Dynamic Malware Detection Techniques with Instruction-level Behavior doi: 10.13016/m21q-qhlu:
In the paper "Improving Existing Static and Dynamic Malware Detection Techniques with Instruction-level Behavior," the author discusses the importance of malware detection and the limitations of current hybrid schemes. The author proposes a two-phase system that combines static and dynamic analysis to improve malware detection accuracy and efficiency.This information is from the paper Improving Existing Static and Dynamic Malware Detection Techniques with Instruction-level Behavior doi: 10.13016/m21q-qhlu:
The author's system is designed to classify potentially malicious programs and generate alerts for hard-to-classify programs that may require human analysis. The system's ability to block 89% of malware in real-time reduces post-infection damage control and removal costs for enterprises.This information is from the paper Improving Existing Static and Dynamic Malware Detection Techniques with Instruction-level Behavior doi: 10.13016/m21q-qhlu:
The paper presents an analysis of bucket 2 programs, which are hard-to-classify programs, using static and dynamic analysis. The results show that dynamic analysis is more effective at distinguishing these programs, significantly increasing the detection rate of malware and reducing the false positive rate compared to static analysis alone.This information is from the paper Improving Existing Static and Dynamic Malware Detection Techniques with Instruction-level Behavior doi: 10.13016/m21q-qhlu:
The author concludes that current IDSs (Intrusion Detection Systems) use of both static and dynamic analysis is suboptimal and proposes a novel method that optimally combines these techniques. The author's system uses static disassembly and Convolutional Neural Networks (CNNs) to automatically generate machine learning features for malware detection. The use of CNNs reduces the time and effort required for feature generation and improves the accuracy of detection tools. The addition of the author's generated features to existing static analysis tools decreases the number of missed malware by about 40% and performs well on packed and obfuscated malware.This information is from the paper Improving Existing Static and Dynamic Malware Detection Techniques with Instruction-level Behavior doi: 10.13016/m21q-qhlu:
Overall, the author argues that machine learning, specifically the use of CNNs, has the potential to enhance static detection of malware and improve the efficiency and accuracy of malware detection tools.This information is from the paper Improving Existing Static and Dynamic Malware Detection Techniques with Instruction-level Behavior doi: 10.13016/m21q-qhlu:
[92] Matilda Rhode, Pete Burnap, and Kevin Jones. Early stage malware prediction using recurrent neural networks. arXiv preprint arXiv:1708.03513, 2017.
[95] Priyadarshani M Kate and Sunita V Dhavale. Two phase static analysis technique for android malware detection. In Proceedings of the Third International Symposium on Women in Computing and Informatics, pages 650‚Äì655. ACM, 2015.
[98] Sang Kil Cha, Iulian Moraru, Jiyong Jang, John Truelove, David Brumley, and David G Andersen. Splitscreen: Enabling efficient, distributed malware detection. Journal of Communications and Networks, 13(2):187‚Äì200, 2011.
[103] Zane Markel and Michael Bilzor. Building a machine learning classifier for malware detection. In Anti-malware Testing Research (WATeR), 2014 Second Workshop on, pages 1‚Äì4. IEEE, 2014.
[105] Ziyun Zhu and Tudor Dumitras. Featuresmith: Automatically engineering features for malware detection by mining the security literature. In Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security, pages 767‚Äì778. ACM, 2016.
[109] Bojan Kolosnjaji, Apostolis Zarras, George Webster, and Claudia Eckert. Deep learning for classification of malware system call sequences. In Australasian Joint Conference on Artificial Intelligence, pages 137‚Äì149. Springer, 2016.
[110] Omid E David and Nathan S Netanyahu. Deepsign: Deep learning for automatic malware signature generation and classification. In Neural Networks (IJCNN), 2015 International Joint Conference on, pages 1‚Äì8. IEEE, 2015.This information is from the paper Improving Existing Static and Dynamic Malware Detection Techniques with Instruction-level Behavior doi: 10.13016/m21q-qhlu:
The paper "Improving Existing Static and Dynamic Malware Detection Techniques with Instruction-level Behavior" discusses the use of machine learning for malware detection. The author incorporates a set of dynamic program-level (DPL) features that provide additional instruction-level insight to differentiate malware from goodware.This information is from the paper Improving Existing Static and Dynamic Malware Detection Techniques with Instruction-level Behavior doi: 10.13016/m21q-qhlu:
One of the features used is the detection of correct usage of return instructions, where all returns go to the instruction after the corresponding call instruction (72). The author found that this behavior occurred significantly more in malware than in goodware.This information is from the paper Improving Existing Static and Dynamic Malware Detection Techniques with Instruction-level Behavior doi: 10.13016/m21q-qhlu:
Another set of features focuses on function analysis, where the number of external and internal functions found in a program is measured, as well as the number of times these functions are called dynamically. The author hypothesizes that malware relies less on external dlls and dependencies and may call more internal functions than goodware (73).This information is from the paper Improving Existing Static and Dynamic Malware Detection Techniques with Instruction-level Behavior doi: 10.13016/m21q-qhlu:
Control flow analysis is also used to quantify the control flow of a program. The detection of the number of edges between basic blocks in the program's execution, the number of outgoing edges from basic blocks that end in an indirect branch, and the number of times indirect branches execute are collected as features. These metrics can be useful in detecting code flattening, which is a technique used by malware to prevent static tools from building full control flow graphs (73).This information is from the paper Improving Existing Static and Dynamic Malware Detection Techniques with Instruction-level Behavior doi: 10.13016/m21q-qhlu:
Instruction execution is monitored and quantified, measuring statistics such as the average and maximum number of times a basic block executes, the number of unique opcodes that execute, and the frequency of opcode execution. These features provide insight into the general execution trends of goodware and malware and help improve the accuracy of machine learning models (74).This information is from the paper Improving Existing Static and Dynamic Malware Detection Techniques with Instruction-level Behavior doi: 10.13016/m21q-qhlu:
The paper also describes the implementation of the malware detection tool using Cuckoo Sandbox for dynamic program analysis and DynamoRio for DPL analysis. The author utilized a neural networks-based approach, specifically a multilayer perceptron (MLP) model, to train the malware detection tool. The MLP configuration included one hidden layer, a rectified linear unit activation function, and a softmax activation function for outputting the probability of maliciousness (77).This information is from the paper Improving Existing Static and Dynamic Malware Detection Techniques with Instruction-level Behavior doi: 10.13016/m21q-qhlu:
The malware detection tool was implemented in conjunction with ClamAV to simulate a real-world deployment. If either ClamAV or the MLP tool flagged a program as malicious, it was considered malicious. If neither tool flagged the program, it was considered benign (78).This information is from the paper Improving Existing Static and Dynamic Malware Detection Techniques with Instruction-level Behavior doi: 10.13016/m21q-qhlu:
The dataset used for training and testing the malware detection tool consisted of over 400,000 programs, including over 200,000 malware samples obtained from Virus Total and over 195,000 goodware samples. The malware samples were selected based on having at least 15 detections on Virus Total, ensuring their maliciousness. The goodware samples were obtained from programs with zero detections on Virus Total (79).This information is from the paper Improving Existing Static and Dynamic Malware Detection Techniques with Instruction-level Behavior doi: 10.13016/m21q-qhlu:
Overall, the incorporation of DPL features in machine learning models proved to be effective in improving the accuracy of malware detection and providing additional insight into malware behavior.This information is from the paper Improving Existing Static and Dynamic Malware Detection Techniques with Instruction-level Behavior doi: 10.13016/m21q-qhlu:
Other works such as [45, 49, 50, 71, 77, 104] propose machine learning-based malware detection tool based on static features such as PE imports, strings, and other metadata. As previously mentioned, these types of features are more prone to overfitting than perhaps a CNN model would be and thus when run in a time split experiment, their performance drops off rapidly. This is also supported by our findings in our Results.Work such as [105, 111] use similar natural language processing methods for malware detection goals, but differ from my work because [111] focuses on capturing malicious payloads and [105] focuses solely on android malware.This information is from the paper Improving Existing Static and Dynamic Malware Detection Techniques with Instruction-level Behavior doi: 10.13016/m21q-qhlu:
Conclusion
The need for further advancements in the static detection of malware with machine learning is necessary to handle the ever-growing cyber threats. The use of CNNs and raw opcode sequences is innovative because it reduces the need for malware and malicious code expertise and manual analysis. Instead, it relies on the CNN‚Äôs ability to generate quality features that are helpful to existing static detection tools. My Results show that with the added CNN model‚Äôs automatically generated features, it can reduce the false negative rate of a tool trained on existing features by over 40% and by over 50% on a simulated zero-day test. Additionally, our CNN model is capable of robustly handling minor changes in the input sequences of opcodes, resulting in a fuzzy matching of opcode sequences from malware or goodware. This is an advantage over previous work that relied on exact or near-exact matches and proves to be more robust in practice. Although the features generated from the CNN model are not the complete solution to malware detection, it shows promise in finding opcode sequences specific to goodware or malware while maintaining the flexibility needed to handle modern malware.This information is from the paper Improving Existing Static and Dynamic Malware Detection Techniques with Instruction-level Behavior doi: 10.13016/m21q-qhlu:
Bibliography
[45] Igor Santos, Felix etc.This information is from the paper Improving Existing Static and Dynamic Malware Detection Techniques with Instruction-level Behavior doi: 10.13016/m21q-qhlu:
In recent years, there has been a growing interest in using machine learning techniques for malware detection. Several studies have explored the use of machine learning algorithms to improve the accuracy and efficiency of malware detection systems. For example, Gil Tahan et al. developed a method called Mal-ID that uses common segment analysis and meta-features to automatically detect malware (Tahan et al., 2012) [47]. J Zico Kolter and Marcus A Maloof proposed a machine learning approach to detect and classify malicious executables in the wild (Kolter and Maloof, 2006) [48]. Matthew G Schultz et al. used data mining methods to detect new malicious executables (Schultz et al., 2001) [49]. Igor Santos et al. introduced opcode sequences as a representation of executables for data-mining-based unknown malware detection (Santos et al., 2013) [45]. Eitan Menahem et al. proposed a multi-inducer ensemble method to improve malware detection (Menahem et al., 2009) [51]. Robert Moskovitch et al. developed techniques for unknown malcode detection based on opcode representation and text categorization (Moskovitch et al., 2008; Moskovitch et al., 2009) [59][60].

Other researchers have investigated the use of dynamic analysis and behavior-based approaches for malware detection. Konrad Rieck et al. proposed an automatic analysis technique using machine learning to analyze the behavior of malware (Rieck et al., 2011) [65]. Swapna Vemparala explored dynamic analysis for malware detection (Vemparala, 2015) [66]. Sean Kilgallon et al. proposed using machine learning to improve the effectiveness and efficiency of dynamic malware analysis (Kilgallon et al., 2017) [88]. Toshiki Shibahara et al. developed an efficient dynamic malware analysis approach based on network behavior using deep learning (Shibahara et al., 2016) [89].

In addition to these approaches, researchers have also explored the use of ensemble learning, feature selection, and other techniques to improve malware detection. For example, Yoseba K Penya et al. proposed a semi-supervised learning method for unknown malware detection (Penya et al., 2011) [50]. Yanfang Ye et al. developed a string-based malware detection system using SVM ensemble with bagging (Ye et al., 2009) [54]. Olivier Henchiri et al. proposed a feature selection and evaluation scheme for computer virus detection (Henchiri et al., 2006) [61]. Boyun Zhang et al. used ensemble learning to improve malware detection (Zhang et al., 2007) [62]. Another approach proposed by Yuval Elovici et al. is the application of machine learning techniques for detection of malicious code in network traffic (Elovici et al., 2007) [63].This information is from the paper Improving Existing Static and Dynamic Malware Detection Techniques with Instruction-level Behavior doi: 10.13016/m21q-qhlu:
Overall, these studies highlight the potential of machine learning techniques for improving malware detection. From opcode sequences to network behavior analysis, various approaches have been explored to enhance the accuracy and efficiency of malware detection systems. However, further research is still needed to develop more robust and effective machine learning-based malware detection techniques.This information is from the paper Improving Existing Static and Dynamic Malware Detection Techniques with Instruction-level Behavior doi: 10.13016/m21q-qhlu:
References:
45. Santos, Igor, Felix Brezo, Xabier Ugarte-Pedrero, and Pablo G Bringas. "Opcode sequences as representation of executables for data-mining-based unknown malware detection." Information Sciences 231 (2013): 64-82.
47. Tahan, Gil, Lior Rokach, and Yuval Shahar. "Mal-id: Automatic malware detection using common segment analysis and meta-features." Journal of Machine Learning Research 13, no. Apr (2012): 949-979.
48. Kolter, J. Zico, and Marcus A. Maloof. "Learning to detect and classify malicious executables in the wild." Journal of Machine Learning Research 7, no. Dec (2006): 2721-2744.
49. Schultz, Matthew G., Eleazar Eskin, F. Zadok, and Salvatore J. Stolfo. "Data mining methods for detection of new malicious executables." In Security and Privacy, 2001. S&P 2001. Proceedings. 2001 IEEE Symposium on, pp. 38-49. IEEE, 2001.
50. Penya, Yoseba K., Jaime Devesa, and Pablo Garcia Bringas. "Semi-supervised learning for unknown malware detection." In DCAI, pp. 415-422. Springer, 201

This information is from the paper Survey of Machine Learning Techniques for Malware Analysis doi: 10.1016/j.cose.2018.11.001:
This survey paper provides an overview of machine learning techniques used for malware analysis in Windows environments, specifically for the analysis of Portable Executables (PEs). The paper reviews 64 recent papers and categorizes them based on their objectives, the features used, and the machine learning techniques employed. The three main objectives identified are malware detection, malware similarity analysis, and malware category detection. The paper also highlights issues and challenges in malware analysis, including overcoming anti-analysis techniques, addressing the inaccuracy of malware behavior modeling, and the obsolescence and unavailability of datasets. The authors propose guidelines for creating suitable benchmarks for malware analysis and identify topical trends such as malware attribution and triage. They also introduce the concept of malware analysis economics, which considers the trade-offs between analysis accuracy, time, and cost. The paper concludes by summarizing its contributions, including the definition of a taxonomy, an analysis of existing literature, identification of issues and challenges, and the proposal of high-level directions for future research. Several related works on machine learning techniques for malware analysis are also mentioned, highlighting their differences and the unique contributions of this survey.This information is from the paper Survey of Machine Learning Techniques for Malware Analysis doi: 10.1016/j.cose.2018.11.001:
In a paper titled "Survey of Machine Learning Techniques for Malware Analysis," the authors conducted a survey on existing literature on malware analysis through machine learning techniques. The survey provided an overview of how machine learning algorithms can be employed in malware analysis, emphasizing which specific feature classes allow achieving the objectives of interest. The authors also organized the existing literature on PE malware analysis through machine learning according to a proposed taxonomy and provided a detailed comparative analysis of surveyed works. They highlighted current issues in machine learning for malware analysis, including anti-analysis techniques used by malware and the consideration of operation sets and datasets. The authors introduced the concept of malware analysis economics, which focuses on the investigation and exploitation of trade-offs between performance metrics of malware analysis and economical costs. They suggested that novel combinations of objectives, features, and algorithms could be investigated to achieve better accuracy compared to the state of the art. The discussion on malware analysis issues can provide further ideas worth exploring, and defining appropriate benchmarks for malware analysis is a priority in the research area. The authors acknowledge the partial support of their work by a grant from the Italian Presidency of Ministry Council and the Laboratorio Nazionale of Cyber Security of the CINI (Consorzio Interuniversitario Nazionale Informatica). This information is from the paper Survey of Machine Learning Techniques for Malware Analysis doi: 10.1016/j.cose.2018.11.001:
References:
[1] Y. Ye, T. Li, D. Adjeroh, S. S. Iyengar, "A survey on malware detection using data mining techniques," ACM Computing Surveys (CSUR) 50 (3) (2017) 41.
[2] AV-TEST, "Security Report 2016/17," https://www.av-test.org/fileadmin/pdf/security_report/AV-TEST_Security_Report_2016-2017.pdf (2017).
[3] A. Shabtai, R. Moskovitch, Y. Elovici, C. Glezer, "Detection of malicious code by applying machine learning classifiers on static features: A state-of-the-art survey," Inf. Secur. Tech. Rep. 14 (1) (2009) 16‚Äì29.
[4] M. K. Sahu, M. Ahirwar, A. Hemlata, "A review of malware detection based on pattern matching technique," Int. J. of Computer Science and Information Technologies (IJCSIT) 5 (1) (2014) 944‚Äì947.
[5] A. Souri, R. Hosseini, "A state-of-the-art survey of malware detection approaches using data mining techniques," Human-centric Computing and Information Sciences 8 (1) (2018) 3.
[6] C. LeDoux, A. Lakhotia, "Malware and machine learning," in: Intelligent Methods for Cyber Warfare, Springer, 2015, pp. 1‚Äì42.
[7] Z. Bazrafshan, H. Hashemi, S. M. H. Fard, A. Hamzeh, "A survey on heuristic malware detection techniques," in: Information and Knowledge Technology (IKT), 2013 5th Conference on, IEEE, 2013, pp. 113‚Äì120.
[8] I. Basu, "Malware detection based on source data using data mining: A survey," American Journal Of Advanced Computing 3 (1).
[9] J. J. Barriga, S. G. Yoo, "Malware detection and evasion with machine learning techniques: A survey," International Journal of Applied Engineering Research 12 (318).
[10] J. Gardiner, S. Nagaraja, "On the security of machine learning in malware c&amp;c detection: A survey," ACM Comput. Surv. 49 (3) (2016) 59:1‚Äì59:39.
[11] M. G. Schultz, E. Eskin, F. Zadok, S. J. Stolfo, "Data mining methods for detection of new malicious executables," in: Security and Privacy, 2001. SP 2001. Proceedings. 2001 IEEE Symposium on, 2001, pp. 38‚Äì49.
[12] J. Z. Kolter, M. A. Maloof, "Learning to detect and classify malicious executables in the wild," J. Mach. Learn. Res. 7 (2006) 2721‚Äì2744.
[13] F. Ahmed, H. Hameed, M. Z. Shafiq, M. Farooq, "Using spatio-temporal information in api calls with machine learning algorithms for malware detection," in: Proceedings of the 2nd ACM workshop on Security and artificial intelligence, ACM, This information is from the paper Survey of Machine Learning Techniques for Malware Analysis doi: 10.1016/j.cose.2018.11.001:
3.1.2. Malware Similarity Analysis
- Variants Detection: Variants detection is crucial for recognizing samples that are variants of known malware and reducing the workload for human analysts. Several papers have focused on the detection of variants [37, 30, 38, 39, 40, 41].
- Families Detection: Families detection involves selecting the families that a particular sample likely belongs to. This information can provide valuable insights for further analysis [42, 43, 44, 45, 46, 47, 48, 49, 50, 31, 51, 52, 53, 54, 36].
- Similarities Detection: Similarities detection aims to identify the similarities and differences in the binaries being analyzed. This helps to focus on what is new and discard what doesn't require further investigation [55, 56, 57, 58, 59].
- Differences Detection: Identifying what is different from previously observed samples can guide towards discovering novel aspects that should be analyzed more in depth [56, 60, 57, 58, 61, 62].This information is from the paper Survey of Machine Learning Techniques for Malware Analysis doi: 10.1016/j.cose.2018.11.001:
3.1.3. Malware Category Detection
- Malware can be categorized based on their behaviors and objectives. Categories such as spyware, ransomware, and remote access toolkits provide a coarse-grained but significant description of malicious samples [63, 64, 65, 66, 32, 67].This information is from the paper Survey of Machine Learning Techniques for Malware Analysis doi: 10.1016/j.cose.2018.11.001:
3.2. Malware Analysis Features
- Features can be extracted through static or dynamic analysis or a combination of both. Dynamic analysis techniques include the use of debuggers, simulators, emulators, and sandboxes [1].
- Dynamic analysis techniques are more commonly used in reviewed works [42, 55, 56, 15, 44, 16, 60, 57, 66, 46, 50, 58, 24, 26, 28, 30, 51, 52, 53, 35, 40], but some works rely on static analysis alone or a combination of both [11, 12, 63, 64, 72, 17, 65, 19, 47, 49, 61, 22, 23, 25, 31, 73, 27, 29, 37, 38, 54, 67, 74, 39].
- Specific features considered in malware analysis include byte sequences, opcodes, APIs and system calls, network activity, file system interactions, CPU registers, PE file characteristics, and strings [11, 74, 36, 63, 64, 45, 16, 18, 47, 49, 61, 20, 31, 37, 38, 54, 67, 74].This information is from the paper Survey of Machine Learning Techniques for Malware Analysis doi: 10.1016/j.cose.2018.11.001:
3.3. Malware Analysis Algorithms
- Supervised learning algorithms used in the reviewed papers include rule-based classifiers, Bayes classifiers, Naive Bayes, Bayesian Networks, and Support Vector Machines (SVM) [11, 29, 30, 67, 40, 78, 60, 13, 61, 20, 26, 51, 35, 21, 16, 65, 66, 48, 49, 24].This information is from the paper Survey of Machine Learning Techniques for Malware Analysis doi: 10.1016/j.cose.2018.11.001:
References:
- [28, 29, 30, 31, 32, 33, 34, 35, 36]
- [37, 30, 38, 39, 40, 41]
- [42, 43, 44, 45, 46, 47, 48, 49, 50, 31, 51, 52, 53, 54, 36]
- [55, 56, 57, 58, 59]
- [56, 60, 57, 58, 61, 62]
- [63, 64, 65, 66, 32, 67]
- [1]
- [42, 55, 56, 15, 44, 16, 60, 57, 66, 46, 50, 58, 24, 26, 28, 30, 51, 52, 53, 35, 40]
- [11, 12, 63, 64, 72, 17, 65, 19, 47, 49, 61, 22, 23, 25, 31, This information is from the paper Survey of Machine Learning Techniques for Malware Analysis doi: 10.1016/j.cose.2018.11.001:
Anti-analysis Techniques:
- Malware developers use anti-analysis techniques to hinder reverse engineering (¬ß 5.1)
- Static analysis is prevented by obfuscation, packing, and encryption (¬ß 5.1)
- Dynamic analysis can reveal hidden information (¬ß 5.1)
- Environmental awareness is used to detect analysis settings (¬ß 5.1)
- Timing-based evasion and requiring user interaction are other techniques (¬ß 5.1)
- Overcoming anti-analysis techniques is important for improving malware analysis (¬ß 5.1)This information is from the paper Survey of Machine Learning Techniques for Malware Analysis doi: 10.1016/j.cose.2018.11.001:
Operation Set:
- Opcodes, instructions, APIs, and system calls are commonly used for malware analysis (¬ß 5.2)
- Ignoring some operations can reduce accuracy of malware behavior models (¬ß 5.2)
- Machine learning techniques and improved program analysis can address this issue (¬ß 5.2)This information is from the paper Survey of Machine Learning Techniques for Malware Analysis doi: 10.1016/j.cose.2018.11.001:
Datasets:
- 72% of surveyed works use datasets with both malicious and benign samples (¬ß 5.3)
- 28% rely on datasets with malware only, while 2 works use benign datasets only (¬ß 5.3)
- Public repositories, security vendors, and sandboxed analysis services are common sources (¬ß 5.3)
- Most benign datasets consist of legitimate applications, while malware is obtained from public repositories, security vendors, and sandboxed analysis services (¬ß 5.3)
- Lack of shared datasets hinders comparison of works (¬ß 5.3)This information is from the paper Survey of Machine Learning Techniques for Malware Analysis doi: 10.1016/j.cose.2018.11.001:
Topical Trends:
- Malware development detection: leveraging online services like VirusTotal and Malwr for additional analysis information (¬ß 6.1)
- Malware attribution: identifying specific malicious actors through programming language, IP addresses, URLs, language of comments and resources, time slots of communication, and digital certificates (¬ß 6.2)This information is from the paper Survey of Machine Learning Techniques for Malware Analysis doi: 10.1016/j.cose.2018.11.001:
[47] X. Hu, K. G. Shin, S. Bhatkar, K. Griffin, Mutantx-s: Scalable malware
clustering based on static features, in: USENIX Annual Technical Con-
ference, 2013, pp. 187‚Äì198.This information is from the paper Survey of Machine Learning Techniques for Malware Analysis doi: 10.1016/j.cose.2018.11.001:
[48] R. Islam, R. Tian, L. M. Batten, S. Versteeg, Classification of malware
based on integrated static and dynamic features, Journal of Network and
Computer Applications 36 (2) (2013) 646‚Äì656.This information is from the paper Survey of Machine Learning Techniques for Malware Analysis doi: 10.1016/j.cose.2018.11.001:
[49] D. Kong, G. Yan, Discriminant malware distance learning on structural
information for automated malware classification, in: ACM SIGKDD ‚Äô13,
KDD ‚Äô13, ACM, New York, NY, USA, 2013, pp. 1357‚Äì1365.This information is from the paper Survey of Machine Learning Techniques for Malware Analysis doi: 10.1016/j.cose.2018.11.001:
[50] S. Nari, A. A. Ghorbani, Automated malware classification based on net-
work behavior, in: Computing, Networking and Communications (ICNC),
2013 International Conference on, IEEE, 2013, pp. 642‚Äì647.This information is from the paper Survey of Machine Learning Techniques for Malware Analysis doi: 10.1016/j.cose.2018.11.001:
[51] N. Kawaguchi, K. Omote, Malware function classification using apis in
initial behavior, in: Information Security (AsiaJCIS), 2015 10th Asia Joint
Conference on, IEEE, 2015, pp. 138‚Äì144.This information is from the paper Survey of Machine Learning Techniques for Malware Analysis doi: 10.1016/j.cose.2018.11.001:
[52] C.-T. Lin, N.-J. Wang, H. Xiao, C. Eckert, Feature selection and ex-
traction for malware classification, Journal of Information Science and
Engineering 31 (3) (2015) 965‚Äì992.This information is from the paper Survey of Machine Learning Techniques for Malware Analysis doi: 10.1016/j.cose.2018.11.001:
[53] A. Mohaisen, O. Alrawi, M. Mohaisen, Amal: High-fidelity, behavior-
based automated malware analysis and classification, computers & secu-
rity 52 (2015) 251‚Äì266.This information is from the paper Survey of Machine Learning Techniques for Malware Analysis doi: 10.1016/j.cose.2018.11.001:
[54] S. Pai, F. Di Troia, C. A. Visaggio, T. H. Austin, M. Stamp, Clustering
for malware classification, J Comput Virol Hack Tech.This information is from the paper Survey of Machine Learning Techniques for Malware Analysis doi: 10.1016/j.cose.2018.11.001:
[55] M. Bailey, J. Oberheide, J. Andersen, Z. M. Mao, F. Jahanian, J. Nazario,
Automated classification and analysis of internet malware, in: Recent
advances in intrusion detection, Springer, 2007, pp. 178‚Äì197.This information is from the paper Survey of Machine Learning Techniques for Malware Analysis doi: 10.1016/j.cose.2018.11.001:
[56] U. Bayer, P. M. Comparetti, C. Hlauschek, C. Kruegel, E. Kirda, Scalable,
behavior-based malware clustering, in: NDSS, Vol. 9, 2009, pp. 8‚Äì11.This information is from the paper Survey of Machine Learning Techniques for Malware Analysis doi: 10.1016/j.cose.2018.11.001:
[57] K. Rieck, P. Trinius, C. Willems, T. Holz, Automatic analysis of malware
behavior using machine learning, Journal of Computer Security 19 (4)
(2011) 639‚Äì668.This information is from the paper Survey of Machine Learning Techniques for Malware Analysis doi: 10.1016/j.cose.2018.11.001:
[58] S. Palahan, D. Babic¬¥, S. Chaudhuri, D. Kifer, Extraction of statistically
significant malware behaviors, in: Computer Security Applications Con-
ference, ACM, 2013, pp. 69‚Äì78.This information is from the paper Survey of Machine Learning Techniques for Malware Analysis doi: 10.1016/j.cose.2018.11.001:
[59] M. Egele, M. Woo, P. Chapman, D. Brumley, Blanket execution: Dynamic
similarity testing for program binaries and components, in: USENIX Se-
curity ‚Äô14, USENIX Association, San Diego, CA, 2014, pp. 303‚Äì317.This information is from the paper Survey of Machine Learning Techniques for Malware Analysis doi: 10.1016/j.cose.2018.11.001:
[60] M. Lindorfer, C. Kolbitsch, P. M. Comparetti, Detecting environment-
sensitive malware, in: Recent Advances in Intrusion Detection, Springer,
2011, pp. 338‚Äì357.This information is from the paper Survey of Machine Learning Techniques for Malware Analysis doi: 10.1016/j.cose.2018.11.001:
[61] I. Santos, F. Brezo, X. Ugarte-Pedrero, P. G. Bringas, Opcode sequences
as representation of executables for data-mining-based unknown malware
detection, Information Sciences 231 (2013) 64‚Äì82.This information is from the paper Survey of Machine Learning Techniques for Malware Analysis doi: 10.1016/j.cose.2018.11.001:
[62] M. Polino, A. Scorti, F. Maggi, S. Zanero, Jackdaw: Towards Automatic
Reverse Engineering of Large Datasets of Binaries, in: Detection of In-
trusions and Malware, and Vulnerability Assessment, Lecture Notes in
Computer Science, Springer International Publishing, 2015, pp. 121‚Äì143.This information is from the paper Survey of Machine Learning Techniques for Malware Analysis doi: 10.1016/j.cose.2018.11.001:
[63] W. Wong, M. Stamp, Hunting for metamorphic engines,

