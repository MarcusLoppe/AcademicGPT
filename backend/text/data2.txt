This information is from: Application of Adversarial Attacks on Malware Detection Models (2023) by Nagireddy, Vaishnavi:
Table of Contents   1 1 2 44 2.1 55 2.2 77 2.3  Adversarial Attacks on Machine Learning Models Error! Bookmark not defined.8 3 99 3.1 99 3.1.1 1212 3.1.2 1313 3.1.3 144 3.2 155 3.3 Random Forest  16 3.4 K - Nearest Neighbors 18 3.5 Classification of Malware using Deep Learning and Machine Learning 19   3.5.1 Malware Classification using Neural Networks 20   3.5.2 Malware Classification using SVM 22   3.5.3 Malware Classification using Random Forest 22   3.5.4 Malware Classification using K-Nearest Neighbors 23   Vaishnavi Nagireddy APPLICATION OF ADVERSARIAL ATTACKS ON MALWARE DETECTION MODELS  7  4 2424 5 255 5.1 2626 5.1.1 266 5.1.2 Error! Bookmark not defined.27 5.1.3 2727 5.1.4 2929 5.2 3131 5.2.1 3232 5.2.2 32 35 5.2.3 32 39 5.2.4 32 42 5.2.5 32 48 5.2.6 32 52 6 5353 6.1 5353 6.2 5454 6.2.1 5454 6.2.2 54 59 7 6161 8 6767 Vaishnavi Nagireddy APPLICATION OF ADVERSARIAL ATTACKS ON MALWARE DETECTION MODELS  8  8.1 6868

This information is from: Application of Adversarial Attacks on Malware Detection Models (2023) by Nagireddy, Vaishnavi:
systems and data. Numerous researches on different methods like filtering out adversarial samples and techniques to strengthen ML and DL models against these attacks are being conducted to develop new techniques to detect and mitigate the risk of adversarial attacks. As the field of machine learning and deep learning continues to evolve, it is likely that new approaches will be developed to Vaishnavi Nagireddy APPLICATION OF ADVERSARIAL ATTACKS ON MALWARE DETECTION MODELS  3  address these critical security issues. In this project, we will explore problems that cause threats to systems and techniques to overcome these problems in the field of cybersecurity. We will focus on different machine learning models and neural network methods for malware detection with and without adversarial samples. By this means, we address the questions: How accurate the machine learning models are in identifying malicious data? How accurate the machine learning models are in identifying the families of fake malware data? How adversarial data can affect the performance of the machine learning models? How are bert embeddings useful for malware detection? Which machine learning model can be helpful for malware detection when the data is in the form of bert embeddings?  In this work, we will explore different machine learning models and neural networks for malware classification with no adversarial samples and compare the performance of these models when increasing percentages of adversarial samples are given to these models.     Vaishnavi Nagireddy APPLICATION OF ADVERSARIAL ATTACKS ON MALWARE DETECTION MODELS  4     Fig. 1

This information is from: Application of Adversarial Attacks on Malware Detection Models (2023) by Nagireddy, Vaishnavi:
Abstract Malware detection is vital as it ensures that a computer is safe from any kind of malicious software that puts users at risk. Too many variants of these malicious software are being introduced everyday at increased speed. Thus, to guarantee security of computer systems, huge advancements in the field of malware detection are made and one such approach is to use machine learning for malware detection. Even though machine learning is very powerful, it is prone to adversarial attacks. In this project, we will try to apply adversarial attacks on malware detection models. To perform these attacks, fake samples that are generated using Generative Adversarial Networks (GAN) algorithm are used and these fake malware data along with the actual data is given to a machine learning model for malware detection. Here, we will also be experimenting with the percentage of fake malware samples to be considered and observe the behavior of the model according to the given input. The novelty of this project is given by the use of adversarial samples that are generated by the implementation of word embeddings produced by our generative algorithms. Index Terms â€“ Malware Detection, Adversarial Attacks, Machine Learning, Fake Malware Generation.      Vaishnavi Nagireddy APPLICATION OF ADVERSARIAL ATTACKS ON MALWARE DETECTION MODELS  6

This information is from: Application of Adversarial Attacks on Malware Detection Models (2023) by Nagireddy, Vaishnavi:
give as inputs for ML models.    Vaishnavi Nagireddy APPLICATION OF ADVERSARIAL ATTACKS ON MALWARE DETECTION MODELS  27  5.1.2

This information is from: Application of Adversarial Attacks on Malware Detection Models (2023) by Nagireddy, Vaishnavi:
Literature Review on different machine learning approaches involving supervised and unsupervised algorithms.  Vaishnavi Nagireddy APPLICATION OF ADVERSARIAL ATTACKS ON MALWARE DETECTION MODELS  2  Advanced Machine Learning engine (AML) was developed by Symantec to classify a file as benign or malware by analyzing the nature of file [5] but identifying a zero day malware has been a challenging task because as per the survey conducted by McAfee, around 60 million novel malicious software samples were generated only in the span of three months[6]. Application of machine learning for detecting zero day malware was illustrated by TrendMicro [7]. Recent investigations witnessed the fact that both ML and Deep Learning (DL) techniques are highly effective in detecting latest and unprecedented malware. This is due to their ability to analyze vast amounts of data and identify patterns that might be difficult for humans to detect. However, despite their success, these techniques are not infallible. One of the biggest challenges that both ML and DL models are facing is the threat of adversarial attacks. These attacks involve malicious actors who deliberately modify legitimate inputs to trick the models into making incorrect predictions. Adversarial examples can be created by slightly and carefully perturbing inputs that cause the model to misclassify them.  Adversarial attacks were studied primarily in the field of computer vision, specifically in the context of image classification. Nevertheless, these attacks have since been found to be applicable to other domains as well, including Natural Language Processing (NLP), audio recognition and even malware detection. These adversarial attacks can be highly effective and can have serious consequences, particularly in the context of cybersecurity as they can be used to bypass security measures and gain unauthorized access to sensitive systems and data. Numerous researches on different methods like filtering out adversarial samples

This information is from: Application of Adversarial Attacks on Malware Detection Models (2023) by Nagireddy, Vaishnavi:


This information is from: Application of Adversarial Attacks on Malware Detection Models (2023) by Nagireddy, Vaishnavi:
Results: The number of neighbors to be considered while making a prediction is tuned to the value 10 in this model. With this parameter the model performed really well and thus the accuracy for this model is 98%. The precision, recall and F1 score for this model are 0.98, 0.99 and 0.98 respectively. The training and testing split considered for this model is 70-30 split.  5.2.1.5 Observations and Accuracy Plot: The accuracy obtained by the multi layer perceptron model and rest of the machine learning models were pretty high as we have considered only real malware samples and benign samples. Vaishnavi Nagireddy APPLICATION OF ADVERSARIAL ATTACKS ON MALWARE DETECTION MODELS  35  We have considered an equal number of malware and benign samples to avoid the problem of imbalanced data, which can be essential to obtain better 